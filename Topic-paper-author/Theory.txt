FOCS	Parallel Linear Programming in Fixed Dimension Almost Surely in Constant Time	Noga Alon,Nimrod Megiddo	1990	It is shown that, for any fixed dimension d, the linear programming problem with n inequality constraints can be solvent on a probabilistic CRCW PRAM (concurrent-read-concurrent-write parallel random-access machine) with O(n) processors almost surely in constant time. The algorithm always finds the correct solution. With nd/log/sup 2/d processors, the probability that the algorithm will not finish within O(d/sup 2/log/sup 2/d) time tends to zero exponentially with n.
FOCS	Coin-Flipping Games Immune against Linear-Sized Coalitions (Extended Abstract)	Noga Alon,Moni Naor	1990	Coin-Flipping Games Immune against Linear-Sized Coalitions (Extended Abstract)
FOCS	A Time-Space Tradeoff for Boolean Matrix Multiplication	Karl R. Abrahamson	1990	A time-space tradeoff is established in the branching program model for the problem of computing the product of two n*n matrices over a certain semiring. It is assumed that each element of each n*n input matrix is chosen independently to be 1 with probability n/sup -1/2/ and to be 0 with probability 1-n/sup -1/2/. Letting S and T denote expected space and time of a deterministic algorithm, the tradeoff is ST= Omega (n/sup 3.5/) for T0. The lower bounds are matched to within a logarithmic factor by upper bounds in the branching program model. Thus, the tradeoff possesses a sharp break at T= Theta (n/sup 2.5/). These expected case lower bounds are also the best known lower bounds for the worst case.
FOCS	"A Markovian Extension of Valiant's Learning Model (Extended Abstract)"	David Aldous,Umesh V. Vazirani	1990	"A Markovian Extension of Valiant's Learning Model (Extended Abstract)"
FOCS	"An Approach for Proving Lower Bounds: Solution of Gilbert-Pollak's Conjecture on Steiner Ratio"	Ding-Zhu Du,Frank K. Hwang	1990	A family of finitely many continuous functions on a polytope X, namely (g/sub i/(x))/sub i in I/, is considered, and the problem of minimizing the function f(x)=max/sub i in I/g/sub i/(x) on X is treated. It is shown that if every g/sub i/(x) is a concave function, then the minimum value of f(x) is achieved at finitely many special points in X. As an application, a long-standing problem about Steiner minimum trees and minimum spanning trees is solved. In particular, if P is a set of n points on the Euclidean plane and L/sub s/(P) and L/sub m/(P) denote the lengths of a Steiner minimum tree and a minimum spanning tree on P, respectively, it is proved that, for any P, L/sub S/(P)>or= square root 3L/sub m/(P)/2, as conjectured by E.N. Gilbert and H.O. Pollak (1968).
FOCS	Uniform Memory Hierarchies	Bowen Alpern,Larry Carter,Ephraim Feig	1990	"The authors introduce a model, called the uniform memory hierarchy (UMH) model, which reflects the hierarchical nature of computer memory more accurately than the RAM (random-access-machine) model, which assumes that any item in memory can be accessed with unit cost. In the model memory occurs as a sequence of increasingly large levels. Data are transferred between levels in fixed-size blocks (the size is level dependent). Within a level blocks are random access. The model is easily extended to handle parallelism. The UMH model is really a family of models parameterized by the rate at which the bandwidth decays as one travels up the hierarchy. A program is parsimonious on a UMH if the leading terms of the program's (time) complexity on the UMH and on a RAM are identical. If these terms differ by more than a constant factor, then the program is inefficient. The authors analyze two standard FFT programs with the same RAM complexity. One is efficient; the other is not."
FOCS	Simple Constructions of Almost k-Wise Independent Random Variables	Noga Alon,Oded Goldreich,Johan Håstad,René Peralta	1990	The authors present three alternative simple constructions of small probability spaces on n bits for which any k bits are almost independent. The number of bits used to specify a point in the sample space is O(log log n+k+log 1/ epsilon ), where epsilon is the statistical difference between the distribution induced on any k-bit locations and the uniform distribution. This is asymptotically comparable to the construction recently presented by J. Naor and M. Naor (1990). An advantage of the present constructions is their simplicity. Two of the constructions are based on bit sequences that are widely believed to possess randomness properties, and the results can be viewed as an explanation and establishment of these beliefs.
FOCS	Learning Conjunctions of Horn Clauses (Extended Abstract)	Dana Angluin,Michael Frazier,Leonard Pitt	1990	Learning Conjunctions of Horn Clauses (Extended Abstract)
FOCS	Fault Tolerant Sorting Network	Shay Assaf,Eli Upfal	1990	A general technique for enhancing the reliability of sorting networks and other comparator-based networks is presented. The technique converts any network that uses unreliable comparators to a fault-tolerant network that produces the correct output with overwhelming probability, even if each comparator is faulty with some probability smaller than 1/2, independently of other comparators. The depth of the fault-tolerant network is only a constant times the depth of the original network, and the width of the network is increased by a logarithmic factor.
FOCS	Are Wait-Free Algorithms Fast? (Extended Abstract)	Hagit Attiya,Nancy A. Lynch,Nir Shavit	1990	Are Wait-Free Algorithms Fast? (Extended Abstract)
FOCS	Communication-Optimal Maintenance of Replicated Information	Baruch Awerbuch,Israel Cidon,Shay Kutten	1990	"It is shown that keeping track of history allows significant improvements in the realistic model of communication complexity of dynamic network protocols. The communication complexity for solving an arbitrary graph problem is improved from Theta (E) to Theta (V), thus achieving the lower bound. Moreover, O(V) is also the amortized complexity of solving an arbitrary function (not only graph functions) defined on the local inputs of the nodes. As a corollary, it is found that amortized communication complexity, i.e. incremental cost of adapting to a single topology change, can be smaller than the communication complexity of solving the problem from scratch. The first stage in the solution is a communication-optimal maintenance of a spanning tree in a dynamic network. The second stage is the optimal maintenance of replicas of databases. An important example of this task is the problem of updating the description of the network's topology at every node. For this problem the message complexity is improved from O(EV) to Theta (V). The improvement for a general database is even larger if the size of the database is larger than E."
FOCS	Sparse Partitions (Extended Abstract)	Baruch Awerbuch,David Peleg	1990	Sparse Partitions (Extended Abstract)
FOCS	Network Synchronization with Polylogarithmic Overhead	Baruch Awerbuch,David Peleg	1990	The synchronizer is a simulation methodology for simulating a synchronous network by an asynchronous one, thus enabling the execution of a synchronous algorithm on an asynchronous network. Previously known synchronizers require each processor in the network to participate in each pulse of the synchronization process. The resulting communication overhead depends linearly on the number n of network nodes. A synchronizer with overhead only polylogarithmically dependent on n is introduced. This synchronizer can also be realized with polylog(n) space. The polylog-overhead synchronizer is based on involving only the relevant portions of the network in the synchronization process.
FOCS	A Dining Philosophers Algorithm with Polynomial Response Time	Baruch Awerbuch,Michael E. Saks	1990	Presents an efficient distributed online algorithm for scheduling jobs that are created dynamically, subject to resource constraints that require that certain pairs of jobs not run concurrently. The focus is on the response time of the system to each job, i.e. the length of the time interval that starts when the job is created or assigned to a processor and ends at the instant the execution of the job begins. The goal is to provide guarantees on the response time to each job j in terms of the density of arrivals of jobs that conflict with j. The model is completely asynchronous and includes various resource allocation problems that have been studied extensively, including the dining philosophers problem and its generalizations to arbitrary networks. In these versions of the problem, the resource requirements of each new job j determines an upper bound delta /sub j/ on the number of jobs that can exist concurrently in the system and conflict with j. Given such upper bounds, no scheduling algorithm can guarantee a response time better than delta /sub j/ times the maximum execution or message transmission time. A simple algorithm that guarantees response time that is essentially polynomial in delta /sub j/ is presented. It is based on the notion of a distribution queue and has a compact implementation.
FOCS	A Characterization of \sharp P Arithmetic Straight Line Programs	László Babai,Lance Fortnow	1990	A Characterization of \sharp P Arithmetic Straight Line Programs
FOCS	Non-Deterministic Exponential Time Has Two-Prover Interactive Protocols	László Babai,Lance Fortnow,Carsten Lund	1990	Non-Deterministic Exponential Time Has Two-Prover Interactive Protocols
FOCS	On the Diameter of Finite Groups	László Babai,Gábor Hetyei,William M. Kantor,Alexander Lubotzky,Ákos Seress	1990	"The diameter of a group G with respect to a set S of generators is the maximum over g in G of the length of the shortest word in S union S/sup -1/ representing g. This concept arises in the contexts of efficient communication networks and Rubik's-cube-type puzzles. 'Best' generators are pertinent to networks, whereas 'worst' and 'average' generators seem more adequate models for puzzles. A substantial body of recent work on these subjects by the authors is surveyed. Regarding the 'best' case, it is shown that, although the structure of the group is essentially irrelevant if mod S mod is allowed to exceed (log mod G mod )/sup 1+c/(c>0), it plays a strong role when mod S mod =O(1)."
FOCS	Deterministic On-Line Routing on Area-Universal Networks (Extended Abstract)	Paul Bay,Gianfranco Bilardi	1990	Deterministic On-Line Routing on Area-Universal Networks (Extended Abstract)
FOCS	Time-Space Tradeoffs for Undirected Graph Traversal	Paul Beame,Allan Borodin,Prabhakar Raghavan,Walter L. Ruzzo,Martin Tompa	1990	"Time-space tradeoffs for traversing undirected graphs are proved. One of these tradeoffs is a quadratic lower bound on a deterministic model that closely matches the probabilistic upper bound of A.Z. Broder et al. (1989). The models used are variants of S.A. Cook and C.W. Rackoff's (1980) jumping automata for graphs. Some open problems are stated."
FOCS	Communication-Space Tradeoffs for Unrestricted Protocols	Paul Beame,Martin Tompa,Peiyuan Yan	1990	Communicating branching programs are introduced, and a general technique for demonstrating communication-space tradeoffs for pairs of communicating branching programs is developed. The technique is used to prove communication-space tradeoffs for any pair of communicating branching programs that hashes according to a universal family of hash functions. Other tradeoffs follow from this result. For example any pair of communicating Boolean branching programs that computes matrix-vector products over GF(2) requires communication-space product Omega (n/sup 2/). These are the first examples of communication-space tradeoffs on a completely general model of communicating processes.
FOCS	Randomness in Interactive Proofs	Mihir Bellare,Oded Goldreich,Shafi Goldwasser	1990	The quantitative aspects of randomness in interactive proof systems are studied. The result is a randomness-efficient error-reduction technique: given an Arthur-Merlin proof system (error probability
FOCS	Hidden Surface Removal for Axis-Parallel Polyhedra (Extended Abstract)	Mark de Berg,Mark H. Overmars	1990	Hidden Surface Removal for Axis-Parallel Polyhedra (Extended Abstract)
FOCS	Some Triply-Logarithmic Parallel Algorithms (Extended Abstract)	Omer Berkman,Joseph JáJá,Sridhar Krishnamurthy,Ramakrishna Thurimella,Uzi Vishkin	1990	Some Triply-Logarithmic Parallel Algorithms (Extended Abstract)
FOCS	Provably Good Mesh Generation	Marshall W. Bern,David Eppstein,John R. Gilbert	1990	Several versions of the problem of generating triangular meshes for finite-element methods are studied. It is shown how to triangulate a planar point set or a polygonally bounded domain with triangles of bounded aspect ratio, how to triangulate a planar point set with triangles having no obtuse angles, how to triangulate a point set in arbitrary dimension with simplices of bounded aspect ratio, and how to produce a linear-size Delaunay triangulation of a multidimensional point set by adding a linear number of extra points. All the triangulations have size within a constant factor of optimal and run in optimal time O(n log n+k) with input of size n and output of size k. No previous work on mesh generation simultaneously guarantees well-shaped elements and small total size.
FOCS	Separating Distribution-Free and Mistake-Bound Learning Models over the Boolean Domain	Avrim Blum	1990	Two of the most commonly used models in computational learning theory are the distribution-free model, in which examples are chosen from a fixed but arbitrary distribution, and the absolute mistake-bound model, in which examples are presented in order by an adversary. Over the Boolean domain
FOCS	Some Tools for Approximate 3-Coloring (Extended Abstract)	Avrim Blum	1990	Some Tools for Approximate 3-Coloring (Extended Abstract)
FOCS	Polynomial Threshold Functions, AC^0 Functions and Spectral Norms (Extended Abstract)	Jehoshua Bruck,Roman Smolensky	1990	Polynomial Threshold Functions, AC^0 Functions and Spectral Norms (Extended Abstract)
FOCS	On the Predictability of Coupled Automata: An Allegory about Chaos	Samuel R. Buss,Christos H. Papadimitriou,John N. Tsitsiklis	1990	The authors show a sharp dichotomy between systems of identical automata with symmetric global control whose behavior is easy to predict and those whose behavior is hard to predict. The division pertains to whether the global control rule is invariant with respect to permutations of the states of the automaton. It is also shown that testing whether the global control rule has this invariance property is an undecidable problem. It is argued that there is a natural analog between complexity in the present model and chaos in dynamical systems.
FOCS	Triangulating a Simple Polygon in Linear Time	Bernard Chazelle	1990	A linear-time deterministic algorithm for triangulating a simple polygon is developed. The algorithm is elementary in that it does not require the use of any complicated data structures; in particular, it does not need dynamic search trees, finger trees, or fancy point location structures.
FOCS	Counting and Cutting Cycles of Lines and Rods in Space	Bernard Chazelle,Herbert Edelsbrunner,Leonidas J. Guibas,Richard Pollack,Raimund Seidel,Micha Sharir,Jack Snoeyink	1990	A number of rendering algorithms in computer graphics sort three-dimensional objects by depth and assume that there is no cycle that makes the sorting impossible. One way to resolve the problem caused by cycles is to cut the objects into smaller pieces. The problem of estimating how many such cuts are always sufficient is addressed. A few related algorithmic and combinatorial geometry problems are considered.
FOCS	New Results on Dynamic Planar Point Location	Siu-Wing Cheng,Ravi Janardan	1990	A point location scheme is presented for an n-vertex dynamic planar subdivision whose underlying graph is only required to be connected. The scheme uses O(n) space and yields an O(log/sup 2/n) query time and an O(log n) update time. Insertion (respectively, deletion) of an arbitrary k-edge chain inside a region can be performed in O(k log(n+k)) (respectively, O(k log n)) time. The scheme is then extended to speed up the insertion/deletion of a k-edge monotone chain to O(log/sup 2/n log log n+k) time (or O(log n log log n+k) time for an alternative model of input), but at the expense of increasing the other time bounds slightly. All bounds are worst case. Additional results include a generalization to planar subdivisions consisting of algebraic segments of bounded degree and a persistent scheme for planar point location.
FOCS	Bounds on Tradeoffs between Randomness and Communication Complexity	Ran Canetti,Oded Goldreich	1990	A quantitative investigation of the power of randomness in the context of communication complexity is initiated. The authors prove general lower bounds on the length of the random input of parties computing a function f, depending on the number of bits communicated and the deterministic communication complexity of f. Four standard models for communication complexity are considered: the random input of the parties may be shared or local, and the communication may be one-way or two-way. The bounds are shown to be tight for all the models, for all values of the deterministic communication complexity, and for all possible quantities of bits exchanged. It is shown that it is possible to reduce the number of random bits required by any protocol, without increasing the number of bits exchanged (up to a limit depending on the advantage achieved by the protocol).
FOCS	Private Computations Over the Integers (Extended Abstract)	Benny Chor,Mihály Geréb-Graus,Eyal Kushilevitz	1990	Private Computations Over the Integers (Extended Abstract)
FOCS	Approximate String Matching in Sublinear Expected Time	William I. Chang,Eugene L. Lawler	1990	The k differences approximate string matching problem specifies a text string of length n, a pattern string of length m, and the number k of differences (insertions, deletions, substitutions) allowed in a match, and asks for every location in the text where a match occurs. Previous algorithms required at least O(nk) time. When k is as large as a fraction of m, no substantial progress has been made over O(nm) dynamic programming. The authors have investigated much faster algorithms for restricted cases of the problem, such as when the text string is random and errors are not too frequent. They have devised an algorithm that, for k
FOCS	Online Algorithms for Finger Searching (Extended Abstract)	Richard Cole,Arvind Raghunathan	1990	Online Algorithms for Finger Searching (Extended Abstract)
FOCS	On the Exact Complexity of String Matching (Extended Abstract)	Livio Colussi,Zvi Galil,Raffaele Giancarlo	1990	On the Exact Complexity of String Matching (Extended Abstract)
FOCS	Exploring an Unknown Graph (Extended Abstract)	Xiaotie Deng,Christos H. Papadimitriou	1990	Exploring an Unknown Graph (Extended Abstract)
FOCS	Perfectly Secure Message Transmission	Danny Dolev,Cynthia Dwork,Orli Waarts,Moti Yung	1990	The problem of perfectly secure communication in a general network in which processors and communication lines may be faulty is studied. Lower bounds are obtained on the connectivity required for successful secure communication. Efficient algorithms that operate with this connectivity and rely on no complexity theoretic assumptions are derived. These are the first algorithms for secure communication in a general network to achieve simultaneously the goals of perfect secrecy, perfect resiliency, and a worst case time which is linear in the diameter of the network.
FOCS	Faster Tree Pattern Matching	Moshe Dubiner,Zvi Galil,Edith Magen	1990	Recently, R. Kosaraju (Proc. 30th IEEE Symp. on Foundations of Computer Science, 1989, p.178-83) gave an O(nm/sup 0.75/ polylog(m))-step algorithm for tree pattern matching. The authors improve this result by designing a simple O(n square root m polylog (m)) algorithm.
FOCS	Computing with Snakes in Directed Networks of Automata (Extended Abstract)	Shimon Even,Ami Litman,Peter Winkler	1990	Computing with Snakes in Directed Networks of Automata (Extended Abstract)
FOCS	Multiple Non-Interactive Zero Knowledge Proofs Based on a Single Random String (Extended Abstract)	Uriel Feige,Dror Lapidot,Adi Shamir	1990	Multiple Non-Interactive Zero Knowledge Proofs Based on a Single Random String (Extended Abstract)
FOCS	Drawing Graphs in the Plane with High Resolution	Michael Formann,Torben Hagerup,James Haralambides,Michael Kaufmann,Frank Thomson Leighton,Antonios Symvonis,Emo Welzl,Gerhard J. Woeginger	1990	The problem of drawing a graph in the plane so that edges appear as straight lines and the minimum angle formed by any pair of incident edges is maximized is studied. The resolution of a layout is defined to be the size of the minimum angle formed by incident edges of the graph, and the resolution of a graph is defined to be the maximum resolution of any layout of the graph. The resolution R of a graph is characterized in terms of the maximum node degree d of the graph by proving that Omega (1/d/sup 2/)
FOCS	Augmenting Graphs to Meet Edge-Connectivity Requirements	András Frank	1990	The problem of determining the minimum number gamma of edges to be added to a graph G so that in the resulting graph the edge-connectivity between every pair (u,v) of nodes is at least a prescribed value r(u,v) is treated. A min-max formula for gamma is derived, and a polynomial-time algorithm for computing gamma is described. The directed counterpart of the problem is also solved for the case in which r(u,v)=k>or=1. The approach used makes it possible to solve a degree-constrained version of the problem. The minimum-cost augmentation problem can also be solved in polynomial time provided that the edge costs arise from node costs.
FOCS	Competitive k-Server Algorithms (Extended Abstract)	Amos Fiat,Yuval Rabani,Yiftach Ravid	1990	Competitive k-Server Algorithms (Extended Abstract)
FOCS	Permuting	Faith E. Fich,J. Ian Munro,Patricio V. Poblete	1990	The fundamental problem of permuting the elements of an array according to some given permutation is addressed. The goal is to perform the permutation quickly using only a polylogarithmic number of bits of extra storage. The main result is an O(n log n)-time, O(log/sup 2/n)-space worst case method. A simpler method is presented for the case in which both the permutation and its inverse can be computed at (amortized) unit cost. This algorithm requires O(n log n) time and O(log n) bits in the worst case. These results are extended to the situation in which a power of the permutation is to be applied. A linear time, O(log n)-bit method is presented for the special case in which the data values are all distinct and are either initially in sorted order or will be when permuted.
FOCS	Trans-dichotomous Algorithms for Minimum Spanning Trees and Shortest Paths	Michael L. Fredman,Dan E. Willard	1990	"The fusion tree method is extended to develop a linear-time algorithm for the minimum spanning tree problem and an O(m+n log n/log log n) implementation of Dijkstra's shortest-path algorithm for a graph with n vertices and m edges. The shortest-path algorithm surpasses information-theoretic limitations. The extension of the fusion tree method involves the development of a new data structure, the atomic heap. The atomic heap accommodates heap (priority queue) operations in constant amortized time under suitable polylog restrictions on the heap size. The linear-time minimum spanning tree algorithm results from a direct application of the atomic heap. To obtain the shortest path algorithm, the atomic heap is used as a building block to construct a new data structure, the AF-heap, which has no size restrictions and surpasses information theoretic limitations. The AF-heap belongs to the Fibonacci heap family."
FOCS	Robust Separations in Inductive Inference	Mark A. Fulk	1990	"Results in recursion-theoretic inductive inference have been criticized as depending on unrealistic self-referential examples. J.M. Barzdin (1974) proposed a way of ruling out such examples and conjectured that one of the earliest results of inductive inference theory would fall if his method were used. The author refutes Barzdin's conjecture and proposes a new line of research examining robust separations which are defined using a strengthening of Barzdin's original idea. Preliminary results are presented, and the most important open problem is stated as a conjecture. The extension of this work from function learning to formal language learning is discussed."
FOCS	Exact Identification of Circuits Using Fixed Points of Amplification Functions (Extended Abstract)	Sally A. Goldman,Michael J. Kearns,Robert E. Schapire	1990	Exact Identification of Circuits Using Fixed Points of Amplification Functions (Extended Abstract)
FOCS	Security Preserving Amplification of Hardness	Oded Goldreich,Russell Impagliazzo,Leonid A. Levin,Ramarathnam Venkatesan,David Zuckerman	1990	The task of transforming a weak one-way function (which may be easily inverted on all but a polynomial fraction of the range) into a strong one-way function (which can be easily inverted only on a negligible function of the range) is considered. The previously known transformation does not preserve the security (i.e. the running time of the inverting algorithm) within any polynomial. Its resulting function, F(x), applies the weak one-way function to many small (of length mod x mod /sup theta /, theta
FOCS	Interpolation of Sparse Rational Functions Without Knowing Bounds on Exponents	Dima Grigoriev,Marek Karpinski,Michael F. Singer	1990	The authors present the first algorithm for the (black box) interpolation of t-sparse, n-variate, rational functions without knowing bounds on exponents of their sparse representation, with the number of queries independent of exponents. In fact, the algorithm uses O(nt/sup t/) queries to the black box, and it can be implemented for a fixed t in a polynomially bounded storage (or polynomial parallel time).
FOCS	Matrix Decomposition Problem Is Complete for the Average Case	Yuri Gurevich	1990	The first algebraic average-case complete problem is presented. The focus of attention is the modular group, i.e., the multiplicative group SL/sub 2/(Z) of two-by-two integer matrices of determinant 1. By default, in this study matrices are elements of the modular group. The problem is arguably the simplest natural average-case complete problem to date.
FOCS	Deciding Properties of Nonregular Programs (Preliminary Version)	David Harel,Danny Raz	1990	Deciding Properties of Nonregular Programs (Preliminary Version)
FOCS	On the Power of Small-Depth Threshold Circuits	Johan Håstad,Mikael Goldmann	1990	The power of threshold circuits of small depth is investigated. In particular, functions that require exponential-size unweighted threshold circuits of depth 3 when the bottom fan-in is restricted are given. It is proved that there are monotone functions f/sub k/ that can be computed on depth k and linear size AND, OR circuits but require exponential-size to be computed by a depth-(k-1) monotone weighted threshold circuit.
FOCS	Simplifying Nested Radicals and Solving Polynomials by Radicals in Minimum Depth	Gwoboa Horng,Ming-Deh A. Huang	1990	The notion of pure nested radicals and its field-theoretic counterpart, pure root extensions, are defined and used for investigating exact radical solutions.
FOCS	No Better Ways to Generate Hard NP Instances than Picking Uniformly at Random	Russell Impagliazzo,Leonid A. Levin	1990	No Better Ways to Generate Hard NP Instances than Picking Uniformly at Random
FOCS	Coloring Inductive Graphs On-Line	Sandy Irani	1990	Online graph coloring, in which the vertices are presented one at a time, is considered. Each vertex must be assigned a color, different from the colors of its neighbors, before the next vertex is given. The class of d-inductive graphs is treated. A graph G is said to be d-inductive if the vertices of G can be numbered so that each vertex has at most d edges to higher numbered vertices. First Fit (FF) is the algorithm that assigns each vertex the lowest numbered color possible. It is shown that if G is d-inductive, then FF uses O(d log n) colors on G. This yields an upper bound of O(log n) on the performance ratio of FF on chordal and planar graphs. FF does as well as any online algorithm for d-inductive graphs; it is shown that for any d and any online graph-coloring algorithm A, there is a d-inductive graph that forces A to use Omega (d log n) colors to color G. Online graph coloring with lookahead is also investigated.
FOCS	Constructing Generalized Universal Traversing Sequences of Polynomial Size for Graphs with Small Diameter (Extended Abstract)	Sorin Istrail	1990	Constructing Generalized Universal Traversing Sequences of Polynomial Size for Graphs with Small Diameter (Extended Abstract)
FOCS	Asymptotically Tight Bounds for Computing with Faulty Arrays of Processors (Extended Abstract)	Christos Kaklamanis,Anna R. Karlin,Frank Thomson Leighton,Victor Milenkovic,Prabhakar Raghavan,Satish Rao,Clark D. Thomborson,A. Tsantilas	1990	Asymptotically Tight Bounds for Computing with Faulty Arrays of Processors (Extended Abstract)
FOCS	Finite-Memory Automata (Extended Abstract)	Michael Kaminski,Nissim Francez	1990	Finite-Memory Automata (Extended Abstract)
FOCS	Inferring Evolutionary History from DNA Sequences (Extended Abstract)	Sampath Kannan,Tandy Warnow	1990	Inferring Evolutionary History from DNA Sequences (Extended Abstract)
FOCS	Efficient Distribution-free Learning of Probabilistic Concepts (Extended Abstract)	Michael J. Kearns,Robert E. Schapire	1990	Efficient Distribution-free Learning of Probabilistic Concepts (Extended Abstract)
FOCS	Approximation through Multicommodity Flow	Philip N. Klein,Ajit Agrawal,R. Ravi,Satish Rao	1990	The first approximate max-flow-min-cut theorem for general multicommodity flow is proved. It is used to obtain approximation algorithms for minimum deletion of clauses of a 2-CNF identical to formula, via minimization problems, and other problems. Also presented are approximation algorithms for chordalization of a graph and for register sufficiency that are based on undirected and directed node separators.
FOCS	Towards a DNA Sequencing Theory (Learning a String) (Preliminary Version)	Ming Li	1990	Towards a DNA Sequencing Theory (Learning a String) (Preliminary Version)
FOCS	Efficient Parallel Algorithms for Tree-Decomposition and Related Problems	Jens Lagergren	1990	An efficient parallel algorithm for the tree-decomposition problem for fixed width w is presented. The algorithm runs in time O(log/sup 3/ n) and uses O(n) processors on a concurrent-read, concurrent-write parallel random access machine (CRCW PRAM). This result can be used to construct efficient parallel algorithms for three important classes of problems: MS (monadic second-order) properties, linear EMS (extended monadic second-order) extremum problems, and enumeration problems for MS properties, for graphs of tree width at most w. The sequential time complexity of the tree-composition problem for fixed w is improved, and some implications for this improvement are stated.
FOCS	A Tree-Partitioning Technique with Applications to Expression Evaluation and Term Matching (Extended Abstract)	S. Rao Kosaraju,Arthur L. Delcher	1990	A Tree-Partitioning Technique with Applications to Expression Evaluation and Term Matching (Extended Abstract)
FOCS	Complexity of Unification in Free Groups and Free Semi-groups	Antoni Koscielski,Leszek Pacholski	1990	It is proved that the exponent of periodicity of a minimal solution of a word equation is at most 2/sup 2.54n/, where n is the length of the equation. Since the best known lower bound is 2/sup 0.31n/, this upper bound is almost optimal and exponentially better than the original bound. Thus the result implies exponential improvement of known upper bounds on complexity of word-unification algorithms. Evidence is given that, contrary to common belief, the algorithm deciding satisfiability of equations in free groups, given by G.S. Makanin (1977), is not primitive recursive.
FOCS	A (fairly) Simple Circuit that (usually) Sorts	Frank Thomson Leighton,C. Greg Plaxton	1990	A (fairly) Simple Circuit that (usually) Sorts
FOCS	Decision Problems for Propositional Linear Logic	Patrick Lincoln,John C. Mitchell,Andre Scedrov,Natarajan Shankar	1990	It is shown that, unlike most other propositional (quantifier-free) logics, full propositional linear logic is undecidable. Further, it is provided that without the model storage operator, which indicates unboundedness of resources, the decision problem becomes PSPACE-complete. Also established are membership in NP for the multiplicative fragment, NP-completeness for the multiplicative fragment extended with unrestricted weakening, and undecidability for certain fragments of noncommutative propositional linear logic.
FOCS	Tight Bounds on the Complexity of Cascaded Decomposition of Automata	Oded Maler,Amir Pnueli	1990	Exponential upper and lower bounds on the size of the cascaded (Krohn-Rhodes) decomposition of automata are given. These results are used to obtain elementary algorithms for various translations between automata and temporal logic, where the previously known translations were nonelementary. The relevance of the result is discussed.
FOCS	Asynchronous PRAMs Are (Almost) as Good as Synchronous PRAMs	Charles U. Martel,Ramesh Subramonian,Arvin Park	1990	A PRAM (parallel random-access-machine) model that allows processors to have arbitrary asynchronous behavior is introduced. The main result shows that any n-processor CRCW (concurrent-read, concurrent-write) PRAM program can be simulated on an asynchronous CRCW PRAM using O(n) expected work per parallel step and up to n/log n log*n asynchronous processors. It is shown that a synchronization primitive for n parallel instructions can be computed using O(n) expected work by a system of asynchronous processors. Since a special case of asynchronous behavior is a fail-stop error, the simulation technique described above can convert any PRAM program into a PRAM program that is resistant to all fail-stop errors and has the same expected work as the original program.
FOCS	The Mixing Rate of Markov Chains, an Isoperimetric Inequality, and Computing the Volume	László Lovász,Miklós Simonovits	1990	A. Sinclair and M. Jerrum (1988) derived a bound on the mixing rate of time-reversible Markov chains in terms of their conductance. The authors generalize this result by not assuming time reversibility and using a weaker notion of conductance. They prove an isoperimetric inequality for subsets of a convex body. These results are combined to simplify an algorithm of M. Dyer et al. (1989) for approximating the volume of a convex body and to improve running-time bounds.
FOCS	Algebraic Methods for Interactive Proof Systems	Carsten Lund,Lance Fortnow,Howard J. Karloff,Noam Nisan	1990	An algebraic technique for the construction of interactive proof systems is proposed. The technique is used to prove that every language in the polynomial-time hierarchy has an interactive proof system. For the proof, a method is developed for reducing the problem of verifying the value of a low-degree polynomial at two points to verifying the value at one new point. The results have implications for program checking, verification, and self-correction.
FOCS	Communication Complexity of Algebraic Computation (Extended Abstract)	Zhi-Quan Luo,John N. Tsitsiklis	1990	Communication Complexity of Algebraic Computation (Extended Abstract)
FOCS	Probabilities of Sentences about Very Sparse Random Graphs	James F. Lynch	1990	The author considers random graphs with edge probability beta n/sup - alpha /, where n is the number of vertices of the graph, beta >0 is fixed, and alpha =1 or alpha =(l+1)/l for some fixed positive integer l. It is proved that, for every first-order sentence, the probability that the sentence is true for the random graph has an asymptotic limit. Also, there is an effective procedure for generating the value of the limit in closed form.
FOCS	On the Complexity of Learning from Counterexamples and Membership Queries	Wolfgang Maass,György Turán	1990	It is shown that for any concept class C the number of equivalence and membership queries that are needed to learn C is bounded from below by Omega (VC-dimension(C)). Furthermore, it is shown that the required number of equivalence and membership queries is also bounded from below by Omega (LC-ARB(C)/log(1+LC-ARB(C))), where LC-ARB(C) is the required number of steps in a different model where no membership queries but equivalence queries with arbitrary subsets of the domain are permitted. These two relationships are the only relationships between the learning complexities of the common online learning models and the related combinatorial parameters that have remained open. As an application of the first lower bound, the number of equivalence and membership queries that are needed to learn monomials of k out of n variables is determined. Learning algorithms for threshold gates that are based on equivalence queries are examined. It is shown that a threshold gate can learn not only concepts but also nondecreasing functions in polynomially many steps.
FOCS	On Graph-Theoretic Lemmata and Complexity Classes (Extended Abstract)	Christos H. Papadimitriou	1990	On Graph-Theoretic Lemmata and Complexity Classes (Extended Abstract)
FOCS	A Fast Algorithm for Optimally Increasing the Edge-Connectivity	Dalit Naor,Dan Gusfield,Charles U. Martel	1990	"An undirected, unweighted graph G=(V, E with n nodes, m edges, and connectivity lambda ) is considered. Given an input parameter delta , the edge augmentation problem is to find the smallest set of edges to add to G so that its edge-connectivity is increased by delta . A solution to this problem that runs in time O( delta /sup 2/nm+nF(n)), where F(n) is the time to perform one maximum flow on G, is given. The solution gives the optimal augmentation for every delta ', 1"
FOCS	Faster Circuits and Shorter Formulae for Multiple Addition, Multiplication and Symmetric Boolean Functions	Mike Paterson,Nicholas Pippenger,Uri Zwick	1990	A general theory is developed for constructing the shallowest possible circuits and the shortest possible formulas for the carry-save addition of n numbers using any given basic addition unit. More precisely, it is shown that if BA is a basic addition unit with occurrence matrix N, then the shortest multiple carry-save addition formulas that could be obtained by composing BA units are of size n/sup 1/p+o(1)/, where p is the unique real number for which the L/sub p/ norm of the matrix N equals 1. An analogous result connects the delay matrix M of the basic addition unit BA and the minimal q such that multiple carry-save addition circuits of depth (q+o(1)) log n could be constructed by combining BA units. On the basis of these optimal constructions of multiple carry-save adders, the shallowest known multiplication circuits are constructed.
FOCS	Specified Precision Polynomial Root Isolation is in NC	C. Andrew Neff	1990	Given a polynomial p(z) od degree n with integer coefficients, whose absolute values are bounded above by 2/sup m/, and a specified integer mu , it is shown that the problem of determining all roots of p with error less than 2/sup - mu / is in the parallel complexity class NC. To do this, an algorithm that runs on at most POLY(n+m+ mu ) processors with a parallel time complexity of O(log/sup 3/(n+m+ mu )) is constructed. This algorithm extends the algorithm of M. Ben-Or et al. (SIAM J. Comput., vol.17, p.1081-92, 1988) by removing the severe restriction that all the roots of p(z) should be real.
FOCS	On Threshold Circuits for Parity	Ramamohan Paturi,Michael E. Saks	1990	Motivated by, the problem of understanding the limitations of neural networks for representing Boolean functions, the authors consider size-depth tradeoffs for threshold circuits that compute the parity function. They give an almost optimal lower bound on the number of edges of any depth-2 threshold circuit that computes the parity function with polynomially bounded weights. The main technique used in the proof, which is based on the theory of rational approximation, appears to be a potentially useful technique for the analysis of such networks. It is conjectured that there are no linear size, bounded-depth threshold circuits for computing parity.
FOCS	Distributed Reactive Systems Are Hard to Synthesize	Amir Pnueli,Roni Rosner	1990	The problem of synthesizing a finite-state distributed reactive system is considered. Given a distributed architecture A, which comprises several processors P/sub 1/, . . ., P/sub k/ and their interconnection scheme, and a propositional temporal specification phi , a solution to the synthesis problem consists of finite-state programs Pi /sub 1/, . . ., Pi /sub k/ (one for each processor), whose joint (synchronous) behavior maintains phi against all possible inputs from the environment. Such a solution is referred to as the realization of the specification phi over the architecture A. Specifically, it is shown that the problem of realizing a given propositional specification over a given architecture is undecidable, and it is nonelementarily decidable for the very restricted class of hierarchical architectures. An extensive characterization of architecture classes for which the realizability problem is elementarily decidable and of classes for which it is undecidable is given.
FOCS	The Computability and Complexity of Optical Beam Tracing	John H. Reif,J. D. Tygar,Akitoshi Yoshida	1990	The ray-tracing problem is considered for optical systems consisting of a set of refractive or reflective surfaces. It is assumed that the position and the tangent of the incident angle of the initial light ray are rational. The computability and complexity of the ray-tracing problems are investigated for various optical models. The results show that, depending on the optical model, ray tracing is sometimes undecidable, sometimes PSPACE-hard, and sometimes in PSPACE.
FOCS	IP=PSPACE	Adi Shamir	1990	In this paper, it is proven that when both randomization and interaction are allowed, the proofs that can be verified in polynomial time are exactly those proofs that can be generated with polynomial space.
FOCS	On Interpolation by Analytic Functions with Special Properties and Some Weak Lower Bounds on the Size of Circuits with Symmetric Gates	Roman Smolensky	1990	The author investigates the question of whether or not a specific Boolean function in n variables can be interpolated by an analytic function in the same variables whose partial derivatives of all orders span a subspace of low dimension in the space of analytic functions. The upper and lower bounds for this dimension yield some weak circuit lower bounds. For a particular function, an Omega (n/log n)-size lower bound is obtained for its computation by a circuit whose gates are symmetric. For the same function an Omega (n) lower bound is obtained for the circuit with mod/sub k/ gates.
FOCS	Efficiently Inverting Bijections Given by Straight Line Programs	Carl Sturtivant,Zhi-Li Zhang	1990	Let K be any field, and let F: K/sup n/ to K/sup n/ be a bijection with the property that both F and F/sup -1/ are computable using only arithmetic operations from K. Motivated by cryptographic considerations, the authors concern themselves with the relationship between the arithmetic complexity of F and the arithmetic complexity of F/sup -1/. They give strong relations between the complexity of F and F/sup -1/ when F is an automorphism in the sense of algebraic geometry (i.e. a formal bijection defined by n polynomials in n variables with a formal inverse of the same form). These constitute all such bijections in the case in which K is infinite. The authors show that at polynomially bounded degree, if an automorphism F has a polynomial-size arithmetic circuit, then F/sup -1/ has a polynomial-size arithmetic circuit. Furthermore, this result is uniform in the sense that there is an efficient algorithm for finding such a circuit for F/sup -1/, given such a circuit for F. This algorithm can also be used to check whether a circuit defines an automorphism F. If K is the Boolean field GF(2), then a circuit defining a bijection does not necessarily define an automorphism. However, it is shown in this case that, given any K/sup n/ to K/sup n/ bijection, there always exists an automorphism defining that bijection. This is not generally true for an arbitrary finite field.
FOCS	The Complexity of Finding Medians	Seinosuke Toda	1990	"PF( Hash P) is characterized in a manner similar to M.W. Krentel's (1988) characterization of Pf(NP). If MidP is the class of functions that give the medians in the outputs of metric Turing machines, then it is shown that every function in PF( Hash P) is polynomial time 1-Turing reducible to a function in MidP and MidP contained in PF( Hash P); that is, PF( Hash P)=PF(MidP(1)). Intuitively, finding medians is as hard computationally as PF( Hash P); this forms a contrast to an intuitive interpretation of Krentel's result that finding maxima (or minima) is as hard as PF(NP). Several applications of the result are shown."
FOCS	Reducing the Parallel Complexity of Certain Linear Programming Problems (Extended Abstract)	Pravin M. Vaidya	1990	Reducing the Parallel Complexity of Certain Linear Programming Problems (Extended Abstract)
FOCS	The Lattice Reduction Algorithm of Gauss: An Average Case Analysis	Brigitte Vallée,Philippe Flajolet	1990	The lattice reduction algorithm of Gauss is shown to have an average-case complexity that is asymptotic to a constant. The analysis makes use of elementary properties of continued fractions and of linear fractional transformations.
FOCS	Randomized Online Graph Coloring (Preliminary Version)	Sundar Vishwanathan	1990	Randomized Online Graph Coloring (Preliminary Version)
FOCS	On ACC and Threshold Circuits	Andrew Chi-Chih Yao	1990	It is proved that any language in ACC can be approximately computed by two-level circuits of size 2 raised to the (log n)/sup k/ power, with a symmetric-function gate at the top and only AND gates on the first level. This implies that any language in ACC can be recognized by depth-3 threshold circuits of that size. This result gives the first nontrivial upper bound on the computing power of ACC circuits.
FOCS	General Weak Random Sources	David Zuckerman	1990	The following model for a weak random source is considered. The source is asked only once for R bits, and the source outputs an R-bit string such that no string has probability more than 2/sup - delta R/ of being output. for some fixed delta >0. A pseudorandom generator that runs in time n/sup O(log n)/ and simulates RP using as a seed a string from such a source is exhibited. Under the generalized Paley graph conjecture, a generator that runs in polynomial time and simulates RP is given, as well as a different generator that produces almost perfectly random bits at a rate arbitrarily close to optimal using as seeds strings from a constant number of independent weak random sources.
FOCS	31st Annual Symposium on Foundations of Computer Science, 22-24 October 1990, St. Louis, Missouri, USA		1990	31st Annual Symposium on Foundations of Computer Science, 22-24 October 1990, St. Louis, Missouri, USA
FOCS	31st Annual Symposium on Foundations of Computer Science, 22-24 October 1990, St. Louis, Missouri, USA		1990	31st Annual Symposium on Foundations of Computer Science, 22-24 October 1990, St. Louis, Missouri, USA
SODA	Incremental Evaluation of Computational Circuits.	Bowen Alpern,Roger Hoover,Barry K. Rosen,Peter F. Sweeney,F. Kenneth Zadeck	1990	Incremental Evaluation of Computational Circuits.
SODA	Efficient Pattern Matching with Scaling.	Amihood Amir,Gad M. Landau,Uzi Vishkin	1990	Efficient Pattern Matching with Scaling.
SODA	An Efficiently Computable Metric for Comparing Polygonal Shapes.	Esther M. Arkin,L. Paul Chew,Daniel P. Huttenlocher,Klara Kedem,Joseph S. B. Mitchell	1990	A method for comparing polygons that is a metric, invariant under translation, rotation, and change of scale, reasonably easy to compute, and intuitive is presented. The method is based on the L/sub 2/ distance between the turning functions of the two polygons. It works for both convex and nonconvex polygons and runs in time O(mn log mn), where m is the number of vertices in one polygon and n is the number of vertices in the other. Some examples showing that the method produces answers that are intuitively reasonable are presented.
SODA	Incremental Algorithms for Minimal Length Paths.	Giorgio Ausiello,Giuseppe F. Italiano,Alberto Marchetti-Spaccamela,Umberto Nanni	1990	Incremental Algorithms for Minimal Length Paths.
SODA	Factor Refinement.	Eric Bach,James R. Driscoll,Jeffrey Shallit	1990	Factor Refinement.
SODA	Analysis of Boyer-Moore-Type String Searching Algorithms.	Ricardo A. Baeza-Yates,Gaston H. Gonnet,Mireille Régnier	1990	Analysis of Boyer-Moore-Type String Searching Algorithms.
SODA	Parallel Search for Maximal Independence Given Minimal Dependence.	Paul Beame,Michael Luby	1990	Parallel Search for Maximal Independence Given Minimal Dependence.
SODA	Experiments on Traveling Salesman Heuristics.	Jon Louis Bentley	1990	Experiments on Traveling Salesman Heuristics.
SODA	Fast Linear Expected-Time Algorithms for Computing Maxima and Convex Hulls.	Jon Louis Bentley,Kenneth L. Clarkson,David B. Levine	1990	Fast Linear Expected-Time Algorithms for Computing Maxima and Convex Hulls.
SODA	Approximation Algorithms for the Maximum Acyclic Subgraph Problem.	Bonnie Berger,Peter W. Shor	1990	Approximation Algorithms for the Maximum Acyclic Subgraph Problem.
SODA	A Competitive 3-Server Algorithm.	Piotr Berman,Howard J. Karloff,Gábor Tardos	1990	A Competitive 3-Server Algorithm.
SODA	Visibility with a Moving Point of View.	Marshall W. Bern,David P. Dobkin,David Eppstein,Robert L. Grossman	1990	Visibility with a Moving Point of View.
SODA	Multilevel Adaptive Hashing.	Andrei Z. Broder,Anna R. Karlin	1990	Multilevel Adaptive Hashing.
SODA	A Data Structure for Arc Insertion and Regular Path Finding.	Adam L. Buchsbaum,Paris C. Kanellakis,Jeffrey Scott Vitter	1990	If $G$ is a directed graph with labeled edges and $L$ is a fixed regular language, the {\em regular path problem}, given two nodes, $u$ and $v$, in $G$, is to find a path between $u$ and $v$ such that the labels on the arcs along that path form a string which is a member of $L$. We consider a dynamic version of this problem, adding arcs to and performing regular path queries on $G$ over $L$, and present a data structure that solves both problems in average time per operation linear in the number of nodes of the graph for any fixed regular language.
SODA	Efficient Maintenance of the Union Intervals on a Line, with Applications.	Siu-Wing Cheng,Ravi Janardan	1990	Efficient Maintenance of the Union Intervals on a Line, with Applications.
SODA	title=New Results on Server Problems.	Marek Chrobak,Howard J. Karloff,T. H. Payne,Sundar Vishwanathan	1990	title=New Results on Server Problems.
SODA	First-Fit Storage of Linear Lists: Tight Probabilistic Bounds on Wasted Space.	Edward G. Coffman Jr.,Leopold Flatto,Frank Thomson Leighton	1990	First-Fit Storage of Linear Lists: Tight Probabilistic Bounds on Wasted Space.
SODA	Shrinking Lattice Polyhedra.	John Cremona,Susan Landau	1990	Shrinking Lattice Polyhedra.
SODA	Fast Parallel Algorithms for the Clique Separator Decomposition.	Elias Dahlhaus,Marek Karpinski,Mark B. Novick	1990	"We give an efficient {\it NC} algorithm for finding a clique separator decomposition of an {\it arbitrary} graph, that is, a series of cliques whose removal disconnects the graph. This algorithm allows one to extend a large body of results which were originally formulated for chordal graphs to other classes of graphs. Our algorithm is optimal to within a polylogarithmic factor of Tarjan''s $O(mn)$ time sequential algorithm. The decomposition can also be used to find {\it NC} algorithms for some optimization problems on special families of graphs, assuming these problems can be solved in {\it NC} for the prime graphs of the decomposition. These optimization problems include: finding a maximum-weight clique, a minimum coloring, a maximum-weight independent set, and a minimum fill-in elimination order. We also give the first parallel algorithms for solving these problems by using the clique separator decomposition. Our maximum-weight independent set algorithm applied to chordal graphs yields the most efficient known parallel algorithm for finding a maximum-weight independent set of a chordal graph."
SODA	A Practical Algorithm for Computing the Delaunay Triangulation for Convex Distance Functions.	Robert L. (Scot) Drysdale III	1990	A Practical Algorithm for Computing the Delaunay Triangulation for Convex Distance Functions.
SODA	Sparse Dynamic Programming.	David Eppstein,Zvi Galil,Raffaele Giancarlo,Giuseppe F. Italiano	1990	Sparse Dynamic Programming.
SODA	Maintenance of a Minimum Spanning Forest in a Dynamic Planar Graph.	David Eppstein,Giuseppe F. Italiano,Roberto Tamassia,Robert Endre Tarjan,Jeffery Westbrook,Moti Yung	1990	Maintenance of a Minimum Spanning Forest in a Dynamic Planar Graph.
SODA	Data Structures for Weighted Matching and Nearest Common Ancestors with Linking.	Harold N. Gabow	1990	Data Structures for Weighted Matching and Nearest Common Ancestors with Linking.
SODA	On the Parsimonious Property of Connectivity Problems.	Michel X. Goemans,Dimitris Bertsimas	1990	On the Parsimonious Property of Connectivity Problems.
SODA	An Efficient Parallel Algorithm that Finds Independent Sets of Guaranteed Size.	Mark K. Goldberg,Thomas H. Spencer	1990	An Efficient Parallel Algorithm that Finds Independent Sets of Guaranteed Size.
SODA	Applying Parallel Processing Techniques to Classification Problems in Constructive Solid Geometry.	Michael T. Goodrich	1990	Applying Parallel Processing Techniques to Classification Problems in Constructive Solid Geometry.
SODA	Compact Interval Trees: A Data Structure for Convex Hulls.	Leonidas J. Guibas,John Hershberger,Jack Snoeyink	1990	Compact Interval Trees: A Data Structure for Convex Hulls.
SODA	Efficient Algorithms for Generalized Cut Trees.	Dan Gusfield,Dalit Naor	1990	Efficient Algorithms for Generalized Cut Trees.
SODA	Asymptotically Fast Triangularization of Matrices Over Rings.	James L. Hafner,Kevin S. McCurley	1990	Asymptotically Fast Triangularization of Matrices Over Rings.
SODA	On the Number of Minimum Size Separating Vertex Sets in a Graph and How to Find All of Them.	Arkady Kanevsky	1990	On the Number of Minimum Size Separating Vertex Sets in a Graph and How to Find All of Them.
SODA	Determining the Evolutionary Tree.	Sampath Kannan,Eugene L. Lawler,Tandy Warnow	1990	Determining the Evolutionary Tree.
SODA	Competitive Randomized Algorithms for Non-Uniform Problems.	Anna R. Karlin,Mark S. Manasse,Lyle A. McGeoch,Susan S. Owicki	1990	Competitive Randomized Algorithms for Non-Uniform Problems.
SODA	Superlinear Bounds on Matrix Searching.	Maria M. Klawe	1990	Superlinear Bounds on Matrix Searching.
SODA	Stable Husbands.	Donald E. Knuth,Rajeev Motwani,Boris Pittel	1990	Stable Husbands.
SODA	Length-Limited Coding.	Lawrence L. Larmore,Daniel S. Hirschberg	1990	Length-Limited Coding.
SODA	On-Line Dynamic Programming with Applications to the Prediction of RNA Secondary Structure.	Lawrence L. Larmore,Baruch Schieber	1990	On-Line Dynamic Programming with Applications to the Prediction of RNA Secondary Structure.
SODA	Selection and Sorting in Totally Monotone Arrays.	Dina Kravets,James K. Park	1990	Selection and Sorting in Totally Monotone Arrays.
SODA	An Optimal Algorithm for the Maximum Two-Chain Problem.	Ruey-Der Lou,Majid Sarrafzadeh,D. T. Lee	1990	An Optimal Algorithm for the Maximum Two-Chain Problem.
SODA	Split Decomposition of Undirected Graphs.	Tze-Heng Ma,Jeremy Spinrad	1990	Split Decomposition of Undirected Graphs.
SODA	Coloration Neighborhood Structures for General Graph Coloring.	Craig A. Morgenstern,Harry Shapiro	1990	Coloration Neighborhood Structures for General Graph Coloring.
SODA	Suffix Arrays: A New Method for On-Line String Searches.	Udi Manber,Gene Myers	1990	Suffix Arrays: A New Method for On-Line String Searches.
SODA	Using Separation Algorithms in Fixed Dimension.	Carolyn Haibt Norton,Serge A. Plotkin,Éva Tardos	1990	Using Separation Algorithms in Fixed Dimension.
SODA	On Finding Non-Intersecting Paths in Grids and Its Application in Reconfiguring VLSI/WSI Arrays.	Vwani P. Roychowdhury,Jehoshua Bruck	1990	On Finding Non-Intersecting Paths in Grids and Its Application in Reconfiguring VLSI/WSI Arrays.
SODA	Packing Random Items of Three Colors.	Wansoo T. Rhee,Michel Talagrand	1990	Packing Random Items of Three Colors.
SODA	The Bisection Width of Grid Graphs.	Christos H. Papadimitriou,Martha Sideri	1990	The Bisection Width of Grid Graphs.
SODA	Optimal Binary Space Partitions for Orthogonal Objects.	Mike Paterson,F. Frances Yao	1990	A binary space partition, or BSP is a scheme for recursively dividing a configuration of objects by hyperplanes until all objects are separated. BSPs are widely used in computer graphics as the underlying data structure for computations such as real-time hidden-surface removal, ray tracing, and solid modelling. In these applications, the computational cost is directly related to the size of the BSP, ie the toal number of fragments of the objects generated by the partition. Until recently, the question of minimizing the size of BSPs for given inputs had been studied only empirically. We concentrate here on ortogonal objects, a case which arises frequently in practice and deserves special attention. We construct BSPs of linear size for any set of orthogonal line segments in the plane. In three dimensions, BSPs of size O(n^1.5) for any set of n mutually orthogonal line segments or rectangles are constructed. These bounds are optimal and may be contrasted with the omega(n^2) bound for general polygonal objects in R^3.
SODA	Embedding Planar Graphs on the Grid.	Walter Schnyder	1990	Embedding Planar Graphs on the Grid.
SODA	Improved Dual Network Simplex.	Serge A. Plotkin,Éva Tardos	1990	Improved Dual Network Simplex.
SODA	New Techniques for the Union-Find Problems.	Johannes A. La Poutré	1990	New Techniques for the Union-Find Problems.
SODA	Characterization and Algorithms for Greedily Solvable Transportation Problems.	Ron Shamir,Brenda L. Dietrich	1990	Characterization and Algorithms for Greedily Solvable Transportation Problems.
SODA	New Techniques for Some Dynamic Closest-Point and Farthest-Point Problems.	Kenneth J. Supowit	1990	New Techniques for Some Dynamic Closest-Point and Farthest-Point Problems.
SODA	Finding Steiner Forests in Planar Graphs.	Hitoshi Suzuki,Takehiro Akama,Takao Nishizeki	1990	Finding Steiner Forests in Planar Graphs.
SODA	Manhattan Channel Routing with Good Theoretical and Practical Performance.	Charlotte Wieners-Lummer	1990	Manhattan Channel Routing with Good Theoretical and Practical Performance.
SODA	Representing Sets with Constant Time Equality Testing.	Daniel M. Yellin	1990	Representing Sets with Constant Time Equality Testing.
SODA	Proceedings of the First Annual ACM-SIAM Symposium on Discrete Algorithms, 22-24 January 1990, San Francisco, California.	David S. Johnson	1990	Proceedings of the First Annual ACM-SIAM Symposium on Discrete Algorithms, 22-24 January 1990, San Francisco, California.
STOC	Solving Query-Retrieval Problems by Compacting Voronoi Diagrams (Extended Abstract)	Alok Aggarwal,Mark Hansen,Frank Thomson Leighton	1990	Solving Query-Retrieval Problems by Compacting Voronoi Diagrams (Extended Abstract)
STOC	A Separator Theorem for Graphs with an Excluded Minor and its Applications	Noga Alon,Paul D. Seymour,Robin Thomas	1990	A Separator Theorem for Graphs with an Excluded Minor and its Applications
STOC	On-line Algorithms for Path Selection in a Nonblocking Network (Extended Abstract)	Sanjeev Arora,Frank Thomson Leighton,Bruce M. Maggs	1990	On-line Algorithms for Path Selection in a Nonblocking Network (Extended Abstract)
STOC	On the Power of Randomization in Online Algorithms (Extended Abstract)	Shai Ben-David,Allan Borodin,Richard M. Karp,Gábor Tardos,Avi Wigderson	1990	On the Power of Randomization in Online Algorithms (Extended Abstract)
STOC	The Round Complexity of Secure Protocols (Extended Abstract)	Donald Beaver,Silvio Micali,Phillip Rogaway	1990	The Round Complexity of Secure Protocols (Extended Abstract)
STOC	Perfect Zero-Knowledge in Constant Rounds	Mihir Bellare,Silvio Micali,Rafail Ostrovsky	1990	Perfect Zero-Knowledge in Constant Rounds
STOC	The (True) Complexity of Statistical Zero Knowledge	Mihir Bellare,Silvio Micali,Rafail Ostrovsky	1990	The (True) Complexity of Statistical Zero Knowledge
STOC	Learning Boolean Functions in an Infinite Atribute Space (Extended Abstract)	Avrim Blum	1990	Learning Boolean Functions in an Infinite Atribute Space (Extended Abstract)
STOC	Self-Testing/Correcting with Applications to Numerical Problems	Manuel Blum,Michael Luby,Ronitt Rubinfeld	1990	Self-Testing/Correcting with Applications to Numerical Problems
STOC	On the Necessity of Occam Algorithms	Raymond A. Board,Leonard Pitt	1990	On the Necessity of Occam Algorithms
STOC	Online Algorithms for Locating Checkpoints	Marshall W. Bern,Daniel H. Greene,Arvind Raghunathan,Madhu Sudan	1990	Online Algorithms for Locating Checkpoints
STOC	On the Decidability of Sparse Univariate Polynomial Interpolation (Preliminary Version)	Allan Borodin,Prasoon Tiwari	1990	On the Decidability of Sparse Univariate Polynomial Interpolation (Preliminary Version)
STOC	Towards Optimal Simulations of Formulas by Bounded-Width Programs	Richard Cleve	1990	Towards Optimal Simulations of Formulas by Bounded-Width Programs
STOC	On the Dynamic Finger Conjecture for Splay Trees (Extended Abstract)	Richard Cole	1990	On the Dynamic Finger Conjecture for Splay Trees (Extended Abstract)
STOC	Random Walks on Weighted Graphs, and Applications to On-line Algorithms (Preliminary Version)	Don Coppersmith,Peter Doyle,Prabhakar Raghavan,Marc Snir	1990	Random Walks on Weighted Graphs, and Applications to On-line Algorithms (Preliminary Version)
STOC	Deterministic Sorting in Nearly Logarithmic Time on the Hypercube and Related Computers	Robert Cypher,C. Greg Plaxton	1990	Deterministic Sorting in Nearly Logarithmic Time on the Hypercube and Related Computers
STOC	How to Distribute a Dictionary in a Complete Network	Martin Dietzfelbinger,Friedhelm Meyer auf der Heide	1990	How to Distribute a Dictionary in a Complete Network
STOC	The Use of a Synchronizer Yields Maximum Computation Rate in Distributed Networks (Extended Abstract)	Shimon Even,Sergio Rajsbaum	1990	The Use of a Synchronizer Yields Maximum Computation Rate in Distributed Networks (Extended Abstract)
STOC	Computing with Unreliable Information (Preliminary Version)	Uriel Feige,David Peleg,Prabhakar Raghavan,Eli Upfal	1990	Computing with Unreliable Information (Preliminary Version)
STOC	Witness Indistinguishable and Witness Hiding Protocols	Uriel Feige,Adi Shamir	1990	Witness Indistinguishable and Witness Hiding Protocols
STOC	The Wakeup Problem (Extended Abstract)	Michael J. Fischer,Shlomo Moran,Steven Rudich,Gadi Taubenfeld	1990	The Wakeup Problem (Extended Abstract)
STOC	The Information Theory Bound Is Tight for Selection in a Heap	Greg N. Frederickson	1990	The Information Theory Bound Is Tight for Selection in a Heap
STOC	BLASTING through the Information Theoretic Barrier with FUSION TREES	Michael L. Fredman,Dan E. Willard	1990	BLASTING through the Information Theoretic Barrier with FUSION TREES
STOC	Not All Keys Can Be Hashed in Constant Time (Preliminary Version)	Joseph Gil,Friedhelm Meyer auf der Heide,Avi Wigderson	1990	Not All Keys Can Be Hashed in Constant Time (Preliminary Version)
STOC	Optimal Randomized Algorithms for Local Sorting and Set-Maxima	Wayne Goddard,Valerie King,Leonard J. Schulman	1990	Optimal Randomized Algorithms for Local Sorting and Set-Maxima
STOC	Decidability of the Multiplicity Equivalence of Multitape Finite Automata	Tero Harju,Juhani Karhumäki	1990	Decidability of the Multiplicity Equivalence of Multitape Finite Automata
STOC	Pseudo-Random Generators under Uniform Assumptions	Johan Håstad	1990	Pseudo-Random Generators under Uniform Assumptions
STOC	Computing in Quotient Groups	William M. Kantor,Eugene M. Luks	1990	Computing in Quotient Groups
STOC	Towards Overcoming the Transitive-Closure Bottleneck: Efficient Parallel Algorithms for Planar Digraphs	Ming-Yang Kao,Philip N. Klein	1990	Towards Overcoming the Transitive-Closure Bottleneck: Efficient Parallel Algorithms for Planar Digraphs
STOC	An Optimal Algorithm for On-line Bipartite Matching	Richard M. Karp,Umesh V. Vazirani,Vijay V. Vazirani	1990	An Optimal Algorithm for On-line Bipartite Matching
STOC	Efficient Robust Parallel Computations (Extended Abstract)	Zvi M. Kedem,Krishna V. Palem,Paul G. Spirakis	1990	Efficient Robust Parallel Computations (Extended Abstract)
STOC	The Undecidability of the Semi-Unification Problem (Preliminary Report)	A. J. Kfoury,Jerzy Tiuryn,Pawel Urzyczyn	1990	The Undecidability of the Semi-Unification Problem (Preliminary Report)
STOC	"Quantitative Steinitz's Theorems with Applications to Multifingered Grasping"	David G. Kirkpatrick,Bhubaneswar Mishra,Chee-Keng Yap	1990	"Quantitative Steinitz's Theorems with Applications to Multifingered Grasping"
STOC	Leighton-Rao Might Be Practical: Faster Approximation Algorithms for Concurrent Flow with Uniform Capacities	Philip N. Klein,Clifford Stein,Éva Tardos	1990	Leighton-Rao Might Be Practical: Faster Approximation Algorithms for Concurrent Flow with Uniform Capacities
STOC	On the Complexity of Computing a Gröbner Basis for the Radical of a Zero Dimensional Ideal	Yagati N. Lakshman	1990	On the Complexity of Computing a Gröbner Basis for the Radical of a Zero Dimensional Ideal
STOC	The Number Field Sieve	Arjen K. Lenstra,Hendrik W. Lenstra Jr.,Mark S. Manasse,John M. Pollard	1990	The Number Field Sieve
STOC	Approximate Inclusion-Exclusion	Nathan Linial,Noam Nisan	1990	Approximate Inclusion-Exclusion
STOC	The Computational Complexity of Universal Hashing	Yishay Mansour,Noam Nisan,Prasoon Tiwari	1990	The Computational Complexity of Universal Hashing
STOC	Separators in Two and Three Dimensions	Gary L. Miller,William P. Thurston	1990	Separators in Two and Three Dimensions
STOC	Output Sensitive Construction of Levels and Voronoi Diagrams in R^d of Order 1 to k	Ketan Mulmuley	1990	Output Sensitive Construction of Levels and Voronoi Diagrams in R^d of Order 1 to k
STOC	Small-bias Probability Spaces: Efficient Constructions and Applications	Joseph Naor,Moni Naor	1990	Small-bias Probability Spaces: Efficient Constructions and Applications
STOC	Public-key Cryptosystems Provably Secure against Chosen Ciphertext Attacks	Moni Naor,Moti Yung	1990	Public-key Cryptosystems Provably Secure against Chosen Ciphertext Attacks
STOC	Psuedorandom Generators for Space-Bounded Computation	Noam Nisan	1990	Psuedorandom Generators for Space-Bounded Computation
STOC	On Polynomial Time Bounded Truth-Table Reducibility of NP Sets to Sparse Sets	Mitsunori Ogiwara,Osamu Watanabe	1990	On Polynomial Time Bounded Truth-Table Reducibility of NP Sets to Sparse Sets
STOC	Efficient Computation on Oblivious RAMs	Rafail Ostrovsky	1990	Efficient Computation on Oblivious RAMs
STOC	Quantifiers and Approximation (Extended Abstract)	Alessandro Panconesi,Desh Ranjan	1990	Quantifiers and Approximation (Extended Abstract)
STOC	On the Complexity of Local Search (Extended Abstract)	Christos H. Papadimitriou,Alejandro A. Schäffer,Mihalis Yannakakis	1990	On the Complexity of Local Search (Extended Abstract)
STOC	Lower Bounds for the Union-Find and the Split-Find Problem on Pointer Machines	Johannes A. La Poutré	1990	Lower Bounds for the Union-Find and the Split-Find Problem on Pointer Machines
STOC	One-Way Functions are Necessary and Sufficient for Secure Signatures	John Rompel	1990	One-Way Functions are Necessary and Sufficient for Secure Signatures
STOC	Monotone Circuits for Matching Require Linear Depth	Ran Raz,Avi Wigderson	1990	It is proven that monotone circuits computing the perfect matching function on n-vertex graphs require &OHgr;(n) depth. This implies an exponential gap between the depth of monotone and nonmonotone circuits.
STOC	The Analysis of Closed Hashing under Limited Randomness (Extended Abstract)	Jeanette P. Schmidt,Alan Siegel	1990	The Analysis of Closed Hashing under Limited Randomness (Extended Abstract)
STOC	The Discrete Log is Very Discreet	A. W. Schrift,Adi Shamir	1990	The Discrete Log is Very Discreet
STOC	Unique Binary Search Tree Representations and Equality-testing of Sets and Sequences	Rajamani Sundar,Robert Endre Tarjan	1990	This paper studies the problem of representing sets over an ordered universe by unique binary search trees, so that dictionary operations can be performed efficiently on any set. Although efficient randomized solutions to the problem are known, its deterministic complexity has been open. The paper exhibits representations that permit the execution of dictionary operations in optimal deterministic time when the dictionary is sufficiently sparse or sufficiently dense. The results demonstrate an exponential separation between the deterministic and randomized complexities of the problem. Unique representations are applied to obtain efficient data structures for maintaining a dynamic collection of sets/sequences under queries that test the equality of a pair of objects. The data structure for set equality testing tests equality of sets in constant time and processes set updates in $O(\log m)$ amortized time and $O(\log m)$ space, where $m$ denotes the total number of updates performed. It is based on an efficient implementation of cascades of C{\vipt ONS} operations on uniquely stored S-expressions. The data structure for sequence equality testing tests equality of sequences in constant time and processes updates in $O(\sqrt{n \log m}\, + \log m)$ amortized time and $O(\sqrt{n})$ amortized space where $n$ denotes the length of the sequence that is updated and $m$ denotes the total number of updates performed.
STOC	Functions with Bounded Symmetric Communication Complexity and Circuits with \mathop mod m Gates	Mario Szegedy	1990	Functions with Bounded Symmetric Communication Complexity and Circuits with \mathop mod m Gates
STOC	Searching for Primitive Roots in Finite Fields	Victor Shoup	1990	Searching for Primitive Roots in Finite Fields
STOC	Deterministic Sampling-A New Technique for Fast Pattern Matching	Uzi Vishkin	1990	Deterministic Sampling-A New Technique for Fast Pattern Matching
STOC	Optimal Disk I/O with Parallel Block Transfer (Extended Abstract)	Jeffrey Scott Vitter,Elizabeth A. M. Shriver	1990	Optimal Disk I/O with Parallel Block Transfer (Extended Abstract)
STOC	A Technique for Lower Bounding the Cover Time	David Zuckerman	1990	A Technique for Lower Bounding the Cover Time
STOC	Coherent Functions and Program Checkers (Extended Abstract)	Andrew Chi-Chih Yao	1990	Coherent Functions and Program Checkers (Extended Abstract)
STOC	Proceedings of the Twenty Second Annual ACM Symposium on Theory of Computing, 14-16 May 1990, Baltimore, Maryland, USA		1990	Proceedings of the Twenty Second Annual ACM Symposium on Theory of Computing, 14-16 May 1990, Baltimore, Maryland, USA
FOCS	Polynomial Algorithms for LP over a Subring of the Algebraic Integers with Applications to LP with Circulant Matrices	Ilan Adler,Peter A. Beling	1991	It is shown that a modified variant of the interior point method can solve linear programs (LPs) whose coefficients are real numbers from a subring of the algebraic integers. By defining the encoding size of such numbers to be the bit size of the integers that represent them in the subring, it is proved that the modified algorithm runs in time polynomial in the encoding size of the input coefficients, the dimension of the problem, and the order of the subring. The Tardos scheme is then extended to this case, yielding a running time that is independent of the objective and right-hand side data. As a consequence of these results, it is shown that LPs with real circulant coefficient matrices can be solved in strongly polynomial time. It is also shown how the algorithm can be applied to LPs whose coefficients belong to the extension of the integers by a fixed set of square roots.
FOCS	A parallel algorithmic version of the Local Lemma	Noga Alon	1991	The Lovasz local lemma (1975) is a tool that enables one to show that certain events hold with positive, though very small probability. It often yields existence proofs of results without supplying any efficient way of solving the corresponding algorithmic problems. J. Beck has recently found a method for converting some of these existence proofs into efficient algorithmic procedures, at the cost of losing a little in the estimates, but his method does not seem to be parallelizable. His technique is modified to achieve an algorithmic version that can be parallelized, thus providing deterministic NC/sup 1/ algorithms for various interesting algorithmic search problems.
FOCS	On the Exponent of the All Pairs Shortest Path Problem	Noga Alon,Zvi Galil,Oded Margalit	1991	On the Exponent of the All Pairs Shortest Path Problem
FOCS	Exact Learning of Read-Twice DNF Formulas (Extended Abstract)	Howard Aizenstein,Leonard Pitt	1991	A polynomial-time algorithm is presented for exactly learning the class of read-twice DNF formulas, i.e. Boolean formulas in disjunctive normal form where each variable appears at most twice. The (standard) protocol used allows the learning algorithm to query whether a given assignment of Boolean variables satisfies the DNF formula to be learned (membership queries), as well as to obtain counterexamples to the correctness of its current hypothesis which can be any arbitrary DNF formula (equivalence queries). The formula output by the learning algorithm is logically equivalent to the formula to be learned.
FOCS	Adaptive Dictionary Matching	Amihood Amir,Martin Farach	1991	Semiadaptive and fully adaptive dictionary matching algorithms are presented. In the fully adaptive algorithm, the dictionary is processed in time O( mod D mod log mod D mod ). Inserting a new pattern P/sub k+1/ into the dictionary can be done in time O mod P/sub K+1/ mod log mod D mod ). A dictionary pattern can be deleted in time O(log mod D mod ). Text scanning is accomplished in time O( mod T mod log mod D mod ). Also presented is a parallel version of the algorithm with optimal speedup for the dictionary construction and pattern addition phase and a logarithmic overhead in the text scan phase. The method used incorporates a new way of using suffix trees as well as a new data structure in which the suffix tree is embedded for the sequential algorithm.
FOCS	Faster Uniquely Represented Dictionaries	Arne Andersson,Thomas Ottmann	1991	The authors present a solution to the dictionary problem where each subset of size n of an ordered universe is represented by a unique structure, containing a (unique) binary search tree. The structure permits the execution of search, insert, and delete operations in O(n/sup 1/3/) time in the worst case. They also give a general lower bound, stating that for any unique representation of a set in a graph of, bounded outdegree, one of the operations search or update must require a cost of Omega (n/sup 1/3/) Therefore, the result sheds new light on previously claimed lower bounds for unique binary search tree representations.
FOCS	Asymptotically Optimal PRAM Emulation on Faulty Hypercubes (Extended Abstract)	Yonatan Aumann,Michael Ben-Or	1991	"A scheme for emulating the parallel random access machine (PRAM) on a faulty hypercube is presented. All components of the hypercube, including the memory modules, are assumed to be subject to failure. The faults may occur at any time during the emulation and the system readjusts dynamically. The scheme, which rests on L.G. Valiant's BSP model (1990), is the first to achieve optimal and work-preserving PRAM emulation on a dynamically faulty network."
FOCS	Self-Stabilization By Local Checking and Correction (Extended Abstract)	Baruch Awerbuch,Boaz Patt-Shamir,George Varghese	1991	The first self-stabilizing end-to-end communication protocol and the most efficient known self-stabilizing network reset protocol are introduced. A simple method of local checking and correction, by which distributed protocols can be made self-stabilizing without the use of unbounded counters, is used. The self-stabilization model distinguishes between catastrophic faults that abstract arbitrary corruption of global state, and other restricted kinds of anticipated faults. It is assumed that after the execution starts there are no further catastrophic faults, but the anticipated faults may continue to occur.
FOCS	The Maintenance of Common Data in a Distributed System	Baruch Awerbuch,Leonard J. Schulman	1991	A basic task in distributed computation is the maintenance at each processor of the network, of a current and accurate copy of a common database. Such a database must be updated in the wake of locally generated changes to its contents. Due to previous disconnections of parts of the network, a maintenance protocol may need to update processors holding widely varying versions of the database. A deterministic protocol, which has only polylogarithmic overhead in its time and communication complexities, is provided for this problem. Previous deterministic solutions required polynomial overhead in at least one of these measures.
FOCS	Distributed Program Checking: a Paradigm for Building Self-stabilizing Distributed Protocols (Extended Abstract)	Baruch Awerbuch,George Varghese	1991	The notion of distributed program checking as a means of making a distributed algorithm self-stabilizing is explored. A compiler that converts a deterministic synchronous protocol pi for static networks into a self-stabilizing version of pi for dynamic networks is described. If T/sub pi / is the time complexity of pi and D is a bound on the diameter of the final network, the compiled version of pi stabilizes in time O(D+T/sub pi /) and has the same space complexity as pi . The general method achieves efficient results for many specific noninteractive tasks. For instance, solutions for the shortest paths and spanning tree problems take O(D) to stabilize, an improvement over the previous best time of O(D/sup 2/).
FOCS	Approximate Representation Theory of Finite Groups	László Babai,Katalin Friedl	1991	The asymptotic stability and complexity of floating point manipulation of representations of a finite group G are considered, especially splitting them into irreducible constituents and deciding their equivalence. Using rapid mixing estimates for random walks, the authors analyze a classical algorithm by J. Dixon (1970). They find that both its stability and complexity critically depend on the diameter d=diam(G,S) (S is the set that generates G). They propose a worst-case speedup by using Erdos-Renyi generators and modifying the Dixon averaging method. The overall effect in asymptotic complexity is a guaranteed (n log mod G mod )/sup O(1)/ running time.
FOCS	On-line Scheduling in the Presence of Overload	Sanjoy K. Baruah,Gilad Koren,Bhubaneswar Mishra,Arvind Raghunathan,Louis E. Rosier,Dennis Shasha	1991	The preemptive scheduling of sporadic tasks on a uniprocessor is considered. A task may arrive at any time, and is characterized by a value that reflects its importance, an execution time that is the amount of processor time needed to completely execute the task, and a deadline by which the task is to complete execution. The goal is to maximize the sum of the values of the completed tasks. An online scheduling algorithm that achieves optimal performance when the system is underloaded and provides a nontrivial performance guarantee when the system is overloaded is designed. The algorithm is implemented using simple data structures to run at a cost of O(log n) time per task, where n bounds the number of tasks in the system at any instant. Upper bounds on the best performance guarantee obtainable by an online algorithm in a variety of settings are derived.
FOCS	Languages that Are Easier than their Proofs	Richard Beigel,Mihir Bellare,Joan Feigenbaum,Shafi Goldwasser	1991	Languages in NP are presented for which it is harder to prove membership interactively than it is to decide this membership. Similarly, languages where checking is harder than computing membership are presented. Under assumptions about triple-exponential time, incoherent sets in NP are constructed. Without any assumptions, incoherent sets are constructed in DSPACE (n to the log n), yielding the first uncheckable and non-random-self-reducible sets in that space.
FOCS	On ACC	Richard Beigel,Jun Tarui	1991	"It has been shown by A. Yao (1990) that every language in ACC is recognized by a sequence of depth-2 probabilistic circuits with a symmetric gate at the root and n/sup polylog/(n) AND gates of fan-in polylog (n) at the leaves. The authors simplify Yao's proof and strengthen his results: every language in ACC is recognized by a sequence of depth-2 deterministic circuits with a symmetric gate at the root and n/sup polylog/(n) AND gates of fan-in polylog(n) at the leaves. They also analyze and improve modulus-amplifying polynomials constructed by S. Toda (1989) and Yao: this yields smaller circuits in Yao's and the present results on ACC."
FOCS	Lower Bounds for Data Structure Problems on RAMs (Extended Abstract)	Amir M. Ben-Amram,Zvi Galil	1991	"A technique is described for deriving lower bounds and tradeoffs for data structure problems. Two quantities are defined. The output variability depends only on the model of computation. It characterizes in some sense the power of a model. The problem variability depends only on the problem under consideration. It characterizes in some sense the difficulty of the problem. The first theorem states that if a model's output variability is smaller than the problem variability, a lower bound on the worst case (average case) time for the problem follows. A RAM that can add, subtract and compare unbounded integers is considered. The second theorem gives an upper bound on the output variability of this model. The two theorems are used to derive lower bounds for the union-find problem in this RAM."
FOCS	Computing Sums of Radicals in Polynomial Time	Johannes Blömer	1991	For a certain sum of radicals the author presents a Monte Carlo algorithm that runs in polynomial time to decide whether the sum is contained in some number field Q( alpha ), and, if so, its coefficient representation in Q( alpha ) is computed. As a special case the algorithm decides whether the sum is zero. The main algorithm is based on a subalgorithm which is of interest in its own right. This algorithm uses probabilistic methods to check for an element beta of an arbitrary (not necessarily) real algebraic number field Q( alpha ) and some positive rational integer r whether there exists an rth root of beta in Q( alpha ).
FOCS	Checking the Correctness of Memories	Manuel Blum,William S. Evans,Peter Gemmell,Sampath Kannan,Moni Naor	1991	The notion of program checking is extended to include programs that alter their environment, in particular, programs that store and retrieve data from memory. The model considered allows the checker a small amount of reliable memory. The checker is presented with a sequence of requests (online) to a data structure which must reside in a large but unreliable memory. The data structure is viewed as being controlled by an adversary. The checker is to perform each operation in the input sequence using its reliable memory and the unreliable data structure so that any error in the operation of the structure will be detected by the checker with high probability. Checkers for various data structures are presented. Lower bounds of log n on the amount of reliable memory needed by these checkers, where n is the size of the structure, are proved.
FOCS	Subquadratic Zero-Knowledge	Joan Boyar,Gilles Brassard,René Peralta	1991	The communication complexity of zero-knowledge proof systems is improved. Let C be a Boolean circuit of size n. Previous zero-knowledge proof systems for the satisfiability of C require the use of Omega (kn) bit commitments in order to achieve a probability of undetected cheating not greater than 2/sup -k/. In the case k=n, the communication complexity of these protocols is therefore Omega (n/sup 2/) bit commitments. A zero-knowledge proof is given for achieving the same goal with only O(n/sup m/+k square root n/sup m/) bit commitments, where m=1+ epsilon /sub n/ and epsilon /sub n/ goes to zero as n goes to infinity. In the case k=n, this is O(n square root n/sup m/). Moreover, only O(k) commitments need ever be opened, which is interesting if committing to a bit is significantly less expensive than opening a commitment.
FOCS	Size-Depth Tradeoffs for Algebraic Formulae	Nader H. Bshouty,Richard Cleve,Wayne Eberly	1991	Some tradeoffs between the size and depth of algebraic formulas are proved. It is shown that, for any fixed in >0, any algebraic formula of size S can be converted into an equivalent formula of depth O(log S) and size O(S/sup 1+ in /). This result is an improvement over previously known results where, to obtain the same depth bound, the formula size is Omega (S/sup alpha /), with alpha >or=2.
FOCS	An Optimal Convex Hull Algorithm and New Results on Cuttings (Extended Abstract)	Bernard Chazelle	1991	An optimal algorithm for computing hyperplane cuttings is given. It results in a new kind of cutting, which enjoys all the properties of the previous ones and, in addition, can be refined by composition. An optimal algorithm for computing the convex hull of a finite point set in any fixed dimension is also given.
FOCS	How to Learn an Unknown Environment (Extended Abstract)	Xiaotie Deng,Tiko Kameda,Christos H. Papadimitriou	1991	The authors consider the problem faced by a newborn that must explore and learn an unknown room with obstacles in it. They seek algorithms that achieve a bounded ratio of the worst-case distance traversed in order to see all visible points of the environment (thus creating a map), divided by the optimum distance needed to verify the map. The situation is complicated by the fact that the latter offline problem (optimally verifying a map) is NP-hard and thus must be solved approximately. Although the authors show that there is no such competitive algorithm for general obstacle courses, they give a competitive algorithm for the case of a polygonal room with a bounded number of obstacles in it.
FOCS	On the Complexity of Computing the Homology Type of a Triangulation	Bruce Randall Donald,Davied Renpan Chang	1991	An algorithm for computing the homology type of a triangulation is analyzed. By triangulation is meant a finite simplicial complex; its homology type is given by its homology groups (with integer coefficients). The algorithm could be used in computer-aided design to tell whether two finite-element meshes or Bezier-spline surfaces are of the same topological type, and whether they can be embedded in R/sup 3/. Homology computation is a pure combinatorial problem of considerable intrinsic interest. While the worst-case bounds obtained for this algorithm are poor, it is argued that many triangulations (in general) and virtually all triangulations in design are very sparse in a particular sense. This sparseness measure is formalized, and a probabilistic analysis of the sparse case is performed to show that the expected running time, of the algorithm is roughly quadratic in the geometric complexity (number of simplices) and linear in the dimension.
FOCS	On Better Heuristic for Euclidean Steiner Minimum Trees (Extended Abstract)	Ding-Zhu Du,Yanjun Zhang,Qing Feng	1991	Finding a shortest network interconnecting a given set of points in the Euclidean plane (a Steiner minimum tree) is known to be NP-hard. It is shown that there exists a polynomial-time heuristic with a performance ratio bigger than square root 3/2.
FOCS	A Quadratic Time Algorithm for The MinMax Length Triangulation (Extended Abstract)	Herbert Edelsbrunner,Tiow Seng Tan	1991	A Quadratic Time Algorithm for The MinMax Length Triangulation (Extended Abstract)
FOCS	Communication Complexity Towards Lower Bounds on Circuit Depth	Jeff Edmonds,Steven Rudich,Russell Impagliazzo,Jiri Sgall	1991	Communication Complexity Towards Lower Bounds on Circuit Depth
FOCS	Tree Automata, Mu-Calculus and Determinacy (Extended Abstract)	E. Allen Emerson,Charanjit S. Jutla	1991	Tree Automata, Mu-Calculus and Determinacy (Extended Abstract)
FOCS	A General Approach to Removing Degeneracies	Ioannis Z. Emiris,John F. Canny	1991	Algorithms modeled as algebraic branching programs, with inputs from an infinite ordered field, are studied. Direct perturbations on the input, so that an algorithm designed under the assumption of nondegeneracy can be applied to all inputs, are described. A deterministic method for algorithms with determinant tests and a randomized one for arbitrary test expressions are defined. They both incur extra complexity factors that are constant in several cases. Moreover, polynomial and exponential time algorithms always remain in the same complexity class while being enhanced with the power to execute on arbitrary inputs. Both methods are distinguished by their conceptual elegance and are significantly faster than previous ones.
FOCS	Dynamic Three-Dimensional Linear Programming	David Eppstein	1991	Linear programming optimizations on the intersection of k polyhedra in R/sup 3/, represented by their outer recursive decompositions, are performed in expected time O(k log k log n+ square root k log k log/sup 3/ n). This result is used to derive efficient algorithms for dynamic linear programming problems ill which constraints are inserted and deleted, and queries must optimize specified objective functions. As an application, an improved solution to the planar 2-center problem, is described.
FOCS	Amortized Communication Complexity (Preliminary Version)	Tomás Feder,Eyal Kushilevitz,Moni Naor	1991	The authors study the direct sum problem with respect to communication complexity: Consider a function f: D to (0, 1), where D contained in (0, 1)/sup n/*(0, 1)/sup n/. The amortized communication complexity of f, i.e. the communication complexity of simultaneously computing f on l instances, divided by l is studied. The authors present, both in the deterministic and the randomized model, functions with communication complexity Theta (log n) and amortized communication complexity O(1). They also give a general lower bound on the amortized communication complexity of any function f in terms of its communication complexity C(f).
FOCS	Approximating Clique is Almost NP-Complete (Preliminary Version)	Uriel Feige,Shafi Goldwasser,László Lovász,Shmuel Safra,Mario Szegedy	1991	The computational complexity of approximating omega (G), the size of the largest clique in a graph G, within a given factor is considered. It is shown that if certain approximation procedures exist, then EXPTIME=NEXPTIME and NP=P.
FOCS	Dynamic Scheduling on Parallel Machines	Anja Feldmann,Jiri Sgall,Shang-Hua Teng	1991	The problem of online job scheduling on various parallel architectures is studied. An O((log log n)/sup 1/2/)-competitive algorithm for online dynamic scheduling on an n*n mesh is given. It is proved that this algorithm is optimal up to a constant factor. The algorithm is not greedy, and the lower bound proof shows that no greedy-like algorithm can be very good. The upper bound result can be generalized to any fixed-dimensional meshes. Competitive scheduling algorithms for other architectures are given.
FOCS	Competitive Algorithms for Layered Graph Traversal	Amos Fiat,Dean P. Foster,Howard J. Karloff,Yuval Rabani,Yiftach Ravid,Sundar Vishwanathan	1991	A layered graph is a connected, weighted graph whose vertices are partitioned into sets L/sub 0/=(s), L/sub 1/, L/sub 2/, . . ., and whose edges run between consecutive layers. Its width is max( mod L/sub i/ mod ). In the online layered graph traversal problem, a searcher starts at s in a layered graph of unknown width and tries to reach a target vertex t; however, the vertices in layer i and the edges between layers i-1 and i are only revealed when the searcher reaches layer i-1. The authors give upper and lower bounds on the competitive ratio of layered graph traversal algorithms. They give a deterministic online algorithm that is O(9w)-competitive on width-w graphs and prove that for no w can a deterministic online algorithm have a competitive ratio better than 2w/sup -2/ on width-w graphs. They prove that for all w, w/2 is a lower bound on the competitive ratio of any randomized online layered graph traversal algorithm. For traversing layered graphs consisting of w disjoint paths tied together at a common source, they give a randomized online algorithm with a competitive ratio of O(log w) and prove that this is optimal up to a constant factor.
FOCS	Ambivalent Data Structures for Dynamic 2-Edge-Connectivity and k Smallest Spanning Trees	Greg N. Frederickson	1991	Ambivalent data structures are presented for several problems on undirected graphs. They are used in finding the k smallest spanning trees of a weighted undirected graph in O(m log beta (m,n)+min(k/sup 3/2/, km/sup 1/2/)) time, where m is the number of edges and n the number of vertices in the graph. The techniques are extended to find the k smallest spanning trees in an embedded planar graph in O(n+k(log n)/sup 3/) time. Ambivalent data structures are also used to maintain dynamically 2-edge-connectivity information. Edges and vertices can be inserted or deleted in O(m/sup 1/2/) time, and a query as to whether two vertices are in the same 2-edge-connected component can be answered in O(log n) time, where m and n are understood to be the current number of edges and vertices, respectively. Again, the techniques are extended to maintain an embedded planar graph so that edges and vertices can be inserted or deleted in O((log n)/sup 3/) time, and a query answered in O(log n) time.
FOCS	Lower Bounds for the Complexity of Reliable Boolean Circuits with Noisy Gates	Anna Gál	1991	It is proved that the reliable computation of any Boolean function with, sensitivity s requires Omega (s log s) gates if the gates of the circuit fail independently with a fixed positive probability. The Omega (s log s) bound holds even if s is the block sensitivity instead of the sensitivity of the Boolean function. Some open problems are mentioned.
FOCS	Applications of a Poset Representation to Edge Connectivity and Graph Rigidity	Harold N. Gabow	1991	A poset representation for a family of sets defined by a labeling algorithm is investigated. Poset representations are given for the family of minimum cuts of a graph, and it is shown how to compute them quickly. The representations are the starting point for algorithms that increase the edge connectivity of a graph, from lambda to a given target tau = lambda + delta , adding the fewest edges possible. For undirected graphs the time bound is essentially the best-known bound to test tau -edge connectivity; for directed graphs the time bound is roughly a factor delta more. Also constructed are poset representations for the family of rigid subgraphs of a graph, when graphs model structures constructed from rigid bars. The link between these problems is that they all deal with graphic matroids.
FOCS	Fault-tolerant Computation in the Full Information Model (Extended Abstract)	Oded Goldreich,Shafi Goldwasser,Nathan Linial	1991	Efficient two-party protocols for fault-tolerant computation of any two-argument function are presented. It is proved that the influence of a dishonest player in these protocols is the minimum one possible (up to polylogarithmic factors). Also presented are efficient m-party fault-tolerant protocols for sampling a general distribution (m>or=2). Efficient m-party protocols for computation of any m-argument function are given, and it is proved for these protocols that for most functions, the influence of any t dishonest players on the outcome of the protocol is the minimum one possible (up to polylogarithmic factors).
FOCS	Efficient Exponentiation in Finite Fields (Extended Abstract)	Joachim von zur Gathen	1991	Optimal sequential and parallel algorithms for exponentiation in a finite field extension are presented, assuming that a normal basis over the ground field is given.
FOCS	Quantifying Knowledge Complexity	Oded Goldreich,Erez Petrank	1991	One of the many contributions of the paper of Goldwasser, Micali and Rackoff is the introduction of the notion of knowledge complexity. Knowledge complexity zero (also known as zero-knowledge) seems to have received most of the attention of the authors and all the attention of their followers. Unfortunately, the formulation of knowledge complexity (greater than zero) as appearing in that pioneering paper seems to be inadequate. In this paper, we present several alternative definitions of knowledge complexity and investigate the relations between them.
FOCS	A Deterministic Parallel Algorithm for Planar Graphs Isomorphism	Hillel Gazit	1991	A deterministic parallel algorithm for determining whether two planar graphs are isomorphic is presented. The algorithm needs O(log n) separators that have to be computed one after the other. The running time is T=O(log/sup 3/ n) time for finding separators, and the processors count is n/sup 1.5/ log n/T. It is also shown that every planar graph has a separator, and a parallel algorithm for finding the separator is given.
FOCS	Towards a Theory of Nearly Constant Time Parallel Algorithms	Joseph Gil,Yossi Matias,Uzi Vishkin	1991	It is demonstrated that randomization is an extremely powerful tool for designing very fast and efficient parallel algorithms. Specifically, a running time of O(lg* n) (nearly-constant), with high probability, is achieved using n/lg* n (optimal speedup) processors for a wide range of fundamental problems. Also given is a constant time algorithm which, using n processors, approximates the sum of n positive numbers to within an error which is smaller than the sum by an order of magnitude. A variety of known and new techniques are used. New techniques, which are of independent interest, include estimation of the size of a set in constant time for several settings, and ways for deriving superfast optimal algorithms from superfast nonoptimal ones.
FOCS	Using Approximation Algorithms to Design Parallel Algorithms that May Ignore Processor Allocation (Preliminary Version)	Michael T. Goodrich	1991	A framework is presented for designing parallel algorithms that may ignore processor allocation. A number of fast approximation algorithms are developed, and it is shown how to use these algorithms to simulate any algorithm that fits this framework in a work-preserving fashion on a randomized CRCW PRAM. Several applications of the approach to parallel computational geometry are given.
FOCS	An Approximation Algorithm for the Number of Zeros of Arbitrary Polynomials over GF[q]	Dima Grigoriev,Marek Karpinski	1991	The authors design the first polynomial time (for an arbitrary and fixed field GF(q)) ( in , delta )-approximation algorithm for the number of zeros of arbitrary polynomial f(x/sub 1/. . . x/sub n/) over GF(q). It gives the first efficient method for estimating the number of zeros and nonzeros of multivariate polynomials over small finite fields other than GF(2) (like GF(3)), the case important for various circuit approximation techniques. The algorithm is based on the estimation of the number of zeros of an arbitrary polynomial f(x/sub 1/. . .,x/sub n/) over GF(q) in the function of the number m of its terms. The bounding ratio is proved to be m/sup (q-1)/log/sup q/.
FOCS	Computing Planar Intertwines	Arvind Gupta,Russell Impagliazzo	1991	"The proof of Wagner's conjecture by N. Robertson and P. Seymour gives a finite description of any family of graphs which is closed under the minor ordering, called the obstructions of the family. Since the intersection and the union of two minor closed graph families are again a minor closed graph family, an interesting question is that of computing the obstructions of the new family given the obstructions for the original two families. It is easy to compute the obstructions of the intersection, but, until very recently, it was an open problem to compute the obstructions of the union. It is shown that if the original families are planar, then the obstructions of the union are no larger than n to the O(n/sup 2/) power, where n is the size of the largest obstruction of the original family."
FOCS	Low Contention Linearizable Counting	Maurice Herlihy,Nir Shavit,Orli Waarts	1991	The linearizable counting problem requires asynchronous concurrent processes to assign themselves successive values so that the order of the values assigned reflects the real-time order in which they were requested. It is shown that the problem can be solved without funneling all processes through a common memory location. Two new constructions for linearizable counting networks, data structures that solve the linearizable counting problem, are given. The first construction is nonblocking: some process takes a value after O(n) network gates have been traversed. The second construction is wait-free: it guarantees that each process takes a value after it traverses O(wn) gates, where w is a parameter affecting contention. It is shown that in any nonblocking or wait-free linearizable counting network, processes must traverse an average of Omega (n) gates, and so the constructions are close to optimal. A simpler and more efficient network is constructed by giving up the robustness requirements and allowing processes to wait for one another.
FOCS	The Art Gallery Theorem for Polygons With Holes	Frank Hoffmann,Michael Kaufmann,Klaus Kriegel	1991	Art gallery problems which have been extensively studied over the last decade ask how to station a small (minimum) set of guards in a polygon such that every point of the polygon is watched by at least one guard. The graph-theoretic formulation and solution to the gallery problem for polygons in standard form is given. A complexity analysis is carried out, and open problems are discussed.
FOCS	A Linear Time Algorithm for Triconnectivity Augmentation (Extended Abstract)	Tsan-sheng Hsu,Vijaya Ramachandran	1991	The problem of finding the smallest set of edges whose addition triconnects an undirected graph is considered. This is a fundamental graph-theoretic problem that has applications in designing reliable networks and fault-tolerant computing. A linear time sequential algorithm is given for the problem. This is a substantial improvement over the best previous algorithm for this problem, which runs in O(n(n+m)/sup 2/) time on a graph with n vertices and m edges.
FOCS	Efficient Algorithms for the Riemann-Roch Problem and for Addition in the Jacobian of a Curve (Extended Abstract)	Ming-Deh A. Huang,Doug Ierardi	1991	Several computational problems concerning the construction of rational functions and intersecting curves over a given curve are studied. The first problem is to construct a rational function with prescribed zeros and poles over a given curve. More precisely, let C be a smooth projective curve and assume as given an affine plane model F(x,y)=0 for C, a finite set of points P/sub i/=(X/sub i/, Y/sub i/) with F (X/sub i/, Y/sub i/)=0 and natural numbers n/sub i/, and a finite set of points Q/sub i/=(X/sub j/, Y/sub j/) with F(X/sub j/, Y/sub j/)=0 and natural numbers m/sub j/. The problem is to decide whether there is a rational function which has zeros at each point P/sub i/ of order n/sub i/, poles at each Q/sub j/ of order m/sub j/, and no zeros or poles anywhere else on C. One would also like to construct such a rational function if one exists. An efficient algorithm for solving this problem when the given plane curve has only ordinary multiple points is given.
FOCS	Connected Components in O(\lg^3/2 |V|) Parallel Time for the CREW PRAM	Donald B. Johnson,Panagiotis Takis Metaxas	1991	Connected Components in O(\lg^3/2 |V|) Parallel Time for the CREW PRAM
FOCS	Better Expansion for Ramanujan Graphs	Nabil Kahale	1991	The expansion properties of regular graphs are investigated. The best previously known expansion of subsets of linear size of explicit k-regular graphs is k/4. This bound is achieved by nonbipartite Ramanujan graphs of degree k=p+1, which have the property that all but the largest eigenvalue have absolute value at most 2 square root p. The expansion coefficient for linear subsets for nonbipartite Ramanujan graphs is improved to 3(k-2)/8. Other results are established, including improved results about random walks on expanders.
FOCS	On-Line Maintenance of the Four-Connected Components of a Graph (Extended Abstract)	Arkady Kanevsky,Roberto Tamassia,Giuseppe Di Battista,Jianer Chen	1991	On-Line Maintenance of the Four-Connected Components of a Graph (Extended Abstract)
FOCS	"A New Characterization of Mehlhorn's Polynomial Time Functionals (Extended Abstract)"	Bruce M. Kapron,Stephen A. Cook	1991	"A. Cobham (1964) presented a machine-independent characterization of computational feasibility, via inductive definition. R. Constable (1973) was apparently the first to consider the notion of feasibility for type 2 functionals. K. Mehlhorn's (1976) study of feasible reducibilities proceeds from Constable's work. Here, a class of polytime operators is defined, using a generalization of Cobham's definition. The authors provide an affirmative answer to the question of whether there is a natural machine based definition of Mehlhorn's class."
FOCS	Finding the Hidden Path: Time Bounds for All-Pairs Shortest Paths	David R. Karger,Daphne Koller,Steven J. Phillips	1991	The all-pairs shortest paths problem in weighted graphs is investigated. An algorithm called the hidden paths algorithm, which finds these paths in time O(m*+n n/sup 2/ log n), where m* is the number of edges participating in shortest paths, is presented. It is argued that m* is likely to be small in practice, since m*=O(n log n) with high probability for many probability distributions on edge weights. An Omega (mn) lower bound on the running time of any path-comparison-based algorithm for the all-pairs shortest paths problem is proved.
FOCS	Progress Measures for Complementation of omega-Automata with Applications to Temporal Logic	Nils Klarlund	1991	A new approach to complementing omega -automata, which are finite-state automata defining languages of infinite words, is given. Instead of using usual combinatorial or algebraic properties of transition relations, it is shown that a graph-theoretic approach based on the notion of progress measures is a potent tool for complementing omega -automata. Progress measures are applied to the classical problem of complementing Buchi automata, and a simple method is obtained. The technique applies to Streett automata, for which an optimal complementation method is also obtained. As a consequence, it is seen that the powerful temporal logic ETLs is much more tractable than previously thought.
FOCS	Walking an Unknown Street with Bounded Detour	Rolf Klein	1991	A polygon with two distinguished vertices, s and g, is called a street if the two boundary chains from s to g are mutually weakly visible. For a mobile robot with onboard vision, a strategy for finding a short path from s to g in a street not known in advance is described, and it is proved that the length of the path created does not exceed 1+3 pi /2 times the length of the shortest path from s to g. Experiments suggest that the strategy is much better than this, as no ratio bigger than 1.8 has yet been observed. This is complemented by a lower bound of 1.41 for the relative detour each strategy can be forced to generate.
FOCS	Concentrated Regular Data Streams on Grids: Sorting and Routing Near to the Bisection Bound	Manfred Kunde	1991	Sorting and routing on r-dimensional n*. . .*n grids of processors is studied. Deterministic algorithms are presented for h-h problems, h>or=1, where each processor initially and finally contains h elements. It is shown that the classical 1-1 sorting can be solved with (2r-1.5)n+o(n) transport steps, i.e. in about 2.5n steps for r=2. The general h-h sorting problem, h>or=4r-4 can be solved within a number of transport steps that asymptotically differs by a factor of at most 3 from the trivial bisection bound. Furthermore, the bisection bound is asymptotically tight for sequences of h permutation routing problems, h=4cr, c>or=1, and for so-called offline routing.
FOCS	Fully Parallelized Multi Prover Protocols for NEXP-Time (Extended Abstract)	Dror Lapidot,Adi Shamir	1991	A major open problem in the theory of multiprover protocols is to characterize the languages which can be accepted by fully parallelized protocols which achieve an exponentially low probability of cheating in a single round. The problem was motivated by the observation that the probability of cheating the n parallel executions of a multiprover protocol can be exponentially higher than the probability of cheating in n sequential executions of the same protocol. The problem is solved by proving that any language in NEXP-time has a fully parallelized multiprover protocol. By combining this result with a fully parallelized version of the protocol of M. Ben-Or et al. (ACM Symp. on Theory of Computing, 1988), a one-round perfect zero-knowledge protocol (under no cryptographic assumptions) can be obtained for every NEXPTIME language.
FOCS	Variation Ranks of Communication Matrices and Lower Bounds for Depth Two Circuits Having Symmetric Gates with Unbounded Fan-In	Matthias Krause,Stephan Waack	1991	An exponential lower bound for depth two circuits with arbitrary symmetric gates in the bottom level and with a MOD/sub m/-gate in the top level is proved. This solves a problem posed by R. Smolensky (1990). The method uses the variation rank of communication matrices. A variant of this method is used for deriving lower bounds for the size of depth-two circuits having a threshold gate at the top.
FOCS	Highly Fault-Tolerant Sorting Circuits	Frank Thomson Leighton,Yuan Ma,C. Greg Plaxton	1991	The problem of constructing a sorting circuit that will work well even if a constant fraction of its comparators fail at random is addressed. Two types of comparator failure are considered: passive failures, which result in no comparison being made (i.e., the items being compared are output in the same order that they are input), and destructive failures, which result in the items being output in the reverse of the correct order. In either scenario, it is assumed that each comparator is faulty with some constant probability rho , and a circuit is said to be fault-tolerant if it performs some desired function with high probability given that each comparator fails with probability rho . One passive and two destructive circuits are constructed.
FOCS	Efficient Algorithms for Dynamic Allocation of Distributed Memory	Frank Thomson Leighton,Eric J. Schwabe	1991	Efficient Algorithms for Dynamic Allocation of Distributed Memory
FOCS	Reporting Points in Halfspaces	Jirí Matousek	1991	The author considers the halfspace range reporting problem: Given a finite set P of points in E/sup d/, preprocess it so that given a query halfspace gamma , the points of p intersection gamma can be reported efficiently. It is shown that, with almost linear storage, this problem can be solved substantially more efficiently than the more general simplex range searching problem. A data structure for halfspace range reporting in dimensions d>or=4 is given. It uses O(n log log n) space and O (n log n) deterministic preprocessing time. The query time is also given. Results for the halfspace emptiness problem, where one only wants to know whether P intersection gamma is empty, are also presented.
FOCS	Discrepancy and epsilon-approximations for bounded VC-dimension	Jirí Matousek,Emo Welzl,Lorenz Wernisch	1991	Let (X, R) be a set system on an n-point set X. For a two-coloring on X, its discrepancy is defined as the maximum number by which the occurrences of the two colors differ in any set in R. It is shown that if for any m-point subset Y contained in X the number of distinct subsets induced by R on Y is bounded by O(m/sup d/) for a fixed integer d is a coloring with discrepancy bounded by O(n/sup 1/2-1/2d/ (log n)/sup 1+1/2d/). Also, if any subcollection of m sets of R partitions the points into at most O(m/sup d/) classes, then there is a coloring with discrepancy at most O(n/sup 1/2-1/2d/ n). These bounds imply improved upper bounds on the size of in -approximations for (X, R). All of the bounds are tight up to polylogarithmic factors in the worst case. The results allow the generalization of several results of J. Beck (1984) bounding the discrepancy in certain geometric settings to the case when the discrepancy is taken relative to an arbitrary measure.
FOCS	Fat Triangles Determine Linearly Many Holes	Jirí Matousek,Nathaly Miller,János Pach,Micha Sharir,Shmuel Sifrony,Emo Welzl	1991	Fat Triangles Determine Linearly Many Holes
FOCS	Search Problems in the Decision Tree Model (Preliminary Version)	László Lovász,Moni Naor,Ilan Newman,Avi Wigderson	1991	The relative power of determinism, randomness, and nondeterminism for search problems in the Boolean decision tree model is studied. It is shown that the CNF search problem is complete for all the variants of decision trees. It is then shown that the gaps between the nondeterministic, the randomized, and the deterministic complexities can be arbitrarily large for search problems. The special case of nondeterministic complexity is discussed.
FOCS	On the Computational Power of Sigmoid versus Boolean Threshold Circuits	Wolfgang Maass,Georg Schnitger,Eduardo D. Sontag	1991	On the Computational Power of Sigmoid versus Boolean Threshold Circuits
FOCS	A Unified Geometric Approach to Graph Separators	Gary L. Miller,Shang-Hua Teng,Stephen A. Vavasis	1991	A class of graphs called k-overlap graphs is proposed. Special cases of k-overlap graphs include planar graphs, k-nearest neighbor graphs, and earlier classes of graphs associated with finite element methods. A separator bound is proved for k-overlap graphs embedded in d dimensions. The result unifies several earlier separator results. All the arguments are based on geometric properties of embedding. The separator bounds come with randomized linear-time and randomized NC algorithms. Moreover, the bounds are the best possible up to the leading term.
FOCS	Explicit Construction of Natural Bounded Concentrators	Moshe Morgenstern	1991	The first known direct construction for linear families of bounded concentrators is given. The construction is explicit, and the results are simple natural bounded concentrators.
FOCS	Interactive Communication: Balanced Distributions, Correlated Files, and Average-Case Complexity	Alon Orlitsky	1991	Suppose (X,Y) is a pair of random variables distributed over a support set S. Person P/sub x/ knows X, person P/sub y/ knows Y, and both know S. Using a predetermined protocol, they exchange binary messages in order for P/sub y/ to learn X. P/sub x/ may or may not learn Y. Bounds on communication complexity are obtained and used to obtain efficient protocols for the correlated files problem where X and Y are binary strings (files) within a small edit distance from each other. The average number of bits required for P/sub y/ to learn X when at most m messages are permitted is also determined.
FOCS	Randomized Multidimensional Search Trees: Lazy Balancing and Dynamic Shuffling (Extended Abstract)	Ketan Mulmuley	1991	A randomized technique, called dynamic shuffling, is given for multidimensional dynamic search. This technique, when specialized to the problem of searching in sorted lists, yields the previously known randomized binary trees (treaps). The crux of the technique is a multidimensional generalization of the rotation operation on binary search trees. Simultaneously, it is shown how to dynamize the randomized incremental algorithms so as to allow additions as well as deletions of objects. The techniques are based on remembering the history of the actual or imaginary sequence of updates. The techniques are applied to several problems in computational geometry.
FOCS	Randomized Multidimensional Search Trees: Further Results in Dynamic Sampling (Extended Abstract)	Ketan Mulmuley	1991	The use of randomization in dynamic search structures by means of a technique called dynamic sampling is investigated. In particular, an efficient algorithm for dynamic (logarithmic time) point location in 3-D partitions induced by a set of possibly interesting polygons in R/sup 3/ is given. The expected running time of the algorithm on a random sequence of updates is close to optimal. Efficient algorithms for dynamic nearest-k-neighbor queries and half space range queries in R/sup d/ are also given.
FOCS	On Selecting a Satisfying Truth Assignment (Extended Abstract)	Christos H. Papadimitriou	1991	The complexity of certain natural generalizations of satisfiability, in which one of the possibly exponentially many satisfying truth assignments must be selected, is studied. Two natural selection criteria, default preference and minimality (circumscription), are considered. The thrust of the complexity results seems to be that hard problems become harder, while easy problems remain easy. This consideration yields as a byproduct a new and very natural polynomial-time randomized algorithm for 2SAT.
FOCS	Optimal File Sharing in Distributed Networks (Preliminary Version)	Moni Naor,Ron M. Roth	1991	Given a distributed network of processors represented by an undirected graph G=(V, E) and a file size k, the problem of distributing an arbitrary file w of k bits among all nodes of the network G is considered. Memory devices are to be assigned to the node of G such that, by accessing the memory of its own and of its adjacent nodes, each node can reconstruct the contents of w. The objective is to minimize the total size memory in the network. A file distribution scheme that realizes this objective for k>>log Delta /sub G/, where Delta /sub G/, stands for the maximum degree in G, is presented. For this range of k, the total size of memory required by the suggested scheme approaches an integer programming lower bound on that size.
FOCS	Shrinkage of de~Morgan formulae under restriction	Mike Paterson,Uri Zwick	1991	It is shown that a random restriction leaving only a fraction epsilon of the input variables unassigned reduces the expected de Morgan formula size of the induced function by at least a factor of epsilon^((5-sqrt(3))/2)~=epsilon^1.63. (A de Morgan formula is a formula over the basis {/\, \/, ~}.) This improves a long-standing result of epsilon^1.5 by Subbotovskaya and a recent improvement to epsilon^((21-sqrt(73))/8)~=epsilon^1.55 by Nisan and Impagliazzo. The new exponent yields an increased lower bound of omega(n^((7-sqrt(3))/2-O(1)) for the de Morgan formula size of a function defined by Andreev. This is the largest lower bound known for a function in NP.
FOCS	Fast Approximation Algorithms for Fractional Packing and Covering Problems	Serge A. Plotkin,David B. Shmoys,Éva Tardos	1991	Fast algorithms that find approximate solutions for a general class of problems, which are called fractional packing and covering problems, are presented. The only previously known algorithms for solving these problems are based on general linear programming techniques. The techniques developed greatly outperform the general methods in many applications, and are extensions of a method previously applied to find approximate solutions to multicommodity flow problems. The algorithms are based on a Lagrangian relaxation technique, and an important result is a theoretical analysis of the running time of a Lagrangian relaxation based algorithm. Several applications of the algorithms are presented.
FOCS	Communication Complexity for Parallel Divide-and-Conquer	I-Chen Wu,H. T. Kung	1991	The relationship between parallel computation cost and communication cost for performing divide-and-conquer (D&C) computations on a parallel system of p processors is studied. The parallel computation cost is the maximal number of the D&C nodes that any processor in the parallel system may expand, whereas the communication cost is the total number of cross nodes (nodes generated by one processor but expanded by another processor). A scheduling algorithm is proposed, and lower bounds on the communication cost are derived. The proposed scheduling algorithm is optimal with respect to the communication cost, since the parallel computation cost of the algorithm is near optimal.
FOCS	Better Bounds for Threshold Formulas	Jaikumar Radhakrishnan	1991	The computation of threshold functions using formulas over the basis (AND, OR, NOT) is considered. It is shown that every monotone formula that computes the threshold function T/sub k//sup n/2
FOCS	Reliable Computation with Noisy Circuits and Decision Trees-A General n log n Lower Bound	Rüdiger Reischuk,Bernd Schmeltz	1991	Reliable Computation with Noisy Circuits and Decision Trees-A General n log n Lower Bound
FOCS	Finding k-cuts within Twice the Optimal	Huzur Saran,Vijay V. Vazirani	1991	Two simple approximation algorithms are presented for the minimum k-cut problem. Each algorithm finds a k-cut having weight within a factor of (2-2/k) of the optimal. One of the algorithms is particularly efficient, requiring a total of only n-1 maximum flow computations for finding a set of near-optimal k-cuts, one for each value of k between 2 and n.
FOCS	Dynamic Maintenance of Geometric Structures Made Easy	Otfried Schwarzkopf	1991	"The problem of dynamically maintaining geometric structures is considered. A technique is proposed that uses randomized incremental algorithms which are augmented to allow deletions of objects. A model for distributions on the possible input sequences of insertions and deletions is developed and analyzed using R. Seidel's backwards analysis. It is further shown how to apply this to maintain Voronoi diagrams, convex hulls, and planar subdivisions. A strikingly simple algorithm for the maintenance of convex hulls in any dimension is given. The expected running time is determined."
FOCS	Scheduling Parallel Machines On-Line	David B. Shmoys,Joel Wein,David P. Williamson	1991	The authors study the problem of scheduling jobs on parallel machines when the existence of a job is not known until an unknown release date and the processing requirement of a job is not known until the job is processed to completion. They demonstrate two general algorithmic techniques for converting existing polynomial-time algorithms that require complete knowledge about the input data into algorithms that need less advance knowledge. They prove information-theoretic lower bounds on the lengths of online schedules for several basic parallel machine models and then show that the algorithms construct schedules with lengths that either match or come within a constant factor of the lower bounds.
FOCS	How to Pack Better than Best Fit: Tight Bounds for Average-Case On-Line Bin Packing	Peter W. Shor	1991	An O(n log n)-time online algorithm is given for packing items i.i.d. uniform on (0, 1) into bins of size 1 with expected wasted space Theta (n/sup 1/2/ log /sup 1/2/n). This matches the lowest bound that no online algorithm can achieve O(n/sup 1/2/ log /sup 1/2/ n) wasted space. It is done by analyzing another algorithm which involves putting balls into buckets online. The analysis of this second algorithm also gives bound on the stochastic rightward matching problem, which arises in analyzing not only the above online bin packing problem, but also a 2-D problem of packing rectangles into a half-infinite strip. The bounds on rightward matching thus give good bounds for the 2-D strip packing problem.
FOCS	Lower Bounds for Polynomial Evaluation and Interpolation Problems	Victor Shoup,Roman Smolensky	1991	It is shown that there is a set of points p/sub 1/, p/sub 2/,. . .,p/sub n/ such that any algebraic program of depth d for polynomial evaluation (or interpolation) at these points has size Omega (n log n/log d). Moreover, if d is a constant, then a lower bound of Omega (n/sup 1+1/d/) is obtained.
FOCS	A Lower Bound for the Dictionary Problem under a Hashing Model	Rajamani Sundar	1991	"A fundamental open question in data structures concerns the existence of a dictionary data structure that processes the operations in constant amortized time and uses space polynomial in the dictionary size. The complexity of the dictionary problem is studied under a multilevel hashing model that is based on A.C. Yao's (1981) cell probe model, and it is proved that dictionary operations require log-algorithmic amortized time jn this model. The model encompasses many known solutions to the dictionary problem, and the result is the first nontrivial lower bound for the problem in a reasonably general model that takes into account the limited wordsize of memory locations and realistically measures the cost of update operations. This lower bound separates the deterministic and randomized complexities of the problem under this model."
FOCS	A Theory of Using History for Equational Systems with Applications (Extended Abstract)	Rakesh M. Verma	1991	A Theory of Using History for Equational Systems with Applications (Extended Abstract)
FOCS	Optimal Prefetching via Data Compression (Extended Abstract)	Jeffrey Scott Vitter,P. Krishnan	1991	A form of the competitive philosophy is applied to the problem of prefetching to develop an optimal universal prefetcher in terms of fault ratio, with particular applications to large-scale databases and hypertext systems. The algorithms are novel in that they are based on data compression techniques that are both theoretically optimal and good in practice. Intuitively, in order to compress data effectively, one has to be able to predict feature data well, and thus good data compressors should be able to predict well for purposes of prefetching. It is shown for powerful models such as Markov sources and mth order Markov sources that the page fault rates incurred by the prefetching algorithms presented are optimal in the limit for almost all sequences of page accesses.
FOCS	An Asynchronous Two-Dimensional Self-Correcting Cellular Automaton	Weiguo Wang	1991	Earlier work of P. Gacs and J. Reif (see J. Comput. Syst. Sci., vol.36, no.2, p.125-147 (1988)) on reliable computation using cellular automata is extended to asynchronous cellular automata. The goal is to find ways to implement computations of arbitrary size by a homogeneous asynchronous array of unreliable elementary components. An asynchronous two-dimensional cellular automaton is constructed so that given any computation and reliability requirement, a program can be found for such an automaton that performs the computation with probability that meets the reliability requirement. This is the strongest among the published results on reliable computation in an asynchronous environment. It is stronger than its asynchronous counterpart in the sense that it removes the assumption of a fault-free global synchronization clock underlying a synchronous system.
FOCS	Simulating BPP Using a General Weak Random Source	David Zuckerman	1991	It is shown how to simulate BPP and approximation algorithms in polynomial time using the output from a delta -source. A delta -source is a weak random source that is asked only once for R bits, and must output an R-bit string according to some distribution that places probability no more than 2/sup - delta R/ on any particular string. Also given are two applications: one to show the difficulty of approximating the size of the maximum clique, and the other to the problem of implicit O(1) probe search.
FOCS	32nd Annual Symposium on Foundations of Computer Science, 1-4 October 1991, San Juan, Puerto Rico		1991	32nd Annual Symposium on Foundations of Computer Science, 1-4 October 1991, San Juan, Puerto Rico
SODA	A Sublinear-Time Randomized Parallel Algorithm for the Maximum Clique Problem in Perfect Graphs.	Farid Alizadeh	1991	A Sublinear-Time Randomized Parallel Algorithm for the Maximum Clique Problem in Perfect Graphs.
SODA	Planar Geometric Location Problems and Maintaining the Width of a Planar Set.	Pankaj K. Agarwal,Micha Sharir	1991	Planar Geometric Location Problems and Maintaining the Width of a Planar Set.
SODA	Efficient 2-dimensional Approximate Matching of Non-Rectangular Figures.	Amihood Amir,Martin Farach	1991	Efficient 2-dimensional Approximate Matching of Non-Rectangular Figures.
SODA	Learning the Fourier Spectrum of Probabilistic Lists and Trees.	William Aiello,Milena Mihail	1991	Learning the Fourier Spectrum of Probabilistic Lists and Trees.
SODA	Matching Points into Noise Regions: Combinatorial Bounds and Algorithms.	Esther M. Arkin,Klara Kedem,Joseph S. B. Mitchell,Josef Sprinzak,Michael Werman	1991	Matching Points into Noise Regions: Combinatorial Bounds and Algorithms.
SODA	An Efficient Parallel Algorithm for the Row Minima of a Totally Monotone Matrix.	Mikhail J. Atallah,S. Rao Kosaraju	1991	An Efficient Parallel Algorithm for the Row Minima of a Totally Monotone Matrix.
SODA	The Canadian Traveller Problem.	Amotz Bar-Noy,Baruch Schieber	1991	The Canadian Traveller Problem.
SODA	The Fourth Moment Method.	Bonnie Berger	1991	Higher moment analysis has typically been used to upper bound certain functions. In this paper, we introduce a new combinatorial method to lower bound the expectation of the absolute value of a random variable X by the expectation of a quartic in X. In the special case where we are looking at the absolute value of a (weighted) sum of {-1,+1} unbiased random variables, we achieve tight bounds, using only a fourth moment, for the total discrepancy of a set system. Because the fourth moment depends only on 4-wise independence, our bounds will hold over polynomially sized distributions, and so these bounds will be directly applicable in removing randomness to obtain NC algorithms. We obtain the first NC algorithms for the problems of total discrepancy, maximum acyclic subgraph, tournament ranking, the Gale--Berlekamp switching game, and edge discrepancy. We show that for most of these applications it is truly necessary to consider a fourth moment by exhibiting a 3-wise independent distribution which does not achieve the required bounds. Our method is strong enough to give a new combinatorial bound on tournament ranking.
SODA	Complexity Results and Algorithms for { <, <=, = }-Constrained Scheduling.	Bonnie Berger,Lenore Cowen	1991	Complexity Results and Algorithms for { <, <=, = }-Constrained Scheduling.
SODA	Tight Bounds for On-Line Tree Embeddings.	Sandeep N. Bhatt,David S. Greenberg,Frank Thomson Leighton,Pangfeng Liu	1991	Tree-structured computations are relatively easy to process in parallel. As leaf processes are recursively spawned they can be assigned to independent processors in a multicomputer network. However, to achieve good performance the on-line mapping algorithm must maintain load balance, i.e., distribute processes equitably among processors. Additionally, the algorithm itself must be distributed in nature, and process allocation must be completed via message-passing with minimal communication overhead.This paper investigates bounds on the performance of deterministic and randomized algorithms for on-line tree embeddings. In particular, we study trade-offs between computation overhead (load imbalance) and communication overhead (message congestion). We give a simple technique to derive lower bounds on the congestion that any on-line allocation algorithm must incur in order to guarantee load balance. This technique works for both randomized and deterministic algorithms. We prove that the advantage of randomization is limited. Optimal bounds are achieved for several networks, including multidimensional grids and butterflies.
SODA	Parallel Complexity of Tridiagonal Symmetric Eigenvalue Problem.	Dario Bini,Victor Y. Pan	1991	Parallel Complexity of Tridiagonal Symmetric Eigenvalue Problem.
SODA	A Fast Algorithm for Connecting Grid Points to the Boundary with Nonintersecting Straight Lines.	Yitzhak Birk,Jeffrey B. Lotspiech	1991	A Fast Algorithm for Connecting Grid Points to the Boundary with Nonintersecting Straight Lines.
SODA	On the Parallel Complexity of Evaluating Game Trees.	Andrei Z. Broder,Anna R. Karlin,Prabhakar Raghavan,Eli Upfal	1991	On the Parallel Complexity of Evaluating Game Trees.
SODA	Circular Hulls and Orbiforms of Simple Polygons.	V. Chandru,R. Venkataraman	1991	Circular Hulls and Orbiforms of Simple Polygons.
SODA	Computing a Face in an Arrangement of Line Segments.	Bernard Chazelle,Herbert Edelsbrunner,Leonidas J. Guibas,Micha Sharir,Jack Snoeyink	1991	Computing a Face in an Arrangement of Line Segments.
SODA	On Partitions and Presortedness of Sequences.	Jingsen Chen,Svante Carlsson	1991	On Partitions and Presortedness of Sequences.
SODA	Space-efficient Ray-shooting and Intersection Searching: Algorithms, Dynamization, and Applications.	Siu-Wing Cheng,Ravi Janardan	1991	Space-efficient Ray-shooting and Intersection Searching: Algorithms, Dynamization, and Applications.
SODA	Efficient Sequential and Parallel Algorithms for Computing Recovery Points in Trees and Paths.	Marek Chrobak,David Eppstein,Giuseppe F. Italiano,Moti Yung	1991	Efficient Sequential and Parallel Algorithms for Computing Recovery Points in Trees and Paths.
SODA	Approximation Algorithms for Planar Traveling Salesman Tours and Minimum-Length Triangulations.	Kenneth L. Clarkson	1991	Approximation Algorithms for Planar Traveling Salesman Tours and Minimum-Length Triangulations.
SODA	Algorithms and Complexity Analysis for Some Flow Problems.	Edith Cohen,Nimrod Megiddo	1991	Algorithms and Complexity Analysis for Some Flow Problems.
SODA	Dynamic Expression Trees and their Applications (Extended Abstract).	Robert F. Cohen,Roberto Tamassia	1991	Dynamic Expression Trees and their Applications (Extended Abstract).
SODA	Tight Bounds on the Complexity of the Boyer-Moore String Matching Algorithm.	Richard Cole	1991	The problem of finding all occurrences of a pattern of length $m$ in a text of length $n$ is considered. It is shown that the Boyer--Moore string matching algorithm performs roughly $3n$ comparisons and that this bound is tight up to $O(n/m)$; more precisely, an upper bound of $3n - 3(n-m+1)/(m+2)$ comparisons is shown, as is a lower bound of $3n(1-o(1))$ comparisons, as $\frac{n}{m}\rightarrow\infty$ and $m\rightarrow\infty$. While the upper bound is somewhat involved, its main elements provide a simple proof of a $4n$ upper bound for the same algorithm.
SODA	Bounded Space On-Line Bin Packing: Best is Better than First.	János Csirik,David S. Johnson	1991	Bounded Space On-Line Bin Packing: Best is Better than First.
SODA	"The Aquarium Keeper's Problem."	Jirel Czyzowicz,Peter Egyed,Hazel Everett,David Rappaport,Thomas C. Shermer,Diane L. Souvaine,Godfried T. Toussaint,Jorge Urrutia	1991	"The Aquarium Keeper's Problem."
SODA	Persistence, Amortization and Randomization.	Paul F. Dietz,Rajeev Raman	1991	Persistence, Amortization and Randomization.
SODA	Fully Persistent Lists with Catenation.	James R. Driscoll,Daniel Dominic Sleator,Robert Endre Tarjan	1991	This paper considers the problem of representing stacks with catenation so that any stack, old or new, is available for access or update operations. This problem arises in the implementation of list-based and functional programming languages. A solution is proposed requiring constant time and space for each stack operation except catenation, which requires O(log log k) time and space. Here k is the number of stack operations done before the catenation. All the resource bounds are amortized over the sequence of operations.
SODA	The Analysis of Multidimensional Searching in Quad-Trees.	Philippe Flajolet,Gaston H. Gonnet,Claude Puech,J. M. Robson	1991	The Analysis of Multidimensional Searching in Quad-Trees.
SODA	Routing through a Dense Channel with Minimum Total Wire Length.	Michael Formann,Dorothea Wagner,Frank Wagner	1991	Routing through a Dense Channel with Minimum Total Wire Length.
SODA	Optimal Algorithms for Tree Partitioning.	Greg N. Frederickson	1991	Optimal Algorithms for Tree Partitioning.
SODA	Fast Hashing on a PRAM - Designing by Expectation.	Joseph Gil,Yossi Matias	1991	Fast Hashing on a PRAM - Designing by Expectation.
SODA	Edge Coloring Planar Graphs with Two Outerplanar Subgraphs.	Lenwood S. Heath	1991	The standard problem of edge coloring a graph with k colors is equivalent to partitioning the edge set of the graph into k matchings. Here edge coloring is generalized by replacing matchings with outerplanar graphs. We give a polynomial-time algorithm that edge colors any planar graph with two outerplanar subgraphs. Two is clearly minimal for the class of planar graphs. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player
SODA	Offline Maintenance of Planar Configurations.	John Hershberger,Subhash Suri	1991	Offline Maintenance of Planar Configurations.
SODA	Upward Planar Drawing of Single Source Acyclic Digraphs.	Michael D. Hutton,Anna Lubiw	1991	Upward Planar Drawing of Single Source Acyclic Digraphs.
SODA	Randomized Competitive Algorithms for the List Update Problem.	Sandy Irani,Nick Reingold,Jeffery Westbrook,Daniel Dominic Sleator	1991	Randomized Competitive Algorithms for the List Update Problem.
SODA	On-Line Weighted Matching.	Bala Kalyanasundaram,Kirk Pruhs	1991	On-Line Weighted Matching.
SODA	Triangulating Three-Colored Graphs.	Sampath Kannan,Tandy Warnow	1991	Triangulating Three-Colored Graphs.
SODA	Approximating the Number of Zeroes of a GF[2] Polynomial.	Marek Karpinski,Michael Luby	1991	Approximating the Number of Zeroes of a GF[2] Polynomial.
SODA	On Finding Minimal 2-Connected Subgraphs.	Pierre Kelsen,Vijaya Ramachandran	1991	We present efficient parallel algorithms for the problems of finding a minimal 2-edge-connected spanning subgraph of a 2-edge-connected graph and finding a minimal biconnected spanning subgraph of a biconnected graph. The parallel algorithms for both problems run in polylog time using a linear number of PRAM processors. We also give sequential algorithms for these problems that run in time O(m+n log n) where n and m denote the number of vertices and edges, respectively, in the input graph.
SODA	Adaptive Heuristics for Binary Search Trees and Constant Linkage Cost.	Tony W. Lai,Derick Wood	1991	We present lower and upper bounds on adaptive heuristics for maintaining binary search trees using a constant number of link or pointer changes for each operation (constant linkage cost (CLC)). We show that no adaptive heuristic with an amortized linkage cost of o(log n) can be competitive. In particular, we show that any heuristic that performs f(n)=o(log n) promotions (rotations) amortized over each access has a competitive ratio of at least $\Omega(\log n/f(n))$ against an oblivious adversary, and any heuristic that performs f(n)=o(log n) pointer changes amortized over each access has a competitive ratio of at least $\Omega(\frac{\log n}{f(n)\log(\log n/f(n))})$ against an adaptive online adversary.In our investigation of upper bounds we present four adaptive heuristics: a randomized, worst-case-CLC heuristic randomized two-promotion (R2P) whose expected search time is within a constant factor of the search time using an optimal tree; that is, it is statically competitive against an oblivious adversary; a randomized, expected-CLC heuristic (locally optimized randomized partial splay (LORPS)) that has O(log n) expected-amortized update time and is statically competitive against an oblivious adversary; a deterministic, amortized-CLC heuristic (locally optimized partial splay (LOPS)) that has O(log n) amortized update time and is statically competitive against an adaptive adversary; a practical, randomized heuristic (randomized partial splay (RPS)) that is not CLC but has performance bounds comparable with those of the splay heuristic of Sleator and Tarjan; it is statically competitive against an adaptive adversary. The randomized heuristics use only constant extra space, whereas the deterministic heuristic uses O(n) extra space.
SODA	Recognizing Strong Connectivity in (Dynamic) Periodic Graphs and its Relation to Integer Programming.	Murali S. Kodialam,James B. Orlin	1991	Recognizing Strong Connectivity in (Dynamic) Periodic Graphs and its Relation to Integer Programming.
SODA	Density Graphs and Separators.	Gary L. Miller,Stephen A. Vavasis	1991	"We propose a class of graphs that would occur naturally in finite-element problems, and we prove a bound on separators for this class of graphs. For three-dimensional graphs, our separator bound is $O(N^{2/3})$. We also propose a simple randomized algorithm to find this separator in $O(N)$ time. Such an algorithm would be used as a preprocessing step for the domain decomposition method of efficiently solving a finite-element problem on a parallel computer. This paper generalizes ``local graphs'''' of Vavasis [1990] to the case of graphs with varying densities of nodes. It also generalizes aspects of Miller and Thurston''s [1990] ``stable graphs.''''"
SODA	Decomposing Graphs into Regions of Small Diameter.	Nathan Linial,Michael E. Saks	1991	Decomposing Graphs into Regions of Small Diameter.
SODA	An O(n) Time Algorithm for the 2-Chain Cover Problem and Related Problems.	Tze-Heng Ma,Jeremy Spinrad	1991	An O(n) Time Algorithm for the 2-Chain Cover Problem and Related Problems.
SODA	Ultra-Fast Expected Time Parallel Algorithms.	Philip D. MacKenzie,Quentin F. Stout	1991	Ultra-Fast Expected Time Parallel Algorithms.
SODA	The First Classical Ramsey Number for Hypergraphs is Computed.	Brendan D. McKay,Stanislaw P. Radziszowski	1991	The First Classical Ramsey Number for Hypergraphs is Computed.
SODA	Optimal Time Randomized Consensus - Making Resilient Algorithms Fast in Practice.	Michael E. Saks,Nir Shavit,Heather Woll	1991	Optimal Time Randomized Consensus - Making Resilient Algorithms Fast in Practice.
SODA	Finding Stabbing Lines in 3-Dimensional Space.	Marco Pellegrini,Peter W. Shor	1991	Finding Stabbing Lines in 3-Dimensional Space.
SODA	Tight Bounds on the Number of Minimum-Mean Cycle Cancellations and Related Results.	Tomasz Radzik,Andrew V. Goldberg	1991	Tight Bounds on the Number of Minimum-Mean Cycle Cancellations and Related Results.
SODA	Improved Approximation Algorithms for Shop Scheduling Problems.	David B. Shmoys,Clifford Stein,Joel Wein	1991	"In the job shop scheduling problem, there are $m$ machines and $n$ jobs. A job consists of a sequence of operations, each of which must be processed on a specified machine, and the aim is to complete all jobs as quickly as possible. This problem is strongly ${\cal NP}$-hard even for very restrictive special cases. The authors give the first randomized and deterministic polynomial-time algorithms that yield polylogarithmic approximations to the optimal length schedule. These algorithms also extend to the more general case where a job is given not by a linear ordering of the machines on which it must be processed but by an arbitrary partial order. Comparable bounds can also be obtained when there are $m'$ types of machines, a specified number of machines of each type, and each operation must be processed on one of the machines of a specified type, as well as for the problem of scheduling unrelated parallel machines subject to chain precedence constraints."
SODA	A New Lower Bound Technique and Its Application: Tight Lower Bound for a Polygon Triangulation Problem.	Prakash V. Ramanan	1991	A New Lower Bound Technique and Its Application: Tight Lower Bound for a Polygon Triangulation Problem.
SODA	Maintaining the Minimal Distance of a Point Set in Polylogarithmic Time.	Michiel H. M. Smid	1991	Maintaining the Minimal Distance of a Point Set in Polylogarithmic Time.
SODA	Time-Work Tradeoffs for Parallel Graph Algorithms.	Thomas H. Spencer	1991	Time-Work Tradeoffs for Parallel Graph Algorithms.
SODA	On-Line Caching as Cache Size Varies.	Neal E. Young	1991	On-Line Caching as Cache Size Varies.
SODA	Proceedings of the Second Annual ACM/SIGACT-SIAM Symposium on Discrete Algorithms, 28-30 January 1991, San Francisco, California.	Alok Aggarwal	1991	Proceedings of the Second Annual ACM/SIGACT-SIAM Symposium on Discrete Algorithms, 28-30 January 1991, San Francisco, California.
STOC	Generic Computation and Its Complexity	Serge Abiteboul,Victor Vianu	1991	Generic Computation and Its Complexity
STOC	Factoring Numbers Using Singular Integers	Leonard M. Adleman	1991	Factoring Numbers Using Singular Integers
STOC	When Trees Collide: An Approximation Algorithm for the Generalized Steiner Problem on Networks	Ajit Agrawal,Philip N. Klein,R. Ravi	1991	We give the first approximation algorithm for the {\em generalized network Steiner tree problem}, a problem in network design. An instance consists of a network with link-costs and, for each pair ${i,j}$ of nodes, an edge-connectivity requirement. The goal is to find a minimum-cost network using the available links and satisfying the requirements. Our algorithm outputs a solution whose cost is within $ 2 \log R $ of optimal, where $R$ is the highest requirement value. In the course of proving the performance guarantee, we prove a combinatorial min-max approximate equality relating minimum-cost networks to maximum packings of certain kinds of cuts. As a consequence of the proof of this theorem, we obtain an approximation algorithm for optimally packing these cuts; we show that this algorithm has application to estimating the reliability of a probabilistic network.
STOC	Wait-free Parallel Algorithms for the Union-Find Problem	Richard J. Anderson,Heather Woll	1991	Wait-free Parallel Algorithms for the Union-Find Problem
STOC	"When Won't Membership Queries Help? (Extended Abstract)"	Dana Angluin,Michael Kharitonov	1991	"When Won't Membership Queries Help? (Extended Abstract)"
STOC	Sampling and Integration of Near Log-Concave functions	David Applegate,Ravi Kannan	1991	Sampling and Integration of Near Log-Concave functions
STOC	Searching in the Presence of Linearly Bounded Errors (Extended Abstract)	Javed A. Aslam,Aditi Dhagat	1991	Searching in the Presence of Linearly Bounded Errors (Extended Abstract)
STOC	The Expressive Power of Voting Polynomials	James Aspnes,Richard Beigel,Merrick L. Furst,Steven Rudich	1991	The Expressive Power of Voting Polynomials
STOC	Counting Networks and Multi-Processor Coordination	James Aspnes,Maurice Herlihy,Nir Shavit	1991	Counting Networks and Multi-Processor Coordination
STOC	Bounds on the Time to Reach Agreement in the Presence of Timing Uncertainty	Hagit Attiya,Cynthia Dwork,Nancy A. Lynch,Larry J. Stockmeyer	1991	Bounds on the Time to Reach Agreement in the Presence of Timing Uncertainty
STOC	Local Expansion of Vertex-Transitive Graphs and Random Generation in Finite Groups	László Babai	1991	Local Expansion of Vertex-Transitive Graphs and Random Generation in Finite Groups
STOC	Fast Monte Carlo Algorithms for Permutation Groups	László Babai,Gene Cooperman,Larry Finkelstein,Eugene M. Luks,Ákos Seress	1991	Fast Monte Carlo Algorithms for Permutation Groups
STOC	Checking Computations in Polylogarithmic Time	László Babai,Lance Fortnow,Leonid A. Levin,Mario Szegedy	1991	Checking Computations in Polylogarithmic Time
STOC	Deterministic Algorithms for Undirected s-t Connectivity Using Polynomial Time and Sublinear Space (Extended Abstract)	Greg Barnes,Walter L. Ruzzo	1991	Deterministic Algorithms for Undirected s-t Connectivity Using Polynomial Time and Sublinear Space (Extended Abstract)
STOC	PP Is Closed Under Intersection (Extended Abstract)	Richard Beigel,Nick Reingold,Daniel A. Spielman	1991	PP Is Closed Under Intersection (Extended Abstract)
STOC	Linear Approximation of Shortest Superstrings	Avrim Blum,Tao Jiang,Ming Li,John Tromp,Mihalis Yannakakis	1991	We consider the following problem: given a collection of strings s1,&hellip;, sm, find the shortest string s such that each si appears as a substring (a consecutive block) of s. Although this problem is known to be NP-hard, a simple greedy procedure appears to do quite well and is routinely used in DNA sequencing and data compression practice, namely: repeatedly merge the pair of (distinct) strings with maximum overlap until only one string remains. Let n denote the length of the optimal superstring. A common conjecture states that the above greedy procedure produces a superstring of length O(n) (in fact, 2n), yet the only previous nontrivial bound known for any polynomial-time algorithm is a recent O(n log n) result. We show that the greedy algorithm does in fact achieve a constant factor approximation, proving an upper bound of 4n. Furthermore, we present a simple modified version of the greedy algorithm that we show produces a superstring of length at most 3n. We also show the superstring problem to be MAXSNP-hard, which implies that a polynomial-time approximation scheme for this problem is unlikely.
STOC	Integral Equations, Systems of Quadratic Equations, and Exponential-Time Completeness (Extended Abstract)	Ker-I Ko	1991	Integral Equations, Systems of Quadratic Equations, and Exponential-Time Completeness (Extended Abstract)
STOC	Navigating in Unfamiliar Geometric Terrain (Preliminary Version)	Avrim Blum,Prabhakar Raghavan,Baruch Schieber	1991	Navigating in Unfamiliar Geometric Terrain (Preliminary Version)
STOC	Competitive Paging with Locality of Reference (Preliminary Version)	Allan Borodin,Sandy Irani,Prabhakar Raghavan,Baruch Schieber	1991	Competitive Paging with Locality of Reference (Preliminary Version)
STOC	A Lower Bound for Parallel String Matching	Dany Breslauer,Zvi Galil	1991	A Lower Bound for Parallel String Matching
STOC	"Counting Linear Extensions is \	P-Complete"	Graham Brightwell,Peter Winkler	1991
STOC	Finding Hidden Hamiltonian Cycles (Extended Abstract)	Andrei Z. Broder,Alan M. Frieze,Eli Shamir	1991	Finding Hidden Hamiltonian Cycles (Extended Abstract)
STOC	Constructing Nonresidues in Finite Fields and the Extended Riemann Hypothesis	Johannes Buchmann,Victor Shoup	1991	Constructing Nonresidues in Finite Fields and the Extended Riemann Hypothesis
STOC	Algorithms for Parallel k-Vertex Connectivity and Sparse Certificates (Extended Abstract)	Joseph Cheriyan,Ramakrishna Thurimella	1991	Algorithms for Parallel k-Vertex Connectivity and Sparse Certificates (Extended Abstract)
STOC	Fundamental Discrepancies between Average-Case Analyses under Discrete and Continuous Distributions: A Bin Packing Case Study	Edward G. Coffman Jr.,Costas Courcoubetis,M. R. Garey,David S. Johnson,Lyle A. McGeoch,Peter W. Shor,Richard R. Weber,Mihalis Yannakakis	1991	Fundamental Discrepancies between Average-Case Analyses under Discrete and Continuous Distributions: A Bin Packing Case Study
STOC	Proof of the 4/3 Conjecture for Preemptive vs. Nonpreemptive Two-Processor Scheduling	Edward G. Coffman Jr.,M. R. Garey	1991	Proof of the 4/3 Conjecture for Preemptive vs. Nonpreemptive Two-Processor Scheduling
STOC	Improved Algorithms for Linear Inequalities with Two Variables per Inequality (Extended Abstract)	Edith Cohen,Nimrod Megiddo	1991	Improved Algorithms for Linear Inequalities with Two Variables per Inequality (Extended Abstract)
STOC	Infinite Games, Randomization, Computability, and Applications to Online Problems (Preliminary Version)	Xiaotie Deng,Sanjeev Mahajan	1991	Infinite Games, Randomization, Computability, and Applications to Online Problems (Preliminary Version)
STOC	An Efficient Algorithm for the Genus Problem with Explicit Construction of Forbidden Subgraphs	Hristo Djidjev,John H. Reif	1991	An Efficient Algorithm for the Genus Problem with Explicit Construction of Forbidden Subgraphs
STOC	Non-Malleable Cryptography (Extended Abstract)	Danny Dolev,Cynthia Dwork,Moni Naor	1991	Non-Malleable Cryptography (Extended Abstract)
STOC	Clique Partitions, Graph Compression, and Speeding-Up Algorithms	Tomás Feder,Rajeev Motwani	1991	Clique Partitions, Graph Compression, and Speeding-Up Algorithms
STOC	Rigorous Time/Space Tradeoffs for Inverting Functions	Amos Fiat,Moni Naor	1991	We provide rigorous time-space tradeoffs for inverting any function. Given a function f, we give a time space tradeoff of TS2 = N3q(f), where q(f) is the probability that two random elements are mapped to the same image under f. We also give a more general tradeoff, TS3 = N3, that can invert any function at any point.
STOC	A Matroid Approach to Finding Edge Connectivity and Packing Arborescences	Harold N. Gabow	1991	A Matroid Approach to Finding Edge Connectivity and Packing Arborescences
STOC	Fully Dynamic Algorithms for Edge-Connectivity Problems (Extended Abstract)	Zvi Galil,Giuseppe F. Italiano	1991	Fully Dynamic Algorithms for Edge-Connectivity Problems (Extended Abstract)
STOC	Self-Testing/Correcting for Polynomials and for Approximate Functions	Peter Gemmell,Richard J. Lipton,Ronitt Rubinfeld,Madhu Sudan,Avi Wigderson	1991	Self-Testing/Correcting for Polynomials and for Approximate Functions
STOC	Dynamic Trees and Dynamic Point Location (Preliminary Version)	Michael T. Goodrich,Roberto Tamassia	1991	Dynamic Trees and Dynamic Point Location (Preliminary Version)
STOC	The Harmonic Online K-Server Algorithm Is Competitive	Edward F. Grove	1991	The Harmonic Online K-Server Algorithm Is Competitive
STOC	Constant-Time Parallel Integer Sorting (Extended Abstract)	Torben Hagerup	1991	Constant-Time Parallel Integer Sorting (Extended Abstract)
STOC	Hamiltonian Paths in Infinite Graphs	David Harel	1991	Hamiltonian Paths in Infinite Graphs
STOC	A Model for Data in Motion	Simon Kahan	1991	A Model for Data in Motion
STOC	Effective Noether Irreducibility Forms and Applications (Extended Abstract)	Erich Kaltofen	1991	Effective Noether Irreducibility Forms and Applications (Extended Abstract)
STOC	Lower Bounds for Randomized k-Server and Motion Planning Algorithms	Howard J. Karloff,Yuval Rabani,Yiftach Ravid	1991	Lower Bounds for Randomized k-Server and Motion Planning Algorithms
STOC	Probabilistic Recurrence Relations	Richard M. Karp	1991	Probabilistic Recurrence Relations
STOC	Combining Tentative and Definite Executions for Very Fast Dependable Parallel Computing (Extended Abstract)	Zvi M. Kedem,Krishna V. Palem,A. Raghunathan,Paul G. Spirakis	1991	Combining Tentative and Definite Executions for Very Fast Dependable Parallel Computing (Extended Abstract)
STOC	A General Completeness Theorem for Two-Party Games	Joe Kilian	1991	A General Completeness Theorem for Two-Party Games
STOC	Learning Decision Trees Using the Fourier Sprectrum (Extended Abstract)	Eyal Kushilevitz,Yishay Mansour	1991	Learning Decision Trees Using the Fourier Sprectrum (Extended Abstract)
STOC	Fast Approximation Algorithms for Multicommodity Flow Problems	Frank Thomson Leighton,Fillia Makedon,Serge A. Plotkin,Clifford Stein,Éva Tardos,Spyros Tragoudas	1991	"In this paper, we describe the first polynomial-time combinatorial algorithms for approximately solving the multicommodity flow problem. Our algorithms are significantly faster than the best previously known algorithms, that were based on linear programming. For a k-commodity multicommodity flow problem, the running time of our randomized algorithm is (up to log factors) the same as the time needed to solve k single-commodity flow problems, thus giving the surprising result that approximately computing a k-commodity maximum-flow is not much harder than computing about k single-commodity maximum-flows in isolation. Given any multicommodity flow problem as input, our algorithm is guaranteed to provide a feasible solution to a modified flow problem in which all capacities are increased by a (1 + epsilon)-factor, or to provide a proof that there is no feasible solution to the original problem. We also describe faster approximation algorithms for multicommodity flow problems with a special structure, such as those that arise in the ""sparsest cut"" problems and the uniform concurrent flow problems if k >= the square root of m."
STOC	On-Line Learning of Linear Functions	Nick Littlestone,Philip M. Long,Manfred K. Warmuth	1991	We present an algorithm for the on-line learning of linear functions which is optimal to within a constant factor with respect to bounds on the sum of squared errors for a worst case sequence of trials. The bounds are logarithmic in the number of variables. Furthermore, the algorithm is shown to be optimally robust with respect to noise in the data (again to within a constant factor). We also discuss an application of our methods to the iterative solution of sparse systems of linear equations.
STOC	On Deterministic Approximation of DNF	Michael Luby,Boban Velickovic	1991	On Deterministic Approximation of DNF
STOC	Converting High Probability into Nearly-Constant Time-with Applications to Parallel Hashing (Extended Abstract)	Yossi Matias,Uzi Vishkin	1991	Converting High Probability into Nearly-Constant Time-with Applications to Parallel Hashing (Extended Abstract)
STOC	Approximations and Optimal Geometric Divide-And-Conquer	Jirí Matousek	1991	Approximations and Optimal Geometric Divide-And-Conquer
STOC	Perfect Cryptographic Security from Partially Independent Channels	Ueli M. Maurer	1991	Perfect Cryptographic Security from Partially Independent Channels
STOC	Reducing Elliptic Curve Logarithms to Logarithms in a Finite Field	Alfred Menezes,Scott A. Vanstone,Tatsuaki Okamoto	1991	Reducing Elliptic Curve Logarithms to Logarithms in a Finite Field
STOC	Hidden Surface Removal with Respect to a Moving View Point	Ketan Mulmuley	1991	Hidden Surface Removal with Respect to a Moving View Point
STOC	Lower Bounds for Non-Commutative Computation (Extended Abstract)	Noam Nisan	1991	Lower Bounds for Non-Commutative Computation (Extended Abstract)
STOC	Rounds in Communication Complexity Revisited	Noam Nisan,Avi Wigderson	1991	Rounds in Communication Complexity Revisited
STOC	Separating Concurrent Languages with Categories of Language Embeddings (Extended Abstract)	Ehud Y. Shapiro	1991	Separating Concurrent Languages with Categories of Language Embeddings (Extended Abstract)
STOC	Testing Finite State Machines (Extended Abstract)	Mihalis Yannakakis,David Lee	1991	Testing Finite State Machines (Extended Abstract)
STOC	Proceedings of the Twenty Third Annual ACM Symposium on Theory of Computing, 6-8 May 1991, New Orleans, Louisiana, USA		1991	Proceedings of the Twenty Third Annual ACM Symposium on Theory of Computing, 6-8 May 1991, New Orleans, Louisiana, USA
FOCS	Halvers and Expanders	Miklós Ajtai,János Komlós,Endre Szemerédi	1992	Halvers and Expanders
FOCS	Dynamic Half-Space Reporting, Geometric Optimization, and Minimum Spanning Trees	Pankaj K. Agarwal,David Eppstein,Jirí Matousek	1992	The authors describe dynamic data structures for half-space range reporting and for maintaining the minima of a decomposable function. Using these data structures, they obtain efficient dynamic algorithms for a number of geometric problems, including closest/farthest neighbor searching, fixed dimension linear programming, bi-chromatic closest pair, diameter, and Euclidean minimum spanning tree.
FOCS	Efficient Minimum Cost Matching Using Quadrangle Inequality	Alok Aggarwal,Amotz Bar-Noy,Samir Khuller,Dina Kravets,Baruch Schieber	1992	The authors present efficient algorithms for finding a minimum cost perfect matching, and for solving the transportation problem in bipartite graphs, G = (Red union Blue, Red * Blue), where mod Red mod = n, mod Blue mod = m, n
FOCS	Fault Tolerant Graphs, Perfect Hash Functions and Disjoint Paths	Miklós Ajtai,Noga Alon,Jehoshua Bruck,Robert Cypher,Ching-Tien Ho,Moni Naor,Endre Szemerédi	1992	Given a graph G on n nodes the authors say that a graph T on n + k nodes is a k-fault tolerant version of G, if one can embed G in any n node induced subgraph of T. Thus T can sustain k faults and still emulate G without any performance degradation. They show that for a wide range of values of n, k and d, for any graph on n nodes with maximum degree d there is a k-fault tolerant graph with maximum degree O(kd). They provide lower bounds as well: there are graphs G with maximum degree d such that any k-fault tolerant version of them has maximum degree at least Omega (d square root k).
FOCS	The Algorithmic Aspects of the Regularity Lemma (Extended Abstract)	Noga Alon,Richard A. Duke,Hanno Lefmann,Vojtech Rödl,Raphael Yuster	1992	The Algorithmic Aspects of the Regularity Lemma (Extended Abstract)
FOCS	Witnesses for Boolean Matrix Multiplication and for Shortest Paths	Noga Alon,Zvi Galil,Oded Margalit,Moni Naor	1992	The subcubic (O(n/sup w/) for w(3) algorithms to multiply Boolean matrices do not provide the witnesses; namely, they compute C=A.B but if C/sub ij/=1 they do not find an index k (a witness) such that A/sub ik/=B/sub kj/=1. The authors design a deterministic algorithm for computing the matrix of witnesses that runs in O(n/sup w/) time, where here O(n/sup w/) denotes O(n/sup w/(log n)/sup O(1)/). The subcubic methods to compute the shortest distances between all pairs of vertices also do not provide for witnesses; namely they compute the shortest distances but do not generate information for computing quickly the paths themselves. A witness for a shortest path from v/sub i/ to v/sub j/ is an index k such that v/sub k/ is the first vertex on such a path. They describe subcubic methods to compute such witnesses for several versions of the all pairs shortest paths problem. As a result, they derive shortest paths algorithms that provide characterization of the shortest paths in addition to the shortest distances in the same time (up to a polylogarithmic factor) needed for computing the distances; namely O(n/sup (3+w)/2/) time in the directed case and O(n/sup w/) time in the undirected case. They also design an algorithm that computes witnesses for the transitive closure in the same time needed to compute witnesses for Boolean matrix multiplication.
FOCS	Read-Thrice DNF Is Hard to Learn With Membership and Equivalence Queries	Howard Aizenstein,Lisa Hellerstein,Leonard Pitt	1992	A general technique is developed to obtain nonlearnability results in the model of exact learning from equivalence and membership queries. The technique is applied to show that, assuming NP not=co-NP, there does not exist a polynomial-time membership and equivalence query algorithm for exactly learning read-thrice DNF formulas-boolean formulas in disjunctive normal form where each variable appears at most three times. This result adds evidence to the conjecture that DNF is hard to learn in the membership and equivalence query model.
FOCS	Lower Bounds on the Competitive Ratio for Mobile User Tracking and Distributed Job Scheduling (Extended Abstract)	Noga Alon,Gil Kalai,Moty Ricklin,Larry J. Stockmeyer	1992	Lower Bounds on the Competitive Ratio for Mobile User Tracking and Distributed Job Scheduling (Extended Abstract)
FOCS	Back to the Future: Towards a Theory of Timed Regular Languages	Rajeev Alur,Thomas A. Henzinger	1992	The authors introduce two-way timed automata-timed automata that can move back and forth while reading a timed word. Two-wayness in its unrestricted form leads, like nondeterminism, to the undecidability of language inclusion. However, if they restrict the number of times an input symbol may be revisited, then two-wayness is both harmless and desirable. The authors show that the resulting class of bounded two-way deterministic timed automata is closed under all boolean operations, has decidable (PSPACE-complete) emptiness and inclusion problems, and subsumes all decidable real-time logics we know. They obtain a strict hierarchy of real-time properties: deterministic timed automata can accept more languages as the bound on the number of times an input symbol may be revisited is increased. This hierarchy is also enforced by the number of alternations between past and future operators in temporal logic. The combination of the results leads to a decision procedure for a real-time logic with past operators.
FOCS	Reconstructing Algebraic Functions from Mixed Data	Sigal Ar,Richard J. Lipton,Ronitt Rubinfeld,Madhu Sudan	1992	The authors consider the task of reconstructing algebraic functions given by black boxes. Unlike traditional settings, they are interested in black boxes which represent several algebraic functions-f/sub 1/, . . ., f/sub k/, where at each input x, the box arbitarrily chooses a subset of f/sub 1/(x), . . ., f/sub k/(x) to output. They show how to reconstruct the functions f/sub 1/,. . ., f/sub k/ from the black box. This allows them to group the same points into sets, such that for each set, all outputs to points in the set are from the same algebraic function. The methods are robust in the presence of errors in the black box. The model and techniques can be applied in the areas of computer vision, machine learning, curve fitting and polynomial approximation, self-correcting programs and bivariate polynomial factorization.
FOCS	Proof Verification and Hardness of Approximation Problems	Sanjeev Arora,Carsten Lund,Rajeev Motwani,Madhu Sudan,Mario Szegedy	1992	The class PCP(f(n),g(n)) consists of all languages L for which there exists a polynomial-time probabilistic oracle machine that used O(f(n)) random bits, queries O(g(n)) bits of its oracle and behaves as follows: If x in L then there exists an oracle y such that the machine accepts for all random choices but if x not in L then for every oracle y the machine rejects with high probability. Arora and Safra (1992) characterized NP as PCP(log n, (loglogn)/sup O(1)/). The authors improve on their result by showing that NP=PCP(logn, 1). The result has the following consequences: (1) MAXSNP-hard problems (e.g. metric TSP, MAX-SAT, MAX-CUT) do not have polynomial time approximation schemes unless P=NP; and (2) for some epsilon >0 the size of the maximal clique in a graph cannot be approximated within a factor of n/sup epsilon / unless P=NP.
FOCS	Probabilistic Checking of Proofs; A New Characterization of NP	Sanjeev Arora,Shmuel Safra	1992	The authors give a new characterization of NP: the class NP contains exactly those languages L for which membership proofs (a proof that an input x is in L) can be verified probabilistically in polynomial time using logarithmic number of random bits and sub-logarithmic number of queries to the proof. This is a non-relativizing characterization of NP. They discuss implications of this characterization; specifically, they show that approximating clique (or independent set) is NP-hard.
FOCS	Randomized Consensus in Expected O(n log ^2 n) Operations Per Processor	James Aspnes,Orli Waarts	1992	This paper presents a new randomized algorithm for achieving consensus among asynchronous processors that communicate by reading and writing shared registers. The fastest previously known algorithm requires a processor to perform an expected $O(n^2 \log n)$ read and write operations in the worst case. In our algorithm, each processor executes at most an expected $O(n \log^2 n)$ read and write operations, which is close to the trivial lower bound of $\Omega(n)$. All previously known polynomial-time consensus algorithms were structured around a shared-coin protocol [J. Algorithms, 11 (1990), pp. 441--446] in which each processor repeatedly adds random $\pm 1$ votes to a common pool. Consequently, in all of these protocols, the worst-case expected bound on the number of read and write operations done by a single processor is asymptotically no better than the bound on the total number of read and write operations done by all of the processors together. We succeed in breaking this tradition by allowing the processors to cast votes of increasing weights. This grants the adversary greater control since he can choose from up to $n$ different weights (one for each processor) when determining the weight of the next vote to be cast. We prove that our shared-coin protocol is nevertheless correct using martingale arguments.
FOCS	Clock Construction in Fully Asynchronous Parallel Systems and PRAM Simulation (Extended Abstract)	Yonatan Aumann,Michael O. Rabin	1992	Clock Construction in Fully Asynchronous Parallel Systems and PRAM Simulation (Extended Abstract)
FOCS	On-line Load Balancing (Extended Abstract)	Yossi Azar,Andrei Z. Broder,Anna R. Karlin	1992	On-line Load Balancing (Extended Abstract)
FOCS	The Distributed k-Server Problem-A Competitive Distributed Translator for k-Server Algorithms	Yair Bartal,Adi Rosén	1992	The authors consider the k-server problem in a distributed setting. Given a network of n processors, and k identical mobile servers, requests for service appear at the processors and a server must reach the request point. Besides modeling problems in computer networks where k identical mobile resources are shared by the processors of the network, this models a realistic situation where the transfer of information is costly and there is no central control that governs the behavior of servers that move around to satisfy requests for service. The problem is that of devising algorithms that minimize not only the travel of the server but also the communication cost incurred for the transmission of control messages. The main contribution is a general translator to transform any deterministic global-control competitive k-server algorithm into a distributed competitive one. As consequences they get poly(k)-competitive distributed algorithms for the line, trees and the ring.
FOCS	Improved Parallel Polynomial Division and Its Extensions	Dario Bini,Victor Y. Pan	1992	The authors compute the first N coefficients of the reciprocal r(x) of a given polynomial p(x), (r(x)p(x)=1 mod x/sup N/, p(0) not=0), by using, under the PRAM arithmetic models, O(h log N) time-steps and O((N/h)(1+2/sup -h/log/sup (h)/ N)) processors, for any h, h=1,2, . . .,log/sup */ N, provided that O(logm) steps and m processors suffice to perform DFT on m points and that log/sup (0)/ N=N, log/sup (h)/ N=log/sub 2/log/sup (h-1)/N, h=1, . . .,log/sup */N, log/sup */N=max(h:log/sup (h)/N>0). The same complexity estimates apply to some other computations, such as the division with a remainder of two polynomials of degrees O(N) and the inversion of an N*N triangular Toeplitz matrix. They also show how to extend the techniques to parallel implementation of other recursive processes, such as the evaluation modulo x/sup N/ of the m-th root, p(x)/sup 1/m/, of p(x) (for any fixed natural m), for which we need O(log N log log N) time-steps and O(N/log log N) processors. The paper demonstrates some new techniques of supereffective slowdown of parallel algebraic computations, which they combine with a technique of stream contraction.
FOCS	"How to Denest Ramanujan's Nested Radicals"	Johannes Blömer	1992	The author presents a simple condition when nested radical expressions of depth two can be denested using real radicals or radicals of some bounded degree. He describes the structure of these denestings and determines an upper bound on the maximum size of a denesting. Also for depth two radicals he describes an algorithm that will find such a denesting whenever one exists. Unlike all previous denesting algorithms the algorithm does not use Galois theory. In particular, he avoids the construction of the minimal polynomial and splitting field of a nested radical expression. Thus he can obtain the first denesting algorithm whose run time is at most, and in general much less, than polynomial in description size of the minimal polynomial. The algorithm can be used to determine non-trivial denestings for expressions of depth larger than two.
FOCS	Towards a Computational Theory of Statistical Tests (Extended Abstract)	Manuel Blum,Oded Goldreich	1992	Towards a Computational Theory of Statistical Tests (Extended Abstract)
FOCS	A Decomposition Theorem and Bounds for Randomized Server Problems	Avrim Blum,Howard J. Karloff,Yuval Rabani,Michael E. Saks	1992	The authors prove a lower bound of Omega ( square root logk/loglogk) for the competitive ratio of randomized algorithms for the k-server problem against an oblivious adversary. The bound holds for arbitrary metric spaces (of at least k+1 points) and provides a new lower bound for the metrical task system problem as well. This improves the previous best lower bound of Omega (loglogk) for arbitrary metric spaces, more closely approaching the conjectured lower bound of Omega (logk). They also prove a lower bound of Omega (/sup logk///sub loglogk/) for the server problem on k+1 equally-spaced points on a line, which corresponds to some natural motion-planning problems.
FOCS	On the Exact Learning of Formulas in Parallel (Extended Abstract)	Nader H. Bshouty,Richard Cleve	1992	On the Exact Learning of Formulas in Parallel (Extended Abstract)
FOCS	Data Structural Bootstrapping, Linear Path Compression, and Catenable Heap Ordered Double Ended Queues	Adam L. Buchsbaum,Rajamani Sundar,Robert Endre Tarjan	1992	The authors provide an efficient implementation of catenable mindeques. To prove that the resulting data structure achieves constant amortized time per operation, they consider order preserving path compression. They prove a linear bound on deque ordered spine-only path compression, a case of order persevering path compression employed by the data structure.
FOCS	On the Completeness of Object-Creating Query Languages (Extended Abstract)	Jan Van den Bussche,Dirk Van Gucht,Marc Andries,Marc Gyssens	1992	On the Completeness of Object-Creating Query Languages (Extended Abstract)
FOCS	Mick Gets Some (the Odds Are on His Side)	Vasek Chvátal,Bruce A. Reed	1992	Mick Gets Some (the Odds Are on His Side)
FOCS	Safe and Effective Determinant Evaluation	Kenneth L. Clarkson	1992	"The problem of evaluating the sign of the determinant of a small matrix aries in many geometric algorithms. Given an n*n matrix A with integer entries, whose columns are all smaller than M in Euclidean norm, the algorithm given evaluates the sign of the determinant det A exactly. The algorithm requires an arithmetic precision of less than 1.5n+2lgM bits. The number of arithmetic operations needed is O(n/sup 3/)+O(n/sup 2/) log OD(A)/ beta , where OD(A) mod det A mod is the product of the lengths of the columns of A, and beta is the number of 'extra' bits of precision, min(lg(1/u)-1.1n-2lgn-2,lgN-lgM-1.5n-1), where u is the roundoff error in approximate arithmetic, and N is the largest representable integer. Since OD(A)"
FOCS	The Complexity of Parallel Prefix Problems on Small Domains	Shiva Chaudhuri,Jaikumar Radhakrishnan	1992	The authors study the complexity of some prefix problems in the CRCW PRAM model. The main result is an Omega ( alpha (n)) lower bound for chaining, matching a previous upper bound and solving an open problem. They give reductions to show an Omega ( alpha (n)) lower bound on the complexity of the prefix maxima and range maxima problems even when the domain is (1,...,n). An interesting consequence is that prefix maximum is strictly harder than simple maximum. They also give a reduction to show an Omega ( alpha (n)) lower bound on a parenthesis matching problem, matching the upper bound. No lower bounds were previously known for any of these problems. The lower bounds contribute to the study of very fast parallel algorithms by introducing techniques for proving lower bounds for small domain problems.
FOCS	Approximate Max Flow on Small Depth Networks	Edith Cohen	1992	The author considers the maximum flow problem on directed acyclic networks with m edges and depth r (length of the longest s-t path). The main result is a new deterministic algorithm for solving the relaxed problem of computing an s-t flow of value at least (1- epsilon ) of the maximum flow. For instances where r and epsilon /sup -1/ are small (i.e., O(polylog(m))), this algorithm is in NC and uses only O(m) processors, which is a significant improvement over existing parallel algorithms. As one consequence, he obtains an NC O(m) processor algorithm to find a bipartite matching of cardinality (1- epsilon ) of the maximum (for epsilon /sup -1/ = O(polylog(m))). The parallel bounds are based on a novel approach to the blocking flow problem that produces fractional valued flow augmentations even when capacities are integral. She shows that a fractional flow on any network with integral capacities can be rounded in polylogarithmic time to an integral flow of no smaller value using O(m) processors. Hence, within the same resource bounds, an integral flow can be obtained when desired.
FOCS	Tighter Bounds on the Exact Complexity of String Matching (Extended Abstract)	Richard Cole,Ramesh Hariharan	1992	Tighter Bounds on the Exact Complexity of String Matching (Extended Abstract)
FOCS	A Class of Logic Problems Solvable by Linear Programming	Michele Conforti,Gérard Cornuéjols	1992	Several problems of propositional logic, such as satisfiability, MAXSAT and logical inference, can be formulated as integer programs. The authors consider sets of clauses for which these integer programs can be solved as linear programs. They prove that balanced sets of clauses have this property.
FOCS	Lower Bounds on the Depth of Monotone Arithmetic Computations (Extended Summary)	Don Coppersmith,Baruch Schieber	1992	Lower Bounds on the Depth of Monotone Arithmetic Computations (Extended Summary)
FOCS	Amplification and Percolation	Moshe Dubiner,Uri Zwick	1992	Amplification and Percolation
FOCS	On Efficient Band Matrix Arithmetic	Wayne Eberly	1992	An efficient parallel Las Vegas algorithm is presented for computation of the determinant of a non-singular band matrix and for the solution of a system of linear equations with a band matrix as coefficient matrix. The algorithm can be implemented using time polylogarithmic in n with O(nm/sup omega -1/) processors, in order to process an input matrix with order n and band width m, provided that n*n matrices can be multiplied in logarithmic time with O(n/sup omega /) processors. If asymptotically efficient matrix multiplication is used ( omega
FOCS	Competitive Analysis of Financial Games	Ran El-Yaniv,Amos Fiat,Richard M. Karp,G. Turpin	1992	In the unidirectional conversion problem an on-line player is given the task of converting dollars to yen over some period of time. Each day, a new exchange rate is announced and the player must decide how many dollars to convert. His goal is to minimize the competitive ratio. defined as sup/sub E/ (P/sub OPT/(E)/P/sub X/E) where E ranges over exchange rate sequences. P/sub OPT/(E) is the number of yen obtained by an optimal off-line algorithm, and Px(E) is the number of yen obtained by the on-line algorithm X. The authors also consider a continuous version of the problem. in which the exchange rate varies over a continuous time interval. The on-line line players a priori information about the fluctuation of exchange rates distinguishes different variants of the problem. For three variants they show that a simple threat-based strategy is optimal for the on-line player and determine its competitive ratio. They also derive and analyze an optimal policy for the on-line player when he knows the probability distribution of the maximum value that the exchange rate will reach. Finally, they consider a bidirectional conversion problem, which the player may trade dollars for yen or yen for dollars.
FOCS	Sparsification-A Technique for Speeding up Dynamic Graph Algorithms (Extended Abstract)	David Eppstein,Zvi Galil,Giuseppe F. Italiano,Amnon Nissenzweig	1992	Sparsification-A Technique for Speeding up Dynamic Graph Algorithms (Extended Abstract)
FOCS	On Four-Connecting a Triconnected Graph (Extended Abstract)	Tsan-sheng Hsu	1992	On Four-Connecting a Triconnected Graph (Extended Abstract)
FOCS	Exact Analysis of Hot-Potato Routing (Extended Abstract)	Uriel Feige,Prabhakar Raghavan	1992	Exact Analysis of Hot-Potato Routing (Extended Abstract)
FOCS	A Theory of Wormhole Routing in Parallel Computers (Extended Abstract)	Sergio A. Felperin,Prabhakar Raghavan,Eli Upfal	1992	A Theory of Wormhole Routing in Parallel Computers (Extended Abstract)
FOCS	The Isomorphism Conjecture Holds Relative to an Oracle	Stephen A. Fenner,Lance Fortnow,Stuart A. Kurtz	1992	The authors introduce symmetric perfect generic sets. these sets vary from the usual generic sets by allowing limited infinite encoding into the oracle. They then show that the Berman-Hartmanis (1977) isomorphism conjecture holds relative to any sp-generic oracle, i.e., for any symmetric perfect generic set A, all NP/sup A/-complete sets are polynomial-time isomorphic relative to A. As part of the proof that the isomorphism conjecture holds relative to symmetric perfect generic sets they also show that P/sup A/=FewP/sup A/ for any symmetric perfect generic/sup /A.
FOCS	On the Bit Extraction Problem	Joel Friedman	1992	"Consider a coloring of the n-dimensional Boolean cube with c=2/sup s/ colors in such a way that every k-dimensional subcube is equicolored, i.e. each color occurs the same number of times. The author shows that for such a coloring one necessarily has (k-1)/n>or= theta /sub c/=(c/2-1)/(c-1). This resolves the 'bit extraction' or 't-resilient functions' problem (also a special case of the privacy amplification problem) in many cases, such as c-1/n, proving that XOR type colorings are optimal, and always resolves this question to within c/4 in determining the optimal value of k (for any fixed n and c). He also studies the problem of finding almost equicolored colorings when (k-1)/n"
FOCS	Truly Alphabet-Independent Two-Dimensional Pattern Matching	Zvi Galil,Kunsoo Park	1992	A. Amir, G. Benson and M. Farach (see Proc. 24th STOC, p.59-68 (1992)) gave an algorithm for two-dimensional pattern matching (ABF for short) whose text processing is independent of the alphabet and takes O(n/sup 2/) time, but whose pattern processing is dependent on the alphabet and takes O(m/sup 2/log mod Sigma mod ) time. The authors present an algorithm that is truly independent of the alphabet and takes linear O(m/sup 2/+n/sup 2/) time. As in the Knuth-Morris-Pratt algorithm, the only operation on the alphabet is the equality test of two symbols. All previous algorithms except the ABF algorithm reduce the two-dimensional problem into one-dimensional string matching, and use known techniques in string matching. The ABF algorithm uses two-dimensional periodicity for text processing, but their pattern processing resorts to one-dimensional techniques. The authors present a two-dimensional technique for both pattern processing and text processing.
FOCS	A Subexponential Algorithm for Abstract Optimization Problems	Bernd Gärtner	1992	An abstract optimization problem (AOP) is a triple (H,
FOCS	Fast Algorithms for Matrix Normal Forms	Mark Giesbrecht	1992	A Las Vegas type probabilistic algorithm is presented for computing the Frobenius normal form of an n*n matrix T over any field K. The algorithm requires O/sup approximately /(MM(n))=MM(n)/sup ./(log n)/sup O(1)/ operations in K, where O(MM(n)) operations in K are sufficient to multiply two n*n matrices over K. This nearly matches the lower bound of Omega (MM(n)) operations in K for this problem, and improves on the O(n/sup 4/) operations in K required by the previously best known algorithm. The author applies the algorithm to evaluate a polynominal g in K(x) at T with /sup approximately /(MM(n)) operations in K when deg g
FOCS	Hierarchies in Transitive Closure Logic, Stratified Datalog and Infinitary Logic	Erich Grädel,Gregory L. McColm	1992	The authors establish a general hierarchy theorem for quantifier classes in the infinitary logic L/sub infinity omega //sup omega / on finite structures. In particular, it is shown that no infinitary formula with bounded number of universal quantifiers can express the negation of a transitive closure. This implies the solution of several open problems in finite model theory: On finite structures, positive transitive closure logic is not closed under negation. More generally the hierarchy defined by interleaving negation and transitive closure operators is strict. This proves a conjecture of N. Immerman (1987). The authors also separate the expressive power of several extensions of Datalog, giving new insight in the fine structure of stratified Datalog.
FOCS	Separating the Communication Complexities of MOD m and MOD p Circuits	Vince Grolmusz	1992	The author proves in this paper that it is much harder to evaluate depth-2, size-N circuits with MOD m gates than with MOD p gates by k-party communication protocols: he shows a k-party protocol which communicates O(1) bits to evaluate circuits with MOD p gates, while evaluating circuits with MOD m gates needs Omega (N) bits, where p denotes a prime, and m a composite, non-prime power number. As a corollary, for all m, he shows a function, computable with a depth-2 circuit with MOD m gates, but not with any depth-2 circuit with MOD p gates. He proves in the second part that the GIP function by L. Babai et al. (1989) needs exponential size in n when it is computed by some depth-3 circuits, with threshold, symmetric, and MOD m gates.
FOCS	Waste Makes Haste: Tight Bounds for Loose Parallel Sorting	Torben Hagerup,Rajeev Raman	1992	"Conventional parallel sorting requires the n input keys to be output in an array of size n, and is known to take Omega (log n/log log n) time using any polynomial number of processors. The lower bound does not apply to the more 'wasteful' convention of padded sorting, which requires the keys to be output in sorted order in an array of size (1+o(1))n. The authors give very fast randomised CRCW PRAM algorithms for several padded-sorting problems. Applying only pairwise comparisons to the input and using kn processors, where 2"
FOCS	Apple Tasting and Nearly One-Sided Learning	David P. Helmbold,Nick Littlestone,Philip M. Long	1992	"In the standard on-line model the learning algorithm tries to minimize the total number of mistakes made in a series of trials. On each trial the learner sees an instance, either accepts or rejects that instance, and then is told the appropriate response. The authors define a natural variant of this model ('apple tasting') where the learner gets feedback only when the instance is accepted. They use two transformations to relate the apple tasting model to an enhanced standard model where false acceptances are counted separately from false rejections. They present a strategy for trading between false acceptances and false rejections in the standard model. From one perspective this strategy is exactly optimal, including constants. They apply the results to obtain a good general purpose apple tasting algorithm as well as nearly optimal apple tasting algorithms for a variety of standard classes, such as conjunctions and disjunctions of n boolean variables. They also present and analyze a simpler transformation useful when the instances are drawn at random rather than selected by an adversary."
FOCS	Fault-tolerant Wait-free Shared Objects	Prasad Jayanti,Tushar Deepak Chandra,Sam Toueg	1992	"The authors classify object failures into two broad categories: responsive and non-responsive. They require that wait-free objects subject to responsive failures continue to respond (in finite time) to operation invocations. The responses may be incorrect. In contrast, wait-free objects subject to non-responsive failures are exempt from responding to operation invocations. Such objects may 'hang' on the invoking process. They divide responsive failures into three models: R-crash,R-omission, and R-arbitrary. They divide non-responsive failures into crash, omission, and arbitrary. An object subject to crash failure behaves correctly until it fails, and once it fails, it never responds to operation invocations. An object subject to omission failures may fail to respond to the invocations of an arbitrary subset of processes, but continue to respond to the invocations of the remaining processes (forever)."
FOCS	A Mildly Exponential Approximation Algorithm for the Permanent	Mark Jerrum,Umesh V. Vazirani	1992	An approximation algorithm for the permanent of an n*n 0,1-matrix is presented. The algorithm is shown to have worst-case time complexity exp (0(n/sup 1/2/ log/sup 2/ n)). Asymptotically, this represents a considerable improvement over the best existing algorithm, which has worst-case time complexity of the form e/sup theta (n)/.
FOCS	On the Second Eigenvalue and Linear Expansion of Regular Graphs	Nabil Kahale	1992	The authors investigate the relation between the second eigen-value and the linear expansion of regular graphs. The spectral method is the best currently known technique to prove lower bounds on the expansion. He improves this technique by showing that the expansion coefficient of linear-sized subsets of a k-regular graph G is at least k/2(1- square root max(0,1-/sub lambda 1(G)2//sup 4k-4/))/sup -/ , where lambda /sub 1/(G) is the second largest eigenvalue of the graph. In particular, the linear expansion of Ramanujan graphs, which have the property that the second largest eigenvalue is at most 2 square root k-1, is at least (k/2)/sup -/. This improves upon the best previously known lower bound of 3(k-2)/8. For any integer k such that k-1 is prime, he explicitly constructs an infinite family of k-regular graphs G/sub n/ on n vertices whose linear expansion is k/2 and such that lambda /sub 1/(G/sub n/)
FOCS	Processor-Efficient Parallel Solution of Linear Systems II: The Positive Characteristic and Singular Cases (Extended Abstract)	Erich Kaltofen,Victor Y. Pan	1992	Processor-Efficient Parallel Solution of Linear Systems II: The Positive Characteristic and Singular Cases (Extended Abstract)
FOCS	Drawing Planar Graphs Using the lmc-Ordering (Extended Abstract)	Goos Kant	1992	Drawing Planar Graphs Using the lmc-Ordering (Extended Abstract)
FOCS	Markov Paging (Extended Abstract)	Anna R. Karlin,Steven J. Phillips,Prabhakar Raghavan	1992	Markov Paging (Extended Abstract)
FOCS	On Minimum and Maximum Spanning Trees of Linearly Moving Points	Naoki Katoh,Takeshi Tokuyama,Kazuo Iwano	1992	The authors investigate the upper bounds on the numbers of transitions of minimum and maximum spanning trees (MinST and MaxST for short) for linearly moving points. Suppose that one is given a set of n points in general d-dimensional space, S=(p/sub 1/,p/sub 2/, . . ., p/sub n/), and that all points move along different straight lines at different but fixed speeds, i.e., the position of p/sub i/ is a linear function of a real parameter. They investigate the numbers of transitions of MinST and MaxST when t increases from - infinity to + infinity . They assume that the dimension d is a fixed constant. Since there are O(n/sup 2/) distances among n points, there are naively O(n/sup 4/) transitions of MinST and MaxST. They improve these trivial upper bounds for L/sub 1/ and L/sub infinity / distance metrics. Let c/sub p/(n, min) (resp. c/sub p/(n, max)) be the number of maximum possible transitions of MinST (resp. MaxST) in L/sub p/ metric for n linearly moving points. They give the following results; c/sub 1/(n, min)=O(n/sup 5/2/a(n)), c/sub infinity /(n, min)=O(n/sup 5/2/a(n)), c/sub 1/(n, max)=O(n/sup n/) and c/sub infinity /(n, max)=O(n/sup 2/) where O(n) is the inverse Ackermann function. They also investigate two restricted cases.
FOCS	Tiling a Polygon with Rectangles	Claire Kenyon,Richard Kenyon	1992	The authors study the problem of tiling a simple polygon of surface n with rectangles of given types (tiles). They present a linear time algorithm for deciding if a polygon can be tiled with 1 * m and k * 1 tiles (and giving a tiling when it exists), and a quadratic algorithm for the same problem when the tile types are m * k and k * m.
FOCS	Efficient Inference of Partial Types	Dexter Kozen,Jens Palsberg,Michael I. Schwartzbach	1992	"Partial types for the lambda -calculus were introduced by Thatte (1988) as a means of typing objects that are not typable with simple types, such as heterogeneous lists and persistent data. He showed that type inference for partial types was semidecidable. Decidability remained open until O'Keefe and Wand gave an exponential time algorithm for type inference. The authors give an O(n/sup 3/) algorithm. The algorithm constructs a certain finite automaton that represents a canonical solution to a given set of type constraints. Moreover, the construction works equally well for recursive types."
FOCS	On the Fault Tolerance of Some Popular Bounded-Degree Networks	Frank Thomson Leighton,Bruce M. Maggs,Ramesh K. Sitaraman	1992	The authors analyze the fault-tolerance properties of several bounded-degree networks that are commonly used for parallel computation. Among other things, they show that an N-node butterfly containing N/sup 1- epsilon / worst-case faults (for any constant epsilon >0) can emulate a fault-free butterfly of the same size with only constant slowdown. Similar results are proved for the shuffle-exchange graph. Hence, these networks become the first connected bounded-degree networks known to be able to sustain more than a constant number of worst-case faults without suffering more than a constant-factor slowdown in performance. They also show that an N-node butterfly whose nodes fail with some constant probability p can emulate a fault-free version of itself with a slowdown of 2/sup O(log* N)/, which is a very slowly increasing function of N. The proofs of these results combine the technique of redundant computation with new algorithms for routing packets around faults in hypercubic networks. Techniques for reconfiguring hypercubic networks around faults that do not rely on redundant computation are also presented. These techniques tolerate fewer faults but are more widely applicable since they can be used with other networks such as binary trees and meshes of trees.
FOCS	Enumerating the k Closest Pairs Optimally	Hans-Peter Lenhof,Michiel H. M. Smid	1992	Let S be a set of n points in D-dimensional space, where D is a constant, and let k be an integer between 1 and (/sub 2//sup n/) An algorithm is given that computes the k closest pairs in the set S in O(nlogn+k) time, using O(n+k) space. The algorithm fits in the algebraic decision tree model and is, therefore, optimal.
FOCS	Undecidability of the Horn-Clause Implication Problem	Jerzy Marcinkowski,Leszek Pacholski	1992	"The authors prove that the problem 'given two Horn clauses H/sub 1/=( alpha /sub 1/ V-product alpha /sub 2/ to beta ) and H/sub 2/=( gamma /sub 1/ V-product . . . V-product gamma /sub k/ to delta ), where alpha /sub i/, beta , gamma /sub i/, delta are atomic formulas, decide if H/sub 2/, is a consequence of H/sub 1/' is not recursive. This solves one of the last open decidability problems concerning formulas in pure predicate logic (i.e. without equality symbol). The proof depends on a thorough analysis of derivation trees of one rule of inference with two premisses and one conclusion, and it may have further applications."
FOCS	On the Randomized Complexity of Volume and Diameter	László Lovász,Miklós Simonovits	1992	The authors give an O(n/sup 7/log/sup 2/n) randomised algorithm to approximate the volume of a convex body, and an O(n/sup 6/log n) algorithm to sample a point from the uniform distribution over a convex body. For convex polytopes the algorithm runs in O(n/sup 7/log/sup 4/n) steps. Several tools are developed that may be interesting on their own. They extend results of Sinclair-Jerrum (1988) and the authors (1990) on the mixing rate of Markov chains from finite to arbitrary Markov chains. They describe an algorithm to integrate a function with respect to the stationary distribution of a general Markov chain. They also analyze the mixing rate of various random walks on convex bodies, in particular the random walk with steps from the uniform distribution over a unit ball. In several previous positive and negative results, the problem of computing the diameter of a convex body behaved similarly as the volume problem. In contrast to this, they show that there is no polynomial randomized algorithm to compute the diameter within a factor of n/sup 1/4/.
FOCS	Computing in Solvable Matrix Groups	Eugene M. Luks	1992	The author announces methods for efficient management of solvable matrix groups over finite fields. He shows that solvability and nilpotence can be tested in polynomial-time. Such efficiency seems unlikely for membership-testing, which subsumes the discrete-log problem. However, assuming that the primes in mod G mod (other than the field characteristic) are polynomially-bounded, membership-testing and many other computational problems are in polynomial time. These problems include finding stabilizers of vectors and of subspaces and finding centralizers and intersections of subgroups. An application to solvable permutation groups puts the problem of finding normalizers of subgroups into polynomial time. Some of the results carry over directly to finite matrix groups over algebraic number fields; thus, testing solvability is in polynomial time, as is testing membership and finding Sylow subgroups.
FOCS	The Asymptotic Complexity of Merging Networks	Peter Bro Miltersen,Mike Paterson,Jun Tarui	1992	"Let M(m,n) be the minimum number of comparators needed in a comparator network that merges m elements x/sub 1/or=m. Batcher's odd-even merge yields the following upper bound: M(m,n)or=m to infinity :M(m,n)>or=/sup 1///sub 2/(m+n)log/sub 2/(m+1)-O(m); in particular, M(n,n)>or=nlog/sub 2/n-O(n). The authors' proof technique extends to give similarly tight lower bounds for the size of monotone Boolean circuits for merging, and for the size of switching networks capable of realizing the set of permutations that arise from merging."
FOCS	Computing a Shortest k-Link Path in a Polygon	Joseph S. B. Mitchell,Christine D. Piatko,Esther M. Arkin	1992	"The authors consider the problem of finding a shortest polygonal path from s to t within a simple polygon P, subject to the restriction that the path have at most k links (edges). They give an algorithm to compute a k-link path with length at most (1 + epsilon ) times the length of a shortest k-link path, for any error tolerance epsilon >0. The algorithm runs in time O(n/sup 3/k/sup 3/ log (Hk/ epsilon /sup 1/k/)), where N is the largest integer coordinate among the n vertices of P. They also study the more general problem of approximating shortest k-link paths in polygons with holes. In this case, they give an algorithm that returns a path with at most 2k links and length at most that of a shortest k-link path; the running time is O(kE/sup 2/), where E is the number of edges in the visibility graph. Finally, they study the bicriteria path problem in which the two criteria are link length and 'total turn' (the integral of mod Delta theta mod along a path). They obtain in an exact polynomial-time algorithm for polygons with holes."
FOCS	Undirected Connectivity in O(log ^1.5 n) Space	Noam Nisan,Endre Szemerédi,Avi Wigderson	1992	Undirected Connectivity in O(log ^1.5 n) Space
FOCS	Randomized Geometric Algorithms and Pseudo-Random Generators (Extended Abstract)	Ketan Mulmuley	1992	Randomized Geometric Algorithms and Pseudo-Random Generators (Extended Abstract)
FOCS	The Power of Combining the Techiques of Algebraic and Numerical Computing: Improved Approximate Multipoint Polynomial Evaluation and Improved Multipole Algorithms	Victor Y. Pan,John H. Reif,Stephen R. Tate	1992	The authors demonstrate the power of combining the techniques of algebraic computation with ones of numerical computation. They do this by improving the known methods for polynomial evaluation on a set of real points and for simulation of n charged particles on the plane. In both cases they approximate (rather than exactly compute) the solutions and do this by exploiting algebraic techniques of the algorithm design.
FOCS	The Complexity of the Hajós Calculus	Toniann Pitassi,Alasdair Urquhart	1992	The Hajos construction is a simple, nondeterministic procedure for generating the class of graphs that are not 3-colorable. A.J. Mansfield and D.J.A. Welsh have posed the problem of proving whether or not there exists a polynomial-size Hajos construction for every non-3-colorable graph. The main result of this paper is a proof that the Hajos calculus is polynomially-bounded if and only if extended Frege proof systems are polynomially bounded. This result links an open problem in graph theory to an important open problem in the complexity of propositional proof systems. In addition, the authors establish an exponential lower bound for a strong subsystem of the Hajos calculus. Lastly, they discuss an interesting graph-theoretical consequence of this result.
FOCS	Improved Lower Bounds for Shellsort	C. Greg Plaxton,Bjorn Poonen,Torsten Suel	1992	The authors give improved lower bounds for Shellsort based on a new and relatively simple proof idea. The lower bounds obtained are both stronger and more general than the previously known bounds. In particular, they hold for nonmonotone increment sequences and adaptive Shellsort algorithms, as well as for some recently proposed variations of Shellsort.
FOCS	Quadratic Dynamical Systems (Preliminary Version)	Yuri Rabinovich,Alistair Sinclair,Avi Wigderson	1992	Quadratic Dynamical Systems (Preliminary Version)
FOCS	"Newton's Method for Fractional Combinatorial Optimization"	Tomasz Radzik	1992	"The authors considers Newton's method for the linear fractional combinatorial optimization. He proves a strongly polynomial bound on the number of iterations for the general case. He considers the maximum mean-weight cut problem, which is a special case of the linear fractional combinatorial optimization. This problem is closely related to the parametric flow problem and the flow problem when the maximum arc cost is being minimised. He proves that Newton's method runs in O(m) iterations for the maximum mean-weight cut problem. One iteration is dominated by the maximum flow computation. This gives the best known strongly polynomial bound of O(m/sup 2/n) for all three problems mentioned."
FOCS	Fully Dynamic Biconnectivity in Graphs	Monika Rauch	1992	"The author presents an algorithm for maintaining the bi-connected components of a graph during a sequence of edge insertions and deletions. It requires linear storage and preprocessing time. The amortized running time for insertions and for deletions is O(m/sup 2/3/), where m is the number of edges in the graph. Each query of the form 'Are the vertices u and v biconnected?' can be answered in time O(1). This is the first sublinear algorithm for this problem. If the input is a planar embedded graph, the amortized running time for insertions and deletions drops to O( square root nlogn) and the worst case query time is O((logn)/sup 2/), where n is the number of vertices in the graph. The best previously known solution takes time O(n/sup 2/3/) per update or query."
FOCS	Zero-Knowledge Proofs of Knowledge Without Interaction (Extended Abstract)	Alfredo De Santis,Giuseppe Persiano	1992	Zero-Knowledge Proofs of Knowledge Without Interaction (Extended Abstract)
FOCS	Communication on Noisy Channels: A Coding Theorem for Computation	Leonard J. Schulman	1992	"Communication is critical to distributed computing, parallel computing, or any situation in which automata interact-hence its significance as a resource in computation. In view of the likelihood of errors occurring in a lengthy interaction, it is desirable to incorporate this possibility in the model of communication. The author relates the noisy channel and the standard (noise less channel) complexities of a communication problem by establishing a 'two-way' or interactive analogue of Shanon's coding theorem: every noiseless channel protocol can be simulated by a private-coin noisy channel protocol whose time bound is proportional to the original (noiseless) time bound and inversely proportional to the capacity of the channel, while the protocol errs with vanishing probability. The method involves simulating the original protocol while implementing a hierarchical system of progress checks which ensure that errors of any magnitude in the simulation are, with high probability, rapidly eliminated."
FOCS	Efficient Self-Embedding of Butterfly Networks with Random Faults	Hisao Tamaki	1992	The author studies the embedding of the butterfly network in a faulty version of itself where each node is independently faulty with some constant probability. He shows that such a self-embedding of the N-node butterfly with O(1) load, O((log logN)/sup 2.6/) dilation, and 0((log log N)/sup 8.2/) congestion is possible with high probability, assuming sufficiently small node-failure probability. This embedding is level-preserving in the sense that each node is mapped to a node in the same level of the butterfly. He also derives a lower bound of log log log N-c on the dilation of a level-preserving embedding with O(log/sup alpha / N) load, for any alpha , 00, and some constant c depending on alpha and p.
FOCS	Maximizing Non-Linear Concave Functions in Fixed Dimension	Sivan Toledo	1992	Consider a convex set P in R/sup d/ and a piece wise polynomial concave function F: P to R. Let A be an algorithm that given a point x in IR/sup d/ computes F(x) if x in P, or returns a concave polynomial p such that p(x) or= 0. The author assumes that d is fixed and that all comparisons in A depend on the sign of polynomial functions of the input point. He shows that under these conditions, one can find max/sub P/ F in time which is polynomial in the number of arithmetic operations of A. Using this method he gives the first strongly polynomial algorithms for many nonlinear parametric problems in fixed dimension, such as the parametric max flow problem, the parametric minimum s-t distance, the parametric spanning tree problem and other problems. In addition he shows that in one dimension, the same result holds even if one only knows how to approximate the value of F. Specifically, if one can obtain an alpha -approximation for F(x) then one can alpha -approximate the value of maxF. He thus obtains the first polynomial approximation algorithms for many NP-hard problems such as the parametric Euclidean traveling salesman problem.
FOCS	Optimal Parallel Hull Construction for Simple Polygons in \calO(log log n) Time	Hubert Wagener	1992	Optimal Parallel Hull Construction for Simple Polygons in \calO(log log n) Time
FOCS	Algebraic Decision Trees and Euler Characteristics	Andrew Chi-Chih Yao	1992	For any set S contained in R/sup n/, let chi (S) denote its Euler characteristic. The author shows that any algebraic computation tree or fixed-degree algebraic decision tree must have height Omega (log mod chi (S) mod )for deciding the membership question of a compact semi-algebraic set S. This extends a result by A. Bjorner, L. Lovasz and A. Yao where it was shown that any linear decision tree for deciding the membership question of a closed polyhedron S must have height greater than or equal to log/sub 3/ mod chi (S) mod .
FOCS	Fast Unimodular Reduction: Planar Integer Lattices (Extended Abstract)	Chee-Keng Yap	1992	Fast Unimodular Reduction: Planar Integer Lattices (Extended Abstract)
FOCS	33rd Annual Symposium on Foundations of Computer Science, 24-27 October 1992, Pittsburgh, Pennsylvania, USA		1992	33rd Annual Symposium on Foundations of Computer Science, 24-27 October 1992, Pittsburgh, Pennsylvania, USA
SODA	Comparison-Sorting and Selecting in Totally Monotone Matrices.	Noga Alon,Yossi Azar	1992	An m x n matrix A is called totally monotone if for all i1 < i2 and j1 < j2, A[i1, j1] > A[i1, j2 implies A[i2, j1] > A[i2, j2]. We consider the complexity of comparison-based selection and sorting algorithms in such matrices. Although our selection algorithm counts only comparisons its advantage on all previous work is that it can also handle selection of elements of different (and arbitrary) ranks in different rows (or even selection of elements of several ranks in each row), in time which is slightly better than that of the best known algorithm for selecting elements of the same rank in each row. We also determine the decision tree complexity of sorting each row of a totally monotone matrix up to a factor of at most log n by proving a quadratic lower bound and by slightly improving the upper bound. No nontrivial lower bound was previously known for this problem. In particular for the case m = n we prove a tight &OHgr;(n2) lower bound. This bound holds for any decision-tree algorithm, and not only for a comparison-based algorithm. The lower bound is proved by an exact characterization of the bitonic totally monotone matrices, whereas our new algorithms depend on techniques from parallel comparison algorithms.
SODA	Relative Neighborhood Graphs in Three Dimensions.	Pankaj K. Agarwal,Jirí Matousek	1992	The relative neighborhood graph (RNG) of a set S of n points in R is a graph (S, E), where (p, q) &egr; E if and only if there is no point z &egr; S such that max {d(p, z), d(q,z)} < d(p,q). We show that in R , RNG(S) has O(n4/3) edges. We present a randomized algorithm that constructs RNG(S) in expected time O(n3/2+&egr;) assuming that the points of S are in general position. If the points of S are arbitrary, the expected running time is O(n7/4+&egr;). These algorithms can be made deterministic without affecting their asymptotic running time.
SODA	Finding a Line Transversal of Axial Objects in Three Dimensions.	Nina Amenta	1992	An axial object in E3 is a box or rectangle, all of whose edges are parallel to the coordinate axes. A line transveral of a set of axial objects is a line that intersects every object. We present an algorithm which finds a line transversal, if one exists, in expected linear time. In the process, we generalize a randomized linear programming algorithm, and prove that the set of line transversals of axial objects has a constant number of connected components.
SODA	Two-Dimensional Periodicity and Its Applications.	Amihood Amir,Gary Benson	1992	"String matching is rich with a variety of algorithmic tools. In contrast, multidimensional matching has a rather sparse set of techniques. This paper presents a new algorithmic technique for two-dimensional matching, that of periodicity analysis. Periodicity in strings has been used to solve string matching problems. The success of these algorithms suggests that periodicity can be as important a tool in multidimensional matching. However, multidimensional periodicity is not as simple as it is in strings and was not formally studied or used in pattern matching. This paper's main contribution is defining and analysing two-dimensional periodicity in rectangular arrays. In addition, we introduce a new pattern matching paradigm - Compressed Matching. A text array T and a pattern array P are given in compressed forms c(T) and c(P). We seek all appearances of P in T, without decompressing T. By using periodicity analysis, we show that for the two-dimensional run-length compression there is a O(|c(T)|log|P|+|P|), or almost optimal algorithm that can achieve a search time that is sublinear in the size of the text |T|."
SODA	Applications of Parametric Searching in Geometric Optimization.	Pankaj K. Agarwal,Micha Sharir,Sivan Toledo	1992	"We present several applications in computational geometry of Megiddo's parametric searching technique. These applications include; (1) Finding the minimum Hausdorff distance in the Euclidean metric between two polygonal regions under translation; (2) Computing the biggest line segment that can be placed inside a simple polygon; (3) Computing the smallest width annulus that can contain a given set of points in the plane; (4) Solving the 1-segment center problem&mdash;given a set of points in the plane, find a placement for a given line segment (under translation and rotation) which minimizes the largest distance from the segment to the given points; (5) Given a set of n points in 3-space, finding the largest radius r such that if we place a ball of radius r around each point, no segment connecting a pair of points is intersected by a third ball. Besides obtaining efficient solutions to all these problems (which, in every case, either improve considerably previous solutions or are the first non-trivial solutions to these problems), our goal is to demonstrate the versatility of the parametric searching technique."
SODA	Counting Networks with Arbitrary Fan-Out.	Eran Aharonson,Hagit Attiya	1992	It is shown that an acyclic smoothing network (and hence counting network) with fan-out n cannot be constructed from balancers of fan-out b1,..., bk, if there exists a prime factor p of n, such that p does not divide bi, for all i, 1 ≤ i ≤ k. This holds regardless of the depth, fan-in or size of the network, as long as they are finite. On the positive side, a simple construction of cyclic counting networks with fan-out n, for arbitrary n, is presented. An acyclic counting network with fan-in and fan-out p2k, for any integer k ≥ 0, is constructed out of 2-balancers and p-balancers.
SODA	Improved Parallel Integer Sorting Without Concurrent Writing.	Susanne Albers,Torben Hagerup	1992	We show that n integers in the range 1..n can be stably sorted on an EREW PRAM using O((log n)1/2) time, O(n(log n)1/2(log log n)1/2) operations and O(n) space. In addition, we are able to stably sort n integers in the range 1..n on a deterministic CREW PRAM in O((log n)3/2) time with O(n(log n)1/2) operations and O(n) space and to stably sort n arbitrary integers on a randomized CREW PRAM within the same complexity bounds with high probability. In each case our algorithm is closer to optimality than all previous algorithms for the stated problem in the stated model, and our third result matches the operation count of the best known sequential algorithm. We also show that m integers in the range 1..m can be sorted in O((log n)2) time with O(n) operations on an EREW PRAM using a nonstandard word length of O(log n log log n log m) bits, thereby greatly improving the upper bound on the word length necessary to sort integers with a linear time-processor product, even sequentially. Our algorithms were inspired by, and in one case directly use, the fusion trees recently introduced by Fredman and Willard.
SODA	Optimal Link Path Queries in a Simple Polygon.	Esther M. Arkin,Joseph S. B. Mitchell,Subhash Suri	1992	We develop a data structure for answering link distance queries between two arbitrary points in a simple polygon. The data structure requires O(n3) time and space for its construction and answers link distance queries in O(log n) time. Our result extends to link distance queries between pairs of segments or polygons. We also propose a simpler data structure for computing a link distance approximately, where the error is bounded by a small additive constant. Finally, we also present a scheme for approximating the link and the shortest path distance simultaneously.
SODA	The Competitiveness of On-Line Assignments.	Yossi Azar,Joseph Naor,Raphael Rom	1992	"Consider the on-line problem where a number of servers are ready to provide service to a set of customers. Each customer's job can be handled by any of a subset of the servers. Customers arrive one-by-one and the problem is to assign each customer to an appropriate server in a manner that will balance the load on the servers. This problem can be modeled in a natural way by a bipartite graph where the vertices of one side (customers) appear one at a time and the vertices of the other side (servers) are known in advance. We derive tight bounds on the competitive ratio in both deterministic and randomized cases. Let n denote the number of servers. In the deterministic case we provide an on-line algorithm that achieves a competitive ratio of k = [log2 n] (up to an additive 1) and prove that this is the best competitive ratio that can be achieved by any deterministic on-line algorithm. In a similar way we prove that the competitive ratio for the randomized case is k=ln(n) (up to an additive 1). We conclude that for this problem, randomized algorithms differ from deterministic ones by precisely a constant factor."
SODA	Deciding Finiteness of Matrix Groups in Las Vegas Polynomial Time.	László Babai	1992	Let G be a group of matrices with integer entries, given by a list of generators. It is known that membership in such a group is undecidable, even for 4 x 4 integral matrices [Mi]. In this paper we show that one can decide whether or not G is finite, in Las Vegas polynomial time. The key estimate derived makes the entire &ldquo;black box group&rdquo; theory ([BSz], [BCFLS], [Ba2], [BKL]) applicable to the finite groups of integral matrices. In particular it follows that in this case, structural properties such as solvability and nilpotence are decidable in Monte Carlo polynomial time; and membership, order, isomorphism, and a host of other problems are in the relatively low complexity class AM &cap; coAM [Ba1]. We give two algorithms. The simpler one (Monte Carlo but not Las Vegas) employs a refinement of the random walk technique over groups, developed in [Ba3] (applied here to infinite groups). The termination rule rests on a new estimate on the bit-size of the elements of finite groups G, obtained via polynomial time symbolic manipulation of representations over algebraic number fields using results of [BR]. This symbolic manipulation technique is the basis of the Las Vegas algorithm. (A Las Vegas algorithm is a rnadomized algorithm which never errs; but with small probability, it may r eport failure.)
SODA	On-Line Navigation in a Room.	Eldad Bar-Eli,Piotr Berman,Amos Fiat,Peiyuan Yan	1992	We consider the problem of navigating through an unknown environment in which the obstacles are disjoint oriented rectangles enclosed in an n x n square room. The task of navigating algorithm is to reach the center of the room starting from one of the corners. While there always exists a path of length n, the best previously known navigating algorithm finds paths of length n201nn . We give an efficient deterministic algorithm which finds a path of length O(n ln n); this algorithm uses tactile information only. Moreover, we prove that any deterministic algorithm can be forced to traverse a distance of &OHgr;(n ln n), even if it uses visual information.
SODA	Dynamic Point Location in General Subdivisions.	Hanna Baumgarten,Hermann Jung,Kurt Mehlhorn	1992	The dynamic planar point location problem is the task of maintaining a dynamic set S of n non-intersecting, except possibly at endpoints, line segments in the plane under the following operations: &bull;Locate(q point): Report the segment immediately above q, i.e., the first segment intersected by an upward vertical ray starting at q; &bull;Insert(s segment): Add segment s to the collection S segments; &bull;Delete(s segment): Remove segment s from the collection S of segments. We present a solution which requires space O(n), has query and insertion time O(log n loglog n) and deletion time O(log2 n). A query time below O(log2 n) was previously only known for monotone subdivisions and horizontal segments and required non-linear space.
SODA	Improved Approximations for the Steiner Tree Problem.	Piotr Berman,Viswanathan Ramaiyer	1992	For a set S contained in a metric space, a Steiner tree of S is a tree that connects the points in S. Finding a minimum cost Steiner tree is an NP-hard problem in euclidean and rectilinear metrics as well as in graphs. We give an approximation algorithm and show that the worst-case ratio of the cost of our solutions to the optimal cost is better than previously known ratios in graphs, and in rectilinear metric on the plane. Our method offers a trade-off between the running time and the ratio; on one hand it always allows to improve the ratio, on the other it allows to obtain previously known ratios with much greater efficiency. We use properties of optimal rectilinear Steiner trees to obtain significantly better ratio and running time in rectilinear metric.
SODA	The Complexity of Heaps.	Svante Carlsson,Jingsen Chen	1992	In this paper, we investigate the complexity of heaps. In particular, we study the construction problem and the search problem for heaps. We derive an adversary-based lower bound for the heap construction problem. It is shown that 1.5(n + 1)&ndash;log(n + 1)&ndash;2 comparisons are necessary to construct a heap of size n in the worst case. This is the first non-trivial adversary lower bound for this problem, which improves the previous best lower bound based on an information theoretical argument for the heap construction. Furthermore, we prove fairly trivial tight upper and lower bounds on the number of comparisons needed to search for a given element in a heap. An optimal 3/4n-time search algorithm is presented. Our lower bound for searching is also demonstrated by an adversary argument, which improves the information theory bound for the problem as well.
SODA	Directed Bumberings, Rubber Bands, and Testing Digraph -Vertex Connectivity.	Joseph Cheriyan,John H. Reif	1992	Directed Bumberings, Rubber Bands, and Testing Digraph -Vertex Connectivity.
SODA	Generosity Helps, or an 11-Competitive Algorithm for Three Servers.	Marek Chrobak,Lawrence L. Larmore	1992	Generosity Helps, or an 11-Competitive Algorithm for Three Servers.
SODA	"On Playing ""Twenty Questions"" with a Liar."	Aditi Dhagat,Péter Gács,Peter Winkler	1992	"On Playing ""Twenty Questions"" with a Liar."
SODA	Approximating the Minimum Weight Triangulation.	David Eppstein	1992	In O(n log n) time we compute a triangulation with O(n) new points, and no obtuse triangles, that has length within a constant factor of the minimum possible. We also approximate the minimum weight Steiner triangulation using triangulations with no sharp angles. No previous polyonomial time triangulation achieved an approximation factor better than O(log n).
SODA	New Algorithms for Minimum Area -gons.	David Eppstein	1992	Given a set P of n points in the plane, we wish to find a set Q &sub; P of k points for which the convex hull conv(Q> has the minimum area. We solve this, and the related problem of finding a minimum area convex k-gon, in time O(n2 log n) for fixed k, almost matching known bounds for the minimum area triangle problem. Our algorithm is based on finding a certain number of nearest vertical neighbors to each line segment determined by two input points. We use a classical result of Ramsey theory to prove that these nearest neighbors suffice to determine the minimum convex k-gon.
SODA	Approximating the Minimum Degree Spanning Tree to Within One from the Optimal Degree.	Martin Fürer,Balaji Raghavachari	1992	We consider the problem of constructing a spanning tree for a graph G = (V,E) with n vertices whose maximal degree is the smallest among all spanning trees of G. This problem is easily shown to be NP-hard. We describe an iterative polynomial time approximation algorithm for this problem. This algorithm computes a spanning tree whose maximal degree is at most O(&Dgr; + log n), where &Dgr; is the degree of some optimal tree. The result is generalized to the case where only some vertices need to be connected (Steiner case) and to the case of directed graphs. It is then shown that our algorithm can be refined to produce a spanning tree of degree at most &Dgr; + 1. Unless P = NP, this is the best bound achievable in polynomial time.
SODA	A General Approximation Technique for Constrained Forest Problems.	Michel X. Goemans,David P. Williamson	1992	We present a general approximation technique for a large class of graph problems. Our technique mostly applies to problems of covering, at minimum cost, the vertices of a graph with trees, cycles or paths satisfying certain requirements. In particular, many basic combinatorial optimization problems fit in this framework, including the shortest path, minimum spanning tree, minimum-weight perfect matching, traveling salesman and Steiner tree problems. Our technique produces approximation algorithms that run in O(n2 log n) time and come within a factor of 2 of optimal for most of these problems. For instance, we obtain a 2-approximation algorithm for the minimum-weight perfect matching problem under the triangle inequality. Our running time of O(n2 log n) time compares favorably with the best strongly polynomial exact algorithms running in O(n3) time for dense graphs. A similar result is obtained for the 2-matching problem and its variants.We also derive the first approximation algorithms for many NP-complete problems, including the non-fixed point-to-point connection problem, the exact path partitioning problem and complex location-design problems. Moreover, for the prize-collecting traveling salesman or Steiner tree problems, we obtain 2-approximation algorithms, therefore improving the previously best-known performance guarantees of 2.5 and 3, respectively [4].
SODA	The On-Line -Dimensional Dictionary Problem.	Teofilo F. Gonzalez	1992	We present a new algorithm for the on-line d-dimensional dictionary problem which has many applications including the management of geometrical objects and geometrical searching. The dictionary problem consists of executing on-line any sequence of the following operations: INSERT(p), DELETE(p) and MEMBERSHIP(p), where p is any point in d-space. We introduce a clean structure based on balanced binary search trees, which we call d-dimensional balanced binary search trees, to represent the set of points. We present algorithms for each of the above operations that take O(d + log n) time, where n is the current number of points in the set, and each INSERT and DELETE operation requires no more than a constant number of rotations. Our procedures are almost identical to the ones for balanced binary search trees. The main difference is in the way we search for an element. Our search strategy is based on the principle &ldquo;assume, verify and conquer&rdquo; (AVC). We apply this principle as follows. To avoid multiple verifications we shall assume that some prefixes of strings match. At the end of our search we must determine whether or not these assumptions were valid. This can be done by performing one simple verification step that takes O(d) time. The elimination of multiple verifications is important because in the worst case there are &OHgr;(log n) verifications, and each could take &OHgr;(d) time.
SODA	Theoretical and Practical Aspects of Combinatorial Problem Solving.	Martin Grötschel	1992	Theoretical and Practical Aspects of Combinatorial Problem Solving.
SODA	The Robot Localization Problem in Two Dimensions.	Leonidas J. Guibas,Rajeev Motwani,Prabhakar Raghavan	1992	"We consider the following problem: given a simple polygon P and a star-shaped polygon V, find a point (or the set of points) in P from which the portion of P that is visible is congruent to V. The problem arises in the localization of robots using a range-finder&mdash;P is a map of a known environment, V is the portion visible from the robot's position, and the robot must use this information to determine its position in the map. We give a scheme that preprocesses P so that any subsequent query V is answered in optimal time O(m + log n + A), where m and n are the number of vertices in V and P, and A is the number of points in P that are valid answers (the output size). Our technique allows us to trade off smoothly between the query time and the preprocessing time or space. We also devise a data structure for output-sensitive determination of the visibility polygon of a query point inside a polygon P. We then consider a variant of the localization problem in which there is a maximum distance to which the robot can &ldquo;see&rdquo;&mdash;this is motivated by practical considerations, and we outline a similar solution for this case. We also show that a single localization query V can be answered in time O(mn) with no preprocessing."
SODA	Parametric Optimization of Sequence Alignment.	Dan Gusfield,K. Balasubramanian,Dalit Naor	1992	The optimal alignment or the weighted minimum edit distance between two DNA or amino acid sequences for a given set of weights is computed by classical dynamic programming techniques, and is widely used in Molecular Biology. However, in DNA and amino acid sequences there is considerable disagreement about how to weight matches, mismatches, insertions/deletions (indels) and gaps. Parametric Sequence alignment is the problem of computing the optimal valued alignment between two sequences as a function of variable weights for matches, mismatches, spaces and gaps. The goal is to partition the parameter space into regions (which are necessarily convex) such that in each region one alignment is optimal throughout and such that the regions are maximal for this property. In this paper we are primarily concerned with the structure of this convex decomposition, and secondarily with the complexity of computing the decomposition. The most striking results are the following: For the special case where only matches, mismatches and spaces are counted, and where spaces are counted throughout the alignment, we show that the decomposition is surprisingly simple: all regions are infinite; there are at most n2/3 regions; the lines that bound the regions are all of the form &bgr; = c+(c + 0.5)&agr;; and the entire decomposition can be found in O(knm) time, where k is the actual number of regions and n < m are the lengths of the two strings. These results were found while implementing a large software package to do parametric sequence analysis, and in turn have led to faster algorithms for those tasks.
SODA	Lower Bounds for On-Line Graph Coloring.	Magnús M. Halldórsson,Mario Szegedy	1992	"An algorithm for vertex-coloring graphs is said to be online if each vertex is irrevocably assigned a color before any later vertices are considered. We show that such algorithms are inherently ineffective. The performance ratio of any such algorithm can be no better than &OHgr;(n/log2 n), even for randomized algorithms against oblivious adversary. We also show that various means of relaxing the constraints of the on-line model do not reduce these lower bounds. The features include presenting the input in blocks of log2 n vertices, recoloring any fraction of the vertices, presorting vertices according to degree, and disclosing the adversary's previous coloring."
SODA	Computing Minimal Spanning Subgraphs in Linear Time.	Xiaofeng Han,Pierre Kelsen,Vijaya Ramachandran,Robert Endre Tarjan	1992	Let P be a property of undirected graphs. We consider the following problem: given a graph G that has property P, find a minimal spanning subgraph of G with property P. We describe two related algorithms for this problem and prove their correctness under some rather weak assumptions about P. We devise a general technique for analyzing the worst-case behavior of these algorithms. By applying the technique to 2-edge-connectivity and biconnectivity, we obtain an &OHgr;(m + n log n) lower bound on the worst-case running time of the algorithms for these two properties, thus settling open questions posed earlier with regard to these properties. We then describe refinements of the basic algorithms that yield the first linear-time algorithms for finding a minimal 2-edge-connected spanning subgraph and a minimal biconnected spanning subgraph of a graph.
SODA	A Faster Algorithm for Finding the Minimum Cut in a Graph.	Jianxiu Hao,James B. Orlin	1992	We consider the problem of finding the minimum capacity cut in a network G with n nodes. This problem has applications to network reliability and survivability and is useful in subroutines for other network optimization problems. One can use a maximum flow problem to find a minimum cut separating a designated source node s from a designated sink node t, and by varying the sink node one can find a minimum cut in G as a sequence of at most 2n - 2 maximum flow problems. We then show how to reduce the running time of these 2n - 2 maximum flow algorithms to the running time for solving a single maximum flow problem. The resulting running time is O(nm log n2/m) for finding the minimum cut in either a directed or undirected network. The algorithm also determines the arc connectivity of either a directed or undirected network in O(nm) steps.
SODA	On Efficient Unsuccessful Search.	Lucas Chi Kwong Hui,Charles U. Martel	1992	This paper introduces a general technique for speeding up unsuccessful search using very little extra space (2 bits per key). This technique is applicable to many data structures including linear lists, and search trees. For linear lists we get on-line algorithms for processing a sequence of successful and unsuccessful searches which are competitive with strong off-line algorithms. In a virtual memory environment our self-adjusting algorithm for multi-way search trees is competitive with an optimal static multi-way tree and will often outperform the static tree.
SODA	Strongly Competitive Algorithms for Paging with Locality of Reference.	Sandy Irani,Anna R. Karlin,Steven Phillips	1992	What is the best paging algorithm if one has partial information about the possible sequences of page requests? We give a partial answer to this question, by presenting the analysis of strongly competitive paging algorithms in the access graph model. This model restricts page requests so that they conform to a notion of locality of reference, given by an arbitrary access graph. We first consider optimal algorithms for undirected access graphs. Borodin et al. [2] define an algorithm, called FAR, and proved that it is within a logarithmic factor of the optimal. We prove that FAR is in fact strongly competitive, i.e. within a constant factor of the optimum. For directed access graphs, we present an algorithm that is strongly competitive on all structured program graphs&mdash;graphs modeling the request sequences of structured programs.
SODA	Sequential and Parallel Algorithms to Find a K Minor.	André E. Kézdy,Patrick McGuinness	1992	Sequential and Parallel Algorithms to Find a K Minor.
SODA	A Faster Deterministic Maximum Flow Algorithm.	V. King,S. Rao,Robert Endre Tarjan	1992	"We describe a deterministic version of a 1990 Cheriyan, Hagerup, and Mehlhorn randomized algorithm for computing the maximum flow on a directed graph with n nodes and m edges which runs in time O(mn + n2+&egr;, for any constant &egr;. This improves upon Alon's 1989 bound of O(mn + n8/3log n) [A] and gives an O(mn) deterministic algorithm for all m > n1+&egr;. Thus it extends the range of m/n for which an O(mn) algorithm is known, and matches the 1988 algorithm of Goldberg and Tarjan [GT] for smaller values of m/n."
SODA	Pattern Matching in a Digitized Image.	Gad M. Landau,Uzi Vishkin	1992	The continuous pattern matching problem is defined. Given are two pictures, each consisting of unicolor regions; one picture is called the scene and the other the pattern. The problem is to find all occurrences of the pattern in the scene. As a step towards efficient algorithmic handling of the continuous pattern matching problem by computers, where discretized representations are involved, we give several algorithms. Our strongest algorithmic result is for a one-dimensional version of the problem, where running time which is linear in the length of a digitized representation is achieved. The definitions of our problems are derived from a &ldquo;digitized-based&rdquo; approach to object recognition problems in computer vision, which is different from a common computer vision approach. The digitized based approach may lead towards further research within the discrete algorithms community on computer vision problems.
SODA	On the Number of Eularian Orientations of a Graph.	Milena Mihail,Peter Winkler	1992	"We give efficient randomized schemes to sample and approximately count Eulerian orientations of any Eulerian graph. Eulerian orientations are natural flow-like structures, and Welsh has pointed out that computing their number (i)corresponds to evaluating the Tutte polynomial at the point (0, &ndash;2) [8,19] and (ii) is equivalent to evaluating &ldquo;ice-type partition functions&rdquo; in statistical physics [20]. Our algorithms are based on a reduction to sampling and approximately counting perfect matchings for a class of graphs for which the methods of Broder [3, 10] and others [4, 6] apply. A crucial step of the reduction is the &ldquo;Monotonicity Lemma&rdquo; (Lemma 3.3) which is of independent combinatorial interest. Roughly speaking, the Monotonicity Lemma establishes the intuitive fact that &ldquo;increasing the number of constraints applied on a flow problem can only decrease the number of solutions&rdquo;. In turn, the proof of the lemma involves a new decomposition technique which decouples problematically overlapping structures (a recurrent obstacle in handling large combinatorial populations) and allows detailed enumeration arguments. As a byproduct, (i) we exhibit a class of graphs for which perfect and near-perfect matchings are polynomially related, and hence the permanent can be approximated, for reasons other than &ldquo;short augmenting paths&rdquo; (previously the only known approach); and (ii) we obtain a further direct sampling scheme for Eulerian orientations which is faster than the one suggested by the reduction to perfect matchings. Finally, with respect to our approximate counting algorithm, we give the complementary hardness result, namely, that counting exactly Eulerian orientations is #P-complete, and provide some connections with Eulerian tours."
SODA	On Parallel Complexity of Integer Linear Programming, GCD and the Iterated mod Function.	Yu Lin-Kriz,Victor Y. Pan	1992	We study parallel computational methods for integer linear programming problem with two variables. Applying several novel techniques, we prove that this problem is NC-equivalent to computing the continued fraction expansion of a rational number, that is, to computing all the intermediate remainders in the Euclidean algorithm applied to two integers, plus to computing the output of an iterated modulo function, with the remainder sequence from the Euclidean algorithm (that is, with the continued fraction expansion of a rational number) as its input arguments. The best previously known results are special cases of our theorem.
SODA	Separation and Approximation of Polyhedral Objects.	Joseph S. B. Mitchell,Subhash Suri	1992	"Given a family of disjoint polygons P1, P2,&hellip;, Pk in the plane, and an integer parameter m, it is NP-complete to decide if the Pi's can be separated by a polygonal family consisting of m edges, that is, if there exist polygons R1, R2,&hellip;, Rk with pairwise-disjoint boundaries such that Pi *** Ri and &Sgr;|Ri| &le; m. In three dimensions, the problem of separating even two nested convex polyhedra by a k-facet polyhedron is NP-complete. Many other extensions and generalizations of the polyhedral separation problem, either to families of polyhedra or to higher dimensions, are also intractable. In this paper, we present efficient approximation algorithms for constructing separating families of near-optimal size. Our main results are as follows. In two dimensions, we give an O(n log n) time algorithm for constructing a separating family whose size is within a constant factor of an optimal separating family; n is the number of edges in the input family of polygons. In three dimensions, we can separate a convex polyhedron from a nonconvex polyhedron with a convex polyhedral surface whose facet-complexity is O(log n, times the optimal, where n = |P|+|Q| is the complexity of the input polyhedra. Our algorithm runs in O(n4) time, but improves to O (n3) time if the two polyhedra are nested and convex. Our algorithm for separating a convex polyhedron from a nonconvex polyhedron extends to higher dimensions. In d dimensions, for d &ge; 4, the facet-complexity of the approximation polyhedron is O(d log n) times the optimal, and the algorithm runs in O(nd+1)time. Finally, we also obtain results on separating sets of points, a family of convex polyhedra, and separation by non-polyhedral surfaces, such as spherical patches."
SODA	Load Balancing Requires Omega(log) Expected Time.	Philip D. MacKenzie	1992	In order to obtain very fast parallel algorithms, it is almost always necessary to have some sort of load balancing procedure, so that processors which have finished their required tasks can help processors which have not. If the overloaded processors are not helped, then the expected time of the entire algorithm suffers. In general, we would like to distribute the remaining work as evenly as possible among the processors, or more formally, given at most n independent tasks distributed in an arbitrary way among n processors, we would like to redistribute the tasks so that each processor contains O(1) tasks. We show here that even on the strongest randomized CRCW PRAM model, for a simple random distribution tasks load balancing requires &OHgr;(log* n) expected time. Gil, Matias, and Vishkin [9] give an O(log* n) expected time randomized algorithm which solves the load balancing problem in the worst case, so the lower bound is tight. By reduction we show that both Padded Sort [12], and Linear Approximate Compaction [13] require &OHgr;(log* n) expected time. We note that our basic technique is one of the few parallel lower bound techniques known which only require 0/1 inputs. We also note that the bounds given in this paper do not place any restriction on the instruction set of the machine, the amount of information which can be stored in a memory cell, or on the number of memory cells.
SODA	Deterministic Skip Lists.	J. Ian Munro,Thomas Papadakis,Robert Sedgewick	1992	We explore techniques based on the notion of a skip list to guarantee logarithmic search, insert and delete costs. The basic idea is to insist that between any pair of elements above a given height are a small number of elements of precisely that height. The desired behaviour can be achieved by either using some extra space for pointers, or by adding the constraint that the physical sizes of the nodes be exponentially increasing. The first approach leads to simpler code, whereas the second is ideally suited to a buddy system of memory allocation. Our techniques are competitive in terms of time and space with balanced tree schemes, and, we feel, inherently simpler when taken from first principles.
SODA	Percolation Theory and Computing with Faulty Arrays of Processors.	Thomas R. Mathies	1992	Let H be an n x n mesh-connected array of processors. Each processor is assumed to fail (independently) with probability p. Raghavan [5] gave an algorithm that with high probability routes packets in this mesh with O(log n) dilation and O(log2n) load so long as p &le; 0.29. KKLMRRTT [3] improve the load to O(1) for &ldquo;small&rdquo; p while keeping the O(log n) bound for dilation and showing an o(1) bound for congestion. In this paper we show these bounds hold for p as high as *** 0.4. We also consider the problem where links rather than processors fail and shows these same bounds hold for q < 1/2. In both cases these bounds are tight: for greater probabilities of failure the above embedding bounds cannot be achieved. This short cutoff follows from a zero-one result of percolation theory.
SODA	Randomized Parallel Algorithms for Matroid Union and Intersection, with Applications to Arboresences and Edge-Disjoint Spanning Trees.	H. Narayanan,Huzur Saran,Vijay V. Vazirani	1992	The strong link between matroids and matching is used to extend the ideas that resulted in the design of Random NC algorithms for matching to obtain RNC algorithms for the well-known problems of finding an arboresence and a maximum cardinality set of edge-disjoint spanning trees in a graph. The key tools used are linear algebra and randomization.
SODA	Strong Concentration for Quicksort.	Colin McDiarmid,Ryan Hayward	1992	Let Qn be the random number of comparisons made by quicksort in sorting n distinct keys, when we assume that all n! possible orderings are equally likely. Known results concerning moments for Qn do not show how rare it is for Qn to make large deviations from its mean. Here we give a good approximation to the probability of such a large deviation, and find that this probability is quite small. As well as the basic quicksort we consider the variant in which the partitioning key is chosen as the median of (2t+1) keys.
SODA	Tail Estimates for the Space Complexity of Randomized Incremental Algorithms.	Kurt Mehlhorn,Micha Sharir,Emo Welzl	1992	We give tail estimates for the space complexity of randomized incremental algorithms for line segment intersection in the plane. For n the number of segments, m is the number of intersections, and m &ge; n ln n ln(3) n, there is a constant c such that the probability that the total space cost exceeds c times the expected space cost is e-&OHgr;(m/(n ln n)).
SODA	Self-Testing Polynomial Functions Efficiently and Over Rational Domains.	Ronitt Rubinfeld,Madhu Sudan	1992	In this paper we give the first self-testers and checkers for polynomials over rational and integer domains. We also show significantly stronger bounds on the efficiency of a simple modification of the algorithm for self-testing polynomials over finite fields given in [8].
SODA	On Likely Solutions of a Stable Matching Problem.	Boris Pittel	1992	On Likely Solutions of a Stable Matching Problem.
SODA	An O(n log n log log n) Algorithm for the On-Line Closest Pair Problem.	Christian Schwarz,Michiel H. M. Smid	1992	An O(n log n log log n) Algorithm for the On-Line Closest Pair Problem.
SODA	Minimizing Capacity Violations in a Transshipment Network.	Tomasz Radzik	1992	The problem of minimizing capacity violation is a variation of the transshipment problem. It is equivalent to the problem of computing maximum mean surplus cuts which arises in the dual approach to the minimum cost network circulation problem. McCormick and Ervolina [15] proposed an algorithm which computes a sequence of cuts with increasing mean surpluses, and stops when an optimal one is found. The mean surplus of this cut is equal to the minimum possible maximum capacity violation. McCormick and Ervolina proved that the number of iterations in this algorithm is O(m). One iteration, i.e., finding the subsequent cut, amounts to computing maximum flow in an appropriate network. We prove that the number of iterations in this algorithm is &thgr;(n). This gives the best known upper bound O(n2m) for the problem. We also show a tight analysis of this algorithm for the case with integral capacities and demands, and present some improvements.
SODA	The Probabilistic Method.	Joel Spencer	1992	The use of randomness is now an accepted tool in Theoretical Computer Science but not everyone is aware of the underpinnings of this methodology in Combinatorics - particularly, in what is now called the probabilistic Method as developed primarily by Paul Erdo&huml;s over the past half century. Here I will explore a particular set of problems - all dealing with &ldquo;good&rdquo; colorings of an underlying set of points relative to a given family of sets. A central point will be the evolution of these problems from the purely existential proofs of Erdo&huml;s to the algorithmic aspects of much interest to this audience.
SODA	Finding the Repeated Median Regression Line.	Andrew Stein,Michael Werman	1992	The repeated median regression line is a robust regression estimate, having a maximal 50% breakdown point. This paper presents an O(n(log n)2) algorithm for finding the repeated median regression line through n points in the plane.
SODA	(Un)expected Behavior of Typical Suffix Trees.	Wojciech Szpankowski	1992	Suffix tree is a data structure widely used in algorithms on words and data compression. Despite this, very little is known about its typical behavior. Recently, Chang and Lawler have designed a sublinear expected time algorithm for approximate string matching using simple estimates of some parameters of suffix trees. It seems that any further advances in such an endover are subject to better understanding of suffix trees behavior. In this paper, we use a novel technique called string ruler approach to provide a characterization of several basic parameters of suffix trees (dependency among symbols are allowed !). These findings are used to :(i) settle in the negative the conjecture of Wyner and Ziv regarding the typical behavior of the universal data compression scheme of Lampel and Ziv; (ii) prove an open problem regarding the length of a block in the Lampel-Ziv parsing algorithm; (iii) provide new insights and generalizations of string matching algorithms, particularly the one by Chang and Lawler.
SODA	Efficient Algorithms for the Hitchcock Transportation Problem.	Takeshi Tokuyama,Jun Nakano	1992	We consider the Hitchcock transportation problem on n supply points and k demand points when n is much greater than k. The problem is solved in O(n2k log n + n2 log2 n) time if n > k log k. Further, applying a geometric method named splitter finding and randomization, we improve the time complexity for a case in which the ratio c of the least supply and the maximum supply satisfies the inequality log cn < n/k4 log n. Indeed, if n < k5 log3 k and c = poly(n), the problem is solved in O(kn) time, which is optimal.
SODA	Searching Tree Structures on a Mesh of Processors.	Jyh-Jong Tsay	1992	Searching Tree Structures on a Mesh of Processors.
SODA	Applications of the Fusion Tree Method to Computational Geometry and Searching.	Dan E. Willard	1992	Applications of the Fusion Tree Method to Computational Geometry and Searching.
SODA	On the Approximation of Maximum Satisfiability.	Mihalis Yannakakis	1992	We present a 3/4 polynomial time approximation algorithm for the Maximum Satisfiability problem: Given a set of clauses, find a truth assignment that satisfies the maximum number of clauses. The algorithm applies to the weighted case as well, and involves nontrival application of network flow techniques.
SODA	Algorithms for Subset Testing and Finding Maximal Sets.	Daniel M. Yellin	1992	In this paper we consider two related problems: subset testing and finding maximal sets. First, consider a sequence of n operations, where each operation either creates a set, inserts (deletes) an element into (from) a set, queries whether a particular element is in a set, queries whether or not one set is a subset of another, or queries whether or not the intersection of two sets is empty. We show that for any integer k, one can implement subset and intersection testing in time O(n1-(1/k) log n) and all of the other operations in time O(n1/k log n)). It requires O(nk+1)/k) space. When k = 2, this yields a worst case time complexity of O(n1/2 log n) per operation, and uses O(n3/2) space. Second, consider a set of sets, where the total size of the input is O(n). We show that one can find those sets that are maximal (a set is maximal if it is not contained in any other set) in time O(mn), where m is the number of maximal sets.
SODA	Proceedings of the Third Annual ACM/SIGACT-SIAM Symposium on Discrete Algorithms, 27-29 January 1992, Orlando, Florida.	Greg N. Frederickson	1992	Proceedings of the Third Annual ACM/SIGACT-SIAM Symposium on Discrete Algorithms, 27-29 January 1992, Orlando, Florida.
STOC	Alphabet Independent Two Dimensional Matching	Amihood Amir,Gary Benson,Martin Farach	1992	Alphabet Independent Two Dimensional Matching
STOC	Parallel Computation Over Hyperbolic Groups	Jin-yi Cai	1992	Hyperbolic groups are a rich class of groups frequently encountered in mathematical research, particularly in topology. It has been the focus of intense study by many combinatorial group theorists and topologists recently. We present some computational results for infinite groups, especially for hyperbolic groups. It is shown that the word problem for hyperbolic groups is solvable in NC2. This is the first NC algorithm for a class of groups in combinatorial group theory. We also consider the isomorphism problem of randomly generated groups using a novel technique: the Alexander polynomial from knot theory. These randomly generated groups are almost always hyperbolic groups.
STOC	A Deterministic Poly(log log N)-Time N-Processor Algorithm for Linear Programming in Fixed Dimension	Miklós Ajtai,Nimrod Megiddo	1992	It is shown that for any fixed number of variables, the linear programming problems with n linear inequalities can be solved deterministically by n parallel processors in sub-logarithmic time. The parallel time bound is O((log log n)d) where d is the number of variables. In the one-dimensional case this bound is optimal.
STOC	Polynomial Algorithms for Linear Programming over the Algebraic Numbers	Ilan Adler,Peter A. Beling	1992	We derive an algorithm based on the ellipsoid method that solves linear programs whose coefficients are real algebraic numbers. By defining the encoding size of an algebraic number to be the bit size of the coefficients of its minimal polynomial, we prove the algorithm runs in time polynomial in the dimension of the problem, the encoding size of the input coefficients, and the degree of any algebraic extension which contains the input coefficients. This bound holds even if all input and arithmetic is performed symbolically, using rational numbers only.
STOC	Ray Shooting and Parametric Search	Pankaj K. Agarwal,Jirí Matousek	1992	Ray Shooting and Parametric Search
STOC	Computational Learning Theory: Survey and Selected Bibliography	Dana Angluin	1992	Computational Learning Theory: Survey and Selected Bibliography
STOC	A Correctness Condition for High-Performance Multiprocessors (Extended Abstract)	Hagit Attiya,Roy Friedman	1992	Hybrid consistency, a new consistency condition for shared memory multiprocessors, attempts to capture the guarantees provided by contemporary high-performance architectures. It combines the expressiveness of strong consistency conditions(e.g., sequential consistency, linearizability) and the efficiency of weak consistency conditions (e.g., Pipelined RAM, causal memory). Memory access operations are classified either strong or weak. A global ordering of strong operations at different processes is guaranteed, but there is very little guarantee on the ordering of weak operations at different processes, except for what is implied by their interleaving with the strong operations. A formal and precise definition of this condition is given. An efficient implementation of hybrid consistency on distributed memory machines is presented. In this implementation, weak opearations are executed instantaneously, while the response time for strong operations is linear in the network delay. (It is proven that this is within a constant factor of the optimal time bounds.) To motivate hybrid consistency it is shown that weakly consistent memories do not support non-cooperative (in particular, non-centralized) algorithms for mutual exclusion.
STOC	Computing with Faulty Arrays	Yonatan Aumann,Michael Ben-Or	1992	We present and O(1) slowdown emulation of a fault-free N x N two dimensional mesh with a slack of O(log N log log N) by a faulty mesh of the same size and slack. All components of the faulty mesh, including the memory modules, are assumed to be subject to failure. The faults may occur at any time during the emulation and the system readjusts dynamically.
STOC	Competitive Distributed Job Scheduling (Extended Abstract)	Baruch Awerbuch,Shay Kutten,David Peleg	1992	This paper examines the problem of balancing the job load in a network of processors, and introduces an online algorithm for scheduling a sequence of jobs in a competitive manner. The algorithm is shown to be polylog (n)-competitive according to a strict definition that forces the online algorithm to be competitive even when considering any bounded area of the network and bounded period of time. We also analyze the common greedy feedback-based approach, and provide matching lower and upper bounds (up to a polylogarithmic factor) for the tradeoff between the costs of searches and updates under this approach.
STOC	Adapting to Asynchronous Dynamic Networks (Extended Abstract)	Baruch Awerbuch,Boaz Patt-Shamir,David Peleg,Michael E. Saks	1992	The computational power of different communication models is a fundamental question in the theory of distributed computation. For example, in the synchronous model messages are assumed to be delivered within one time unit, whereas in the asynchronous model message delays may be arbitrary. Another important parameter of the model is the assumptions about the topology. In the dynamic topology model, links are assumed to crash and recover dynamically, but their status is known to the incident node processors. A meaningful computation can be carried out if the topology stabilizes for a sufficiently long period. In this paper we show that the model of asynchronous, dynamic-topology network is equivalent, up to polylogarithmic factors, to the synchronous, static protocols that can withstand arbitrary link delays and changing topology at the expense of only polylogarithmic blowup in the running time, the number of messages, and the space requirement. Previous methods entailed a linear blowup in at least one of these resources. The generality of our method is demonstrated by a series of improvements for important applications, including Breadth First Search, computing compact efficient routing tables, and packet routing on asynchronous networks.
STOC	Biased Random Walks	Yossi Azar,Andrei Z. Broder,Anna R. Karlin,Nathan Linial,Steven Phillips	1992	"How much can an imperfect source of randomness affect an algorithm? We examine several simple questions of this type concerning the long-term behavior of a random walk on a finite graph. In our setup, each step of the random walk a &ldquo;controller&rdquo; can, with a certain small probability, fix the next step, thus introducing a bias. We analyze the extent to which the bias can affect the limit behavior of the walk. The controller is assumed to associate a real, nonnegative, &ldquo;benefit&rdquo; with each state, and to strive to maximize the long-term expected benefit. We derive tight bounds on the maximum of this objective function over all controller's strategies, and present polynomial time algorithms for computing the optimal controller strategy."
STOC	Symmetry and Complexity	László Babai,Robert Beals,Pál Takácsi-Nagy	1992	Symmetry and Complexity
STOC	Representing Boolean Functions as Polynomials Modulo Composite Numbers (Extended Abstract)	David A. Mix Barrington,Richard Beigel,Steven Rudich	1992	Representing Boolean Functions as Polynomials Modulo Composite Numbers (Extended Abstract)
STOC	New Algorithms for an Ancient Scheduling Problem	Yair Bartal,Amos Fiat,Howard J. Karloff,Rakesh Vohra	1992	We consider the on-line version of the original m-machine scheduling problem: given m machines and n positive real jobs, schedule the n jobs on the m machines so as to minimize the makespan, the completion time of the last job. In the on-line version, as soon as job j arrrives, it must be assigned immediately to one of the m machines. We present two main results. The first is a (2&ndash;&egr;)-competitive deterministic algorithm for all m. The competitive ratio of all previous algorithms approaches 2 as m&rarr; &infin; . Indeed, the problem of improving the competitive ratio for large m had been open since 1966, when the first algorithm for this problem appeared. The second result is an optimal randomized algorithm for the case m = 2. To the best of our knowledge, our 4/3-competitive algorithm is the first specifically randomized algorithm for the original, m-machine, on-line scheduling problem.
STOC	Competitive Algorithms for Distributed Data Management (Extended Abstract)	Yair Bartal,Amos Fiat,Yuval Rabani	1992	We deal with the competitive analysis of algorithms for managing data in a distributed environment. We deal with the file allocation problem ([C], [DF], [ML]), where copies of a file may be stored in the local storage of some subset of processors, copies may be replicated and discarded over time so as to optimize communication costs, but multiple copies must be kept consistent and at least one copy must be stored somewhere in the network at all times. We deal with competitive algorithms for minimizing communication costs, over arbitrary sequences of reads and writes, and arbitrary network topologies. We define the constrained file allocation problem to be the solution of many individual file allocation problems simultaneously, subject to the constraints of local memory size. We give competitive algorithms for this prblem on uniform networks. We then introduce distributed competitive algorithms for on-line data tracking (a generalization of mobile user tracking [AP1, AP3] to transform our competitive distributed data management algorithms into distributed algorithms themselves.
STOC	Feasibility Testing for Systems of Real Quadratic Equations	Alexander I. Barvinok	1992	We consider the problem of deciding whether a given system of quadratic homogeneous equations over the reals has non-trivial solution. We design an approximative algorithm whose complexity is polynomial in the number of variables and exponential in the number of equations. Some applications to general systems of polynomial equations and inequalities over the reals are discussed.
STOC	Structure Forest and Composition Factors for Small Base Groups in Nearly Linear Time	Robert Beals,Ákos Seress	1992	Structure Forest and Composition Factors for Small Base Groups in Nearly Linear Time
STOC	Exponential Lower Bounds for the Pigeonhole Principle	Paul Beame,Russell Impagliazzo,Jan Krajícek,Toniann Pitassi,Pavel Pudlák,Alan R. Woods	1992	Exponential Lower Bounds for the Pigeonhole Principle
STOC	Randomized versus Nondeterministic Communication Complexity	Paul Beame,Joan Lawry	1992	Our main result is the demonstration of a Boolean function f with nondeterministic and co-nondeterministic complexities O(log n) and &egr;-error randomized complexity &OHgr;(log2 n), for 0 &le; &egr; < 1/2. This is the first separation of this kind for a decision problem.
STOC	When Do Extra Majority Gates Help? Polylog(n) Majority Gates Are Equivalent to One	Richard Beigel	1992	When Do Extra Majority Gates Help? Polylog(n) Majority Gates Are Equivalent to One
STOC	A New Recursion-Theoretic Characterization of the Polytime Functions (Extended Abstract)	Stephen Bellantoni,Stephen A. Cook	1992	We give a recursion-theoretic characterization of FP which describes polynomial time computation independently of any externally imposed resource bounds. In particular, this syntactic characterization avoids the explicit size bounds on recursion (and the initial function 2|x|.|y|) of Cobham.
STOC	Making Zero-Knowledge Provers Efficient	Mihir Bellare,Erez Petrank	1992	Making Zero-Knowledge Provers Efficient
STOC	Can Finite Samples Detect Singularities of Real-Valued Functions?	Shai Ben-David	1992	"Consider the following type of problem: There is an unknown function, f : Rn &rarr; Rm, there is also a black-box that on query x (&egr; Rn) returns f(x). Is there an algorithm that, using probes to the black-box, can figure out analytic information about f? (For an example: &ldquo;Is f a polynomial?&rdquo;, &ldquo;Is f a second order differentiable at x = (0,0,&hellip;,0)?&rdquo; etc.). Clearly, for examples as these, if we bound the number of probes an algorithm has to settle for, no algorithm can carry the task. On the other hand, if one allows an infinite iteration of a &ldquo;probe compute and guess&rdquo; process, then, (quite surprisingly) for many such questions, there are algorithms that are guaranteed to be correct in all but finitely many of their guesses. We call such questions Decidable In the Limit, (DIL). We analyze the class of DIL problems and provide a necessary and sufficient condition for the membership of a decision problem in this class. We offer an algorithm for any DIL problem, and apply it to several types of learning tasks. Furthermore, if an a-priori probability distribution P, according to which f is being chosen, is available to the algorithm, then it can be strengthened into a finite algorithm. More precisely, for many distributions P, there exists a polynomial function, l, such that for every 0<&dgr;<1, there is an algorithm using at most l(log(&dgr;)) many probes that succeeds on more than (1&ndash;&dgr;) of the f's (as measured by P). We believe that the new approach presented here will be found useful for many further applications."
STOC	Fast Learning of k-Term DNF Formulas with Queries	Avrim Blum,Steven Rudich	1992	This paper presents an algorithm that uses equivalence and membership queries to learn the class of k-term DNF formulas in time O(n&bull;2o(k)), where n is the number of input variables. This improves upon previous O(nk) bounds and allows one to learn DNF of O(log n) terms in polynomial time. We present the algorithm in its most natural form as a randomized algorithm, and then show how recent derandomization techniques can be used to make it deterministic. The algorithm is an exact learning algorithm, but one where the equivalance query hypotheses and the final output are general (not necessarily k-term) DNF formulas. For the special case of 2-term DNF formulas, we give a simpler version of our algorithm that uses at most 4n + 2 total membership and equivalence queries.
STOC	Fault Tolerant Planar Communication Networks	Geng Lin	1992	Fault Tolerant Planar Communication Networks
STOC	Linear Decision Trees: Volume Estimates and Topological Bounds	Anders Björner,László Lovász,Andrew Chi-Chih Yao	1992	Linear Decision Trees: Volume Estimates and Topological Bounds
STOC	Target Shooting with Programmed Random Variables	Graham Brightwell,Teunis J. Ott,Peter Winkler	1992	"LetX1,...,Xn be pairwise independent random variables of known (but not necessarily identical) distribution; we wish to select a subset of these whose sum will be as close as possible to some known target value T. Conditions described below force the selections to be made by a primitive distributed system (similar to one considered by Papadimitriou and Yannakakis [2] in PODC '91); here we are able to obtain a surprising amount of information about optimal solutions. The conditions are that each variable must be &ldquo;programmed&rdquo; in advance, joining the selected set according to its own value. Thus, for example, one variable might be programmed to join just if its value lies between &agr; and &bgr;, while another is told to join regardless of its value. Our object is to find a strategy, that is, a collection of programs, which minimizes the mean square error in approximating T. Typical applications involve producing a steady flow of some commodity when supply is controlled at a multiplicity of random sources. It turns out that there is always an optimal strategy in which each Xi is programmed to join if its value is between 0 and &thgr;i, for appropriate choice of thresholds &thgr;i. When the variables are identically distributed, we examine conditions under which the &thgr;i's must be equal. The case of uniform distributions on [0,1], for which the above conditions are not satisfied, is analyzed in detail, showing the rather bizarre behavior of the &thgr;i's which may take place in general as the target value is gradually changed. Next, we analyze the problem in which the variables are permitted to contribute any part of themselves to the sum; here it turns out that in an optimal strategy each program will be of the form &ldquo;contribute the minimum of Xi and &eegr;i&rdquo; with all the &eegr;i's equal in the i.i.d. case. Finally, we show how the original target shooting problem can be generalized to a kind of load balancing, where variables are assigned to different buckets, each with its own target, and the penalty is a weighted sum of squared errors. The surprising result here is that when the weights are equal, an optimal solution assigns variables only according to their signs."
STOC	Existence and Construction of Edge Disjoint Paths on Expander Graphs	Andrei Z. Broder,Alan M. Frieze,Eli Upfal	1992	Existence and Construction of Edge Disjoint Paths on Expander Graphs
STOC	Learning Arithmetic Read-Once Formulas	Nader H. Bshouty,Thomas R. Hancock,Lisa Hellerstein	1992	A formula is read-once if each variable appears at most once in it. An arithmetic read-once formula is one in which the operators are addition, subtraction, multiplication, and division. We present polynomial time algorithm for exactly learning (or interpolating) arithmetic read-once formulas computing functions over a field. We present an algorithm that uses randomized membership queries (or substitutions) to identify such formulas over large finite fields and infinite fields. We also present a deterministic algorithm that uses equivalence queries as well as membership queries to identify arithmetic read-once formulas over small finite fields. We then non-constructively show the existence of deterministic membership query (interpolation) algorithms for arbitrary formulas over fields of characteristic 0 and for division-free formulas over large or infinite fields. Our algorithms assume we are able to efficiently perform arithmetic operations on field elements and compute square roots in the field. It is shown that the ability to compute square roots is necessary, in the sense that the problem of computing n &ndash; 1 square roots in a field can be reduced to the problem of identifying an arithmetic formula over n variables in that field. Our equivalence queries are of a slightly non-standard form, in which counterexamples are required to not be inputs on which the formula evaluates to 0/0. This assumption is shown to be necessary for fields of size o(n/log n), for which it is shown that there is no polynomial time identification algorithm that uses just membership and standard equivalence queries.
STOC	A Decomposition of Multi-Dimensional Point-Sets with Applications to k-Nearest-Neighbors and n-Body Potential Fields (Preliminary Version)	Paul B. Callahan,S. Rao Kosaraju	1992	We define the notion of a well-separated pair decomposition of points in d-dimensional space. We develop efficient sequential and parallel algorithms for computing such a decomposition. We apply the resulting decomposition to the efficient computation of k-nearest neighbors and n-body potential fields.
STOC	Efficient Fault Tolerant Algorithms for Resource Allocation in Distributed Systems	Manhoi Choy,Ambuj K. Singh	1992	Solutions to resource allocation problems in distributed systems are examined with respect to the measures of response time, message complexity, and failure locality. Response time measures the time it takes for an algorithm to respond to the requests of a process, message complexity measures the number of messages sent and received by a process, and failure locality characterizes the size of the network that is affected by the failure of a single process. An algorithm that achieves a constant failure locality of four along with a quadratic response time and a quadratic message complexity is presented.
STOC	The Complexity of Multiway Cuts (Extended Abstract)	Elias Dahlhaus,David S. Johnson,Christos H. Papadimitriou,Paul D. Seymour,Mihalis Yannakakis	1992	In the Multiway Cut problem we are given an edge-weighted graph and a subset of the vertices called terminals, and asked for a minimum weight set of edges that separates each terminal from all the others. When the number k of terminals is two, this is simply the min-cut, max-flow problem, and can be solved in polynomial time. We show that the problem becomes NP-hard as soon as k = 3, but can be solved in polynomial time for planar graphs for any fixed k. The planar problem is NP-hard, however, if k is not fixed. We also describe a simple approximation algorithm for arbitrary graphs that is guaranteed to come within a factor of 2&ndash;2/k of the optimal cut weight.
STOC	"Graph Decomposition Is NPC-A Complete Proof of Holyer's Conjecture"	Dorit Dor,Michael Tarsi	1992	"An H-decomposition of a graph G = (V,E) is a partition of E into subgraphs isomorphic to H. Given a fixed graph H, the H-decomposition problem is to determine whether an input graph G admits an H-decomposition. I. Holyer (1980) conjectured that H-decomposition is Np-complete whenever H is connected and has at least 3 edges. Some partial results have been obtained during the last decade. A complete proof for Holyer's conjecture is the content of this paper."
STOC	Simple and Efficient Bounded Concurrent Timestamping or Bounded Concurrent Timestamp Systems are Comprehensible!	Cynthia Dwork,Orli Waarts	1992	Simple and Efficient Bounded Concurrent Timestamping or Bounded Concurrent Timestamp Systems are Comprehensible!
STOC	Approximations of General Independent Distributions	Guy Even,Oded Goldreich,Michael Luby,Noam Nisan,Boban Velickovic	1992	We describe efficient constructions of small probability spaces that approximate the independent distribution for general random variables. Previous work on efficient constructions concentrate on approximations of the independent distribution for the special case of uniform boolean-valued random variables. Our results yield efficient constructions of small sets with low discrepancy in high dimensional space and have applications to derandomizing randomized algorithms.
STOC	Balanced Matroids	Tomás Feder,Milena Mihail	1992	Balanced Matroids
STOC	On the Hardness of Computing the Permanent of Random Matrices (Extended Abstract)	Uriel Feige,Carsten Lund	1992	We study the complexity of computing the permanent on random inputs. We consider matrices drawn randomly from the space of n by n matrices with integer values between 0 and p&ndash;1, for any large enough prime p. We show that any polynomial time algorithm which computes the permanent correctly on even an exponentially small fraction of these matrices, implies the collapse of the polynomial-time hierarchy to its second level. We also show that it is hard to get partial information about the value of the permanent modulo p. We show that any balanced polynomial-time 0/1 predicate (e.g., the least significant bit, the parity of all the bits, the quadratic residuosity character) cannot be guessed with probability significantly greater than 1/2 (unless the polynomial hierarchy collapses). This result can be extended to showing simultaneous hardness for linear size groups of bits.
STOC	Two-Prover One-Round Proof Systems: Their Power and Their Problems (Extended Abstract)	Uriel Feige,László Lovász	1992	We characterize the power of two-prover one-round (MIP(2,1)) proof systems, showing that MIP(2,1)=NEXPTIME. However, the following intriguing question remains open: Does parallel repetition decrease the error probability of MIP(2,1) proof systems?. We use techniques based on quadratic programming to study this problem, and prove the parallel repetition conjecture in some special cases. Interestingly, our work leads to a general polynomial time heuristic for any NP-problem. We prove the effectiveness of this heuristic for several problems, such as computing the chromatic number of perfect graphs.
STOC	Communication Complexity of Secure Computation (Extended Abstract)	Matthew K. Franklin,Moti Yung	1992	A secret-ballot vote for a single proposition is an example of a secure distributed computation. The goal is for m participants to jointly compute the output of some n-ary function (in this case, the sum of the votes), while protecting their individual inputs against some form of misbehavior. In this paper, we initiate the investigation of the communication complexity of unconditionally secure multi-party computation, and its relation with various fault-tolerance models. We present upper and lower bounds on communication, as well as tradeoffs among resources. First, we consider the &ldquo;direct sum problem&rdquo; for communications complexity of perfectly secure protocols: Can the communication complexity of securely computing a single function f : Fn &rarr; F at k sets of inputs be smaller if all are computed simultaneously than if each is computed individually? We show that the answer depends on the failure model. A factor of O(n/log n) can be gained in the privacy model (where processors are curious but correct); specifically, when f is n-ary addition (mod 2), we show a lower bound of &OHgr;(n2 log n) for computing f O(n) times simultaneously. No gain is possible in a slightly stronger fault model (fail-stop mode); specifically, when f is n-ary addition over GF(q), we show an exact bound of &THgr;(kn2 log q) for computing f at k sets of inputs simultaneously (for any k &ge; 1). However, if one is willing to pay an additive cost in fault tolerance (from t to t-k+1), then a variety of known non-cryptographic protocols (including &ldquo;provably unparallelizable&rdquo; protocols from above!) can be systematically compiled to compute one function at k sets of inputs with no increase in communication complexity. Our compilation technique is based on a new compression idea of polynomial-based multi-secret sharing. Lastly, we show how to compile private protocols into error-detecting protocols at a big savings of a factor of O(n3) (up to a log factor) over the best known error-correcting protocols. This is a new notion of fault-tolerant protocols, and is especially useful when malicious behavior is infrequent, since error-detection implies error-correction in this case.
STOC	A Constant-Time Optimal Parallel String-Matching Algorithm	Zvi Galil	1992	Given a pattern string, we describe a way to preprocess it. We design a constant-time optimal parallel algorithm for finding all occurences of the (preprocessed) pattern in any given text.
STOC	Fully Dynamic Planarity Testing (Extended Abstract)	Zvi Galil,Giuseppe F. Italiano,Neil Sarnak	1992	Fully Dynamic Planarity Testing (Extended Abstract)
STOC	Computing Frobenius Maps and Factoring Polynomials (Extended Abstract)	Joachim von zur Gathen,Victor Shoup	1992	Computing Frobenius Maps and Factoring Polynomials (Extended Abstract)
STOC	Planar Separators and Parallel Polygon Triangulation (Preliminary Version)	Michael T. Goodrich	1992	Planar Separators and Parallel Polygon Triangulation (Preliminary Version)
STOC	Asymptotic Conditional Probabilities for First-Order Logic	Adam J. Grove,Joseph Y. Halpern,Daphne Koller	1992	Motivated by problems that arise in computing degrees of belief, we consider the problem of computing asymptotic conditional probabilities for first-order formulas. That is, given first-order formulas &fgr; and &thgr;, we consider the number of structures with domain {1,&hellip;,N} that satisfy &thgr;, and compute the fraction of them in which &fgr; is true. We then consider what happens to this probability of first-order formulas, except that now we are considering asymptotic conditional probabilities. Although work has been done on special cases of asymptotic conditional probabilities, no general theory has been developed. This is probably due in part to the fact that it has been known that, if there is a binary predicate symbol in the vocabulary, asymptotic conditional probabilities do not always exist. We show that in this general case, almost all the questions one might want to ask (such as deciding whether the asymptotic probability exists) are highly undecidable. On the other hand, we show that the situation with unary predicates only is much better. If the vocabulary consists only of unary predicate and constant symbols, it is decidable whether the limit exists, and if it does, there is an effective algorithm for computing it. The complexity depends on two parameters: whether there is a fixed finite vocabulary or an infinite one, and whether there is a bound on the depth of quantifier nesting.
STOC	Entropy and Sorting	Jeff Kahn,Jeong Han Kim	1992	We reconsider the old problem of sorting under partial information, and give polynomial time algorithms for the following tasks. (1) Given a partial order P, find (adaptively) a sequence of comparisons (questions of the form, &ldquo;is x < y?&rdquo;) which sorts (i.e. finds an unknown linear extension of) P using O(log(e(P))) comparisons in worst case (where e(P) is the number of linear extensions of P). (2) Compute (on line) answers to any comparison algorithm for sorting a partial order P which force the algorithm to use &OHgr;(log(e(P))) comparisons. (3) Given a partial order P of size n, estimate e(P) to within a factor exponential in n. (We give upper and lower bounds which differ by the factor nn/n!.) Our approach, based on entropy of the comparability graph of P and convex minimization via the ellipsoid method, is completely different from earlier attempts to deal with these questions.
STOC	A Subexponential Randomized Simplex Algorithm (Extended Abstract)	Gil Kalai	1992	A Subexponential Randomized Simplex Algorithm (Extended Abstract)
STOC	Efficient PRAM Simulation on a Distributed Memory Machine	Richard M. Karp,Michael Luby,Friedhelm Meyer auf der Heide	1992	We present a randomized simulation of a nlog log (n) log (n)-processor shared memory machine (DMM) with optimal expected delay O(log log (n)) per step of simulation. The time bound for the delay is guaranteed with overwhelming probability. The algorithm is based on hashing and uses a novel simulation scheme. The best previous simulations use a simpler scheme based on hashing and have much larger expected delay: &THgr;(log(n)/log log (n)) for the simulation of an n-processor PRAM on an n processor DMM, and &THgr;(log(n)) in the case where the simulation preserves the processor-time product.
STOC	Efficient Program Transformations for Resilient Parallel Computation via Randomization (Preliminary Version)	Zvi M. Kedem,Krishna V. Palem,Michael O. Rabin,A. Raghunathan	1992	"In this paper, we address the problem of automatically transforming arbitrary programs written for an ideal parallel machine to run on a completely asynchronous machine. We present a transformation which can be applied to an ideal program such that the resulting program's execution on an asynchronous machine is work and space efficient, relative to the ideal program from which it is derived. Above all, the transformation will guarantee that the ideal program will execute in a continually progressive manner on the asynchronous machine; these instructions are not universal. Furthermore, the individual processors can get delayed for arbitrary amounts of time while executing any instruction. In contrast, previous work relied either on the asynchronous machine having universal read-modify-write instructions as primitives, or on limited asynchrony by restricting the relative speeds of the processors."
STOC	On the Parallel Complexity of Computing a Maximal Independent Set in a Hypergraph	Pierre Kelsen	1992	A maximal independent set in a hypergraph is a subset of vertices that is maximal with respect to the property of not containing any edge of the hypergraph. We show that an algorithm proposed by Beame and Luby is in randomized NC for hypergraphs in which the maximum edge size is bounded by a constant. To prove this, we bound the upper tail of sums of dependent random variables defined on the edges of a hypergraph. These bounds may be viewed as extensions of bounds on the tail of the binomial distribution. We derandomize this algorithm to obtain the first sublinear time deterministic algorithm for hypergraphs with edges of size O(1). The algorithm exhibits the following time-processor tradeoff: it can be made to run in time O(n&egr;) with nO(1/&egr;) processors for a hypergraph on n vertices, for any &egr; &ge; 2d+1&bull; (log log n)/(log n); here d = O(1) denotes the maximum size of an edge in H. In particular, for any constant &egr; > O, we have an algorithm running in time O(n&egr;) on a polynomial number of processors, and we have an algorithm running in time (log n)O(1) on nO(log n/log log n) processors.
STOC	Biconnectivity Approximations and Graph Carvings	Samir Khuller,Uzi Vishkin	1992	A spanning tree in a graph is the smallest connected spanning subgraph. Given a graph, how does one find the smallest (i.e., least number of edges) 2-connected spanning subgraph (connectivity refers to both edge and vertex connectivity, if not specified)? Unfortunately, the problem is known to be NP-hard. We consider the problem of finding an approximation to the smallest 2-connected subgraph, by an efficient algorithm. For 2-edge connectivity our algorithm guarantees a solution that is no more than 3/2 times the optimal. For 2-vertex connectivity our algorithm guarantees a solution that is no more than 5/3 times the optimal. The previous best approximation factor is 2 for each of these problems. The new algorithms (and their analyses) depend upon a structure called a carving of a graph, which is of independent interest. We show that approximating the optimal solution to within an additive constant is NP-hard as well. We also consider the case where the graph has edge weights. We show that an approximation factor of 2 is possible in polynomial time for finding a k-edge connected spanning subgraph. This improves an approximation factor of 3 for k=2 due to [FJ81], and extends it for any k (with an increased running time though).
STOC	A Note on Efficient Zero-Knowledge Proofs and Arguments (Extended Abstract)	Joe Kilian	1992	In this note, we present new zero-knowledge interactive proofs and arguments for languages in NP. To show that x &egr; L, with an error probability of at most 2-k, our zero-knowledge proof system requires O(|x|c1)+O(lgc2|x|)k ideal bit commitments, where c1 and c2 depend only on L. This construction is the first in the ideal bit commitment model that achieves large values of k more efficiently than by running k independent iterations of the base interactive proof system. Under suitable complexity assumptions, we exhibit zero knowledge arguments that require O(lgc|x|kl bits of communication, where c depends only on L, and l is the security parameter for the prover. This is the first construction in which the total amount of communication can be less than that needed to transmit the NP witness. Our protocols are based on efficiently checkable proofs for NP[4].
STOC	A Parallel Randomized Approximation Scheme for Shortest Paths	Philip N. Klein,Sairam Sairam	1992	We give a randomized parallel algorithm for approximate shortest path computation in an undirected weighted graph. The algorithm is based on a technique used by Ullman and Yannakakis in a parallel algorithm for breadth-first search. It has application, e.g., in approximate solution of multicommodity flow problems with unit capacities. We also show how to adapt the algorithm to perform better for planar graphs.
STOC	Small-Depth Counting Networks	Michael Klugerman,C. Greg Plaxton	1992	Small-Depth Counting Networks
STOC	Online Minimization of Transition Systems (Extended Abstract)	David Lee,Mihalis Yannakakis	1992	We are given a transition system implicitly through a compact representation and wish to perform simultaneously reachability analysis and minimization without constructing first the whole system graph. We present an algorithm for this problem that applies to general systems, provided we have appropriate primitive operations for manipulating blocks of states and we can determine termination; the number of operations needed to construct the minimal reachable graph is quadratic in the size of this graph. We specialize the method to obtain efficient algorithms for extended finite state machines that apply separable affine transformations on the variables.
STOC	Methods for Message Routing in Parallel Machines	Frank Thomson Leighton	1992	Methods for Message Routing in Parallel Machines
STOC	epsilon-Approximations with Minimum Packing Constraint Violation (Extended Abstract)	Jyh-Han Lin,Jeffrey Scott Vitter	1992	We present efficient new randomized and deterministic methods for transforming optimal solutions for a type of relaxed integer linear program into provably good solutions for the corresponding NP-hard discrete optimization problem. Without any constraint violation, the &egr;-approximation problem for many problems of this type is itself NP-hard. Our methods provide polynomial-time &egr;-approximations while attempting to minimize the packing constraint violation. Our methods lead to the first known approximation algorithms with provable performance guarantees for the s-median problem, the tree prunning problem, and the generalized assignment problem. These important problems have numerous applications to data compression, vector quantization, memory-based learning, computer graphics, image processing, clustering, regression, network location, scheduling, and communication. We provide evidence via reductions that our approximation algorithms are nearly optimal in terms of the packing constraint violation. We also discuss some recent applications of our techniques to scheduling problems.
STOC	A Logspace Algorithm for Tree Canonization (Extended Abstract)	Steven Lindell	1992	We present a solution to the problem of assigning to each directed tree T of size n a unique isomorphism invariant name for T, using only work space O(log n). Hence, tree isomorphism is computable in logspace. As another consequence, we obtain the corollary that the set of logspace computable queries (Lspace) on trees is recursively enumerable. Our results extend easily to undirected trees and even forests.
STOC	Ham-Sandwich Cuts in R^d	Chi-Yuan Lo,Jirí Matousek,William L. Steiger	1992	Ham-Sandwich Cuts in R^d
STOC	Simple Algorithms for Routing on Butterfly Networks with Bounded Queues (Extended Abstract)	Bruce M. Maggs,Ramesh K. Sitaraman	1992	Simple Algorithms for Routing on Butterfly Networks with Bounded Queues (Extended Abstract)
STOC	On the Angular Resolution of Planar Graphs	Seth M. Malitz,Achilleas Papakostas	1992	It is a well-known fact that every planar graph admits a planar straight-line drawing. The angular resolution of such a drawing is the minimum angle subtended by any pair of incident edges. The angular resolution of the graph is the supremum angular resolution over all planar straight-line drawings of the graph. In a recent paper by Formann et al. [Proc. 31st IEEE Sympos. on Found. of Comput. Sci., 1990, pp. 86-95], the following question is posed: Does there exist a constant $r(d) > 0$ such that every planar graph of maximum degree $d$ has angular resolution $\geq r(d)$ radians? The present authors show that the answer is yes and that it follows easily from results in the literature on disk-packings. The conclusion is that every planar graph of maximum degree $d$ has angular resolution at least $\alpha^d$ radians, $0
STOC	Self-Stabilizing Symmetry Breaking in Constant-Space (Extended Abstract)	Alain J. Mayer,Yoram Ofek,Rafail Ostrovsky,Moti Yung	1992	We investigate the problem of self-stabilizing round-robin token management scheme on an anonymous bidirectional ring of identical processors, where each processor is an asynchronous probabilistic (coin-flipping) finite state machine which sends and receives messages. We show that the solution to this problem is equivalent to symmetry breaking (i.e., leader election). Requiring only constant-size messages and message-passing model has practical implications: our solution can be implemented in high-speed networks using a universal fast hardware switches (i.e., finite state machines) of size independent of the size of the network.
STOC	RL\subseteqSC	Noam Nisan	1992	RL\subseteqSC
STOC	On the Degree of Boolean Functions as Real Polynomials	Noam Nisan,Mario Szegedy	1992	Every boolean function may be represented as a real polynomial. In this paper we characterize the degree of this polynomial in terms of certain combinatorial properties of the boolean function. Our first result is a tight lower bound of &OHgr;(log n) on the degree needed to represent any boolean function that depends on n variables. Our second result states that for every boolean function f the following measures are all polynomially related:(1) The decision tree complexity of f. (2) The degree of the polynomial representing f. (3) The smallest degree of a polynomial approximating f in the Lmax norm.
STOC	Shallow Multiplication Circuits and Wise Financial Investments	Mike Paterson,Uri Zwick	1992	Paterson, Pippenger and Zwick have recently obtained a general theory that describes the optimal way in which given carry-save adders can be combined into carry-save networks. Their work produces, in particular, multiplication circuits of depth 3.71 log* n (these circuits put out two numbers whose sum is the result of the multiplication). In this work an extension of the above general theory is obtained. We now consider carry-save adders that may receive inputs and produce outputs using several different representation methods. We describe the optimal way of utilising any such collection of carry-save adders. The optimality proof uses the min-max theorem of game theory. By using several different representation standards, the depth of multiplication circuits can be surprisingly reduced to 3.48 log* n (again two output numbers are produced). We introduce bit level redundancy by using a novel coding scheme in which each bit is distributed over four wires. Interestingly, the information on these four wires is usually not transmitted simultaneously. Finally, an analogy is made between the optimisation problem faced by the circuit designer and the optimisation problem faced by an investor, offered a collection of financial investment plans, each involving perhaps several different currencies. This analogy is used to obtain intuitive explanations of the results obtained.
STOC	Improved Distributed Algorithms for Coloring and Network Decomposition Problems	Alessandro Panconesi,Aravind Srinivasan	1992	Improved Distributed Algorithms for Coloring and Network Decomposition Problems
STOC	Faster Algorithms for Finding Small Edge Cuts in Planar Graphs (Extended Abstract)	Satish Rao	1992	Faster Algorithms for Finding Small Edge Cuts in Planar Graphs (Extended Abstract)
STOC	On the Degree of Polynomials that Approximate Symmetric Boolean Functions (Preliminary Version)	Ramamohan Paturi	1992	"In this paper, we provide matching (up to a constant factor) upper and lower bounds on the degree of polynomials that represent symmetric boolean functions with an error 1/3. Let &Ggr;(f)=min{|2k&ndash;n+1|:fk &ne; fk+ 1 and 0 &le; k &le; n &ndash; 1} where fi is the value of f on inputs with exactly i 1's. We prove that the minimum degree over all the approximating polynomials of f is &THgr;((n(n-&Ggr;(f))).5). We apply the techniques and tools from approximation theory to derive this result."
STOC	A Hypercubic Sorting Network with Nearly Logarithmic Depth	C. Greg Plaxton	1992	"A natural class of &ldquo;hypercubic&rdquo; sorting networks is defined. The regular structure of these sorting networks allows for elegant and efficient implementations on any of the so-called hypercubic networks (e.g., the hypercube, shuffle-exchange, butterfly, and cube-connected cycles). This class of sorting networks contains Batcher's O(lg2 n)-depth bitonic sort, but not the O(lg n)-depth sorting network of Ajtai, Komlo&acute;s, and Szemere&acute;di. In fact, no o(lg2 n)-depth compare-interchange sort was previously known for any of the hypercubic networks. In this paper, we prove the existence of a family of 2O((lg lg n)1/2) lg n-depth hypercubic sorting networks. Note that this depth is o(lg1+&egr; n) for any constant &egr; > 0."
STOC	Finding Approximate Separators and Computing Tree Width Quickly	Bruce A. Reed	1992	We show that for any fixed k, there is a linear-time algorithm which given a graph G either: (i) finds a cutset X of G with |X| &le; k such that no component of G&ndash;X contains more than 3/4|G&ndash;X| vertices, or (ii) determines that for any set X of vertices of G with |X| &le; k, there is a component of G&ndash;X which contains more than 2/3|G&ndash;X| vertices. This approximate separator algorithm can be used to develop and O(n log n algorithm for determining if G has a tree decomposition of width at most k (for fixed k) and finding such a tree decomposition if it exists.
STOC	Exponential Determinization for omega-Automata with Strong-Fairness Acceptance Condition (Extended Abstract)	Shmuel Safra	1992	In [Saf88] an exponential determination procedure for Bu&uml;chi automata was shown, yielding tight bounds for decision procedures of some logics ([EJ88, Saf88, SV89, KT89]). In [SV89] the complexity of determinization and complementation of &ohgr;-automata was further investigated, leaving as an open question the complexity of the determinization of a single class of &ohgr;-automata. For this class of &ohgr;-automata with strong fairness as acceptance condition (Street automata), [SV89] managed to show an exponential complementation procedure, but showed that the blow-up of the translation of these automata to any of the classes known to admit exponential determinization is inherently exponential. This might suggest that the blow-up of the determinization of Street automata is inherently doubly exponential. Surprisingly, we show an exponential determinization construction for any Streett automaton. In fact, the complexity of our construction is roughly the same as the complexity achieved in [Saf88] for Bu&uml;chi automata. Moreover, a simple observation extends this upper bound to the complexity of the complementation problem. Since any &ohgr;-automaton that admits exponential determinization can be easily converted into a Streett automaton, we get one procedure that can be used for all of these conversions. This construction is optimal (up to a constant factor in the exponent) for all of these conversions. Our results imply that Streett automata (with strong fairness as acceptance condition) can be used instead of Bu&uml;chi automata (with the weaker acceptance condition) without any loss of efficiency.
STOC	The History and Status of the P versus NP Question	Michael Sipser	1992	The History and Status of the P versus NP Question
STOC	Sample Spaces Uniform on Neighborhoods	Leonard J. Schulman	1992	Let a universe of m elements be given, along with a family of subsets of the universe (neighborhoods), each of size at most k. We describe methods for assigning the m elements to points in a small-dimensional vector space (over GF(2)), in such a way that the elements in each neighborhood are assigned to an independent set of vectors. Such constructions lead, through a standard correspondence between linear and statistical independence, to the construction of small sample spaces which restrict to the uniform distribution in each neighborhood. (The sample space is a uniformly-weighted family of binary m-vectors). The size of such a small space will be a function of the number of neighborhoods; and for sparse families, will be substantially smaller than any space which restricts to the uniform distribution in all k-sets. Previous work on small spaces with limited independence focused on providing independence or near-independence in every k-set of the universe. We show how to construct the sample spaces efficiently both sequentially and in parallel. In case there are polynomially many (in m) neighborhoods, each of size O(log m), the parallel construction is in NC. These spaces provide a new derandomization technique for algorithms; particularly, algorithms related to the Lova&acute;sz local lemma. We also describe applications to the exhaustive testing of VLSI circuits, and to coding for burst errors on noisy channels.
STOC	On the All-Pairs-Shortest-Path Problem	Raimund Seidel	1992	On the All-Pairs-Shortest-Path Problem
STOC	On the Complexity of RAM with Various Operation Sets	Janos Simon,Mario Szegedy	1992	We prove that polynomial time bounded RAMs with the instruction set [shift, +, X, boolean ] accept exactly the languages in PSPACE. This generalizes previous results: [5] showed the same for the instruction set that does not include multiplication, [5] and [7] proved the weaker theorems, that RAMs (and even PRAMs) with this instruction set could be simulated in EXPTAPE. The PRAM result is a simple corollary to our theorems. We also introduce other powerful string-manipulating instructions for RAMs, show a nontrivial simulation of Turing machines by these RAMs, and show that in a sense such simulations are optimal.
STOC	Average Case Intractability of Matrix and Diophantine Problems (Extended Abstract)	Ramarathnam Venkatesan,Sivaramakrishnan Rajagopalan	1992	Average Case Intractability of Matrix and Diophantine Problems (Extended Abstract)
STOC	Proceedings of the Twenty Fourth Annual ACM Symposium on Theory of Computing, 4-6 May 1992, Victoria, British Columbia, Canada		1992	Proceedings of the Twenty Fourth Annual ACM Symposium on Theory of Computing, 4-6 May 1992, Victoria, British Columbia, Canada
FOCS	Synchronization power depends on the register size (Preliminary Version)	Yehuda Afek,Gideon Stupp	1993	Synchronization power depends on the register size (Preliminary Version)
FOCS	A Polynomial-Time Algorithm for the Perfect Phylogeny Problem when the Number of Character States is Fixed	Richa Agarwala,David Fernández-Baca	1993	We present a polynomial-time algorithm for determining whether a set of species, described by the characters they exhibit, has a perfect phylogeny, assuming the maximum number of possible states for a character is fixed. This solves a longstanding open problem. Our result should be contrasted with the proof by Steel and Bodlaender, Fellows, and Warnow that the perfect phylogeny problem is NP-complete in general.
FOCS	Scale-sensitive Dimensions, Uniform Convergence, and Learnability	Noga Alon,Shai Ben-David,Nicolò Cesa-Bianchi,David Haussler	1993	"Learnability in Valiant's PAC learning model has been shown to be strongly related to the existence of uniform laws of large numbers. These laws define a distribution-free convergence property of means to expectations uniformly over classes of random variables. Classes of real-valued functions enjoying such a property are also known as uniform Gliveako-Cantelli classes. In this paper we prove, through a generalization of Sauer's lemma that may be interesting in its own right, a new characterization of uniform Glivenko-Cantelli classes. Our characterization yields Dudley, Gine, and Zinn's previous characterization as a corollary. Furthermore, it is the first based on a simple combinatorial quantity generalizing the Vapnik-Chervonenkis dimension. We apply this result to characterize PAC learnability in the statistical regression framework of probabilistic concepts, solving an open problem posed by Kearns and Schapire. Our characterization shows that the accuracy parameter plays a crucial role in determining the effective complexity of the learner's hypothesis class."
FOCS	The Union of Convex Polyhedra in Three Dimensions	Boris Aronov,Micha Sharir	1993	We show that the number of vertices, edges, and faces of the union of k convex polyhedra in 3-space, having a total of n faces, is O(k/sup 3/+knlog/sup 2/ k). This bound is almost tight in the worst case. We also describe a rather simple randomized incremental algorithm for computing the boundary of the union in O(k/sup 3/+knlog/sup 3/ k) expected time.
FOCS	The Hardness of Approximate Optimia in Lattices, Codes, and Systems of Linear Equations	Sanjeev Arora,László Babai,Jacques Stern,Z. Sweedyk	1993	We prove the following about the Nearest Lattice Vector Problem (in any l/sub p/ norm), the Nearest Code-word Problem for binary codes, the problem of learning a halfspace in the presence of errors, and some other problems. 1. Approximating the optimum within any constant factor is NP-hard. 2. If for some /spl epsiv/>0 there exists a polynomial time algorithm that approximates the optimum within a factor of 2/sup log(0.5-/spl epsiv/)/ /sup n/ then NP is in quasi-polynomial deterministic time: NP/spl sube/DTIME(n/sup poly(log/ /sup n)/). Moreover, we show that result 2 also holds for the Shortest Lattice Vector Problem in the l/sub /spl infin// norm. Improving the factor 2/sup log(0.5-/spl epsiv/)/ /sup n/ to /spl radic/(dim) for either of the lattice problems would imply the hardness of the Shortest Vector Problem in l/sub 2/ norm; an old open problem. Our proofs use reductions from few-prover, one-round interactive proof systems, either directly, or through a set-cover problem.
FOCS	General Bounds on Statistical Query Learning and PAC Learning with Noise via Hypothesis Bounding	Javed A. Aslam,Scott E. Decatur	1993	We derive general bounds on the complexity of learning in the statistical query model and in the PAC model with classification noise. We do so by considering the problem of boosting the accuracy of weak learning algorithms which fall within the statistical query model. This new model was introduced by M. Kearns (1993) to provide a general framework for efficient PAC learning in the presence of classification noise.
FOCS	Highly Efficient Asynchronous Execution of Large-Grained Parallel Programs	Yonatan Aumann,Zvi M. Kedem,Krishna V. Palem,Michael O. Rabin	1993	An n-thread parallel program p is large-grained if in every parallel step the computations on each of the threads are complex procedures requiring numerous processor instructions. This practically relevant style of programs differs from PRAM programs in its large granularity and the possibility that within a parallel step the computations on different threads may considerably vary in size. Let M be an n-processor asynchronous parallel system, with no restriction on the degree of asynchrony and without any specialized synchronization mechanisms. It is a challenging theoretical as well as practically important problem to ensure correct execution of P on such a parallel machine. Let P be a large-grained program requiring total work W for its execution on a synchronous a-processor parallel system. We present a transformation (compilation) of P into a program C(P) which correctly and efficiently effects the computation of P on the asynchronous machine M. Under moderate assumptions on the granularity of threads and the size of the program variables, execution of C(P) requires just O(Wlog* n) expected total work, and the memory space overhead is a small multiplicative constant.
FOCS	Throughput-Competitive On-Line Routing	Baruch Awerbuch,Yossi Azar,Serge A. Plotkin	1993	"We develop a framework that allows us to address the issues of admission control and routing in high-speed networks under the restriction that once a call is admitted and routed, it has to proceed to completion and no reroutings are allowed. The ""no rerouting"" restriction appears in all the proposals for future high-speed networks and stems from current hardware limitations, in particular the fact that the bandwidth-delay product of the newly developed optical communication links far exceeds the buffer capacity of the network. In case the goal is to maximize the throughput, our framework yields an on-line O(log nT)-competitive strategy, where n is the number of nodes in the network and T is the maximum call duration. In other words, our strategy results in throughput that is within O(log nT) factor of the highest possible throughput achievable by an omniscient algorithm that knows all of the requests in advance. Moreover, we show that no on-line strategy can achieve a better competitive ratio. Our framework leads to competitive strategies applicable in several more general settings. Extensions include assigning each connection an associated ""profit"" that represents the importance of this connection, and addressing the issue of call-establishment costs."
FOCS	Near-Linear Cost Sequential and Distribured Constructions of Sparse Neighborhood Covers	Baruch Awerbuch,Bonnie Berger,Lenore Cowen,David Peleg	1993	"This paper introduces the first near-linear (specifically, O(Elog n+nlog/sup 2/ n)) time algorithm for constructing a sparse neighborhood cover in sequential and distributed environments. This automatically implies analogous improvements (from quadratic to near-linear) to all the results in the literature that rely on network decompositions, both in sequential and distributed domains, including adaptive routing schemes with O/spl tilde/(1) stretch and memory, small edge cuts in planar graphs, sequential algorithms for dynamic approximate shortest paths with O/spl tilde/(E) cost for edge insertion/deletion and O/spl tilde/(1) time to answer shortest-path queries, weight and distance-preserving graph spanners with O/spl tilde/(E) running time and space, and distributed asynchronous ""from-scratch"" breadth-first-search and network synchronizer constructions with O/spl tilde/(1) message and space overhead (down from O(n))."
FOCS	Heat & Dump: Competitive Distributed Paging	Baruch Awerbuch,Yair Bartal,Amos Fiat	1993	Heat & Dump: Competitive Distributed Paging
FOCS	A Simple Local-Control Approximation Algorithm for Multicommodity Flow	Baruch Awerbuch,Frank Thomson Leighton	1993	A Simple Local-Control Approximation Algorithm for Multicommodity Flow
FOCS	Genome Rearrangements and Sorting by Reversals	Vineet Bafna,Pavel A. Pevzner	1993	"Sequence comparison in molecular biology is in the beginning of a major paradigm shift-a shift from gene comparison based on local mutations to chromosome comparison based on global rearrangements. In the simplest form the problem of gene rearrangements corresponds to sorting by reversals, i.e. sorting of an array using reversals of arbitrary fragments. Kececioglu and Sankoff gave the first approximation algorithm for sorting by reversals with guaranteed error bound and identified open problems related to chromosome rearrangements. One of these problems is Gollan's conjecture on the reversal diameter of the symmetric group. We prove this conjecture and further study the problem of expected reversal distance between two random permutations. We demonstrate that the expected reversal distance is very close to the reversal diameter thereby indicating that reversal distance provides a good separation between related and non-related sequences. The gene rearrangement problem forces us to consider reversals of signed permutations, as the genes in DNA are oriented. Our approximation algorithm for signed permutation provides a 'performance guarantee' of 3/2. Finally, we devise an approximation algorithm for sorting by reversals with a performance ratio of 7/4."
FOCS	Time-Space Bounds for Directed s-t Connectivity on JAG Models (Extended Abstract)	Greg Barnes,Jeff Edmonds	1993	Time-Space Bounds for Directed s-t Connectivity on JAG Models (Extended Abstract)
FOCS	A Polynomial Time Algorithm for Counting Integral Points in Polyhedra when the Dimension Is Fixed	Alexander I. Barvinok	1993	We prove that for any dimension d there exists a polynomial time algorithm for counting integral points in polyhedra in the d-dimensional Euclidean space. Previously such algorithms were known for dimensions d=1,2,3, and 4 only.
FOCS	Las Vegas algorithms for matrix groups	Robert Beals,László Babai	1993	We consider algorithms in finite groups, given by a list of generators. We give polynomial time Las Vegas algorithms (randomized, with guaranteed correct output) for basic problems for finite matrix groups over the rationals (and over algebraic number fields): testing membership, determining the order, finding a presentation (generators and relations), and finding basic building blocks: center, composition factors, and Sylow subgroups. These results extend previous work on permutation groups into the potentially more significant domain of matrix groups. Such an extension has until recently been considered intractable. In case of matrix groups G of characteristic p, there are two basic types of obstacles to polynomial-time computation: number theoretic (factoring, discrete log) and large Lie-type simple groups of the same characteristic p involved in the group. The number theoretic obstacles are inherent and appear already in handling abelian groups. They can be handled by moderately efficient (subexponential) algorithms. We are able to locate all the nonabelian obstacles in a normal subgroup N and solve all problems listed above for G/N.
FOCS	When can we sort in o(n log n) time?	Amir M. Ben-Amram,Zvi Galil	1993	When can we sort in o(n log n) time?
FOCS	An On-Line Algorithm for Improving Performance in Navigation	Avrim Blum,Prasad Chalasani	1993	"Recent papers have shown optimally-competitive on-line strategies for a robot traveling from a point s to a point t in certain unknown geometric environments. We consider the question: Having gained some partial information about the scene on its first trip from s to t, can the robot improve its performance on subsequent trips it might make? This is a type of on-line problem where a strategy must exploit partial information about the future (e.g., about obstacles that lie ahead). For scenes with axis-parallel rectangular obstacles where the Euclidean distance between s and t is n, we present a deterministic algorithm whose average trip length after t trips, k/spl les/n, is O(/spl radic/n/k) times the length of the shortest s-t path in the scene. We also show that this is the best a deterministic strategy can do. This algorithm can be thought of as performing an optimal tradeoff between search effort and the goodness of the path found. We improve this algorithm so that for every i/spl les/n, the robot's ith trip length is O(/spl radic/n/t) times the shortest s-t path length. A key idea of the paper is that a tree structure can be defined in the scene, where the nodes are portions of certain obstacles and the edges are ""short"" paths from a node to its children. The core of our algorithms is an on-line strategy for traversing this tree optimally."
FOCS	Learning an Intersection of k Halfspaces over a Uniform Distribution	Avrim Blum,Ravi Kannan	1993	"We present a polynomial-time algorithm to learn an intersection of a constant number of halfspaces in n dimensions, over the uniform distribution on an n-dimensional ball. The algorithm we present in fact can learn an intersection of an arbitrary (polynomial) number of halfspaces over this distribution, if the subspace spanned by the normal vectors to the bounding hyperplanes has constant dimension. This generalizes previous results for this distribution, in particular a result of E.B. Baum (1990) who showed how to learn an intersection of 2 halfspaces defined by hyperplanes that pass through the origin (his results in fact held for a variety of symmetric distributions). Our algorithm uses estimates of second moments to find vectors in a low-dimensional ""relevant subspace"". We believe that the algorithmic techniques studied here may be useful in other geometric learning applications."
FOCS	A Quantum Bit Commitment Scheme Provably Unbreakable by both Parties	Gilles Brassard,Claude Crépeau,Richard Jozsa,Denis Langlois	1993	We describe a complete protocol for bit commitment based on the transmission of polarized photons. We show that under the laws of quantum physics, this protocol cannot be cheated by either party except with exponentially small probability (exponential in the running time needed to implement the honest protocol). A more thorough analysis is required to adjust all the constants used in this paper to get the best performance from our construction. Better performances may probably be achieved by using a third conjugate transmission-reception basis of circular polarization.
FOCS	Product Range Spaces, Sensitive Sampling, and Derandomization	Hervé Brönnimann,Bernard Chazelle,Jirí Matousek	1993	We introduce the concept of a sensitive /spl epsi/-approximation, and use it to derive a more efficient algorithm for computing /spl epsi/-nets. We define and investigate product range spaces, for which we establish sampling theorems analogous to the standard finite VC-dimensional case. This generalizes and simplifies results from previous works. We derive a simpler optimal deterministic convex hull algorithm, and by extending the method to the intersection of a set of balls with the same radius, we obtain an O(nlog/sup 3/ n) deterministic algorithm for computing the diameter of an n-point set in 3-dimensional space.
FOCS	Exact Learning via the Monotone Theory (Extended Abstract)	Nader H. Bshouty	1993	Exact Learning via the Monotone Theory (Extended Abstract)
FOCS	Geometric Discrepancy Revisited	Bernard Chazelle	1993	Discrepancy theory addresses the general issue of approximating one measure by another one. Originally an offshoot of diophantine approximation theory, the area has expanded into applied mathematics, and now, computer science. Besides providing the theoretical foundation for sampling, it holds some of the keys to understanding the computational power of randomization. A few applications of discrepancy theory are listed. We give elementary algorithms for estimating the discrepancy between various measures arising in practice. We also present a general technique for proving discrepancy lower bounds.
FOCS	Using Difficulty of Prediction to Decrease Computation: Fast Sort, Priority Queue and Convex Hull on Entropy Bounded Inputs	Shenfeng Chen,John H. Reif	1993	Studies have indicated that sorting comprises about 20% of all computing on mainframes. Perhaps the largest use of sorting in computing (particularly business computing) is the sort required for large database operations (e.g. required by joint operations). In these applications the keys are many words long. Since our sorting algorithm hashes the key (rather than compare entire keys as in comparison sorts such as quicksort), our algorithm is even more advantageous in the case of large key lengths; in that case the cutoff is much lower. In case that the compression ratio is high, which can be determined after building the dictionary, we just adopt the previous sorting algorithm, e.g. quick sort. The same techniques can be extended to other problems (e.g. computational geometry problems) to decrease computation by learning the distribution of the inputs.
FOCS	Optimal Parallel All-Nearest-Neighbors Using the Well-Separated Pair Decomposition (Preliminary Version)	Paul B. Callahan	1993	Optimal Parallel All-Nearest-Neighbors Using the Well-Separated Pair Decomposition (Preliminary Version)
FOCS	A Tight Lower Bound for k-Set Agreement	Soma Chaudhuri,Maurice Herlihy,Nancy A. Lynch,Mark R. Tuttle	1993	We prove tight bounds on the time needed to solve k-set agreement, a natural generalization of consensus. We analyze this problem in a synchronous, message-passing model where processors fail by crashing. We prove a lower bound of [f/k]+1 rounds of communication for solutions to k-set agreement that tolerate f failures. This bound is tight, and shows that there is an inherent tradeoff between the running time, the degree of coordination required, and the number of faults tolerated, even in idealized models like the synchronous model. The proof of this result is interesting because it is a geometric combination of other well-known proof techniques.
FOCS	On Bounded Queries and Approximation	Richard Chang,William I. Gasarch	1993	This paper investigates the computational complexity of approximating NP-optimization problems using the number of queries to an NP oracle as a complexity measure. The results show a trade-off between the closeness of the approximation and the number of queries required. For an approximation factor k(n), loglog/sub k(n/) n queries to an NP oracle can be used to approximate the maximum clique size of a graph within a factor of k(n). However, this approximation cannot be achieved using fewer than loglog/sub k(n/) n-c queries to any oracle unless P=NP, where c is a constant that does not depend on k. These results hold when k(n) belongs to a class of functions which include any integer constant function, log n, log/sup a/ n and n/sup 1/a/. Similar results are obtained for graph coloring, set cover and other NP-optimization problems.
FOCS	Sensitive Functions and Approximate Problems	Shiva Chaudhuri	1993	We investigate properties of functions that are good measures of the CRCW PRAM complexity of computing them. While the block sensitivity is known to be a good measure of the CREW PRAM complexity, no such measure is known for CRCW PRAMs. We show that the complexity of computing a function is related to its everywhere sensitivity, introduced by Vishkin and Wigderson (1985). Specifically we show that the time required to compute a function f:D/sup n//spl rarr/R of everywhere sensitivity es(f) with P/spl ges/n processors and unbounded memory is /spl Omega/(log[log es(f)/(log 4P|D|- log es(f))]). This improves previous results of Azar (1992), and Vishkin and Wigderson. We use this lower bound to derive new lower bounds for some approximate problems. These problems can often be solved faster than their exact counterparts and for many applications, it is sufficient to solve the approximate problem. We show that approximate selection requires time /spl Omega/(log[log n/log k]) with kn, processors and approximate counting with accuracy /spl lambda//spl ges/2 requires time /spl Omega/(log[log n/(log k+log /spl lambda/)]) with kn processors. In particular, for constant accuracy, no lower bounds were known for these problems.
FOCS	Parallel computable higher type functionals (Extended Abstract)	Peter Clote,Aleksandar Ignjatovic,Bruce M. Kapron	1993	Parallel computable higher type functionals (Extended Abstract)
FOCS	Fast algorithms for constructing t-spanners and paths with stretch t	Edith Cohen	1993	The distance between two vertices in a weighted graph is the weight of a minimum-weight path between them. A path has stretch t if its weight is at most t times the distance between its end points. We consider a weighted undirected graph G=(V, E) and present algorithms that compute paths with stretch 2/spl les/t/spl les/log n. We present a O/spl tilde/((m+k)n/sup (2+/spl epsiv///t)) time randomized algorithm that finds paths between k specified pairs of vertices and a O/spl tilde/((m+ns)n/sup 2(1+log(n)/ /sup m+/spl epsiv/)/t/) deterministic algorithm that finds paths from s specified sources to all other vertices (for any fixed /spl epsiv/>0), where n=|V| and m=|E|. This improves significantly over the slower O/spl tilde/(min{k, n}m) exact shortest paths algorithms and a previous O/spl tilde/(mn/sup 64/t/+kn/sup 32/t/) time algorithm by Awerbuch et al. A t-spanner of a graph G is a set of weighted edges on the vertices of G such that distances in the spanner are not smaller and within a factor of t from the corresponding distances in G. Previous work was concerned with bounding the size and efficiently constructing t-spanners. We construct t-spanners of size O/spl tilde/(n/sup 1+(2+/spl epsiv///t)) in O/spl tilde/(mn/sup (2+/spl epsiv///t)) expected time (for any fixed /spl epsiv/>0), what constitutes a faster construction (by a factor of n/sup (3+2//t)) of sparser spanners than was previously attainable. We also provide efficient parallel constructions. Our algorithms are based on new structures called pairwise-covers and a novel approach to construct them efficiently.
FOCS	Optimally fast parallel algorithms for preprocessing and pattern matching in one and two dimensions	Richard Cole,Maxime Crochemore,Zvi Galil,Leszek Gasieniec,Ramesh Hariharan,S. Muthukrishnan,Kunsoo Park,Wojciech Rytter	1993	All algorithms below are optimal alphabet-independent parallel CRCW PRAM algorithms. In one dimension: Given a pattern string of length m for the string-matching problem, we design an algorithm that computes a deterministic sample of a sufficiently long substring in constant time. This problem used to be a bottleneck in the pattern preprocessing for one- and two-dimensional pattern matching. The best previous time bound was O(log/sup 2/ m/log log m). We use this algorithm to obtain the following results. 1. Improving the preprocessing of the constant-time text search algorithm from O(log/sup 2/ m/log log m) to n(log log m), which is now best possible. 2. A constant-time deterministic string-matching algorithm in the case that the text length n satisfies n=/spl Omega/(m/sup 1+/spl epsiv//) for a constant /spl epsiv/>0. 3. A simple probabilistic string-matching algorithm that has constant time with high probability for random input. 4. A constant expected time Las-Vegas algorithm for computing the period of the pattern and all witnesses and thus string matching itself, solving the main open problem remaining in string matching.
FOCS	Logical Reducibility and Monadic NP	Stavros S. Cosmadakis	1993	It is shown that, by choosing appropriate encodings of instances as relational structures, several known polynomial-time many-one reductions can he described in first-order logic, and furthermore they are monadic. As a corollary, several known NP-complete problems in monadic NP are shown not to be in monadic co-NP. It is further shown that there is no monadic first-order reduction from connectivity to directed reachability, even in the presence of successor. Finally, some classes of syntactically restricted first-order reductions are shown to be incomparable.
FOCS	The Complexity of the Theory of p-adic Numbers	Lavinia Egidi	1993	"This paper addresses the question of the complexity of the decision problem for the theory Th(Q/sub p/) of p-adic numbers. The best known lower bound for the theory is double exponential alternating time with a linear number of alternations. I have designed an algorithm that determines the truth value of sentences of the theory requiring double exponential space. My algorithm is based on techniques used by G.E. Collins (1975) for the theory Th(R) of the reals, and on J. Denef's work (1986) on semi-algebraic sets and cell decomposition for p-adic fields. No elementary upper bound had been previously established."
FOCS	Better Lower Bounds on Detecting Affine and Spherical Degeneracies	Jeff Erickson,Raimund Seidel	1993	"We show that in the worst case, /spl Omega/(n/sup d/) sidedness queries are required to determine whether a set of n points in R/sup d/ is affinely degenerate, i.e., whether it contains d+1 points on a common hyperplane. This matches known upper bounds. We give a straightforward adversary argument, based on the explicit construction of a point set containing /spl Omega/(n/sup d/) ""collapsible"" simplices, any one of which can be made degenerate without changing the orientation of any other simplex. As an immediate corollary, we have an /spl Omega/(n/sup d/) lower bound on the number of sidedness queries required to determine the order type of a set of n points in R/sup d/. Using similar techniques, we also show that /spl Omega/(n/sup d+1/) in-sphere queries are required to decide the existence of spherical degeneracies in a set of n points in R/sup d/."
FOCS	Signal Propagation, with Application to a Lower Bound on the Depth of Noisy Formulas	William S. Evans,Leonard J. Schulman	1993	We study the decay of an information signal propagating through a series of noisy channels. We obtain exact bounds on such decay, and as a result provide a new lower bound on the depth of formulas with noisy components. This improves upon previous work of N. Pippenger (1988) and significantly decreases the gap between his lower bound and the classical upper bound of von Neumann. We also discuss connections between our work and the study of mixing rates of Markov chains.
FOCS	Testing Equalities of Multiplicative Representations in Polynomial Time (Extended Abstract)	Guoqiang Ge	1993	Testing Equalities of Multiplicative Representations in Polynomial Time (Extended Abstract)
FOCS	A Randomized Time-Space Tradefoff of \tildeO(m\tildeR) for USTCON	Uriel Feige	1993	A Randomized Time-Space Tradefoff of \tildeO(m\tildeR) for USTCON
FOCS	Dynamic Word Problems	Gudmund Skovbjerg Frandsen,Peter Bro Miltersen,Sven Skyum	1993	Let M be a fixed finite monoid. We consider the problem of implementing a data type containing a vector x=(x/sub 1/,x/sub 2/,...,x/sub n/)/spl isin/M/sup n/, initially (1,1,...,1) with two kinds of operations, for each i/spl isin/{1,...,n}, a/spl isin/M, an operation change/sub i,a/ which changes x/sub i/ to a and a single operation product returning /spl Pi//sub i=1//sup n/x/sub i/. This is the dynamic word problem. If we in addition for each j/spl isin/{1,...,n} have an operation prefix/sub j/ returning /spl Pi//sub i=1//sup j/x/sub i/, we talk about the dynamic prefix problem. We analyze the complexity of these problems in the cell probe or decision assignment tree model for two natural cell sizes, 1 bit and log n bits. We obtain a classification of the complexity based on algebraic properties of M.
FOCS	Eavesdropping Games: A Graph-Theoretic Approach to Privacy in Distributed Systems	Matthew K. Franklin,Zvi Galil,Moti Yung	1993	"We initiate a graph-theoretic approach to study the (information-theoretic) maintenance of privacy in distributed environments in the presence of a bounded number of mobile eavesdroppers (""bugs""). For two fundamental privacy problems-secure message transmission and distributed database maintenance-we assume an adversary is ""playing eavesdropping games,"" coordinating the movement of the bugs among the sites to learn the current memory contents. We consider various mobility settings (adversaries), motivated by the capabilities (strength) of the bugging technologies (e.g., how fast can a bug be reassigned). We combinatorially characterize and compare privacy maintenance problems, determine their feasibility (under numerous bug models), suggest protocols for the feasible cases, and analyze their computational complexity."
FOCS	A Framework for Cost-scaling Algorithms for Submodular Flow Problems	Harold N. Gabow	1993	The submodular flow problem includes such problems as minimum-cost network flow, dijoin, edge-connectivity orientation and others. We present a cost-scaling algorithm for submodular flow problems. The algorithm applies to these problems in general; we also examine its efficiency for the dijoin and edge-connectivity orientation problems. A minimum-cost dijoin is found in time O(min{m/sup 1/2/, n/sup 2/3/}nmlog(nN)), where n, m and N denote the number of vertices, number of edges and largest magnitude of an integral edge cost. The previous best-known bound is O(n/sup 2/m) if fast matrix multiplication is not used. A k-edge-connected orientation is found in time O(kn/sup 2/(/spl radic/(kn)+k/sup 2/log(n/k))). A minimum-cost k-edge-connected orientation is found on the above time bound for dijoins when k=O(1) (and a more complicated bound for general k). The scaling algorithm uses a transformation that eliminates vertex weights in edge-capacitated graphs. It also incorporates a scheme to limit the growth in the size of intermediate solutions, using a dual minimum-cost network flow problem.
FOCS	A Sub-Linear Time Distributed Algorithm for Minimum-Weight Spanning Trees (Extended Abstract)	Juan A. Garay,Shay Kutten,David Peleg	1993	A Sub-Linear Time Distributed Algorithm for Minimum-Weight Spanning Trees (Extended Abstract)
FOCS	Solving Systems of Set Constraints with Negated Subset Relationships	Rémi Gilleron,Sophie Tison,Marc Tommasi	1993	We present a decision procedure, based on tree automata techniques, for satisfiability of systems of set constraints including negated subset relationships. This result extends all previous works on set constraints solving and solves a problem which was left open by L. Bachmair et al. (1993). We prove in a constructive way that a non empty set of solutions always contains a regular solution, that is a tuple of regular tree languages. Moreover, we think that the new class of tree automata described here could be interesting in its own.
FOCS	External-Memory Computational Geometry (Preliminary Version)	Michael T. Goodrich,Jyh-Jong Tsay,Darren Erik Vengroff,Jeffrey Scott Vitter	1993	External-Memory Computational Geometry (Preliminary Version)
FOCS	A Chernoff bound for random walks on expander graphs	David Gillman	1993	We consider a finite random walk on a weighted graph G; we show that the sample average of visits to a set of vertices A converges to the stationary probability /spl pi/(A) with error probability exponentially small in the length of the random walk and the square of the size of the deviation from /spl pi/(A). The exponential bound is in terms of the expansion of G and improves previous results. We show that the method of taking the sample average from one trajectory is a more efficient estimate of /spl pi/(A) than the standard method of generating independent sample points from several trajectories. Using this more efficient sampling method, we improve the algorithms of Jerrum and Sinclair (1989) for approximating the number of perfect matchings in a dense graph and for approximating the partition function of an Ising system. We also give a fast estimate of the entropy of a random walk on an unweighted graph.
FOCS	"NP Trees and Carnap's Modal Logic"	Georg Gottlob	1993	"We consider problems and complexity classes definable by interdependent queries to an oracle in NP. How the queries depend on each other is specified by a directed graph G. We first study the class of problems where G is a general dag and show that this class coincides with /spl Delta//sub 2//sup P/. We then consider the class where G is a tree. Our main result states that this class is identical to P/sup NP/ [O(log n)], the class of problems solvable in polynomial time with a logarithmic number of queries to an oracle in NP. Using this result we show that the following problems are all P/sup NP/[O(logn)] complete: validity-checking of formulas in Carnap's modal logic, checking whether a formula is almost surely valid over finite structures in modal logics K, T, and S4, and checking whether a formula belongs to the stable set of beliefs generated by a propositional theory."
FOCS	Gages Accept Concurrent Behavior	Vineet Gupta,Vaughan R. Pratt	1993	We represent concurrent processes as Boolean propositions or gates, cast in the role of accepters of concurrent behavior. This properly extends other mainstream representations of concurrent behavior such as event structures, yet is defined more simply. It admits an intrinsic notion of duality that permits processes to be viewed as either schedules or automata. Its algebraic structure is essentially that of linear logic, with its morphisms being consequence-preserving renamings of propositions, and with its operations forming the core of a natural concurrent programming language.
FOCS	Directed vs. Undirected Monotone Contact Networks for Threshold Functions	Magnús M. Halldórsson,Jaikumar Radhakrishnan,K. V. Subrahmanyam	1993	We consider the problem of computing threshold functions using directed and undirected monotone contact networks. Our main results are the following. First, we show that there exist directed monotone contact networks that compute T/sub k//sup n/, 2/spl les/k/spl les/n-1, of size O(k(n-k+2)log(n-k+2)). This bound is almost optimal for small thresholds, since there exists an /spl Omega/(knlog (n/(k-1))) lower bound. Our networks are described explicitly; the previously best upper bound known, obtained from the undirected networks of Dubiner and Zwick, used non-constructive arguments and gave directed networks of size O(k/sup 3.99/nlog n). Second, we show a lower bound of O(nlogloglog n) on the size of undirected monotone contact networks computing T/sub n-1//sup n/, improving the 2(n-1) lower bound of Markov. Combined with our upper bound result, this shows that directed monotone contact networks compute some threshold functions more easily than undirected networks.
FOCS	Near-Quadratic Bounds for the Motion Planning Problem for a Polygon in a Polygonal Environment	Dan Halperin,Micha Sharir	1993	We consider the problem of planning the motion of an arbitrary k-sided polygonal robot B, free to translate and rotate in a polygonal environment V bounded by n edges. We show that the combinatorial complexity of a single connected component of the free configuration space of B is k/sup 3/n/sup 2/2/sup O(log(2/3)/ n). This is a significant improvement of the naive bound O((kn)/sup 3/); when k is constant, which is often the case in practice, this yields a near-quadratic bound on the complexity of such a component, which almost settles (in this special case) a long-standing conjecture regarding the complexity of a single cell in a three-dimensional arrangement of surfaces. We also present an algorithm that constructs a single component of the free configuration space of B in time O(n/sup 2+/spl epsi//), for any /spl epsi/>0, assuming B has a constant number of sides. This algorithm, combined with some standard techniques in motion planning, yields a solution to the underlying motion planning problem, within the same asymptotic running time.
FOCS	Optimal Bi-Weighted Binary Trees and the Complexity of Maintaining Partial Sums	Haripriyan Hampapuram,Michael L. Fredman	1993	Let A be an array. The partial sum problem concerns the design of a data structure for implementing the following operations. The operation update(j,x) has the effect, A[j]/spl larr/A[j]+x, and the query operation sum(j) returns the partial sum, /spl Sigma//sub i=1//sup j/A[i]. Our interest centers upon the optimal efficiency with which sequences of such operations can be performed, and we derive new upper and lower bounds in the semi-group model of computation. Our analysis relates the optimal complexity of the partial sum problem to optimal binary trees relative to a type of weighting scheme that defines the notion of bi-weighted binary tree.
FOCS	Efficient Computation of Euclidean Shortest Paths in the Plane	John Hershberger,Subhash Suri	1993	We propose a new algorithm for a classical problem in plane computational geometry: computing a shortest path between two points in the presence of polygonal obstacles. Our algorithm runs in worst-case time O(nlog/sup 2/ n) and requires O(nlog n) space, where n is the total number of vertices in the obstacle polygons. Our algorithm actually computes a planar map that encodes shortest paths from a fixed source point to all other points of the plane; the map can be used to answer single-source shortest path queries in O(log n) time. The time complexity of our algorithm is a significant improvement over all previous results known for the shortest path problem.
FOCS	The shrinkage exponent is 2	Johan Håstad	1993	We prove that if we hit a formula of size L with a random restriction from R/sub p/ then the expected remaining size is at most O(p/sup 2/(log p)/sup 3/2/L). As a corollary we obtain a R(n/sup 3-O(1)/) formula size lower bound for an explicit function in NP.
FOCS	Top-Down Lower Bounds for Depth 3 Circuits	Johan Håstad,Stasys Jukna,Pavel Pudlák	1993	We present a top-down lower bound method for depth 3 AND-OR-NOT circuits which is simpler than the previous methods and in some cases gives better lower bounds. In particular we prove that depth 3 AND-OR-NOT circuits that compute PARITY resp. MAJORITY require size at least 2/sup 0.618/ .../spl radic/n/ resp. 2/sup 0.849/.../spl radic/n/. This is the first simple proof of a strong lower bound by a top-down argument for non-monotone circuits.
FOCS	Counting Rational Points on Curves over Finite Fields (Extended Abstract)	Ming-Deh A. Huang,Doug Ierardi	1993	Counting Rational Points on Curves over Finite Fields (Extended Abstract)
FOCS	On the Value of Information in Coordination Games (preliminary version)	Sandy Irani,Yuval Rabani	1993	On the Value of Information in Coordination Games (preliminary version)
FOCS	Simulated Annealing for Graph Bisection	Mark Jerrum,Gregory B. Sorkin	1993	"We resolve in the affirmative a question of R.B. Boppana and T. Bui: whether simulated annealing can with high probability and in polynomial time, find the optimal bisection of a random graph an G/sub npr/ when p-r=(/spl Theta/n/sup /spl Delta/-2/) for /spl Delta//spl les/2. (The random graph model G/sub npr/ specifies a ""planted"" bisection of density r, separating two n/2-vertex subsets of slightly higher density p.) We show that simulated ""annealing"" at an appropriate fixed temperature (i.e., the Metropolis algorithm) finds the unique smallest bisection in O(n/sup 2+/spl epsi//) steps with very high probability, provided /spl Delta/>11/6. (By using a slightly modified neighborhood structure, the number of steps can be reduced to O(n/sup 1+/spl epsi//).) We leave open the question of whether annealing is effective for /spl Delta/ in the range 3/2"
FOCS	The Complexity and Distribution of Hard Problems (Extended Abstract)	David W. Juedes,Jack H. Lutz	1993	The Complexity and Distribution of Hard Problems (Extended Abstract)
FOCS	Universal Emulations with Sublogarithmic Slowdown	Christos Kaklamanis,Danny Krizanc,Satish Rao	1993	The existence of bounded degree networks which can emulate the computation of any bounded degree network of the same size with logarithmic slowdown is well-known. The butterfly is an example of such a universal network. Leiserson was the first to introduce the concept of an area-universal network: a network with VLSI layout area A which can emulate any network of the same size and layout area with logarithmic slowdown. His results imply the existence of an N-node network with layout area O(N log/sup 2/ N) which can emulate any N-node planar network with O(log N) slowdown. The main results of this paper are: There exists an N-node network with layout area O(N log/sup 2/ N) which can emulate any N-node planar network with O(loglogN) slowdown. The N-node butterfly (and hypercube) can emulate any network with VLSI layout area N/sup 2-/spl epsiv// (/spl epsiv/>0) with O(loglogN) slowdown. We also discuss sublogarithmic bounds for the slowdown of emulations of arbitrary bounded degree networks.
FOCS	Random Sampling in Matroids, with Applications to Graph Connectivity and Minimum Spanning Trees	David R. Karger	1993	Random sampling is a powerful way to gather information about a group by considering only a small part of it. We give a paradigm for applying this technique to optimization problems, and demonstrate its effectiveness on matroids. Matroids abstractly model many optimization problems that can be solved by greedy methods, such as the minimum spanning tree (MST) problem. Our results have several applications. We give an algorithm that uses simple data structures to construct an MST in O(m+n log n) time. We give bounds on the connectivity (minimum cut) of a graph suffering random edge failures. We give fast algorithms for packing matroid bases, with particular attention to packing spanning trees in graphs.
FOCS	A linear-processor polylog-time algorithm for shortest paths in planar graphs	Philip N. Klein,Sairam Subramanian	1993	We give an algorithm requiring polylog time and a linear number of processors to solve single-source shortest paths in directed planar graphs, bounded-genus graphs, and 2-dimensional overlap graphs. More generally, the algorithm works for any graph provided with a decomposition tree constructed using size-O(/spl radic/n polylog n) separators.
FOCS	A Weak Version of the Blum, Shub & Smale model	Pascal Koiran	1993	A Weak Version of the Blum, Shub & Smale model
FOCS	On Choosing a Dense Subgraph (Extended Abstract)	Guy Kortsarz,David Peleg	1993	On Choosing a Dense Subgraph (Extended Abstract)
FOCS	Breaking the Theta(n log ^2 n) Barrier for Sorting with Faults (Extended Abstract)	Frank Thomson Leighton,Yuan Ma	1993	Breaking the Theta(n log ^2 n) Barrier for Sorting with Faults (Extended Abstract)
FOCS	Efficient Out-of-Core Algorithms for Linear Relaxation Using Blocking Covers (Extended Abstract)	Charles E. Leiserson,Satish Rao,Sivan Toledo	1993	Efficient Out-of-Core Algorithms for Linear Relaxation Using Blocking Covers (Extended Abstract)
FOCS	A Compact Piecewise-Linear Voronoi Diagram for Convex Sites in the Plane	Michael McAllister,David G. Kirkpatrick,Jack Snoeyink	1993	In the plane, the post-office problem, which asks for the closest site to a query site, and retraction motion planning, which asks for a one-dimensional retract of the free space of a robot, are both classically solved by computing a Voronoi diagram. When the sites are k disjoint convex sets, we give a compact representation of the Voronoi diagram, using O(k) line segments, that is sufficient for logarithmic time post-office location queries and motion planning. If these sets are polygons with n total vertices, we compute this diagram optimally in O(klog n) deterministic time for the Euclidean metric and in O(klog nlog m) deterministic time for the convex distance function defined by a convex m-gon.
FOCS	Refining a Triangulation of a Planar Straight-Line Graph to Eliminate Large Angles	Scott A. Mitchell	1993	We show that any planar straight line graph (PSLG) with v vertices can be triangulated with no angle larger than 7/spl pi//8 by adding O(v/sup 2/log v) Steiner points in O(v/sup 2/log/sup 2/ v) time. We first triangulate the PSLG with an arbitrary constrained triangulation and then refine that triangulation by adding additional vertices and edges. We follow a lazy strategy of starting from an obtuse angle and exploring the triangulation in search of a sequence of Steiner points that will satisfy a local angle condition. Explorations may either terminate successfully (for example at a triangle vertex), or merge. Some PSLGs require /spl Omega/(v/sup 2/) Steiner points in any triangulation achieving any largest angle bound less than /spl pi/. Hence the number of Steiner points added by our algorithm is within a log v factor of worst case optimal. For most inputs the number of Steiner points and running time would be considerably smaller than in the worst case.
FOCS	Space Bounds for Graph Connectivity Problems on Node-named JAGs and Node-ordered JAGs	C. K. Poon	1993	Two new models, NO-JAG and NN-JAG in order of increasing computation power, are introduced as extensions to the conventional JAG model. A space lower bound of /spl Omega/(log/sup 2/ n/log log n) is proved for the problem of directed st-connectivity on a probabilistic NN-JAG and a space upper bound of O(log n) is proved for the problem of directed st-nonconnectivity on a nondeterministic NO-JAG. It is also shown that a nondeterministic NO-JAG is nearly as powerful as a nondeterministic Turing machine.
FOCS	Faster Algorithms for the Generalized Network Flow Problem	Tomasz Radzik	1993	We consider the generalized network flow problem. Each arc e in the network has a gain factor /spl gamma/(e). If f(e) units of flow enter arc e, then f(e)/spl gamma/(e) units arrive at the other end of e. The generalized network flow problem is to maximize the net flow into one specific node, the sink. We give an algorithm which solves this problem in O/spl tilde/(m/sup 2/(m+nloglog B)log B) time, where B is the largest integer used to represent the gain factors, the capacities, and the initial supplies at the nodes. If m is O(n/sup (4/3/-/spl epsiv/) and B is not extremely large, then our bound improves the previous best bound O(m/sup 1.5/n/sup 2/log B) given by P.M. Vaidya (1989). Our algorithm is an approximation scheme which in each iteration reduces by a constant factor the difference between the current net flow into the sink and the optimal one. The solution which is within a factor of 1+/spl xi/ from the optimum can be computed in O/spl tilde/(m/sup 2/n+min{m/sup 2/n, m(m+nloglog B)}log(1//spl xi/)) time. This improves the previous bounds on the approximate generalized flow problem.
FOCS	Primal-dual RNC approximation algorithms for (multi)-set (multi)-cover and covering integer programs	Sridhar Rajagopalan,Vijay V. Vazirani	1993	We build on the classical greedy sequential set cover algorithm, in the spirit of the primal-dual schema, to obtain simple parallel approximation algorithms for the set cover problem and its generalizations. Our algorithms use randomization, and our randomized voting lemmas may be of independent interest. Fast parallel approximation algorithms were known before for set cover, though not for any of its generalizations.
FOCS	"On the ``log rank''-Conjecture in Communication Complexity"	Ran Raz,Boris Spieker	1993	We show the existence of a non-constant gap between the communication complexity of a function and the logarithm of the rank of its input matrix. We consider the following problem: each of two players gets a perfect matching between two n-element sets of vertices. Their goal is to decide whether or not the union of the two matchings forms a Hamiltonian cycle. We prove: (1) The rank of the input matrix over the reals for this problem is 2/sup O(n)/. (2) The non-deterministic communication complexity of the problem is /spl Omega/(n log log n). Our result also supplies a superpolynomial gap between the chromatic number of a graph and the rank of its adjacency matrix. Another conclusion from the second result is an /spl Omega/(n log log n). Lower bound for the graph connectivity problem in the non-deterministic case. We make use of the theory of group representations for the first result. The second result is proved by an information theoretic argument.
FOCS	An O(n log ^3 n) Algorithm for the Real Root Problem	John H. Reif	1993	An O(n log ^3 n) Algorithm for the Real Root Problem
FOCS	The NC Equivalence of Planar Integer Linear Programming and Euclidean GCD	David Shallcross,Victor Y. Pan,Yu Lin-Kriz	1993	We show NC-reduction of integer linear programming with two variables to the evaluation of the remainder sequence arising in the application of the Euclidean algorithm to two positive integers. Due to the previous result of X. Deng (1989), this implies NC-equivalence of both of these problems, whose membership in NC, as well as P-completeness, remain unresolved open problems.
FOCS	Almost Tight Upper Bounds for Lower Envelopes in Higher Dimensions	Micha Sharir	1993	We show that the combinatorial complexity of the lower envelope of n surfaces or surface patches in d-space (d/spl ges/3), all algebraic of constant maximum degree, and bounded by algebraic surfaces of constant maximum degree, is O(n/sup d-1+/spl epsi//), for any /spl epsi/>0; the constant of proportionality depends on /spl epsi/, d, and the shape and degree of the surface patches and of their boundaries. This is the first nontrivial general upper bound for this problem, and it almost establishes a long-standing conjecture that the complexity of the envelope is O(n/sup d-2//spl lambda//sub q/(n)) for some constant q depending on the shape and degree of the surfaces (where /spl lambda//sub q/(n) is the maximum length of (n,q) Davenport-Schinzel sequences). We also present a randomized algorithm for computing the envelope in three dimensions, with expected running time O(n/sup 2+/spl epsi//), and give several applications of the new bounds.
FOCS	On Representations by Low-Degree Polynomials	Roman Smolensky	1993	In the first part of the paper we show that a subset S of a boolean cube B/sub n/ embedded in the projective space P/sup n/ can be approximated by a subset of B/sub n/ defined by nonzeroes of a low-degree polynomial only if the values of the Hilbert function of S are sufficiently small relative to the size of S. The use of this property provides a simple and direct technique for proving lower bounds on the size of ACC[p/sup r/] circuits. In the second part we look at the problem of computing many-output function by ACC[p/sup r/] circuit and give an example when such a circuit can be correct only at exponentially small fraction of assignments.
FOCS	Approximating Shortest Superstrings	Shang-Hua Teng,F. Frances Yao	1993	The Shortest Superstring Problem is to find a shortest possible string that contains every string in a given set as substrings. This problem has applications to data compression and DNA sequencing. As the problem is NP-hard and MAX SNP-hard, approximation algorithms are of interest. We present a new algorithm which always finds a superstring that is at most 2.89 times as long as the shortest superstring. Our result improves the 3-approximation result of Blum, Jiang, Li, Tromp, and Yannakakis (1991).
FOCS	Quantum Circuit Complexity	Andrew Chi-Chih Yao	1993	We propose a complexity model of quantum circuits analogous to the standard (acyclic) Boolean circuit model. It is shown that any function computable in polynomial time by a quantum Turing machine has a polynomial-size quantum circuit. This result also enables us to construct a universal quantum computer which can simulate, with a polynomial factor slowdown, a broader class of quantum machines than that considered by E. Bernstein and U. Vazirani (1993), thus answering an open question raised by them. We also develop a theory of quantum communication complexity, and use it as a tool to prove that the majority function does not have a linear-size quantum formula.
FOCS	34th Annual Symposium on Foundations of Computer Science, 3-5 November 1993, Palo Alto, California, USA		1993	34th Annual Symposium on Foundations of Computer Science, 3-5 November 1993, Palo Alto, California, USA
SODA	Physical Mapping of Chromosomes: A Combinatorial Problem in Molecular Biology.	Farid Alizadeh,Richard M. Karp,Lee Aaron Newberg,Deborah K. Weisser	1993	Physical Mapping of Chromosomes: A Combinatorial Problem in Molecular Biology.
SODA	Ray Shooting Amidst Convex Polytopes in Three Dimensions.	Pankaj K. Agarwal,Micha Sharir	1993	Ray Shooting Amidst Convex Polytopes in Three Dimensions.
SODA	Improved Dynamic Dictionary Matching.	Amihood Amir,Martin Farach,Ramana M. Idury,Johannes A. La Poutré,Alejandro A. Schäffer	1993	Improved Dynamic Dictionary Matching.
SODA	Approximate Nearest Neighbor Queries in Fixed Dimensions.	Sunil Arya,David M. Mount	1993	Approximate Nearest Neighbor Queries in Fixed Dimensions.
SODA	On-line Choice of On-line Algorithms.	Yossi Azar,Andrei Z. Broder,Mark S. Manasse	1993	On-line Choice of On-line Algorithms.
SODA	Solving Mixed 0-1 Programs by a Lift-and-Project Method.	Egon Balas,Sebastián Ceria,Gérard Cornuéjols	1993	Solving Mixed 0-1 Programs by a Lift-and-Project Method.
SODA	On the Satisfiability and Maximum Satisfiability of Random 3-CNF Formulas.	Andrei Z. Broder,Alan M. Frieze,Eli Upfal	1993	On the Satisfiability and Maximum Satisfiability of Random 3-CNF Formulas.
SODA	Confluently Persistent Deques via Data Structural Bootstrapping.	Adam L. Buchsbaum,Robert Endre Tarjan	1993	Confluently Persistent Deques via Data Structural Bootstrapping.
SODA	Faster Algorithms for Some Geometric Graph Problems in Higher Dimensions.	Paul B. Callahan,S. Rao Kosaraju	1993	Faster Algorithms for Some Geometric Graph Problems in Higher Dimensions.
SODA	On Linear-Time Deterministic Algorithms for Optimization Problems in Fixed Dimensions.	Bernard Chazelle,Jirí Matousek	1993	On Linear-Time Deterministic Algorithms for Optimization Problems in Fixed Dimensions.
SODA	Random Weighted Laplacians, Lovász Minimum Digraphs and Finding Minimum Separators.	Joseph Cheriyan	1993	Random Weighted Laplacians, Lovász Minimum Digraphs and Finding Minimum Separators.
SODA	A Unified Approach to Dynamic Point Location, Ray Shooting, and Shortest Paths in Planar Maps.	Yi-Jen Chiang,Franco P. Preparata,Roberto Tamassia	1993	We describe a new technique for dynamically maintaining the trapezoidal decomposition of a connected planar map $\cal M$ with $n$ vertices and apply it to the development of a unified dynamic data structure that supports point-location, ray-shooting, and shortest-path queries in $\cal M$. The space requirement is $O(n\log n)$. Point-location queries take time $O(\log n)$. Ray-shooting and shortest-path queries take time $O(\log^3 n)$ (plus $O(k)$ time if the $k$ edges of the shortest path are reported in addition to its length). Updates consist of insertions and deletions of vertices and edges, and take $O(\log^3 n)$ time (amortized for vertex updates). This is the first polylog-time dynamic data structure for shortest-path and ray-shooting queries. It is also the first dynamic point-location data structure for connected planar maps that achieves optimal query time.
SODA	Finding Connected Components in O(log n log log n) Time on the EREW PRAM.	Ka Wong Chong,Tak Wah Lam	1993	Finding Connected Components in O(log n log log n) Time on the EREW PRAM.
SODA	Competitive Implementation of Parallel Programs.	Xiaotie Deng,Elias Koutsoupias	1993	Competitive Implementation of Parallel Programs.
SODA	Lower Bounds for Set Intersection Queries.	Paul F. Dietz,Kurt Mehlhorn,Rajeev Raman,Christian Uhrig	1993	Lower Bounds for Set Intersection Queries.
SODA	Iterated Nearest Neighbors and Finding Minimal Polytopes.	David Eppstein,Jeff Erickson	1993	Iterated Nearest Neighbors and Finding Minimal Polytopes.
SODA	An O(n) Algorithm for Circular-Arc Graph Recognition.	Elaine M. Eschen,Jeremy Spinrad	1993	An O(n) Algorithm for Circular-Arc Graph Recognition.
SODA	An Efficient Protocol for Unconditionally Secure Secret Key Exchange.	Michael J. Fischer,Rebecca N. Wright	1993	An Efficient Protocol for Unconditionally Secure Secret Key Exchange.
SODA	A Data Structure for Dynamically Maintaining Rooted Trees.	Greg N. Frederickson	1993	A Data Structure for Dynamically Maintaining Rooted Trees.
SODA	Data Structures for Traveling Salesmen.	Michael L. Fredman,David S. Johnson,Lyle A. McGeoch,G. Ostheimer	1993	Data Structures for Traveling Salesmen.
SODA	Analysis of a Simple Greedy Matching Algorithm on Random Cubic Graphs.	Alan M. Frieze,A. J. Radcliffe,Stephen Suen	1993	Analysis of a Simple Greedy Matching Algorithm on Random Cubic Graphs.
SODA	A Representation for Crossing Set Families with Applications to Submodular Flow Problems.	Harold N. Gabow	1993	A Representation for Crossing Set Families with Applications to Submodular Flow Problems.
SODA	Scapegoat Trees.	Igal Galperin,Ronald L. Rivest	1993	Scapegoat Trees.
SODA	Improved Approximation Algorithms for Biconnected Subgraphs via Better Lower Bounding Techniques.	Naveen Garg,Santosh Vempala,Aman Singla	1993	Improved Approximation Algorithms for Biconnected Subgraphs via Better Lower Bounding Techniques.
SODA	The Suffix of a Square Matrix, with Applications.	Raffaele Giancarlo	1993	The Suffix of a Square Matrix, with Applications.
SODA	Scaling Algorithms for the Shortest Paths Problem.	Andrew V. Goldberg	1993	We describe a new method for designing scaling algorithms for the single-source shortest paths problem and use this method to obtain an $O(\sqrt n m \log N)$ algorithm for the problem. (Here $n$ and $m$ is the number of nodes and arcs in the input network and $N$ is essentially the absolute value of the most negative arc length, and arc lengths are assumed to be integral.) This improves previous bounds for the problem. The method extends to related problems.
SODA	Maxima in Convex Regions.	Mordecai J. Golin	1993	Maxima in Convex Regions.
SODA	Randomized Data Structures for the Dynamic Closest-Pair Problem.	Mordecai J. Golin,Rajeev Raman,Christian Schwarz,Michiel H. M. Smid	1993	We describe a new randomized data structure, the sparse partition, for solving the dynamic closest-pair problem. Using this data structure the closest pair of a set of n points in D-dimensional space, for any fixed D, can be found in constant time. If a frame containing all the points is known in advance, and if the floor function is available at unit cost, then the data structure supports insertions into and deletions from the set in expected O(log n) time and requires expected O(n) space. This method is more efficient than any deterministic algorithm for solving the problem in dimension D > 1. The data structure can be modified to run in O(log2 n) expected time per update in the algebraic computation tree model. Even this version is more efficient than the best currently known deterministic algorithm for D > 2. Both results assume that the sequence of updates is not determined in any way by the random choices made by the algorithm.
SODA	Fast Deterministic Processor Allocation.	Torben Hagerup	1993	Fast Deterministic Processor Allocation.
SODA	Efficient Automatic Part Nesting on Irregular and Inhomogeneous Surfaces.	Jörg Heistermann,Thomas Lengauer	1993	Efficient Automatic Part Nesting on Irregular and Inhomogeneous Surfaces.
SODA	A Pedestrian Approach to Ray Shooting: Shoot a Ray, Take a Walk.	John Hershberger,Subhash Suri	1993	A Pedestrian Approach to Ray Shooting: Shoot a Ray, Take a Walk.
SODA	Polygonal Approximations that Minimize the Number of Inflections.	John D. Hobby	1993	Polygonal Approximations that Minimize the Number of Inflections.
SODA	Polynomial Algorithms for Minimum Cost Paths in Periodic Graphs.	Franz Höfting,Egon Wanke	1993	Polynomial Algorithms for Minimum Cost Paths in Periodic Graphs.
SODA	Searching in an Unknown Environment: An Optimal Randomized Algorithm for the Cow-Path Problem.	Ming-Yang Kao,John H. Reif,Stephen R. Tate	1993	Searching in an Unknown Environment: An Optimal Randomized Algorithm for the Cow-Path Problem.
SODA	Global Min-cuts in RNC, and Other Ramifications of a Simple Min-Cut Algorithm.	David R. Karger	1993	Global Min-cuts in RNC, and Other Ramifications of a Simple Min-Cut Algorithm.
SODA	Balancing Minimum Spanning and Shortest Path Trees.	Samir Khuller,Balaji Raghavachari,Neal E. Young	1993	Balancing Minimum Spanning and Shortest Path Trees.
SODA	Upper and Lower Bounds on Constructing Alphabetic Binary Trees.	Maria M. Klawe,Brendan Mumey	1993	This paper studies the long-standing open question of whether optimal alphabetic binary trees can be constructed in $o(n \lg n)$ time. We show that a class of techniques for finding optimal alphabetic trees which includes all current methods yielding $O(n \lg n)$-time algorithms are at least as hard as sorting in whatever model of computation is used. We also give $O(n)$-time algorithms for the case where all the input weights are within a constant factor of one another and when they are exponentially separated.
SODA	The Stanford GraphBase: A Platform for Combinatorial Algorithms.	Donald E. Knuth	1993	The Stanford GraphBase: A Platform for Combinatorial Algorithms.
SODA	Finding Near-Optimal Cuts: An Empirical Evaluation.	Kevin Lang,Satish Rao	1993	Finding Near-Optimal Cuts: An Empirical Evaluation.
SODA	Non-Clairvoyant Scheduling.	Rajeev Motwani,Steven J. Phillips,Eric Torng	1993	Non-Clairvoyant Scheduling.
SODA	Dynamic Generation of Discrete Random Variates.	Yossi Matias,Jeffrey Scott Vitter,Wen-Chun Ni	1993	Dynamic Generation of Discrete Random Variates.
SODA	Efficient Randomized Algorithms for the Repeated Median Line Estimator.	Jirí Matousek,David M. Mount,Nathan S. Netanyahu	1993	Efficient Randomized Algorithms for the Repeated Median Line Estimator.
SODA	A Linear Time 2+epsilon Approximation Algorithm for Edge Connectivity.	David W. Matula	1993	A Linear Time 2+epsilon Approximation Algorithm for Edge Connectivity.
SODA	Optimistic Sorting and Information Theoretic Complexity.	Peter M. McIlroy	1993	Optimistic Sorting and Information Theoretic Complexity.
SODA	Triangulating Vertex Colored Graphs.	Fred R. McMorris,Tandy Warnow,Thomas Wimer	1993	This paper examines the class of vertex-colored graphs that can be triangulated without the introduction of edges between vertices of the same color. This is related to a fundamental and long-standing problem for numerical taxonomists, called the Perfect Phylogeny Problem. These problems are known to be polynomially equivalent and NP-complete. This paper presents a dynamic programming algorithm that can be used to determine whether a given vertex-colored graph can be so triangulated and that runs in $O((n+m(k-2))^{k+1})$ time, where the graph has $n$ vertices, $m$ edges, and $k$ colors. The corresponding algorithm for the Perfect Phylogeny Problem runs in $O(r^{k+1} k^{k+1} + sk^2 )$ time, where $s$ species are defined by $k$ $r$-state characters.
SODA	The Vertex-Disjoint Menger Problem in Planar Graphs.	Heike Ripphausen-Lipa,Dorothea Wagner,Karsten Weihe	1993	We consider the problem of finding a maximum collection of vertex-disjoint paths in undirected, planar graphs from a vertex $s$ to a vertex $t$. This problem is usually solved using flow techniques, which lead to ${\cal O}(nk)$ and ${\cal O}(n\sqrt{n})$ running times, respectively, where $n$ is the number of vertices and $k$ the maximum number of vertex-disjoint $(s,t)$-paths. The best previously known algorithm is based on a divide-and-conquer approach and has running time ${\cal O}(n\log n)$. The approach presented here is completely different from these methods and yields a linear-time algorithm.
SODA	A New and Simple Algorithm for Quality 2-Dimensional Mesh Generation.	Jim Ruppert	1993	"We present a simple new algorithm for triangulating polygons and planar straightline graphs. It provides ""shape"" and ""size"" guarantees: -All triangles have a bounded aspect ratio. - The number of ""Steiner points"" added is within a constant factor of optimal. Such ""quality"" triangulations are desirable as meshes for the finite element method, in which the running time generally increases with the number of triangles, and where the convergence and stability may be hurt by very skinny triangles. The technique we use--successive refinement of the Delaunay triangulation--extends a mesh generation technique of Chew by allowing triangles that vary in size. Previous algorithms with shape and size bounds have all been based on quadtrees. The Delaunay refinement algorithm matches their bounds, but uses a fundamentally different approach. It is much simpler, and hence easier to implement, and it generally produces smaller meshes in practice."
SODA	Chernoff-Hoeffding Bounds for Applications with Limited Independence.	Jeanette P. Schmidt,Alan Siegel,Aravind Srinivasan	1993	"Chernoff-Hoeffding (CH) bounds are fundamental tools used in bounding the tail probabilities of the sums of bounded and independent random variables (r.v.'s). We present a simple technique that gives slightly better bounds than these and that more importantly requires only limited independence among the random variables, thereby importing a variety of standard results to the case of limited independence for free. Additional methods are also presented, and the aggregate results are sharp and provide a better understanding of the proof techniques behind these bounds. These results also yield improved bounds for various tail probability distributions and enable improved approximation algorithms for jobshop scheduling. The limited independence result implies that a reduced amount and weaker sources of randomness are sufficient for randomized algorithms whose analyses use the CH bounds, e.g., the analysis of randomized algorithms for random sampling and oblivious packet routing."
SODA	Scheduling Unrelated Machines with Costs.	David B. Shmoys,Éva Tardos	1993	Scheduling Unrelated Machines with Costs.
SODA	On Traversing Layered Graphs On-line.	H. Ramesh	1993	On Traversing Layered Graphs On-line.
SODA	Fast Construction of Irreducible Polynomials over Finite Fields.	Victor Shoup	1993	Fast Construction of Irreducible Polynomials over Finite Fields.
SODA	Equidistribution of Point Sets for the Traveling Salesman and Related Problems.	Timothy Law Snyder,J. Michael Steele	1993	Equidistribution of Point Sets for the Traveling Salesman and Related Problems.
SODA	Optimal Edge Ranking of Trees in Polynomial Time.	Pilar de la Torre,Raymond Greenlaw,Alejandro A. Schäffer	1993	Optimal Edge Ranking of Trees in Polynomial Time.
SODA	Tree Compatibility and Inferring Evoluationary History.	Tandy Warnow	1993	Tree Compatibility and Inferring Evoluationary History.
SODA	Data Structures and Algorithms for Nearest Neighbor Search in General Metric Spaces.	Peter N. Yianilos	1993	Data Structures and Algorithms for Nearest Neighbor Search in General Metric Spaces.
SODA	Proceedings of the Fourth Annual ACM/SIGACT-SIAM Symposium on Discrete Algorithms, 25-27 January 1993, Austin, Texas.	Vijaya Ramachandran	1993	Proceedings of the Fourth Annual ACM/SIGACT-SIAM Symposium on Discrete Algorithms, 25-27 January 1993, Austin, Texas.
STOC	Depth reduction for noncommutative arithmetic circuits.	Eric Allender,Jia Jiao	1993	Depth reduction for noncommutative arithmetic circuits.
STOC	Routing permutations on graphs via matchings.	Noga Alon,Fan R. K. Chung,Ronald L. Graham	1993	"A class of routing problems on connected graphs $G$ is considered. Initially, each vertex $v$ of $G$ is occupied by a ``pebble'' that has a unique destination $\pi (v)$ in $G$ (so that $\pi$ is a permutation of the vertices of $G$). It is required that all the pebbles be routed to their respective destinations by performing a sequence of moves of the following type: A disjoint set of edges is selected, and the pebbles at each edge's endpoints are interchanged. The problem of interest is to minimize the number of steps required for any possible permutation $\pi$. This paper investigates this routing problem for a variety of graphs $G$, including trees, complete graphs, hypercubes, Cartesian products of graphs, expander graphs, and Cayley graphs. In addition, this routing problem is related to certain network flow problems, and to several graph invariants including diameter, eigenvalues, and expansion coefficients."
STOC	Parametric real-time reasoning.	Rajeev Alur,Thomas A. Henzinger,Moshe Y. Vardi	1993	Parametric real-time reasoning.
STOC	Approximate load balancing on dynamic and asynchronous networks.	William Aiello,Baruch Awerbuch,Bruce M. Maggs,Satish Rao	1993	Approximate load balancing on dynamic and asynchronous networks.
STOC	Checking approximate computations over the reals.	Sigal Ar,Manuel Blum,Bruno Codenotti,Peter Gemmell	1993	Checking approximate computations over the reals.
STOC	On-line load balancing with applications to machine scheduling and virtual circuit routing.	James Aspnes,Yossi Azar,Amos Fiat,Serge A. Plotkin,Orli Waarts	1993	On-line load balancing with applications to machine scheduling and virtual circuit routing.
STOC	Competitive distributed file allocation.	Baruch Awerbuch,Yair Bartal,Amos Fiat	1993	This paper deals with the file allocation problem [6] concerning the dynamic optimization of communication costs to access data in a distributed environment. We develop a dynamic file re-allocation strategy that adapts on-line to a sequence of read and write requests whose location and relative frequencies are completely unpredictable. This is achieved by replicating the file in response to read requests and migrating the file in response to write requests while paying the associated communications costs, so as to be closer to processors that access it frequently. We develop first explicit deterministic on-line strategy assuming existence of global information about the state of the network; previous (deterministic) solutions were complicated and more expensive. Our solution has (optimal) logarithmic competitive ratio. The paper also contains the first explicit deterministic data migration [7] algorithm achieving the best known competitive ratio for this problem. Using somewhat different technique, we also develop the first deterministic distributed file allocation algorithm (using only local information) with poly-logarithmic competitive ratio against a globally optimized optimal prescient strategy.
STOC	Time optimal self-stabilizing synchronization.	Baruch Awerbuch,Shay Kutten,Yishay Mansour,Boaz Patt-Shamir,George Varghese	1993	Time optimal self-stabilizing synchronization.
STOC	A theory of parameterized pattern matching: algorithms and applications.	Brenda S. Baker	1993	A theory of parameterized pattern matching: algorithms and applications.
STOC	Short random walks on graphs.	Greg Barnes,Uriel Feige	1993	The short-term behavior of random walks on graphs is studied, in particular, the rate at which a random walk discovers new vertices and edges. A conjecture by Linial that the expected time to find $\cal N$ distinct vertices is $O({\cal N}^{3})$ is proved. In addition, upper bounds of $O({\cal M}^{2})$ on the expected time to traverse $\cal M$ edges and of $O(\cal M \cal N)$ on the expected time to either visit $\cal N$ vertices or traverse $\cal M$ edges (whichever comes first) are proved.
STOC	Proportionate progress: a notion of fairness in resource allocation.	Sanjoy K. Baruah,N. K. Cohen,C. Greg Plaxton,Donald A. Varvel	1993	Proportionate progress: a notion of fairness in resource allocation.
STOC	Angles of planar triangular graphs.	Giuseppe Di Battista,Luca Vismara	1993	We give a characterization of all the planar drawings of a triangular graph through a system of equations and inequalities relating its angles; we also discuss minimality properties of the characterization. The characterization can be used: (1) to decide in linear time whether a given distribution of angles between the edges of a planar triangular graph can result in a planar drawing; (2) to reduce the problem of maximizing the minimum angle in a planar straight-line drawing of a planar triangular graph to a nonlinear optimization problem purely on a space of angles; (3) to give a characterization of the planar drawings of a triconnected graph through a system of equations and inequalities relating its angles; (4) to give a characterization of Delaunay triangulations through a system of equations and inequalities relating its angles; (5) to give a characterization of all the planar drawings of a triangular graph through a system of equations and inequalities relating the lengths of its edges; in turn, this result allows us to give a new characterization of the disc-packing representations of planar triangular graphs.
STOC	Efficient probabilistically checkable proofs and applications to approximations.	Mihir Bellare,Shafi Goldwasser,Carsten Lund,A. Russeli	1993	Efficient probabilistically checkable proofs and applications to approximations.
STOC	Asynchronous secure computation.	Michael Ben-Or,Ran Canetti,Oded Goldreich	1993	Asynchronous secure computation.
STOC	Space-efficient scheduling of multithreaded computations.	Robert D. Blumofe,Charles E. Leiserson	1993	"This paper considers the problem of scheduling dynamic parallel computations to achieve linear speedup without using significantly more space per processor than that required for a single-processor execution. Utilizing a new graph-theoretic model of multithreaded computation, execution efficiency is quantified by three important measures: T1 is the time required for executing the computation on a 1 processor, $T_\infty$ is the time required by an infinite number of processors, and S1 is the space required to execute the computation on a 1 processor. A computation executed on P processors is time-efficient if the time is $O(T_1/P + T_\infty)$, that is, it achieves linear speedup when $P=O(T_1/T_\infty)$, and it is space-efficient if it uses O(S1P) total space, that is, the space per processor is within a constant factor of that required for a 1-processor execution.The first result derived from this model shows that there exist multithreaded computations such that no execution schedule can simultaneously achieve efficient time and efficient space. But by restricting attention to ""strict"" computations---those in which all arguments to a procedure must be available before the procedure can be invoked---much more positive results are obtainable. Specifically, for any strict multithreaded computation, a simple online algorithm can compute a schedule that is both time-efficient and space-efficient. Unfortunately, because the algorithm uses a global queue, the overhead of computing the schedule can be substantial. This problem is overcome by a decentralized algorithm that can compute and execute a P-processor schedule online in expected time $O(T_1/P + T_\infty\lg P)$ and worst-case space $O(S_1P\lg P)$, including overhead costs."
STOC	Thermodynamics of computation and information distance.	Charles H. Bennett,Péter Gács,Ming Li,Paul M. B. Vitányi,Wojciech H. Zurek	1993	Thermodynamics of computation and information distance.
STOC	A linear time algorithm for finding tree-decompositions of small treewidth.	Hans L. Bodlaender	1993	In this paper, we give for constant $k$ a linear-time algorithm that, given a graph $G=(V,E)$, determines whether the treewidth of $G$ is at most $k$ and, if so, finds a tree-decomposition of $G$ with treewidth at most $k$. A consequence is that every minor-closed class of graphs that does not contain all planar graphs has a linear-time recognition algorithm. Another consequence is that a similar result holds when we look instead for path-decompositions with pathwidth at most some constant $k$.
STOC	Piecewise linear paths among convex obstacles.	Mark de Berg,Jirí Matousek,Otfried Schwarzkopf	1993	Piecewise linear paths among convex obstacles.
STOC	On-line algorithms for cache sharing.	Marshall W. Bern,Daniel H. Greene,Arvind Raghunathan	1993	On-line algorithms for cache sharing.
STOC	Quantum complexity theory.	Ethan Bernstein,Umesh V. Vazirani	1993	"In this paper we study quantum computation from a complexity theoretic viewpoint. Our first result is the existence of an efficient universal quantum Turing machine in Deutsch's model of a quantum Turing machine (QTM) [Proc. Roy. Soc. London Ser. A, 400 (1985), pp. 97--117]. This construction is substantially more complicated than the corresponding construction for classical Turing machines (TMs); in fact, even simple primitives such as looping, branching, and composition are not straightforward in the context of quantum Turing machines. We establish how these familiar primitives can be implemented and introduce some new, purely quantum mechanical primitives, such as changing the computational basis and carrying out an arbitrary unitary transformation of polynomially bounded dimension.We also consider the precision to which the transition amplitudes of a quantum Turing machine need to be specified. We prove that $O(\log T)$ bits of precision suffice to support a $T$ step computation. This justifies the claim that the quantum Turing machine model should be regarded as a discrete model of computation and not an analog one. We give the first formal evidence that quantum Turing machines violate the modern (complexity theoretic) formulation of the Church--Turing thesis. We show the existence of a problem, relative to an oracle, that can be solved in polynomial time on a quantum Turing machine, but requires superpolynomial time on a bounded-error probabilistic Turing machine, and thus not in the class $\BPP$. The class $\BQP$ of languages that are efficiently decidable (with small error-probability) on a quantum Turing machine satisfies $\BPP \subseteq \BQP \subseteq \Ptime^{\SP}$. Therefore, there is no possibility of giving a mathematical proof that quantum Turing machines are more powerful than classical probabilistic Turing machines (in the unrelativized setting) unless there is a major breakthrough in complexity theory."
STOC	The biased coin problem.	Ravi B. Boppana,Babu O. Narayanan	1993	The biased coin problem.
STOC	Comparison-based search in the presence of errors.	Ryan S. Borgstrom,S. Rao Kosaraju	1993	Comparison-based search in the presence of errors.
STOC	How much can hardware help routing?	Allan Borodin,Prabhakar Raghavan,Baruch Schieber,Eli Upfal	1993	We study the extent to which complex hardware can speed up routing. Specifically, we consider the following questions. How much does adaptive routing improve over oblivious routing? How much does randomness help? How does it help if each node can have a large number of neighbors? What benefit is available if a node can send packets to several neighbors within a single time step? Some of these features require complex networking hardware, and thus it is important to investigate whether the performance justifies the investment. By varying these hardware parameters, we obtain a hierarchy of time bounds for worst-case permutation routing. We develop a nearly complete taxonomy of the complexity of routing.
STOC	Generalized FLP impossibility result for t-resilient asynchronous computations.	Elizabeth Borowsky,Eli Gafni	1993	Generalized FLP impossibility result for t-resilient asynchronous computations.
STOC	Fast asynchronous Byzantine agreement with optimal resilience.	Ran Canetti,Tal Rabin	1993	Fast asynchronous Byzantine agreement with optimal resilience.
STOC	How to use expert advice.	Nicolò Cesa-Bianchi,Yoav Freund,David P. Helmbold,David Haussler,Robert E. Schapire,Manfred K. Warmuth	1993	"We analyze algorithms that predict a binary value by combining the predictions of several prediction strategies, called `experts''. Our analysis is for worst-case situations, i.e., we make no assumptions about the way the sequence of bits to be predicted is generated. We measure the performance of the algorithm by the difference between the expected number of mistakes it makes on the bit sequence and the expected number of mistakes made by the best expert on this sequence, where the expectation is taken with respect to the randomization in the predictions. We show that the minimum achievable difference is on the order of the square root of the number of mistakes of the best expert, and we give efficient algorithms that achieve this. Our upper and lower bounds have matching leading constants in most cases. We then show how this leads to certain kinds of pattern recognition/learning algorithms with performance bounds that improve on the best results currently known in this context. We also extend our analysis to the case in which log loss is used instead of the expected number of mistakes."
STOC	Randomness-optimal unique element isolation, with applications to perfect matching and related problems.	Suresh Chari,Pankaj Rohatgi,Aravind Srinivasan	1993	Randomness-optimal unique element isolation, with applications to perfect matching and related problems.
STOC	Improved bounds on weak epsilon-nets for convex sets.	Bernard Chazelle,Herbert Edelsbrunner,Michelangelo Grigni,Leonidas J. Guibas,Micha Sharir,Emo Welzl	1993	Improved bounds on weak epsilon-nets for convex sets.
STOC	Some complexity issues on the simply connected regions of the two-dimensional plane.	Arthur W. Chou,Ker-I Ko	1993	Some complexity issues on the simply connected regions of the two-dimensional plane.
STOC	Markov chains, computer proofs, and average-case analysis of best fit bin packing.	Edward G. Coffman Jr.,David S. Johnson,Peter W. Shor,Richard R. Weber	1993	Markov chains, computer proofs, and average-case analysis of best fit bin packing.
STOC	Reinventing the wheel: an optimal data structure for connectivity queries.	Robert F. Cohen,Giuseppe Di Battista,Arkady Kanevsky,Roberto Tamassia	1993	Reinventing the wheel: an optimal data structure for connectivity queries.
STOC	Multi-scale self-simulation: a technique for reconfiguring arrays with faults.	Richard Cole,Bruce M. Maggs,Ramesh K. Sitaraman	1993	Multi-scale self-simulation: a technique for reconfiguring arrays with faults.
STOC	Probabilistically checkable debate systems and approximation algorithms for PSPACE-hard functions.	Anne Condon,Joan Feigenbaum,Carsten Lund,Peter W. Shor	1993	Probabilistically checkable debate systems and approximation algorithms for PSPACE-hard functions.
STOC	Fast perfection-information leader-election protocol with linear immunity.	Jason Cooper,Nathan Linial	1993	Fast perfection-information leader-election protocol with linear immunity.
STOC	Contention in shared memory algorithms.	Cynthia Dwork,Maurice Herlihy,Orli Waarts	1993	Most complexity measures for concurrent algorithms for asynchronous shared-memory architectures focus on process steps and memory consumption. In practice, however, performance of multiprocessor algorithms is heavily influenced by contention, the extent to which processess access the same location at the same time. Nevertheless, even though contention is one of the principal considerations affecting the performance of real algorithms on real multiprocessors, there are no formal tools for analyzing the contention of asynchronous shared-memory algorithms.This paper introduces the first formal complexity model for contention in shared-memory multiprocessors. We focus on the standard multiprocessor architecture in which n asynchronous processes communicate by applying read, write, and read-modify-write operations to a shared memory. To illustrate the utility of our model, we use it to derive two kinds of results: (1) lower bounds on contention for well-known basic problems such as agreement and mutual exclusion, and (2) trade-offs between the length of the critical path (maximal number of accesses to shared variables performed by a single process in executing the algorithm) and contention for these algorithms. Furthermore, we give the first formal contention analysis of a variety of counting networks, a class of concurrent data structures inplementing shared counters. Experiments indicate that certain counting networks outperform conventional single-variable counters at high levels of contention. Our analysis provides the first formal model explaining this phenomenon.
STOC	Time-space trade-offs for undirected st-connectivity on a JAG.	Jeff Edmonds	1993	Time-space trade-offs for undirected st-connectivity on a JAG.
STOC	Separator based sparsification for dynamic planar graph algorithms.	David Eppstein,Zvi Galil,Giuseppe F. Italiano,Thomas H. Spencer	1993	Separator based sparsification for dynamic planar graph algorithms.
STOC	A robust model for finding optimal evolutionary trees.	Martin Farach,Sampath Kannan,Tandy Warnow	1993	A robust model for finding optimal evolutionary trees.
STOC	Monotone monadic SNP and constraint satisfaction.	Tomás Feder,Moshe Y. Vardi	1993	Monotone monadic SNP and constraint satisfaction.
STOC	Optimal online scheduling of parallel jobs with dependencies.	Anja Feldmann,Ming-Yang Kao,Jiri Sgall,Shang-Hua Teng	1993	We study the following general online scheduling problem. Parallel jobs arrive dynamically according to the dependencies between them. Each job requests a certain number of processors with a specific communication configuration, but its running time is not known until it is completed. We present optimal online algorithms for PRAMs, hypercubes and one-dimensional meshes, and obtain optimal tradeoffs between the competitive ratio and the largest number of processors requested by any job. Our work shows that for efficient online scheduling it is necessary to use virtualization, i.e., to schedule parallel jobs on fewer processors than requested while preserving the work. Assume that the largest number of processors requested by a job is lambda(N), where 0 > lambda > 1 and N is the number of processors of - a machine. With virtualization, our algorithm for PRAMs has a competitive __________ ratio of 2 + /4lamba + 1 - 1 . Our lower bound shows that this ratio _______________ 2lambda is optimal. As lambda goes from 0 to 1, the ratio changes from 2 to 2 + Phi, where Phi ~ 0.168 is the golden ratio. For hypercubes and ~ one-dimensional meshes we present Theta (log N ) -competitive algorithms ______ (log log N) as well as matching lower bounds. Without virtualization, no online scheduling algorithm can achieve a competitive ratio smaller than N for lambda = 1. For lambda > 1, the lower bound is 1 + 1 and our _____ 1 - y algorithm for PRAMs achieves this competitive ratio. We prove that tree constraints are complete for the scheduling problem, i.e., any algorithm that solves the scheduling problem if the dependency graph is a tree can be converted to solve the general problem equally efficiently. This shows that the structure of a dependency graph is not as important for online scheduling as it is for offline scheduling, although even simple dependencies make the problem much harder than scheduling independent jobs.
STOC	Maximum k-chains in planar point sets: combinatorial structure and algorithms.	Stefan Felsner,Lorenz Wernisch	1993	A chain of a set P of n points in the plane is a chain of the dominance order on P. A k-chain is a subset C of P that can be covered by k chains. A k-chain C is a maximum k-chain if no other k-chain contains more elements than C. This paper deals with the problem of finding a maximum k-chain of P in the cardinality and in the weighted case.Using the skeleton S(P) of a point set P introduced by Viennot we describe a fairly simple algorithm that computes maximum k-chains in time O(kn log n) and linear space. The basic idea is that the canonical chain partition of a maximum (k-1)-chain in the skeleton S(P) provides k regions in the plane such that a maximum k-chain for P can be obtained as the union of a maximal chain from each of these regions.By the symmetry between chains and antichains in the dominance order we may use the algorithm for maximum k-chains to compute maximum k-antichains for planar points in time O(kn log n). However, for large k one can do better. We describe an algorithm computing maximum k-antichains (and, by symmetry, k-chains) in time O((n2 k) log n) and linear space. Consequently, a maximum k-chain can be computed in time O(n3/2 log n) for arbitrary k.The background for the algorithms is a geometric approach to the Greene--Kleitman theory for permutations. We include a skeleton-based exposition of this theory and give some hints on connections with the theory of Young tableaux.The concept of the skeleton of a planar point set is extended to the case of a weighted point set. This extension allows to compute maximum weighted k-chains with an algorithm that is similar to the algorithm for the cardinality case. The time and space requirements of the algorithm for weighted k-chains are O(2kn log(2kn)) and O(2kn), respectively.
STOC	Decision trees: old and new results.	Rudolf Fleischer	1993	Decision trees: old and new results.
STOC	Efficient learning of typical finite automata from random walks.	Yoav Freund,Michael J. Kearns,Dana Ron,Ronitt Rubinfeld,Robert E. Schapire,Linda Sellie	1993	Efficient learning of typical finite automata from random walks.
STOC	Fully polynomial Byzantine agreement in t+1 rounds.	Juan A. Garay,Yoram Moses	1993	Fully polynomial Byzantine agreement in t+1 rounds.
STOC	Approximate max-flow min-(multi)cut theorems and their applications.	Naveen Garg,Vijay V. Vazirani,Mihalis Yannakakis	1993	Consider the multicommodity flow problem in which the object is to maximize the sum of commodities routed. We prove the following approximate max-flow min-multicut theorem: $$ \dst \frac{\mbox{\rm min multicut}}{O(\log k)} \leq \mbox{ \rm max flow } \leq \mbox{ \rm min multicut}, $$ \noindent where $k$ is the number of commodities. Our proof is constructive; it enables us to find a multicut within $O(\log k)$ of the max flow (and hence also the optimal multicut). In addition, the proof technique provides a unified framework in which one can also analyse the case of flows with specified demands of Leighton and Rao and Klein et al. and thereby obtain an improved bound for the latter problem.
STOC	Counting curves and their projections.	Joachim von zur Gathen,Marek Karpinski,Igor Shparlinski	1993	Counting curves and their projections.
STOC	Polynomial space polynomial delay algorithms for listing families of graphs.	Leslie Ann Goldberg	1993	Polynomial space polynomial delay algorithms for listing families of graphs.
STOC	Simulating threshold circuits by majority circuits.	Mikael Goldmann,Marek Karpinski	1993	We prove that a single threshold gate with arbitrary weights can be simulated by an explicit polynomial-size, depth-2 majority circuit. In general we show that a polynomial-size, depth-d threshold circuit can be simulated uniformly by a polynomial-size majority circuit of depth d + 1. Goldmann, Håstad, and Razborov showed in [Comput. Complexity, 2 (1992), pp. 277--300] that a nonuniform simulation exists. Our construction answers two open questions posed by them: we give an explicit construction, whereas they use a randomized existence argument, and we show that such a simulation is possible even if the depth d grows with the number of variables n (their simulation gives polynomial-size circuits only when d is constant).
STOC	The asynchronous computability theorem for t-resilient tasks.	Maurice Herlihy,Nir Shavit	1993	The asynchronous computability theorem for t-resilient tasks.
STOC	Matrix searching with the shortest path metric.	John Hershberger,Subhash Suri	1993	We present an O(n) time algorithm for computing row-wise maxima or minima of an implicit, totally monotone $n \times n$ matrix whose entries represent shortest-path distances between pairs of vertices in a simple polygon. We apply this result to derive improved algorithms for several well-known problems in computational geometry. Most prominently, we obtain linear-time algorithms for computing the geodesic diameter, all farthest neighbors, and external farthest neighbors of a simple polygon, improving the previous best result by a factor of O(log n) in each case.
STOC	Multiple matching of rectangular patterns.	Ramana M. Idury,Alejandro A. Schäffer	1993	Multiple matching of rectangular patterns.
STOC	Size-depth trade-offs for threshold circuits.	Russell Impagliazzo,Ramamohan Paturi,Michael E. Saks	1993	Size-depth trade-offs for threshold circuits.
STOC	k one-way heads cannot do string-matching.	Tao Jiang,Ming Li	1993	k one-way heads cannot do string-matching.
STOC	Constant time factors do matter.	Neil D. Jones	1993	Constant time factors do matter.
STOC	Characterizing non-deterministic circuit size.	Mauricio Karchmer,Avi Wigderson	1993	Characterizing non-deterministic circuit size.
STOC	An O~(n) algorithm for minimum cuts.	David R. Karger,Clifford Stein	1993	An O~(n) algorithm for minimum cuts.
STOC	Mapping the genome: some combinatorial problems arising in molecular biology.	Richard M. Karp	1993	Mapping the genome: some combinatorial problems arising in molecular biology.
STOC	Efficient noise-tolerant learning from statistical queries.	Michael J. Kearns	1993	"In this paper, we study the problem of learning in the presence of classification noise in the probabilistic learning model of Valiant and its variants. In order to identify the class of &ldquo;robust&rdquo; learning algorithms in the most general way, we formalize a new but related model of learning from statistical queries. Intuitively, in this model a learning algorithm is forbidden to examine individual examples of the unknown target function, but is given acess to an oracle providing estimates of probabilities over the sample space of random examples.One of our main results shows that any class of functions learnable from statistical queries is in fact learnable with classification noise in Valiant's model, with a noise rate approaching the information-theoretic barrier of 1/2. We then demonstrate the generality of the statistical query model, showing that practically every class learnable in Valiant's model and its variants can also be learned in the new model (and thus can be learned in the presence of noise). A notable exception to this statement is the class of parity functions, which we prove is not learnable from statistical queries, and for which no noise-tolerant algorithm is known."
STOC	Matchings in lattice graphs.	Claire Kenyon,Dana Randall,Alistair Sinclair	1993	Matchings in lattice graphs.
STOC	Cryptographic hardness of distribution-specific learning.	Michael Kharitonov	1993	Cryptographic hardness of distribution-specific learning.
STOC	Excluded minors, network decomposition, and multicommodity flow.	Philip N. Klein,Serge A. Plotkin,Satish Rao	1993	Excluded minors, network decomposition, and multicommodity flow.
STOC	Constructing small sample spaces satisfying given constraints.	Daphne Koller,Nimrod Megiddo	1993	"The subject of this paper is finding small sample spaces for joint distributions of n discrete random variables. Such distributions are often only required to obey a certain limited set of constraints of the form Pr (Event) = $\pi$. It is shown that the problem of deciding whether there exists any distribution satisfying a given set of constraints is NP-hard. However, if the constraints are consistent, then there exists a distribution satisfying them, which is supported by a ""small"" sample space (one whose cardinality is equal to the number of constraints). For the important case of independence constraints, where the constraints have a certain form and are consistent with a joint distribution of independent random variables, a small sample space can be constructed in polynomial time. This last result can be used to derandomize algorithms; this is demonstrated by an application to the problem of finding large independent sets in sparse hypergraphs."
STOC	Lower bounds for randomized mutual exclusion.	Eyal Kushilevitz,Yishay Mansour,Michael O. Rabin,David Zuckerman	1993	We establish, for the first time, lower bounds for randomized mutual exclusion algorithms (with a read-modify-write operation). Our main result is that a constant-size shared variable cannot guarantee strong fairness, even if randomization is allowed. In fact, we prove a lower bound of $\Omega (\log\log n)$ bits on the size of the shared variable, which is also tight.We investigate weaker fairness conditions and derive tight (upper and lower) bounds for them as well. Surprisingly, it turns out that slightly weakening the fairness condition results in an exponential reduction in the size of the required shared variable. Our lower bounds rely on an analysis of Markov chains that may be of interest on its own and may have applications elsewhere.
STOC	Efficient construction of a small hitting set for combinatorial rectangles in high dimension.	Nathan Linial,Michael Luby,Michael E. Saks,David Zuckerman	1993	Efficient construction of a small hitting set for combinatorial rectangles in high dimension.
STOC	A parallel approximation algorithm for positive linear programming.	Michael Luby,Noam Nisan	1993	A parallel approximation algorithm for positive linear programming.
STOC	On the hardness of approximating minimization problems.	Carsten Lund,Mihalis Yannakakis	1993	On the hardness of approximating minimization problems.
STOC	Bounds for the computational power and learning complexity of analog neural nets.	Wolfgang Maass	1993	"It is shown that high-order feedforward neural nets of constant depth with piecewise-polynomial activation functions and arbitrary real weights can be simulated for Boolean inputs and outputs by neural nets of a somewhat larger size and depth with Heaviside gates and weights from {-1, 0, 1}. This provides the first known upper bound for the computational power of the former type of neural nets. It is also shown that in the case of first-order nets with piecewise-linear activation functions one can replace arbitrary real weights by rational numbers with polynomially many bits without changing the Boolean function that is computed by the neural net. In order to prove these results, we introduce two new methods for reducing nonlinear problems about weights in multilayer neural nets to linear problems for a transformed set of parameters. These transformed parameters can be interpreted as weights in a somewhat larger neural net.As another application of our new proof technique we show that neural nets with piecewise-polynomial activation functions and a constant number of analog inputs are probably approximately correct (PAC) learnable (in Valiant's model for PAC learning [Comm. Assoc. Comput. Mach., 27 (1984), pp. 1134--1142])."
STOC	"Finiteness results for sigmoidal ""neural"" networks."	Angus Macintyre,Eduardo D. Sontag	1993	"Finiteness results for sigmoidal ""neural"" networks."
STOC	A deterministic algorithm for the three-dimensional diameter problem.	Jirí Matousek,Otfried Schwarzkopf	1993	A deterministic algorithm for the three-dimensional diameter problem.
STOC	What can be computed locally?	Moni Naor,Larry J. Stockmeyer	1993	"The purpose of this paper is a study of computation that can be done locally in a distributed network, where ""locally"" means within time (or distance) independent of the size of the network. Locally checkable labeling (LCL) problems are considered, where the legality of a labeling can be checked locally (e.g., coloring). The results include the following: There are nontrivial LCL problems that have local algorithms. There is a variant of the dining philosophers problem that can be solved locally. Randomization cannot make an LCL problem local; i.e., if a problem has a local randomized algorithm then it has a local deterministic algorithm. It is undecidable, in general, whether a given LCL has a local algorithm. However, it is decidable whether a given LCL has an algorithm that operates in a given time $t$. Any LCL problem that has a local algorithm has one that is order-invariant (the algorithm depends only on the order of the processor IDs)."
STOC	More deterministic simulation in logspace.	Noam Nisan,David Zuckerman	1993	More deterministic simulation in logspace.
STOC	Linear programming without the matrix.	Christos H. Papadimitriou,Mihalis Yannakakis	1993	Linear programming without the matrix.
STOC	Finding minimum-quotient cuts in planar graphs.	James K. Park,Cynthia A. Phillips	1993	Finding minimum-quotient cuts in planar graphs.
STOC	The network inhibition problem.	Cynthia A. Phillips	1993	The network inhibition problem.
STOC	Online load balancing and network flow.	Steven Phillips,Jeffery Westbrook	1993	Online load balancing and network flow.
STOC	Self-routing superconcentrators.	Nicholas Pippenger	1993	"Superconcentrators are switching systems that solve the generic problem of interconnecting clients and servers during sessions, in situations where either the clients or the servers are interchangable (so that it does not matter which client is connected to which server). Previous constructions of superconcentrators have required an external agent to find the interconnections appropriate in each instance. We remedy this shortcoming by constructing superconcentrators that are ``self-routing'''', in the sense that they compute for themselves the required interconnections. Specifically, we show how to construct, for each n, a system S_n with the following properties. (1) The system S_n has n inputs, n outputs, and O(n) components, each of which is of one of a fixed finite number of finite automata, and is connected to a fixed finite number of other components through cables, each of which carries signals from a fixed finite alphabet. (2) When some of the inputs, and an equal number of outputs, are ``marked'''' (by the presentation of a certain signal), then after O(log n) steps (a time proportional to the ``diameter'''' of the network) the system will establish a set of disjoint paths from the marked inputs to the marked outputs."
STOC	Improved bounds on the max-flow min-cut ratio for multicommodity flows.	Serge A. Plotkin,Éva Tardos	1993	Improved bounds on the max-flow min-cut ratio for multicommodity flows.
STOC	Modified ranks of tensors and the size of circuits.	Pavel Pudlák,Vojtech Rödl	1993	Modified ranks of tensors and the size of circuits.
STOC	Cryptographic defense against traffic analysis.	Charles Rackoff,Daniel R. Simon	1993	Cryptographic defense against traffic analysis.
STOC	Many birds with one stone: multi-objective approximation algorithms.	R. Ravi,Madhav V. Marathe,S. S. Ravi,Daniel J. Rosenkrantz,Harry B. Hunt III	1993	We study network-design problems with multiple design objectives. In particular, we look at two cost measures to be minimized simultaneously: the total cost of the network and the maximum degree of any node in the network. Our main result can be roughly stated as follows: given an integer $b$, we present approximation algorithms for a variety of network-design problems on an $n$-node graph in which the degree of the output network is $O(b \log (\frac{n}{b}))$ and the cost of this network is $O(\log n)$ times that of the minimum-cost degree-$b$-bounded network. These algorithms can handle costs on nodes as well as edges. Moreover, we can construct such networks so as to satisfy a variety of connectivity specifications including spanning trees, Steiner trees and generalized Steiner forests. The performance guarantee on the cost of the output network is nearly best-possible unless $NP = \tilde{P}$. We also address the special case in which the costs obey the triangle inequality. In this case, we obtain a polynomial-time approximation algorithm with a stronger performance guarantee. Given a bound $b$ on the degree, the algorithm finds a degree-$b$-bounded network of cost at most a constant time optimum. There is no algorithm that does as well in the absence of triangle inequality unless $P = NP$. We also show that in the case of spanning networks, we can simultaneously approximate within a constant factor yet another objective: the maximum cost of any edge in the network, also called the bottleneck cost of the network. We extend our algorithms to find TSP tours and $k$-connected spanning networks for any fixed $k$ that simultaneously approximate all these three cost measures.
STOC	Wait-free k-set agreement is impossible: the topology of public knowledge.	Michael E. Saks,Fotios Zaharoglou	1993	In the classical consensus problem, each of n processors receives a private input value and produces a decision value which is one of the original input values, with the requirement that all processors decide the same value. A central result in distributed computing is that, in several standard models including the asynchronous shared-memory model, this problem has no deterministic solution. The k-set agreement problem is a generalization of the classical consensus proposed by Chaudhuri [ Inform. and Comput., 105 (1993), pp. 132--158], where the agreement condition is weakened so that the decision values produced may be different, as long as the number of distinct values is at most k. For $n>k\geq 2$ it was not known whether this problem is solvable deterministically in the asynchronous shared memory model. In this paper, we resolve this question by showing that for any k < n, there is no deterministic wait-free protocol for n processors that solves the k-set agreement problem. The proof technique is new: it is based on the development of a topological structure on the set of possible processor schedules of a protocol. This topological structure has a natural interpretation in terms of the knowledge of the processors of the state of the system. This structure reveals a close analogy between the impossibility of wait-free k-set agreement and the Brouwer fixed point theorem for the k-dimensional ball.
STOC	Deterministic coding for interactive communication.	Leonard J. Schulman	1993	Deterministic coding for interactive communication.
STOC	Locality based graph coloring.	Mario Szegedy,Sundar Vishwanathan	1993	Locality based graph coloring.
STOC	On the generation of multivariate polynomials which are hard to factor.	Adi Shamir	1993	On the generation of multivariate polynomials which are hard to factor.
STOC	Expanders that beat the eigenvalue bound: explicit construction and applications.	Avi Wigderson,David Zuckerman	1993	Expanders that beat the eigenvalue bound: explicit construction and applications.
STOC	A primal-dual approximation algorithm for generalized Steiner network problems.	David P. Williamson,Michel X. Goemans,Milena Mihail,Vijay V. Vazirani	1993	A primal-dual approximation algorithm for generalized Steiner network problems.
STOC	Proceedings of the Twenty-Fifth Annual ACM Symposium on Theory of Computing, 1993		1993	Proceedings of the Twenty-Fifth Annual ACM Symposium on Theory of Computing, 1993
FOCS	Priority Encoding Transmission	Andres Albanese,Johannes Blömer,Jeff Edmonds,Michael Luby,Madhu Sudan	1994	We introduce a novel approach for sending messages over lossy packet-based networks. The new method, called Priority Encoding Transmission, allows a user to specify a different priority on each segment of the message. Based on the priorities, the sender uses the system to encode the segments into packets for transmission. The system ensures recovery of the segments in order of their priority. The priority of a segment determines the minimum number of packets sufficient to recover the segment. We define a measure for a set of priorities, called the rate, which dictates how much information about the message must be contained in each bit of the encoding. We develop systems for implementing any set of priorities with rate equal to one. We also give an information-theoretic proof that there is no system that implements a set of priorities with rate greater than one. This work has applications to multi-media and high speed networks applications, especially in those with bursty sources and multiple receivers with heterogeneous capabilities.
FOCS	"``Go With the Winners'' Algorithms"	David Aldous,Umesh V. Vazirani	1994	"We can view certain randomized optimization algorithms as rules for randomly moving a particle around in a state space; each state might correspond to a distinct solution to the optimization problem, or more generally, the state space might express some other structure underlying the optimization algorithm. In this setting, a general paradigm for designing heuristics is to run several simulations of the algorithm simultaneously, and every so often classify the particles as ""doing well"" or ""doing badly"", and move each particle that is ""doing badly"" to the position of one that is ""doing well"". In this paper, we give a rigorous analysis of such a ""go with the winners"" scheme in the concrete setting of searching for a deep leaf in a tree. There are two relevant parameters of the tree: its depth d, and another parameter /spl kappa/ which is a measure of the imbalance of the tree. We prove that the running time of the ""go with the winners"" scheme (to achieve 99% probability of success) is bounded by a polynomial in d and /spl kappa/. By contrast, the simple restart scheme: run several independent simulations and pick the deepest leaf encountered takes time exponential in /spl kappa/ and d in the worst-case. We also show that any algorithm that guarantees a constant probability of success must have worst case running time at least /spl kappa/d."
FOCS	Algorithmic Number Theory-The Complexity Contribution	Leonard M. Adleman	1994	"Though algorithmic number theory is one of man's oldest intellectual pursuits, its current vitality is perhaps unrivalled in history. This is due in part to the injection of new ideas from computational complexity. In this paper, a brief history of the symbiotic relationship between number theory and complexity theory will be presented. In addition, some of the technical aspects underlying 'modern' methods of primality testing and factoring will be described. Finally, an extensive lists of open problems in algorithmic number theory will be provided."
FOCS	Measure on Small Complexity Classes, with Applications for BPP	Eric Allender,Martin Strauss	1994	"We present a notion of resource-bounded measure for P and other subexponential-time classes. This generalization is based on Lutz's notion of measure, but overcomes the limitations that cause Lutz's definitions to apply only to classes at least as large as E. We present many of the basic properties of this measure, and use it to explore the class of sets that are hard for BPP. Bennett and Gill showed that almost all sets are hard for BPP; Lutz improved this from Lebesgue measure to measure on ESPACE. We use our measure to improve this still further, showing that for all /spl epsiv/>0, almost every set in E/sub /spl epsiv// is hard for BPP, where E/sub /spl epsiv//=/spl cup//sub /spl delta/"
FOCS	A Theory of Competitive Analysis for Distributed Algorithms	Miklós Ajtai,James Aspnes,Cynthia Dwork,Orli Waarts	1994	We introduce a theory of competitive analysis for distributed algorithms. The first steps in this direction were made in the seminal papers of Y. Bartal et al. (1992), and of B. Awerbuch et al. (1992), in the context of data management and job scheduling. In these papers, as well as in other subsequent sequent work, the cost of a distributed algorithm is compared to the cost of an optimal global-control algorithm. In this paper we introduce a more refined notion of competitiveness for distributed algorithms, one that reflects the performance of distributed algorithms more accurately. In particular, our theory allows one to compare the cost of a distributed on-line algorithm to the cost of an optimal distributed algorithm. We demonstrate our method by studying the cooperative collect primitive, first abstracted by M. Saks, N. Shavit, and H. Woll (1991). We provide the first algorithms that allow processes to cooperate to finish their work in fewer steps. Specifically, we present two algorithms (with different strengths), and provide a competitive analysis for each one.
FOCS	Polynomial time randomised approxmiation schemes for the Tutte polynomial of dense graphs	Noga Alon,Alan M. Frieze,Dominic Welsh	1994	The Tutte-Grothendieck polynomial T(G; x, y) of a graph G encodes numerous interesting combinatorial quantities associated with the graph. Its evaluation in various points in the (x,y) plane gave the number of spanning forests of the graph, the number of its strongly connected orientations, the number of its proper k-colorings, the (all terminal) reliability probability of the graph, and various other invariants the exact computation of each of which is well known to be P-hard. Here we develop a general technique that supplies fully polynomial randomised approximation schemes for approximating the valve of T(G; x,, y) for any dense graph G, that is, any graph on n vertices whose minimum degree is /spl Omega/(n), whenever x/spl ges/1 and y/spl ges/1, and in various additional points. This region includes evaluations of reliability and partition functions of the ferromagnetic Q-state Potts model. Extensions to linear matroids where T specialises to the weight enumerator of linear codes are considered as well.
FOCS	Parallel Algorithms for Higher-Dimensional Convex Hulls	Nancy M. Amato,Michael T. Goodrich,Edgar A. Ramos	1994	We give fast randomized and deterministic parallel methods for constructing convex hulls in R/sup d/, for any fixed d. Our methods are for the weakest shared-memory model, the EREW PRAM, and have optimal work bounds (with high probability for the randomized methods). In particular, we show that the convex hull of n points in R/sup d/ can be constructed in O(log n) time using O(n log n+n/sup [d/2]/) work, with high probability. We also show that it can be constructed deterministically in O(log/sup 2/ n) time using O(n log n) work for d=3 and in O(log n) time using O(n/sup [d/2]/ log/sup c([d/2]-[d/2]/) n) work for d/spl ges/4, where c>0 is a constant which is optimal for even d/spl ges/4. We also show how to make our 3-dimensional methods output-sensitive with only a small increase in running time. These methods can be applied to other problems as well.
FOCS	A New Efficient Radix Sort	Arne Andersson,Stefan Nilsson	1994	We present new improved algorithms for the sorting problem. The algorithms are not only efficient but also clear and simple. First, we introduce Forward Radix Sort which combines the advantages of traditional left-to-right and right-to-left radix sort in a simple manner. We argue that this algorithm will work very well in practice. Adding a preprocessing step, we obtain an algorithm with attractive theoretical properties. For example, n binary strings can be sorted in /spl Theta/ (n log(B/(n log n)+2)) time, where B is the minimum number of bits that have to be inspected to distinguish the strings. This is an improvement over the previously best known result by Paige and Tarjan (1987). The complexity may also be expressed in terms of H, the entropy of the input: n strings from a stationary ergodic process can be sorted in /spl Theta/ (n log(1/H+1)) time an improvement over the result recently presented by Chen and Reif (1993).
FOCS	Randomized and deterministic algorithms for geometric spanners of small diameter	Sunil Arya,David M. Mount,Michiel H. M. Smid	1994	Let S be a set of n points in IR/sup d/ and let t>1 be a real number. A t-spanner for S is a directed graph having the points of S as its vertices, such that for any pair p and q of points there is a path from p to q of length at most t times the Euclidean distance between p and p. Such a path is called a t-spanner path. The spanner diameter of such a spanner is defined as the smallest integer D such that for any pair p and q of points there is a t-spanner path from p to q containing at most D edges. Randomized and deterministic algorithms are given for constructing t-spanners consisting of O(n) edges and having O(log n) diameter. Also, it is shown how to maintain the randomized t-spanner under random insertions and deletions. Previously, no results were known for spanners with low spanner diameter and for maintaining spanners under insertions and deletions.
FOCS	Local Optimization of Global Objectives: Competitive Distributed Deadlock Resolution and Resource Allocation	Baruch Awerbuch,Yossi Azar	1994	"The work is motivated by deadlock resolution and resource allocation problems, occurring in distributed server-client architectures. We consider a very general setting which includes, as special cases, distributed bandwidth management in communication networks, as well as variations of classical problems in distributed computing and communication networking such as deadlock: resolution and ""dining philosophers"". In the current paper, we exhibit first local solutions with globally-optimum performance guarantees. An application of our method is distributed bandwidth management in communication networks. In this setting, deadlock resolution (and maximum fractional independent set) corresponds to admission control maximizing network throughput. Job scheduling (and minimum fractional coloring) corresponds to route selection that minimizes load."
FOCS	On-line Admission Control and Circuit Routing for High Performance Computing and Communication	Baruch Awerbuch,Rainer Gawlick,Frank Thomson Leighton,Yuval Rabani	1994	This paper considers the problems of admission control and virtual circuit routing in high performance computing and communication systems. Admission control and virtual circuit routing problems arise in numerous applications, including video-servers, real-lime database servers, and the provision of permanent virtual channel in large-scale communications networks. The paper describes both upper and lower bounds on the competitive ratio of algorithms for admission control and virtual circuit routing in trees, arrays, and hypercubes (the networks most commonly used in conjunction with nigh performance computing and communication). Our results include optimal algorithms for admission control and virtual circuit routing in trees, as well as the first competitive algorithms for these problems on non-tree networks. A key result of our research is the development of on-line algorithms that substantially outperform the greedy-based approaches that are used in practice.
FOCS	On the Combinatorial and Algebraic Complexity of Quantifier Elimination	Saugata Basu,Richard Pollack,Marie-Françoise Roy	1994	In this paper we give a new algorithm for performing quantifier elimination from first order formulae over real closed fields. This algorithm improves the complexity of the asymptotically fastest algorithm for this problem, known to this date. A new feature of our algorithm is that the role of the algebraic part (the dependence on the degrees of the input polynomials) and the combinatorial part (the dependence on the number of polynomials) are separated, making possible our improved complexity bound. Another new feature is that the degrees of the polynomials in the equivalent quantifier-free formula that we output, are independent of the number of input polynomials. As special cases of this algorithm, we obtain new and improved algorithms for deciding a sentence in the first order theory over real closed fields, and also for solving the existential problem in the first order theory over real closed fields. Using the theory developed in this paper, we also give an improved bound on the radius of a ball centered at the origin, which is guaranteed to intersect every connected component of the sign partition induced by a family of polynomials. We also use our methods to obtain algorithms for solving certain decision problems in real and complex geometry which improves the complexity of the currently known algorithms for these problems.
FOCS	"Lower Bound on Hilbert's Nullstellensatz and propositional proofs"	Paul Beame,Russell Impagliazzo,Jan Krajícek,Toniann Pitassi,Pavel Pudlák	1994	"The weak form of the Hilbert's Nullstellensatz says that a system of algebraic equations over a field, Q/sub i/(x~)=0, does not have a solution in the algebraic closure iff 1 is in the ideal generated by the polynomials Q/sub i/(x~). We shall prove a lower bound on the degrees of polynomials P/sub i/(x~) such that /spl Sigma//sub i/ P/sub i/(x~)Q/sub i/(x~)=1. This result has the following application. The modular counting principle states that no finite set whose cardinality is not divisible by q can be partitioned into q-element classes. For each fixed cardinality N, this principle can be expressed as a propositional formula Count/sub q//sup N/. Ajtai (1988) proved recently that, whenever p, q are two different primes, the propositional formulas Count/sub q//sup qn+1/ do not have polynomial size, constant-depth Frege proofs from instances of Count/sub p//sup m/, m/spl ne/0 (mod p). We give a new proof of this theorem based on the lower bound for the Hilbert's Nullstellensatz. Furthermore our technique enables us to extend the independence results for counting principles to composite numbers p and q. This results in an exact characterization of when Count/sub q/ can be proven efficiently from Count/sub p/, for all p and q."
FOCS	Randomness-Efficient Oblivious Sampling	Mihir Bellare,John Rompel	1994	We introduce a natural notion of obliviousness of a sampling procedure, and construct a randomness-efficient oblivious sampler. Our sampler uses O(l+log /spl delta//sup -1//spl middot/log l) coins to output m=poly(/spl epsiv//sup -1/, log /spl delta//sup -1/, log l) sample points x/sub 1/, ..., x/sub m/, /spl isin/ {0, 1}/sup 1/ such that Pr[|1/m/spl Sigma//sub i=1//sup m/f(x/sub i/)-E[f]|
FOCS	Algebraic Computation Trees in Characteristi p>0 (Extended Abstract)	Michael Ben-Or	1994	Algebraic Computation Trees in Characteristi p>0 (Extended Abstract)
FOCS	The Power of Team Exploration: Two Robots Can Learn Unlabeled Directed Graphs	Michael A. Bender,Donna K. Slonim	1994	We show that two cooperating robots can learn exactly any strongly-connected directed graph with n indistinguishable nodes in expected time polynomial in n. We introduce a new type of homing sequence for two robots which helps the robots recognize certain previously-seen nodes. We then present an algorithm in which the robots learn the graph and the homing sequence simultaneously by wandering actively through the graph. Unlike most previous learning results using homing sequences, our algorithm does not require a teacher to provide counterexamples. Furthermore, the algorithm can use efficiently any additional information available that distinguishes nodes. We also present an algorithm in which the robots learn by taking random walks. The rate at which a random walk converges to the stationary distribution is characterized by the conductance of the graph. Our random-walk algorithm learns in expected time polynomial in n and in the inverse of the conductance and is more efficient than the homing-sequence algorithm for high-conductance graphs.
FOCS	Program Result-Checking: A Theory of Testing Meets a Test of Theory	Manuel Blum,Hal Wasserman	1994	We review the field of result-checking, discussing simple checkers and self-correctors. We argue that such checkers could profitably be incorporated in software as an aid to efficient debugging and reliable functionality. We consider how to modify traditional checking methodologies to make them more appropriate for use in real-time, real-number computer systems. In particular, we suggest that checkers should be allowed to use stored randomness: i.e., that they should be allowed to generate, pre-process, and store random bits prior to run-time, and then to use this information repeatedly in a series of run-time checks. In a case study of checking a general real-number linear transformation (for example, a Fourier Transform), we present a simple checker which uses stored randomness, and a self-corrector which is particularly efficient if stored randomness is allowed.
FOCS	Scheduling Multithreaded Computations by Work Stealing	Robert D. Blumofe	1994	Scheduling Multithreaded Computations by Work Stealing
FOCS	On Learning Discretized Geometric Concepts (Extended Abstract)	Nader H. Bshouty,Zhixiang Chen,Steven Homer	1994	On Learning Discretized Geometric Concepts (Extended Abstract)
FOCS	A Spectral Approach to Lower Bounds	Bernard Chazelle	1994	"We establish a nonlinear lower bound for halfplane range searching over a group. Specifically, we show that summing up the weights of n (weighted) points within n halfplanes requires /spl Omega/(n log n) additions and subtractions. This is the first nontrivial lower bound for range searching over a group. By constrast, range searching over a semigroup (which forbids subtractions) is almost completely understood. Our proof has two parts: First, we develop a general, entropy-based, method for relating the linear circuit complexity of a linear map A to the spectrum of A/sup T/A. In the second part of the proof, we design a ""high-spectrum"" geometric set system and, using techniques from discrepancy theory, we estimate the median eigenvalue of its associated map. Interestingly, the method also shows that using up to a linear number of help gates cannot help; these are gates that can compute any bivariate function. The best feature of our method is that it is very general. With any instance of range searching we associate a quadratic form: any lower bound on the mid-range of its spectrum implies a lower bound on the complexity of that range searching problem. The main drawback of our approach is that it (probably) yields weak lower bounds. Another shortcoming is that the method does not seem to generalize to range searching over rings or fields."
FOCS	Efficient Average-Case Algorithms for the Modular Group	Jin-yi Cai,Wolfgang H. J. Fuchs,Dexter Kozen,Zicheng Liu	1994	The modular group occupies a central position in many branches of mathematical sciences. In this paper we give average polynomial-time algorithms for the unbounded and bounded membership problems for finitely generated subgroups of the modular group. The latter result affirms a conjecture of Y. Gurevich (1990).
FOCS	The Complexity of the Membership Problem for 2-generated Commutative Semigroups of Rational Matrices	Jin-yi Cai,Richard J. Lipton,Yechezkel Zalcstein	1994	We present a deterministic polynomial-time algorithm for the ABC problem, which is the membership problem for 2-generated commutative linear semigroups over an algebraic number field. We also obtain a polynomial time algorithm, for the (easier) membership problem, for 2-generated abelian linear groups. Furthermore, we provide a polynomial-sized encoding for the set of all solutions.
FOCS	Set constraints with projections are in NEXPTIME	Witold Charatonik,Leszek Pacholski	1994	Systems of set constraints describe relations between sets of ground terms. They have been successfully used in program analysis and type inference. In this paper we prove that the problem of existence of a solution of a system of set constraints with projections is in NEXPTIME, and thus that it is NEXPTIME-complete. This extends the result of A. Aiken, D. Kozen, and E.L. Wimmers (1993) and R. Gilleron, S. Tison, and M. Tommasi (1990) on decidability of negated set constraints and solves a problem that was open for several years.
FOCS	More Output-Sensitive Geometric Algorithms (Extended Abstract)	Kenneth L. Clarkson	1994	More Output-Sensitive Geometric Algorithms (Extended Abstract)
FOCS	Estimating the Size of the Transitive Closure in Linear Time	Edith Cohen	1994	Computing transitive closure and reachability information in directed graphs is a fundamental graph problem with many applications. The fastest known algorithms run in O(sm) time for computing all nodes reachable from each of 1/spl les/s/spl les/n source nodes, or, using fast matrix multiplication, in O(n/sup 2.38/) time for computing the transitive closure, where n is the number of nodes and m the number of edges in the graph. In query optimization in database applications it is often the case that only estimates on the size of the transitive closure and on the number of nodes reachable from certain nodes are needed. We present an O(m) time randomized algorithm that estimates the number of nodes reachable from every node and the size of the transitive closure. We also obtain a O/spl tilde/(m) time algorithm for estimating sizes of neighborhoods in directed graphs with nonnegative weights, avoiding the O/spl tilde/(mn) time bound of explicitly computing these neighborhoods. Our size-estimation algorithms are much faster than performing the actual computations and improve significantly over previous estimation methods.
FOCS	PAC Learning with Irrelevant Attributes	Aditi Dhagat,Lisa Hellerstein	1994	"We consider the problem of learning in the presence of irrelevant attributes in Valiant's PAC model (1984). In the PAC model, the goal of the learner is to produce an approximately correct hypothesis from random sample data. If the number of relevant attributes in the target function is small, it may be desirable to produce a hypothesis that also depends on only a small number of variables. Haussler (1988) previously considered the problem of learning monomials of a small number of variables. He showed that the greedy set cover approximation algorithm can be used as a polynomial-time Occam algorithm for learning monomials on r of n variables. A outputs a monomial on r(ln q+1) variables, where q is the number of negative examples in the sample. We extend this result by showing that there is a polynomial-time Occam algorithm for learning k-term DNF formulas depending on r of n variables that outputs a DNF formula depending on O(r/sup k/log/sup k/q) variables, where q is the number of negative examples in the sample. We also give a polynomial-time Occam algorithm for learning decision lists (sometimes called 1-decision lists) with k alternations."
FOCS	Finding the k Shortest Paths	David Eppstein	1994	We give algorithms for finding the k shortest paths (not required to be simple) connecting a pair of vertices in a digraph. Our algorithms output an implicit representation of these paths in a digraph with n vertices and m edges, in time O(m+n log n+k). We can also find the k shortest paths from a given source s to each vertex in the graph, in total time O(m+n log n+kn). We describe applications to dynamic programming problems including the knapsack problem, sequence alignment, and maximum inscribed polygons.
FOCS	Optimizing Static Calendar Queues	K. Bruce Erickson,Richard E. Ladner,Anthony LaMarca	1994	The calendar queue is an important implementation of a priority queue which is particularly useful in discrete event simulators. In this paper we present an analysis of the static calendar queue which maintains N active events. A step of the discrete event simulator removes and processes the event with the smallest associated time and inserts a new event whose associated time is the time of the removed event plus a random increment with mean /spl mu/. We demonstrate that for the infinite bucket calendar queue the optimal bucket width is approximately /spl delta//sub opt/=/spl radic/(2b/c)/spl mu//N where b is the time to process an empty bucket and c the incremental time to process a list element. With bucket width chosen to be /spl delta//sub opt/, the expected time to process an event is approximately minimized at the constant c+/spl radic/(2bc)+d, where d is the fixed time to process an event. We show that choosing the number of buckets to be O(N) yields a calendar queue with performance equal to or almost equal to the performance of the infinite bucket calendar queue.
FOCS	Optimal Evolutionary Tree Comparison by Sparse Dynamic Programming (Extended Abstract)	Martin Farach,Mikkel Thorup	1994	Optimal Evolutionary Tree Comparison by Sparse Dynamic Programming (Extended Abstract)
FOCS	Finding separator cuts in planar graphs within twice the optimal	Naveen Garg,Huzur Saran,Vijay V. Vazirani	1994	Building on the works of S.B. Rao (1987, 1992) and J.K. Park and C.A. Phillips (1993), we present a factor 2 approximation algorithm for the problem of finding a minimum cost b-balanced cut in planar graphs, for b/spl les/1/3, if the vertex weights are given in unary (using scaling, a psuedo-approximation algorithm is also presented for the case of binary vertex weights). This problem is of considerable practical significance, especially in VLSI design.
FOCS	Randomized Simplex Algorithms on Klee-Mintny Cubes	Bernd Gärtner,Günter M. Ziegler	1994	We investigate the behavior of randomized simplex algorithms on special linear programs. For this, we develop combinatorial models for the Klee-Minty cubes (1972) and similar linear programs with exponential decreasing paths. The analysis of two most natural randomized pivot rules on the Klee-Minty cubes leads to (nearly) quadratic lower bounds for the complexity of linear programming with random pivots. Thus we disprove two bounds conjectured in the literature. At the same lime, we establish quadratic upper bounds for random pivots on the linear programs under investigation. This motivates the question whether some randomized pivot rules possibly have quadratic worst-case behavior on general linear programs.
FOCS	Multi-Index Hashing for Information Retrieval	Daniel H. Greene,Michal Parnas,F. Frances Yao	1994	We describe a technique for building hash indices for a large dictionary of strings. This technique permits robust retrieval of strings from the dictionary even when the query pattern has a significant number of errors. This technique is closely related to the classical Turan problem for hypergraphs. We propose a general method of multi-index construction by generalizing certain Turan hypergraphs. We also develop an accompanying theory for analyzing such hashing schemes. The resulting algorithms have been implemented and can be applied to a wide variety of recognition and retrieval problems.
FOCS	Complexity Lower Bounds for Computation Trees with Elementary Transcendental Function Gates	Dima Grigoriev,Nicolai Vorobjov	1994	We consider computation trees which admit as gate functions along with the usual arithmetic operations also algebraic or transcendental functions like exp, log, sin, square root (defined in the relevant domains) or much more general, Pfaffian functions. A new method for proving lower bounds on the depth of these trees is developed which allows to prove a lower bound /spl Omega/(/spl radic/(log N)) for testing membership to a convex polyhedron with N facets of all dimensions, provided that N is large enough. This method differs essentially from the previous approaches adopted for algebraic computation trees.
FOCS	Fully Dynamic Cycle-Equivalence in Graphs	Monika Rauch Henzinger	1994	Two edges e/sub 1/ and e/sub 2/ of an undirected graph are cycle-equivalent iff all cycles that contain e/sub 1/ also contain e/sub 2/, i.e., iff e/sub 1/ and e/sub 2/ are a cut-edge pair. The cycle-equivalence classes of the control-flow graph are used in optimizing compilers to speed up existing control-flow and data-flow algorithms. While the cycle-equivalence classes can be computed in linear time, we present the first fully dynamic algorithm for maintaining the cycle-equivalence relation. In an n-node graph our data structure executes an edge insertion or deletion in O(/spl radic/n log n) time and answers the query whether two given edges are cycle-equivalent in O(log/sup 2/ n) time. We also present an algorithm for plane graphs with O(log n) update and query time and for planar graphs with O(log n) insertion time and O(log/sup 2/ n) query and deletion time. Additionally, we show a lower bound of /spl Omega/(log n/log log n) for the amortized time per operation for the dynamic cycle-equivalence problem in the cell probe model.
FOCS	A Polynomial-time Algorithm for Deciding Equivalence of Normed Context-free Processes	Yoram Hirshfeld,Mark Jerrum,Faron Moller	1994	A polynomial-time procedure is presented for deciding bisimilarity of normed context-free processes. It follows as a corollary that language equivalence of simple context-free grammars is decidable in polynomial time.
FOCS	Fast and Lean Self-Stabilizing Asynchronous Protocols	Gene Itkis,Leonid A. Levin	1994	We consider asynchronous general topology dynamic networks of identical nameless nodes with worst-case transient faults. Starting from any faulty configuration, our protocols self-stabilize any computation in time polynomial in the (unknown) network diameter. This version sacrifices some diversity of tasks and efficiency for simplicity and clarity of details. Appendix gives more efficient procedures in less detail.
FOCS	An Efficient Membership-Query Algorithm for Learning DNF with Respect to the Uniform Distribution	Jeffrey C. Jackson	1994	"We present a membership-query algorithm for efficiently learning DNF with respect to the uniform distribution. In fact, the algorithm properly learns the more general class of functions that are computable as a majority of polynomially-many parity functions. We also describe extensions of this algorithm for learning DNF over certain nonuniform distributions and from noisy examples as well as for learning a class of geometric concepts that generalizes DNF. The algorithm utilizes one of Freund's boosting techniques and relies on the fact that boosting does not require a completely distribution-independent weak learner. The boosted weak learner is a nonuniform extension of a Fourier-based algorithm due to Kushilevitz and Mansour (1991)."
FOCS	Tail Bounds for Occupancy and the Satisfiability Threshold Conjecture	Anil Kamath,Rajeev Motwani,Krishna V. Palem,Paul G. Spirakis	1994	The classical occupancy problem is concerned with studying the number of empty bins resulting from a random allocation of m balls to n bins. We provide a series of tail bounds on the distribution of the number of empty bins. These tail bounds should find application in randomized algorithms and probabilistic analysis. Our motivating application is the following well-known conjecture on threshold phenomenon for the satisfiability problem. Consider random 3-SAT formulas with cn clauses over n variables, where each clause is chosen uniformly and independently from the space of all clauses of size 3. It has been conjectured that there is a sharp threshold for satisfiability at c*/spl ap/4.2. We provide the first non-trivial upper bound on the value of c*, showing that for c>4.758 a random 3-SAT formula is unsatisfiable with high probability. This result is based on a structural property, possibly of independent interest, whose proof needs several applications of the occupancy tail bounds.
FOCS	Markov Chains and Polynomial Time Algorithms	Ravi Kannan	1994	This paper outlines the use of rapidly mixing Markov Chains in randomized polynomial time algorithms to solve approximately certain counting problems. They fall into two classes: combinatorial problems like counting the number of perfect matchings in certain graphs and geometric ones like computing the volumes of convex sets.
FOCS	Tractability of parameterized completion problems on chordal and interval graphs: Minimum Fill-in and Physical Mapping	Haim Kaplan,Ron Shamir,Robert Endre Tarjan	1994	We study the parameterized complexity of several NP-Hard graph completion problems: The minimum fill-in problem is to decide if a graph can be triangulated by adding at most k edges. We develop an O(k/sup 5/ mn+f(K)) algorithm for the problem on a graph with n vertices and m edges. In particular, this implies that the problem is fixed parameter tractable (FPT). proper interval graph completion problems, motivated by molecular biology, ask for adding edges in order to obtain a proper interval graph, so that a parameter in that graph does not exceed k. We show that the problem is FPT when k is the number of added edges. For the problem where k is the clique size, we give an O(f(k)n/sup k-1/) algorithm, so it is polynomial for fixed k. On the other hand, we prove its hardness in the parameterized hierarchy, so it is probably not FPT. Those results are obtained even when a set of edges which should not be added is given. That set can be given either explicitly or by a proper vertex coloring which the added edges should respect.
FOCS	(De)randomized Construction of Small Sample Spaces in \calNC	David R. Karger,Daphne Koller	1994	(De)randomized Construction of Small Sample Spaces in \calNC
FOCS	Approximate Graph Coloring by Semidefinite Programming	David R. Karger,Rajeev Motwani,Madhu Sudan	1994	We consider the problem of coloring k-colorable graphs with the fewest possible colors. We give a randomized polynomial time algorithm which colors a 3-colorable graph on n vertices with min {O(/spl Delta//sup 1/3/log/sup 4/3//spl Delta/), O(n/sup 1/4/ log n)} colors where /spl Delta/ is the maximum degree of any vertex. Besides giving the best known approximation ratio in terms of n, this marks the first non-trivial approximation result as a function of the maximum degree /spl Delta/. This result can be generalized to k-colorable graphs to obtain a coloring using min {O/spl tilde/(/spl Delta//sup 1-2/k/), O/spl tilde/(n/sup 1-3/(k+1/))} colors. Our results are inspired by the recent work of Goemans and Williamson who used an algorithm for semidefinite optimization problems, which generalize linear programs, to obtain improved approximations for the MAX CUT and MAX 2-SAT problems. An intriguing outcome of our work is a duality relationship established between the value of the optimum solution to our semidefinite program and the Lovasz /spl thetav/-function. We show lower bounds on the gap between the optimum solution of our semidefinite program and the actual chromatic number; by duality this also demonstrates interesting new facts about the /spl thetav/-function.
FOCS	Maximum Agreement Subtree in a Set of Evolutionary Trees-Metrics and Efficient Algorithms	Dmitry Keselman,Amihood Amir	1994	In this paper we prove that the maximum homeomorphic agreement subtree problem is /spl Nscr//spl Pscr/-complete for three trees with unbounded degrees. We then show an approximation algorithm of time O(kn/sup 5/) for choosing the species that are not in a maximum agreement subtree of a set of k trees. Our approximation is guaranteed to provide a set that is no more than 4 times the optimum solution. While the set of evolutionary trees may be large in practice, the trees usually have very small degrees, typically no larger than three. We develop a new method for finding a maximum agreement subtree of k trees, of which one has degree bounded by d. This new method enables us to find a maximum agreement subtree in time O(kn/sup d+1/).
FOCS	On Syntactic versus Computational Views of Approximability	Sanjeev Khanna,Rajeev Motwani,Madhu Sudan,Umesh V. Vazirani	1994	We attempt to reconcile the two distinct views of approximation classes: syntactic and computational. Syntactic classes such as MAX SNP permit structural results and have natural complete problems, while computational classes such as APX allow us to work with classes of problems whose approximability is well-understood. Our results provide a syntactic characterization of computational classes, and give a computational framework for syntactic classes.
FOCS	On the complexity of Bounded-Interaction and Noninteractive Zero-Knowledge Proofs	Joe Kilian	1994	We consider the basic cryptographic primitive known as zero-knowledge proofs on committed bits. In this primitive, a prover P commits to a set of bits, and then at a later time convinces a verifier V that some property /spl Pscr/ holds for a subset of these bits. It is known how to implement this primitive based on an ordinary bit-committal primitive, but the standard implementations involve a great deal of interaction between the prover and the verifier. We introduce new implementations that require markedly less interaction. We implement bounded-interaction proofs on committed bits, generalizing a model of A. De Micali et al. (1988). For all security parameters, our implementations require only a lg/sup 2/ (n) overhead over the best known circuit-based interactive implementations; for sufficiently large security parameters this gap drops to a lg(n) factor.
FOCS	The Localization Problem for Mobile Robots	Jon M. Kleinberg	1994	"A fundamental task for an autonomous mobile robot is that of localization-determining its location in a known environment. This problem arises in settings that range from the computer analysis of aerial photographs to the design of autonomous Mars rovers. L. Guibas et al. ((1992) have given geometric algorithms for the problem of enumerating locations for a robot consistent with a given view of the environment. We provide an on-line algorithm for a robot to move within its environment so as to uniquely determine its location. The algorithm improves asymptotically on strategies based purely on the ""spiral search"" technique of R. Baeza-Yates et al. (1993); an interesting feature of our approach is the way in which the robot is able to identify ""critical directions"" in the environment which allow it to perform late stages of the search more efficiently."
FOCS	On the Design of Reliable Boolean Circuits that Contain Partially Unreliable Gates	Daniel J. Kleitman,Frank Thomson Leighton,Yuan Ma	1994	We investigate a model of gate failure for Boolean circuits in which a faulty gate is restricted to output one of its input values. For some types of gates, the model (which we call the short-circuit model of gate failure) is weaker than the traditional von Neumann model where faulty gates always output precisely the wrong value. Our model has the advantage that it allows us to design Boolean circuits that can tolerate worst-case faults, as well as circuits that have arbitrarily high success probability in the case of random faults. Moreover, the short-circuit model captures a particular type of fault that commonly appears in practice, and it suggests a simple method for performing post-test alterations to circuits that have more severe types of faults. A variety of bounds on the size of fault-tolerant circuits are proved in the paper. Perhaps, the most important is a proof that any k-fault-tolerant circuit for any input-sensitive function using any type of gates (even arbitrarily powerful, multiple-input gates) must have size at least /spl Omega/(k log k/log log k). Obtaining a tight bound on the size of a circuit for computing the AND of two values if up to k of the gates are faulty is one of the central questions left open in the paper.
FOCS	Reducibility and Completeness in Multi-Party Private Computations	Eyal Kushilevitz,Silvio Micali,Rafail Ostrovsky	1994	We define the notions of reducibility and completeness in multi-party private computations. Let g be an n-argument function. We say that a function f is reducible to g if n honest-but-curious players can compute the function f n-privately, given a black-box for g (for which they secretly give inputs and get the result of operating g on these inputs). We say that g is complete (for multi-party private computations) if every function f is reducible to g. In this paper, we characterize the complete Boolean functions: we show that a Boolean function g is complete if and only if g itself cannot be computed n-privately (when there is no black-box available). Namely, for Boolean functions, the notions of completeness and n-privacy are complementary. This characterization gives a huge collection of complete functions (any non-private Boolean function!) compared to very few examples given (implicitly) in previous work. On the other hand, for non-Boolean functions, we show that these two notions are not complementary. Our results can be viewed as a generalization (for multi-party protocols and for (n/spl ges/2)-argument functions) of the two-party case, where it was known that Oblivious Transfer protocol (and its variants) are complete.
FOCS	Fast and Feasible Periodic Sorting Networks of Constant Depth	Miroslaw Kutylowski,Krzysztof Lorys,Brigitte Oesterdiekhoff,Rolf Wanka	1994	"A periodic comparator network has depth (or period) k, if for every t>k, the compare-exchange operations performed at step t are executed between exactly the same registers as at step t-k. We introduce a general method that converts an arbitrary comparator network that sorts n items in time T(n) and that has layout area A into a periodic sorting network of depth 5 that sorts /spl Theta/(n/spl middot/T(n)) items in time O(T(n)/spl middot/log n) and has layout area O(A/spl middot/T(n)). This scheme applied to the AKS network yields a depth 5 periodic comparator network that sorts in time O(log/sup 2/ n). More practical networks with runtime O(log/sup 3/ n) can be obtained from Batcher's networks. Developing the techniques for the main result, we improve some previous results: Let us fix a d/spl isin/N. Then we can construct a network of depth 3 based on a d-dimensional mesh sorting n items in time O(n/sup 1/d//spl middot/log/sup O(d/) n)."
FOCS	Long Tours and Short Superstrings (Preliminary Version)	S. Rao Kosaraju,James K. Park,Clifford Stein	1994	Long Tours and Short Superstrings (Preliminary Version)
FOCS	Beyond Competitive Analysis	Elias Koutsoupias,Christos H. Papadimitriou	1994	The competitive analysis of online algorithms has been criticized as being too crude and unrealistic. We propose refinements of competitive analysis in two directions: The first restricts the power of the adversary by allowing only certain input distributions, while the other allows for comparisons between information regimes for online decision-making. We illustrate the first with an application to the paging problem; as a byproduct we characterize completely the work functions of this important special case of the k-server problem. We use the second refinement to explore the power of lookahead in server and task systems.
FOCS	The geometry of graphs and some of its algorithmic applications	Nathan Linial,Eran London,Yuri Rabinovich	1994	We explore some implications of viewing graphs as geometric objects. This approach offers a new perspective on a number of graph-theoretic and algorithmic problems. There are several ways to model graphs geometrically and our main concern here is with geometric representations that respect the metric of the (possibly weighted) graph. Given a graph G we map its vertices to a normed space in an attempt to (i) Keep down the dimension of the host space and (ii) Guarantee a small distortion, i.e., make sure that distances between vertices in G closely match the distances between their geometric images. We develop efficient algorithms for embedding graphs low-dimensionally with a small distortion.
FOCS	IP over connection-oriented networks and distributional paging	Carsten Lund,Steven Phillips,Nick Reingold	1994	Next generation wide area network are very likely to use connection-oriented protocols such as Asynchronous Transfer Mode (ATM). For the huge existing investment in current IP networks such as the Internet to remain useful, me must devise mechanisms to carry IP traffic over connection-oriented networks. A basic issue is to devise holding policies for virtual circuits carrying datagrams. In this paper we consider two variants of the paging problem that arise in the design of such holding policies. In the IP-paging problem the page inter-request times are chosen according to independent distributions. For this model we construct a very simple deterministic algorithm whose page fault rate is at most 5 times that of the best online algorithm (that knows the inter-request time distributions). We also show that some natural algorithms for this problem do not have constant competitive ratio. In distributional paging the inter-request time distributions may be dependent, and hence any probabilistic model of page request sequences can be represented. We construct a simple randomized algorithm whose page fault rate is at most 4 times that of the best online algorithm.
FOCS	CS Proofs (Extended Abstracts)	Silvio Micali	1994	CS Proofs (Extended Abstracts)
FOCS	On Rank vs. Communication Complexity	Noam Nisan,Avi Wigderson	1994	This paper concerns the open problem of Lovasz and Saks (1988) regarding the relationship between the communication complexity of a Boolean function and the rank of the associated matrix. We first give an example exhibiting the largest gap known. We then prove two related theorems.
FOCS	Motion Planning on a Graph (Extended Abstract)	Christos H. Papadimitriou,Prabhakar Raghavan,Madhu Sudan,Hisao Tamaki	1994	Motion Planning on a Graph (Extended Abstract)
FOCS	The Load, Capacity and Availability of Quorum Systems	Moni Naor,Avishai Wool	1994	A quorum system is a collection of sets (quorums) every two of which have a nonempty intersection. Quorum systems have been used for a number of applications in the area of distributed systems. We investigate the load, capacity and availability of quorum systems. We present four novel constructions of quorum system, all featuring optimal or near optimal load, and high availability. These desirable properties of the constructions translate into improvements of any protocol using them: a low work load on the processors and a high resilience to processor failures. The best construction, based on paths in a grid, has a load of O(1//spl radic/n), and a failure probability of exp(-O(/spl radic/n)) when the elements fail with probability p
FOCS	An O(n^1+epsilon log b) Algorithm for the Complex Roots Problem	C. Andrew Neff,John H. Reif	1994	An O(n^1+epsilon log b) Algorithm for the Complex Roots Problem
FOCS	Products and Help Bits in Decision Trees	Noam Nisan,Steven Rudich,Michael E. Saks	1994	"We investigate two problems concerning the complexity of evaluating a function f at k-tuple of unrelated inputs by k parallel decision tree algorithms. In the product problem, for some fixed depth bound d, we seek to maximize the fraction of input k-tuples for which all k decision trees are correct. Assume that for a single input to f, the best decision tree algorithm of depth d is correct on a fraction p of inputs. We prove that the maximum fraction of k-tuples on which k depth d algorithms are all correct is at most p/sup k/, which is the trivial lower bound. We show that if we replace the depth d restriction by ""expected depth d"", then this result fails. In the help-bit problem, we are permitted to ask k-1 arbitrary binary questions about the k-tuple of inputs. For each possible k-1-tuple of answers to these queries we will have a k-tuple of decision trees which are supposed to correctly compute all functions on k-tuples that are consistent with the particular answers. The complexity here is the maximum depth of any of the trees in the algorithm. We show that for all k sufficiently large, this complexity is equal to deg/sup s/(f) which is the minimum degree of a multivariate polynomial whose sign is equal to f. Finally, we give a brief discussion of these problems in the context of other complexity models."
FOCS	On the robustness of functional equations	Ronitt Rubinfeld	1994	"Given a functional equation, such as /spl forall/x, y f(x)+f(y)=f(x+y), we study the following general question: When can the ""for all"" quantifiers be replaced by ""for most"" quantifiers without essentially changing the functions that are characterized by the property? When ""for most"" quantifiers are sufficient, we say that the functional equation is robust. We show conditions on functional equations of the form /spl forall/x, y F[f(x-y), f(x+y), f(x), f(y)]=0, where F is an algebraic function, that imply robustness. We then initiate a general study aimed at characterizing properties of functional equations that determine whether or not they are robust. Our results have applications to the area of self-testing/correcting programs-this paper provides results which show that the concept of self-testing/correcting has much broader applications than we previously understood. We show that self-testers and self-correctors can be found for many functions satisfying robust functional equations, including tan x, 1/1+cot x, Ax/1-Ax', cosh x."
FOCS	Nearly Tight Bounds for Wormhole Routing	Abhiram G. Ranade,Saul Schleimer,Daniel Shawcross Wilkerson	1994	We present nearly tight bounds for wormhole muting on Butterfly networks which indicate it is fundamentally different from store-and-forward packet routing. For instance, consider the problem of routing N log N (randomly generated) log N length messages from the inputs to the outputs of an N input Butterfly. We show that with high probability that this must take time at least /spl Omega/(log/sup 3/N/(log log N)/sup 2/). The best lower bound known earlier was /spl Omega/(log/sup 2/ N), which is simply the flit congestion an each link. Thus our lower bound shows that wormhole routing (unlike store-and-forward-routing) is very ineffective in utilizing communication links. We also give a routing algorithm which nearly matches our lower bound. That is, we show that with high probability the time is O(log/sup 3/ N log log N), which improves upon, the previous best bound of O(log/sup 4/ N). Our method also extends to other networks such as the two-dimensional mesh, where it is nearly optimal. Finally, we consider the problem of offline wormhole routing, where we give optimal algorithms for trees and multidimensional meshes.
FOCS	Rapid Rumor Ramification: Approximating the minimum broadcast time (Extended Abstract)	R. Ravi	1994	Rapid Rumor Ramification: Approximating the minimum broadcast time (Extended Abstract)
FOCS	On Monotone Formula Closure of SZK	Alfredo De Santis,Giovanni Di Crescenzo,Giuseppe Persiano,Moti Yung	1994	We investigate structural properties of statistical zero knowledge (SZK) both in the interactive and in the non-interactive model. Specifically, we look into the closure properties of SZK languages under monotone logical formula composition. This gives rise to new protocol techniques. We show that interactive SZK for random self reducible languages (RSR) (and for co-RSR) is closed under monotone Boolean operations. Namely, we give SZK proofs for monotone Boolean formulae whose atoms are statements about an SZK language which is RSR (or a complement of RSR). All previously known languages in SZK are in these classes. We then show that if a language L has a non-interactive SZK proof system then honest-verifier interactive SZK proof systems exist for all monotone Boolean formulae whose atoms are statements about the complement of L. We also discuss extensions and generalizations.
FOCS	Graph Connectivity and Monadic NP	Thomas Schwentick	1994	Ehrenfeucht games are a useful tool in proving that certain properties of finite structures are not expressible by formulas of a certain type. In this paper a new method is introduced that allows the extension of a local winning strategy for Duplicator, one of the two players in Ehrenfeucht games, to a global winning strategy. As an application it is shown that graph connectivity cannot be expressed by existential second-order formulas, where the second-order quantification is restricted to unary relations (monadic NP), even, in the presence of a built-in linear order. As a second application it is stated, that, on the other hand, the presence of a linear order increases the power of monadic NP more than the presence of a successor relation.
FOCS	Algorithms for Quantum Computation: Discrete Logarithms and Factoring	Peter W. Shor	1994	A computer is generally considered to be a universal computational device; i.e., it is believed able to simulate any physical computational device with a cost in computation time of at most a polynomial factor: It is not clear whether this is still true when quantum mechanics is taken into consideration. Several researchers, starting with David Deutsch, have developed models for quantum mechanical computers and have investigated their computational properties. This paper gives Las Vegas algorithms for finding discrete logarithms and factoring integers on a quantum computer that take a number of steps which is polynomial in the input size, e.g., the number of digits of the integer to be factored. These two problems are generally considered hard on a classical computer and have been used as the basis of several proposed cryptosystems. We thus give the first examples of quantum cryptanalysis.
FOCS	On the Power of Quantum Cryptography	Daniel R. Simon	1994	The quantum model of computation is a probabilistic model, similar to the probabilistic Turing Machine, in which the laws of chance are those obeyed by particles on a quantum mechanical scale, rather than the rules familiar to us from the macroscopic world. We present here a problem of distinguishing between two fairly natural classes of function, which can provably be solved exponentially faster in the quantum model than in the classical probabilistic one, when the function is given as an oracle drawn equiprobably from the uniform distribution on either class. We thus offer compelling evidence that the quantum model may have significantly more complexity theoretic power than the probabilistic Turing Machine. In fact, drawing on this work, Shor (1994) has recently developed remarkable new quantum polynomial-time algorithms for the discrete logarithm and integer factoring problems.
FOCS	Efficient Oblivious Branching Programs for Threshold Functions	Rakesh K. Sinha,Jayram S. Thathachar	1994	In his survey paper on branching programs, A.A. Razborov (1991) asked the following question: Does every rectifier-switching network computing the majority of n bits have size n/sup 1+/spl Omega/(1/)? We answer this question in the negative by constructing a simple oblivious branching program of size O(n log/sup 3/ n/log log n log log log n) for computing any threshold function. This improves the previously best known upper bound of O(n/sup 3/2/) due to O.B. Lupanov (1965).
FOCS	Expander Codes	Michael Sipser,Daniel A. Spielman	1994	We present a new class of asymptotically good, linear error-correcting codes based upon expander graphs. These codes have linear time sequential decoding algorithms, logarithmic time parallel decoding algorithms with a linear number of processors, and are simple to understand. We present both randomized and explicit constructions for some of these codes. Experimental results demonstrate the extremely good performance of the randomly chosen codes.
FOCS	Computing with Very Weak Random Sources	Aravind Srinivasan,David Zuckerman	1994	For any fixed /spl epsiv/>0, we show how to simulate RP algorithms in time n/sup O(log n/) using the output of a /spl delta/-source with min-entropy R(/spl epsiv/). Such a weak random source is asked once for R(/spl epsiv/) bits; it outputs an R-bit string such that any string has probability at most 2/sup -R/(/spl epsiv//). If /spl epsiv/>1-1/(k+1), our BPP simulations take time n/sup O(log(k/ n)) (log/sup (k/) is the logarithm iterated k times). We also give a polynomial-time BPP simulation using Chor-Goldreich sources of min-entropy R/sup /spl Omega/(1/), which is optimal. We present applications to time-space tradeoffs, expander constructions, and the hardness of approximation. Also of interest is our randomness-efficient Leftover Hash Lemma, found independently by Goldreich and Wigderson.
FOCS	A note on the Theta number of Lovász and the generalized Delsarte bound	Mario Szegedy	1994	A note on the Theta number of Lovász and the generalized Delsarte bound
FOCS	On the Computation of Boolean Functions by Analog Circuits of Bounded Fan-in (Extended Abstract)	György Turán,Farrokh Vatan	1994	On the Computation of Boolean Functions by Analog Circuits of Bounded Fan-in (Extended Abstract)
FOCS	Maximum (s, t)-Flows in Planar Networks in O(|V| log |V|) Time	Karsten Weihe	1994	Let G=(V, A) be a directed, planar graph, let s, t /spl isin/ V, s/spl ne/t, and let c/sub a/>0 be the capacity of an arc a/spl isin/A. The problem is to find a maximum flow from s to t in G: subject to these capacities. The fastest algorithm known so far requires /spl Oscr/(|V|/spl middot//sup 3//spl radic/|V|/spl middot/log|V|) time, whereas the algorithm introduced in this paper requires only /spl Oscr/(|V|log|V|) time.
FOCS	A Lower Bound for the Monotone Depth of Connectivity	Andrew Chi-Chih Yao	1994	"We show that any monotone circuit for computing graph connectivity must have a depth greater than /spl Omega/((log n)/sup 3/2// log log n). This proves that UCONN/sub n/ is not in monotone NC/sup 1/. The proof technique, which is an adaptation of Razborov's approximation method, is also used to derive lower bounds for a general class of graph problems."
FOCS	35th Annual Symposium on Foundations of Computer Science, 20-22 November 1994, Santa Fe, New Mexico, USA		1994	35th Annual Symposium on Foundations of Computer Science, 20-22 November 1994, Santa Fe, New Mexico, USA
SODA	Reliable Benchmarks Using Numerical Instability.	Sigal Ar,Jin-yi Cai	1994	Reliable Benchmarks Using Numerical Instability.
SODA	Physical Mapping of Chromosomes Using Unique Probes.	Farid Alizadeh,Richard M. Karp,Deborah K. Weisser,Geoffrey Zweig	1994	Physical Mapping of Chromosomes Using Unique Probes.
SODA	Matching Nuts and Bolts.	Noga Alon,Manuel Blum,Amos Fiat,Sampath Kannan,Moni Naor,Rafail Ostrovsky	1994	Matching Nuts and Bolts.
SODA	Selection in the Presence of Noise: The Design of Playoff Systems.	Micah Adler,Peter Gemmell,Mor Harchol-Balter,Richard M. Karp,Claire Kenyon	1994	Selection in the Presence of Noise: The Design of Playoff Systems.
SODA	Surface Approximation and Geometric Partitions.	Pankaj K. Agarwal,Subhash Suri	1994	"Motivated by applications in computer graphics, visualization, and scientific computation, we study the computational complexity of the following problem: given a set S of n points sampled from a bivariate function f(x,y) and an input parameter $\eps > 0$, compute a piecewise-linear function $\Sigma(x,y)$ of minimum complexity (that is, an xy-monotone polyhedral surface, with a minimum number of vertices, edges, or faces) such that $| \Sigma(x_p, y_p) \; - \; z_p | \:\:\leq\:\: \eps$ for all $(x_p, y_p, z_p) \in S$. We give hardness evidence for this problem, by showing that a closely related problem is NP-hard. The main result of our paper is a polynomial-time approximation algorithm that computes a piecewise-linear surface of size O(Ko log Ko), where Ko is the complexity of an optimal surface satisfying the constraints of the problem.The technique developed in our paper is more general and applies to several other problems that deal with partitioning of points (or other objects) subject to certain geometric constraints. For instance, we get the same approximation bound for the following problem arising in machine learning: given n ""red"" and m ""blue"" points in the plane, find a minimum number of pairwise disjoint triangles such that each blue point is covered by some triangle and no red point lies in any of the triangles."
SODA	Let Sleeping Files Lie: Pattern Matching in Z-compressed Files.	Amihood Amir,Gary Benson,Martin Farach	1994	Let Sleeping Files Lie: Pattern Matching in Z-compressed Files.
SODA	Efficient Routing and Scheduling Algorithms for Optical Networks.	Alok Aggarwal,Amotz Bar-Noy,Don Coppersmith,Rajiv Ramaswami,Baruch Schieber,Madhu Sudan	1994	Efficient Routing and Scheduling Algorithms for Optical Networks.
SODA	A Scaling Technique for Better Network Design.	Manica Aggarwal,Naveen Garg	1994	A Scaling Technique for Better Network Design.
SODA	Optimal Parallel Sorting in Multi-Level Storage.	Alok Aggarwal,C. Greg Plaxton	1994	We adapt the Sharesort algorithm of Cypher and Plaxton to run on various parallel models of multi-level storage, and analyze its resulting performance. Sharesort was originally defined in the context of sorting n records on an n-processor hypercubic network. In that context, it is not known whether Sharesort is asymptotically optimal. Nonetheless, we find that Sharesort achieves optimal time bounds for parallel sorting in multi-level storage, under a variety of models that have been defined in the literature.
SODA	On the Greedy Heuristic for Matchings.	Jonathan Aronson,Martin E. Dyer,Alan M. Frieze,Stephen Suen	1994	On the Greedy Heuristic for Matchings.
SODA	An Optimal Algorithm for Approximate Nearest Neighbor Searching.	Sunil Arya,David M. Mount,Nathan S. Netanyahu,Ruth Silverman,Angela Y. Wu	1994	An Optimal Algorithm for Approximate Nearest Neighbor Searching.
SODA	Competitive Routing of Virtual Circuits with Unknown Duration.	Baruch Awerbuch,Yossi Azar,Serge A. Plotkin,Orli Waarts	1994	Competitive Routing of Virtual Circuits with Unknown Duration.
SODA	Competitive Non-Preemptive Call Control.	Baruch Awerbuch,Yair Bartal,Amos Fiat,Adi Rosén	1994	Competitive Non-Preemptive Call Control.
SODA	Exact Analysis of a Priority Queue Algorithm for Random Variate Generation.	Eric Bach	1994	Exact Analysis of a Priority Queue Algorithm for Random Variate Generation.
SODA	Approximation Algorithms for the Vertex Feedback Set Problem with Applications to Constraint Satisfaction and Bayesian Inference.	Reuven Bar-Yehuda,Dan Geiger,Joseph Naor,Ron M. Roth	1994	Approximation Algorithms for the Vertex Feedback Set Problem with Applications to Constraint Satisfaction and Bayesian Inference.
SODA	The Subtree Max Gap Problem with Application to Parallel String Covering.	Amir M. Ben-Amram,Omer Berkman,Costas S. Iliopoulos,Kunsoo Park	1994	The Subtree Max Gap Problem with Application to Parallel String Covering.
SODA	Approximating Maximum Independent Set in Bounded Degree Graphs.	Piotr Berman,Martin Fürer	1994	Approximating Maximum Independent Set in Bounded Degree Graphs.
SODA	Optimal Construction of Edge-Disjoint Paths in Random Graphs.	Andrei Z. Broder,Alan M. Frieze,Stephen Suen,Eli Upfal	1994	Given a graph G=(V,E) with n vertices, m edges, and a family of $\kappa$ pairs of vertices in $V$, we are interested in finding for each pair (ai, bi) a path connecting ai to bi such that the set of $\kappa$ paths so found is edge disjoint. (For arbitrary graphs the problem is ${\cal NP}$-complete, although it is in ${\cal P}$ if $\kappa$ is fixed.)We present a polynomial time randomized algorithm for finding the optimal number of edge disjoint paths (up to constant factors) in the random graph Gn,m for all edge densities above the connectivity threshold. (The graph is chosen first; then an adversary chooses the pairs of endpoints.) Our results give the first tight bounds for the edge-disjoint paths problem for any nontrivial class of graphs.
SODA	On Degeneracy in Geometric Computations.	Christoph Burnikel,Kurt Mehlhorn,Stefan Schirra	1994	On Degeneracy in Geometric Computations.
SODA	Linear and O(n log n) Time Minimum-Cost Matching Algorithms for Quasi-Convex Tours.	Samuel R. Buss,Peter N. Yianilos	1994	Linear and O(n log n) Time Minimum-Cost Matching Algorithms for Quasi-Convex Tours.
SODA	New Results on the Old k-Opt Algorithm for the TSP.	Barun Chandra,Howard J. Karloff,Craig A. Tovey	1994	New Results on the Old k-Opt Algorithm for the TSP.
SODA	A Las Vegas O(n) Algorithm for the Cardinality of a Maximum Matching.	Joseph Cheriyan	1994	A Las Vegas O(n) Algorithm for the Cardinality of a Maximum Matching.
SODA	Shortest Paths Algorithms: Theory and Experimental Evaluation.	Boris V. Cherkassky,Andrew V. Goldberg,Tomasz Radzik	1994	Shortest Paths Algorithms: Theory and Experimental Evaluation.
SODA	Recognizing Balanced 0, +/- Matrices.	Michele Conforti,Gérard Cornuéjols,Ajai Kapoor,Kristina Vuskovic	1994	Recognizing Balanced 0, +/- Matrices.
SODA	Roots of a Polynomial and its Derivatives.	Don Coppersmith,C. Andrew Neff	1994	Roots of a Polynomial and its Derivatives.
SODA	Neighborhood Preserving Hashing and Approximate Queries.	Danny Dolev,Yuval Harari,Nathan Linial,Noam Nisan,Michal Parnas	1994	Let $D \subseteq \Sigma^n$ be a dictionary. We look for efficient data structures and algorithms to solve the following approximate query problem: Given a query $u \in \Sigma^n$ list all words $v \in D$ that are close to u in Hamming distance.The problem reduces to the following combinatorial problem: Hash the vertices of the n-dimensional hypercube into buckets so that (1) the c-neighborhood of each vertex is mapped into at most k buckets and (2) no bucket is too large.Lower and upper bounds are given for the tradeoff between k and the size of the largest bucket. These results are used to derive bounds for the approximate query problem.
SODA	Maximal Empty Ellipsoids.	Rex A. Dwyer,William F. Eddy	1994	Maximal Empty Ellipsoids.
SODA	Approximately Counting Hamilton Cycles in Dense Graphs.	Martin E. Dyer,Alan M. Frieze,Mark Jerrum	1994	Approximately Counting Hamilton Cycles in Dense Graphs.
SODA	A Near-Linear Algorithm for the Planar Segment Center Problem.	Alon Efrat,Micha Sharir	1994	A Near-Linear Algorithm for the Planar Segment Center Problem.
SODA	Average Case Analysis of Dynamic Geometric Optimization.	David Eppstein	1994	Average Case Analysis of Dynamic Geometric Optimization.
SODA	Clustering for Faster Network Simplex Pivots.	David Eppstein	1994	Clustering for Faster Network Simplex Pivots.
SODA	Fast Comparison of Evolutionary Trees.	Martin Farach,Mikkel Thorup	1994	Fast Comparison of Evolutionary Trees.
SODA	A Sublinear Parallel Algorithm for Stable Matching.	Tomás Feder,Nimrod Megiddo,Serge A. Plotkin	1994	A Sublinear Parallel Algorithm for Stable Matching.
SODA	Low-degree Tests.	Katalin Friedl,Zsolt Hátsági,Alexander Shen	1994	Low-degree Tests.
SODA	The Complexity of Resolvent Resolved.	Giovanni Gallo,Bhubaneswar Mishra	1994	The Complexity of Resolvent Resolved.
SODA	The QRQW PRAM: Accounting for Contention in Parallel Algorithms.	Phillip B. Gibbons,Yossi Matias,Vijaya Ramachandran	1994	The QRQW PRAM: Accounting for Contention in Parallel Algorithms.
SODA	Improved Approximation Algorithms for Network Design Problems.	Michel X. Goemans,Andrew V. Goldberg,Serge A. Plotkin,David B. Shmoys,Éva Tardos,David P. Williamson	1994	Improved Approximation Algorithms for Network Design Problems.
SODA	Path Problems in Skew-Symmetric Graphs.	Andrew V. Goldberg,Alexander V. Karzanov	1994	Path Problems in Skew-Symmetric Graphs.
SODA	Optimal Parallel Approximation for Prefix Sums and Integer Sorting.	Michael T. Goodrich,Yossi Matias,Uzi Vishkin	1994	Optimal Parallel Approximation for Prefix Sums and Integer Sorting.
SODA	Moments of Inertia and Graph Separators.	Keith D. Gremban,Gary L. Miller,Shang-Hua Teng	1994	Moments of Inertia and Graph Separators.
SODA	An Efficient Algorithm for Dynamic Text Indexing.	Ming Gu,Martin Farach,Richard Beigel	1994	An Efficient Algorithm for Dynamic Text Indexing.
SODA	Queueing Analysis of Oblivious Packet-Routing Networks.	Mor Harchol-Balter,Paul E. Black	1994	Queueing Analysis of Oblivious Packet-Routing Networks.
SODA	Learning Binary Matroid Ports.	Lisa Hellerstein,Collette R. Coullard	1994	Learning Binary Matroid Ports.
SODA	Polynomial Time Algorithms for Some Evacuation Problems.	Bruce Hoppe,Éva Tardos	1994	Polynomial Time Algorithms for Some Evacuation Problems.
SODA	Comparing Point Sets Under Projection.	Daniel P. Huttenlocher,Jon M. Kleinberg	1994	Comparing Point Sets Under Projection.
SODA	Minimizing Channel Density by Lateral Shifting of Components.	David S. Johnson,Andrea S. LaPaugh,Ron Y. Pinter	1994	Minimizing Channel Density by Lateral Shifting of Components.
SODA	Optimal Constructions of Hybrid Algorithms.	Ming-Yang Kao,Yuan Ma,Michael Sipser,Yiqun Lisa Yin	1994	Optimal Constructions of Hybrid Algorithms.
SODA	Using Randomized Sparsification to Approximate Minimum Cuts.	David R. Karger	1994	Using Randomized Sparsification to Approximate Minimum Cuts.
SODA	A Better Algorithm for an Ancient Scheduling Problem.	David R. Karger,Steven J. Phillips,Eric Torng	1994	A Better Algorithm for an Ancient Scheduling Problem.
SODA	Two and Higher Dimensional Pattern Matching in Optimal Expected Time.	Juha Kärkkäinen,Esko Ukkonen	1994	Algorithms with optimal expected running time are presented for searching the occurrences of a two-dimensional m X m pattern P in a two-dimensional n X n text T over an alphabet of size c. The algorithms are based on placing in the text a static grid of test points, determined only by n, m, and c (not dynamically by earlier test results). Using test strings read from the test points the algorithms eliminate as many potential occurrences of P as possible. The remaining potential occurrences are separately checked for actual occurrences. A suitable choice of the test point set leads to algorithms with expected running time O(n2logc m2/m2) using the uniform Bernoulli model of randomness. This is shown to be optimal by a generalization of a one-dimensional lower bound result by Yao. Experimental results show that the algorithms are efficient in practice, too. The method is also generalized for the k mismatches problem. The resulting algorithm has expected running time O(kn2logc m2/m2), provided that $k\leq(m\lfloor m/\lceil\log_c m^2\rceil\rfloor-1)/2$.\ All algorithms need preprocessing of P which takes time and space O(m2). The text processing can be done on-line, using a rather small window. The algorithms easily generalize to d-dimensional matching for any d.
SODA	Derandomizing Algorithms for Routing and Sorting on Meshes.	Michael Kaufmann,Jop F. Sibeyn,Torsten Suel	1994	Derandomizing Algorithms for Routing and Sorting on Meshes.
SODA	Reconstructing a History of Recombinations from a Set of Sequences.	John D. Kececioglu,Dan Gusfield	1994	Reconstructing a History of Recombinations from a Set of Sequences.
SODA	Approximating the Minimum Equivalent Diagraph.	Samir Khuller,Balaji Raghavachari,Neal E. Young	1994	"The MEG (minimum equivalent graph) problem is the following: ""Given a directed graph, find a smallest subset of the edges that maintains all reachability relations between nodes."" This problem is NP-hard; this paper gives an approximation algorithm achieving a performance guarantee of about 1.64 in polynomial time. The algorithm achieves a performance guarantee of 1.75 in the time required for transitive closure. The heart of the MEG problem is the minimum SCSS (strongly connected spanning subgraph) problem --- the MEG problem restricted to strongly connected digraphs. For the minimum SCSS problem, the paper gives a practical, nearly linear-time implementation achieving a performance guarantee of 1.75. The algorithm and its analysis are based on the simple idea of contracting long cycles. The analysis applies directly to $2$-\Exchange, a general ""local improvement"" algorithm, showing that its performance guarantee is 1.75."
SODA	Optimal Prediction for Prefetching in the Worst Case.	P. Krishnan,Jeffrey Scott Vitter	1994	Response time delays caused by I/O are a major problem in many systems and database applications. Prefetching and cache replacement methods are attracting renewed attention because of their success in avoiding costly I/Os. Prefetching can be looked upon as a type of online sequential prediction, where the predictions must be accurate as well as made in a computationally efficient way. Unlike other online problems, prefetching cannot admit a competitive analysis, since the optimal offline prefetcher incurs no cost when it knows the future page requests. Previous analytical work on prefetching [. Vitter Krishnan 1991.] [J. Assoc. Comput. Mach., 143 (1996), pp. 771--793] consisted of modeling the user as a probabilistic Markov source. In this paper, we look at the much stronger form of worst-case analysis and derive a randomized algorithm for pure prefetching. We compare our algorithm for every page request sequence with the important class of finite state prefetchers, making no assumptions as to how the sequence of page requests is generated. We prove analytically that the fault rate of our online prefetching algorithm converges almost surely for every page request sequence to the fault rate of the optimal finite state prefetcher for the sequence. This analysis model can be looked upon as a generalization of the competitive framework, in that it compares an online algorithm in a worst-case manner over all sequences with a powerful yet nonclairvoyant opponent. We simultaneously achieve the computational goal of implementing our prefetcher in optimal constant expected time per prefetched page using the optimal dynamic discrete random variate generator of [. Matias Matias, Vitter, and Ni [Proc. 4th Annual SIAM/ACM Symposium on Discrete Algorithms, Austin, TX, January 1993].
SODA	On-line Search in a Simple Polygon.	Jon M. Kleinberg	1994	On-line Search in a Simple Polygon.
SODA	An Effective Additive Basis for the Integers.	Mihail N. Kolountzakis	1994	An Effective Additive Basis for the Integers.
SODA	Generating Low-Degree 2-Spanners.	Guy Kortsarz,David Peleg	1994	A k-spanner of a connected graph G = (V,E) is a subgraph G\spr consisting of all the vertices of V and a subset of the edges, with the additional property that the distance between any two vertices in G\spr is larger than that distance in G by no more than a factor of k. This paper concerns the problem of finding a 2-spanner in a given graph, with minimum maximum degree. A randomized approximation algorithm is provided for this problem, with approximation ration of [O\tilde](D1/4).
SODA	An Optimal RAM Implementation of Catenable Min Double-ended Queues.	S. Rao Kosaraju	1994	An Optimal RAM Implementation of Catenable Min Double-ended Queues.
SODA	Online Interval Scheduling.	Richard J. Lipton,Andrew Tomkins	1994	Online Interval Scheduling.
SODA	Tight Bounds for Dynamic Storage Allocation.	Michael Luby,Joseph Naor,Ariel Orda	1994	Tight Bounds for Dynamic Storage Allocation.
SODA	Scheduling Malleable and Nonmalleable Parallel Tasks.	Walter Ludwig,Prasoon Tiwari	1994	Scheduling Malleable and Nonmalleable Parallel Tasks.
SODA	Linear Programs for Randomized On-Line Algorithms.	Carsten Lund,Nick Reingold	1994	Linear Programs for Randomized On-Line Algorithms.
SODA	Computing the Covers of a String in Linear Time.	Dennis Moore,William F. Smyth	1994	Computing the Covers of a String in Linear Time.
SODA	Optimum Parallel Computations with Banded Matrices.	Victor Y. Pan,Isdor Sobze,Antoine Atinkpahoun	1994	Optimum Parallel Computations with Banded Matrices.
SODA	New Techniques for Approximating Complex Polynomial Zeros.	Victor Y. Pan	1994	New Techniques for Approximating Complex Polynomial Zeros.
SODA	On Optimal Strategies for Searching in Presence of Errors.	S. Muthukrishnan	1994	On Optimal Strategies for Searching in Presence of Errors.
SODA	Approximate Data Structures with Applications.	Yossi Matias,Jeffrey Scott Vitter,Neal E. Young	1994	Approximate Data Structures with Applications.
SODA	Linear-Time Modular Decomposition and Efficient Transitive Orientation of Comparability Graphs.	Ross M. McConnell,Jeremy Spinrad	1994	Linear-Time Modular Decomposition and Efficient Transitive Orientation of Comparability Graphs.
SODA	Maintaining Dynamic Sequences Under Equality-Tests in Polylogarithmic Time.	Kurt Mehlhorn,R. Sundar,Christian Uhrig	1994	Maintaining Dynamic Sequences Under Equality-Tests in Polylogarithmic Time.
SODA	Shallow Excluded Minors and Improved Graph Decompositions.	Serge A. Plotkin,Satish Rao,Warren D. Smith	1994	Shallow Excluded Minors and Improved Graph Decompositions.
SODA	Dynamic Two-Connectivity with Backtracking.	Johannes A. La Poutré,Jeffery Westbrook	1994	Dynamic Two-Connectivity with Backtracking.
SODA	An Efficient Parallel Algorithm for the General Planar Monotone Circuit Value Problem.	Vijaya Ramachandran,Honghua Yang	1994	An Efficient Parallel Algorithm for the General Planar Monotone Circuit Value Problem.
SODA	Optimal Randomized Parallel Algorithms for Computing the Row Maxima of a Totally Monotone Matrix.	Rajeev Raman,Uzi Vishkin	1994	Optimal Randomized Parallel Algorithms for Computing the Row Maxima of a Totally Monotone Matrix.
SODA	Testable Algorithms for Self-Avoiding Walks.	Dana Randall,Alistair Sinclair	1994	Testable Algorithms for Self-Avoiding Walks.
SODA	Spanning Trees Short or Small.	R. Ravi,Ravi Sundaram,Madhav V. Marathe,Daniel J. Rosenkrantz,S. S. Ravi	1994	We study the problem of finding small trees. Classical network design problems are considered with the additional constraint that only a specified number $k$ of nodes are required to be connected in the solution. A prototypical example is the $k$MST problem in which we require a tree of minimum weight spanning at least $k$ nodes in an edge-weighted graph. We show that the $k$MST problem is NP-hard even for points in the Euclidean plane. We provide approximation algorithms with performance ratio $2\sqrt{k}$ for the general edge-weighted case and $O(k^{1/4})$ for the case of points in the plane. Polynomial-time exact solutions are also presented for the class of treewidth-bounded graphs, which includes trees, series-parallel graphs, and bounded bandwidth graphs, and for points on the boundary of a convex region in the Euclidean plane. We also investigate the problem of finding short trees and, more generally, that of finding networks with minimum diameter. A simple technique is used to provide a polynomial-time solution for finding $k$-trees of minimum diameter. We identify easy and hard problems arising in finding short networks using a framework due to T. C. Hu.
SODA	Dynamic Algebraic Algorithms.	John H. Reif,Stephen R. Tate	1994	Dynamic Algebraic Algorithms.
SODA	Design of On-line Algorithms Using Hitting Times.	Prasad Tetali	1994	Random walks are well known for playing a crucial role in the design of randomized off-line as well as on-line algorithms. In this work we prove some basic identities for ergodic Markov chains (e.g., an interesting characterization of reversibility in Markov chains is obtained in terms of first passage times). Besides providing new insight into random walks on weighted graphs, we show how these identities give us a way of designing competitive randomized on-line algorithms for certain well-known problems.
SODA	Scheduling Parallel Tasks to Minimize Average Response Time.	John Turek,Uwe Schwiegelshohn,Joel L. Wolf,Philip S. Yu	1994	Scheduling Parallel Tasks to Minimize Average Response Time.
SODA	Computational Experience with an Approximation Algorithm on Large-Scale Euclidean Matching Instances.	David P. Williamson,Michel X. Goemans	1994	Computational Experience with an Approximation Algorithm on Large-Scale Euclidean Matching Instances.
SODA	Proceedings of the Fifth Annual ACM-SIAM Symposium on Discrete Algorithms. 23-25 January 1994, Arlington, Virginia.	Daniel Dominic Sleator	1994	Proceedings of the Fifth Annual ACM-SIAM Symposium on Discrete Algorithms. 23-25 January 1994, Arlington, Virginia.
STOC	A spectral technique for coloring random 3-colorable graphs (preliminary version).	Noga Alon,Nabil Kahale	1994	A spectral technique for coloring random 3-colorable graphs (preliminary version).
STOC	Color-coding: a new method for finding simple paths, cycles and other small subgraphs within large graphs.	Noga Alon,Raphael Yuster,Uri Zwick	1994	Color-coding: a new method for finding simple paths, cycles and other small subgraphs within large graphs.
STOC	Time-adaptive algorithms for synchronization.	Rajeev Alur,Hagit Attiya,Gadi Taubenfeld	1994	We consider concurrent systems in which there is an unknown upper bound on memory access time. Such a model is inherently different from the asynchronous model, where no such bound exists, and also from timing-based models, where such a bound exists and is known a priori. The appeal of our model lies in the fact that while it abstracts from implementation details, it is a better approximation of real concurrent systems than the asynchronous model. Furthermore, it is stronger than the asynchronous model, enabling us to design algorithms for problems that are unsolvable in the asynchronous model.Two basic synchronization problems, consensus and mutual exclusion, are investigated in a shared-memory environment that supports atomic read/write registers. We show that $\Theta(\Delta\frac{\log \Delta}{\log\log \Delta})$ is an upper and lower bound on the time complexity of consensus, where $\Delta$ is the (unknown) upper bound on memory access time. For the mutual exclusion problem, we design an efficient algorithm that takes advantage of the fact that some upper bound on memory access time exists. The solutions for both problems are even more efficient in the absence of contention, in which case their time complexity is a constant.
STOC	The complexity of searching a sorted array of strings.	Arne Andersson,Torben Hagerup,Johan Håstad,Ola Petersson	1994	The complexity of searching a sorted array of strings.
STOC	Choosing a learning team: a topological approach.	Kalvis Apsitis,Rusins Freivalds,Carl H. Smith	1994	Choosing a learning team: a topological approach.
STOC	Simulating quadratic dynamical systems is PSPACE-complete (preliminary version).	Sanjeev Arora,Yuval Rabani,Umesh V. Vazirani	1994	Simulating quadratic dynamical systems is PSPACE-complete (preliminary version).
STOC	Simulating access to hidden information while learning.	Peter Auer,Philip M. Long	1994	Simulating access to hidden information while learning.
STOC	Efficient asynchronous distributed symmetry breaking.	Baruch Awerbuch,Lenore Cowen,Mark A. Smith	1994	Efficient asynchronous distributed symmetry breaking.
STOC	Improved approximation algorithms for the multi-commodity flow problem and local competitive routing in dynamic networks.	Baruch Awerbuch,Tom Leighton	1994	Improved approximation algorithms for the multi-commodity flow problem and local competitive routing in dynamic networks.
STOC	Balanced allocations (extended abstract).	Yossi Azar,Andrei Z. Broder,Anna R. Karlin,Eli Upfal	1994	Suppose that we sequentially place n balls into n boxes by putting each ball into a randomly chosen box. It is well known that when we are done, the fullest box has with high probability lnn/lnlnn(1 + o(1)) balls in it. Suppose instead, that for each ball we choose two boxes at random and place the ball into the one which is less full at the time of placement. We show that with high probability, the fullest box contains only lnlnn/ln2 + O(1) balls - exponentially less than before. Furthermore, we show that a similar gap exists in the infinite process, where at each step one ball, chosen uniformly at random, is deleted, and one ball is added in the manner above. We discuss consequences of this and related theorems for dynamic resource allocation, hashing, and on-line load balancing.
STOC	Efficient probabilistic checkable proofs and applications to approximation.	Mihir Bellare,Shafi Goldwasser,Carsten Lund,Alexander Russell	1994	Efficient probabilistic checkable proofs and applications to approximation.
STOC	Improved non-approximability results.	Mihir Bellare,Madhu Sudan	1994	Improved non-approximability results.
STOC	The minimum latency problem.	Avrim Blum,Prasad Chalasani,Don Coppersmith,William R. Pulleyblank,Prabhakar Raghavan,Madhu Sudan	1994	The minimum latency problem.
STOC	Weakly learning DNF and characterizing statistical query learning using Fourier analysis.	Avrim Blum,Merrick L. Furst,Jeffrey C. Jackson,Michael J. Kearns,Yishay Mansour,Steven Rudich	1994	Weakly learning DNF and characterizing statistical query learning using Fourier analysis.
STOC	Receipt-free secret-ballot elections (extended abstract).	Josh Cohen Benaloh,Dwight Tuinstra	1994	Receipt-free secret-ballot elections (extended abstract).
STOC	On lazy randomized incremental construction.	Mark de Berg,Katrin Dobrindt,Otfried Schwarzkopf	1994	On lazy randomized incremental construction.
STOC	Scalable expanders: exploiting hierarchical random wiring.	Eric A. Brewer,Frederic T. Chong,Tom Leighton	1994	Scalable expanders: exploiting hierarchical random wiring.
STOC	Improved algorithms via approximations of probability distributions (extended abstract).	Suresh Chari,Pankaj Rohatgi,Aravind Srinivasan	1994	Improved algorithms via approximations of probability distributions (extended abstract).
STOC	Computational geometry: a retrospective.	Bernard Chazelle	1994	Computational geometry: a retrospective.
STOC	A near optimal algorithm for edge separators (preliminary version).	Fan R. K. Chung,S.-T. Yau	1994	A near optimal algorithm for edge separators (preliminary version).
STOC	Polylog-time and near-linear work approximation scheme for undirected shortest paths.	Edith Cohen	1994	Shortest paths computations constitute one of the most fundamental network problems. Nonetheless, known parallel shortest-paths algorithms are generally inefficient: they perform significantly more work (product of time and processors) than their sequential counterparts. This gap, known in the literature as the &ldquo;transitive closure bottleneck,&rdquo; poses a long-standing open problem. Our main result is an Omne0+s m+n1+e0 work polylog-time randomized algorithm that computes paths within (1 + O(1/polylog n) of shortest from s source nodes to all other nodes in weighted undirected networks with n nodes and m edges (for any fixed &egr;0>0). This work bound nearly matches the O&d5;sm sequential time. In contrast, previous polylog-time algorithms required nearly minO&d5; n3,O&d5; m2 work (even when s=1), and previous near-linear work algorithms required near-O(n) time. We also present faster sequential algorithms that provide good approximate distances only between &ldquo;distant&rdquo; vertices: We obtain an Om+snne 0 time algorithm that computes paths of weight (1+O(1/polylog n) dist + O(wmax polylog n), where dist is the corresponding distance and wmax is the maximum edge weight. Our chief instrument, which is of independent interest, are efficient constructions of sparse hop sets. A (d,&egr;)-hop set of a network G=(V,E) is a set E* of new weighted edges such that mimimum-weight d-edge paths in V,E&cup;E* have weight within (1+&egr;) of the respective distances in G. We construct hop sets of size On1+e0 where &egr;=O(1/polylog n) and d=O(polylog n).
STOC	On the power of finite automata with both nondeterministic and probabilistic states (preliminary version).	Anne Condon,Lisa Hellerstein,Samuel Pottle,Avi Wigderson	1994	On the power of finite automata with both nondeterministic and probabilistic states (preliminary version).
STOC	The connectivity carcass of a vertex subset in a graph and its incremental maintenance.	Yefim Dinitz,Alek Vainshtein	1994	The connectivity carcass of a vertex subset in a graph and its incremental maintenance.
STOC	Two prover protocols: low error at affordable rates.	Uriel Feige,Joe Kilian	1994	"We introduce the miss-match form for two-prover one-round proof systems. Any two-prover one-round proof system can be easily modified so as to be in miss-match form. Proof systems in miss-match form have the ""projection"" property that is important for deriving hardness of approximation results for NP-hard combinatorial optimization problems.Our main result is an upper bound on the number of parallel repetitions that suffice in order to reduce the error of miss-match proof systems from p to $\epsilon$. This upper bound depends only on p and on $\epsilon$ (polynomial in 1/(1-p) and in $1/\epsilon$). Based on previous work, it follows that for any $\epsilon >0,$ NP has two-prover one-round proof systems with logarithmic-sized questions, constant-sized answers, and error at most $\epsilon$.As part of our proof we prove upper bounds on the influence of random variables on multivariate functions, which may be of independent interest."
STOC	A minimal model for secure computation (extended abstract).	Uriel Feige,Joe Kilian,Moni Naor	1994	A minimal model for secure computation (extended abstract).
STOC	Optimality and domination in repeated games with bounded players.	Lance Fortnow,Duke Whang	1994	Optimality and domination in repeated games with bounded players.
STOC	Efficient splitting off algorithms for graphs.	Harold N. Gabow	1994	Efficient splitting off algorithms for graphs.
STOC	.879-approximation algorithms for MAX CUT and MAX 2SAT.	Michel X. Goemans,David P. Williamson	1994	.879-approximation algorithms for MAX CUT and MAX 2SAT.
STOC	Computational complexity and knowledge complexity (extended abstract).	Oded Goldreich,Rafail Ostrovsky,Erez Petrank	1994	Computational complexity and knowledge complexity (extended abstract).
STOC	Tiny families of functions with random properties (preliminary version): a quality-size trade-off for hashing.	Oded Goldreich,Avi Wigderson	1994	Tiny families of functions with random properties (preliminary version): a quality-size trade-off for hashing.
STOC	Lower bounds on testing membership to a polyhedron by algebraic decision trees.	Dima Grigoriev,Marek Karpinski,Nicolai Vorobjov	1994	Lower bounds on testing membership to a polyhedron by algebraic decision trees.
STOC	A weight-size trade-off for circuits with MOD m gates.	Vince Grolmusz	1994	A weight-size trade-off for circuits with MOD m gates.
STOC	Optimal parallel string algorithms: sorting, merging and computing the minimum.	Torben Hagerup	1994	Optimal parallel string algorithms: sorting, merging and computing the minimum.
STOC	Greed is good: approximating independent sets in sparse and bounded-degree graphs.	Magnús M. Halldórsson,Jaikumar Radhakrishnan	1994	Greed is good: approximating independent sets in sparse and bounded-degree graphs.
STOC	The computational complexity of recognizing permutation functions.	Keju Ma,Joachim von zur Gathen	1994	The computational complexity of recognizing permutation functions.
STOC	Optimal parallel suffix tree construction.	Ramesh Hariharan	1994	Optimal parallel suffix tree construction.
STOC	A simple constructive computability theorem for wait-free computation.	Maurice Herlihy,Nir Shavit	1994	A simple constructive computability theorem for wait-free computation.
STOC	Pseudorandomness for network algorithms.	Russell Impagliazzo,Noam Nisan,Avi Wigderson	1994	Pseudorandomness for network algorithms.
STOC	A functional equation often arising in the analysis of algorithms (extended abstract).	Philippe Jacquet,Wojciech Szpankowski	1994	A functional equation often arising in the analysis of algorithms (extended abstract).
STOC	Circuit complexity: from the worst case to the average case.	Andreas Jakoby,Rüdiger Reischuk,Christian Schindelhauer	1994	Circuit complexity: from the worst case to the average case.
STOC	Aligning sequences via an evolutionary tree: complexity and approximation.	Tao Jiang,Eugene L. Lawler,Lusheng Wang	1994	Aligning sequences via an evolutionary tree: complexity and approximation.
STOC	Two heads are better than two tapes.	Tao Jiang,Joel I. Seiferas,Paul M. B. Vitányi	1994	We show that a Turing machine with two single-head one-dimensional tapes cannot recognize the set.
STOC	Fault-tolerant scheduling.	Bala Kalyanasundaram,Kirk Pruhs	1994	We study fault-tolerant multiprocessor scheduling under the realistic assumption that the occurrence of faults cannot be predicted. The goal in these problems is to minimize the delay incurred by the jobs. Since this is an online problem we use competitive analysis to evaluate possible algorithms. For the problems of minimizing the makespan and minimizing the average completion time (for static release times), we give nonclairvoyant algorithms (both deterministic and randomized) that have provably asymptotically optimal competitive ratios. The main tool used by these algorithms to combat faults is redundancy. We also show that randomization has the same effect as redundancy.
STOC	Random sampling in cut, flow, and network design problems.	David R. Karger	1994	Random sampling in cut, flow, and network design problems.
STOC	On the fault tolerance of the butterfly.	Anna R. Karlin,Greg Nelson,Hisao Tamaki	1994	On the fault tolerance of the butterfly.
STOC	On the learnability of discrete distributions.	Michael J. Kearns,Yishay Mansour,Dana Ron,Ronitt Rubinfeld,Robert E. Schapire,Linda Sellie	1994	On the learnability of discrete distributions.
STOC	Low degree spanning trees of small weight.	Samir Khuller,Balaji Raghavachari,Neal E. Young	1994	Given $n$ points in the plane, the degree-$K$ spanning-tree problem asks for a spanning tree of minimum weight in which the degree of each vertex is at most $K$. This paper addresses the problem of computing low-weight degree-$K$ spanning trees for $K>2$. It is shown that for an arbitrary collection of $n$ points in the plane, there exists a spanning tree of degree 3 whose weight is at most 1.5 times the weight of a minimum spanning tree. It is shown that there exists a spanning tree of degree 4 whose weight is at most 1.25 times the weight of a minimum spanning tree. These results solve open problems posed by Papadimitriou and Vazirani. Moreover, if a minimum spanning tree is given as part of the input, the trees can be computed in $O(n)$ time. The results are generalized to points in higher dimensions. It is shown that for any $d \ge 3$, an arbitrary collection of points in $\Re^d$ contains a spanning tree of degree 3 whose weight is at most 5/3 times the weight of a minimum spanning tree. This is the first paper that achieves factors better than 2 for these problems.
STOC	Faster shortest-path algorithms for planar graphs.	Philip N. Klein,Satish Rao,Monika Rauch Henzinger,Sairam Subramanian	1994	We give a linear-time algorithm for single-source shortest paths in planar graphs with nonnegative edge-lengths. Our algorithm also yields a linear-time algorithm for maximum flow in a planar graph with the source and sink on the same face. The previous best algorithms for these problems required $\Omega(n \sqrt{\log n})$ time where $n$ is the number of nodes in the input graph. For the case where negative edge-lengths are allowed, we give an algorithm requiring $O(n^{4/3} \log nL)$ time, where $L$ is the absolute value of the most negative length. Previous algorithms for shortest paths with negative edge-lengths required $\Omega(n^{3/2})$ time. Our shortest-path algorithm yields an $O(n^{4/3} \log n)$-time algorithm for finding a perfect matching in a planar bipartite graph. A similar improvement is obtained for maximum flow in a directed planar graph.
STOC	A randomized linear-time algorithm for finding minimum spanning trees.	Philip N. Klein,Robert Endre Tarjan	1994	We present a randomized linear-time algorithm for finding a minimum spanning tree in a connected graph with edge weights. The algorithm is a modification of one proposed by Karger and uses random sampling in combination with a recently discovered linear-time algorithm for verifying a minimum spanning tree. Our computational model is a unit-cost random-access machine with the restriction that the only operations allowed on edge weights are binary comparisons.
STOC	Fast algorithms for finding randomized strategies in game trees.	Daphne Koller,Nimrod Megiddo,Bernhard von Stengel	1994	Fast algorithms for finding randomized strategies in game trees.
STOC	Real-time pattern matching and quasi-real-time construction of suffix trees (preliminary version).	S. Rao Kosaraju	1994	Real-time pattern matching and quasi-real-time construction of suffix trees (preliminary version).
STOC	On the computational power of depth 2 circuits with threshold and modulo gates.	Matthias Krause,Pavel Pudlák	1994	On the computational power of depth 2 circuits with threshold and modulo gates.
STOC	The complexity of verification.	Robert P. Kurshan	1994	The complexity of verification.
STOC	Simple strategies for large zero-sum games with applications to complexity theory.	Richard J. Lipton,Neal E. Young	1994	Simple strategies for large zero-sum games with applications to complexity theory.
STOC	On contention resolution protocols and associated probabilistic phenomena.	Philip D. MacKenzie,C. Greg Plaxton,Rajmohan Rajaraman	1994	Consider an on-line scheduling problem in which a set of abstract processes are competing for the use of a number of resources. Further assume that it is either prohibitively expensive or impossible for any two of the processes to directly communicate with one another. If several processes simultaneously attempt to allocate a particular resource (as may be expected to occur, since the processes cannot easily coordinate their allocations), then none succeed. In such a framework, it is a challenge to design efficient contention resolution protocols.Two recently-proposed approaches to the problem of PRAM emulation give rise to scheduling problems of the above kind. In one approach, the resources (in this case, the shared memory cells) are duplicated and distributed randomly. We analyze a simple and efficient deterministic algorithm for accessing some subset of the duplicated resources. In the other approach, we analyze how quickly we can access the given (nonduplicated) resource using a simple randomized strategy. We obtain precise bounds on the performance of both strategies. We anticipate that our results with find other applications.
STOC	Trade-offs between communication throughput and parallel time.	Yishay Mansour,Noam Nisan,Uzi Vishkin	1994	Trade-offs between communication throughput and parallel time.
STOC	Approximation schemes for PSPACE-complete problems for succinct specifications (preliminary version).	Madhav V. Marathe,Harry B. Hunt III,Richard Edwin Stearns,Venkatesh Radhakrishnan	1994	Approximation schemes for PSPACE-complete problems for succinct specifications (preliminary version).
STOC	Lower bounds for union-split-find related problems on random access machines.	Peter Bro Miltersen	1994	We prove =(Clog logn ) lower bounds on the random access machine complexity of several dynamic, partially dynamic and static data structure problems, including the union-split-find problem, dynamic prefix problems and one-dimensional range query problems. The proof techniques include a general technique using perfect hashing for reducing static data structure problems (with a restriction of the size of the structure) into partially dynamic data structure problems (with no such restriction), thus providing a way to transfer lower bounds. We use a generalization of a method due to Ajtai for proving the lower bounds on the static problems, but describe the proof in terms of communication complexity, revealing a striking similarity to the proof used by Karchmer and Wigderson for proving lower bounds on the monotone circuit depth of connectivity.
STOC	Lower bounds for parallel linear programming and other problems.	Ketan Mulmuley	1994	Lower bounds for parallel linear programming and other problems.
STOC	Non-standard stringology: algorithms and complexity.	S. Muthukrishnan,Krishna V. Palem	1994	Non-standard stringology: algorithms and complexity.
STOC	Search for the maximum of a random walk.	Andrew M. Odlyzko	1994	Search for the maximum of a random walk.
STOC	Simple and efficient leader election in the full information model.	Rafail Ostrovsky,Sridhar Rajagopalan,Umesh V. Vazirani	1994	In this paper, we study the leader election problem in the full information model. We show two results in this context. First, we exhibit a constructive $O(\log N)$ round protocol that is resilient against linear size coalitions. That is, our protocol is resilient against any coalition of size less then $\beta N$ for some constant (but small) value of $\beta$. Second, we provide an easy, non-constructive probabilistic argument that shows the existence of $O(\log N)$ round protocol in which $\beta$ can be made as large as $\half - \epsilon$ for any positive $\epsilon$. Our protocols are extremely simple.
STOC	On complexity as bounded rationality (extended abstract).	Christos H. Papadimitriou,Mihalis Yannakakis	1994	On complexity as bounded rationality (extended abstract).
STOC	A theory of clock synchronization (extended abstract).	Boaz Patt-Shamir,Sergio Rajsbaum	1994	A theory of clock synchronization (extended abstract).
STOC	On point location and motion planning among simplices.	Marco Pellegrini	1994	Let $\SS$ be a set of $n$ possibly intersecting $(d-1)$-simplices in $d$-space for $d \geq 2$, and let ${\cal A}(\SS)$ be the arrangement of $\SS$. Let $K = |{\cal A}(\SS)|$ be the number of faces of any dimension in the arrangement of $\SS$. A data structure is described that uses storage $O(n^{d-1+\eps} +K)$ and is built {\em deterministically} in time $O(n^{d-1+\eps} +K\log n)$, where $\eps >0$ is an arbitrarily small constant, such that the face of ${\cal A}(\SS)$ containing a query point is located in time $O(\log^3 n)$. If two query points are in the same cell of ${\cal A}(\SS)$, a collision-free path connecting them is produced. This result is obtained by exploiting powerful and so far overlooked properties of sparse nets introduced by Chazelle [{\em Discrete Comput. Geom.}, 9 (1993), pp. 145--158]. If the $(d-1)$-simplices in $\SS$ have pairwise-disjoint interiors and $d \geq 3$, improved bounds are obtained. A data structure is described that uses $O(n^{d-1})$ storage and is built deterministically in time $O(n^{d-1})$ such that point-location queries are solved in time $O(\log n)$. Also, as a by-product, this method gives the first optimal worst-case algorithm for triangulating a nonsimple polyhedron in 3-space.
STOC	Nearly-linear size holographic proofs.	Alexander Polishchuk,Daniel A. Spielman	1994	Nearly-linear size holographic proofs.
STOC	Alpha-algorithms for incremental planarity testing (preliminary version).	Johannes A. La Poutré	1994	Alpha-algorithms for incremental planarity testing (preliminary version).
STOC	Efficient routing in all-optical networks.	Prabhakar Raghavan,Eli Upfal	1994	Communication in all-optical networks requires novel routing paradigms. The high bandwidth of the optic fiber is utilized through wavelength-division multiplexing : A single physical optical link can carry several logical signals, provided that they are transmitted on different wavelengths. We study the problem of routing a set of requests (each of which is a pair of nodes to be connected by a path) on sparse networks using a limited number of wavelengths, ensuring that different paths using the same wavelength never use the same physical link.
STOC	A coding theorem for distributed computation.	Sridhar Rajagopalan,Leonard J. Schulman	1994	A coding theorem for distributed computation.
STOC	Improved data structures for fully dynamic biconnectivity.	Monika Rauch	1994	We present fully dynamic algorithms for maintaining the biconnected components in general and plane graphs. A fully dynamic algorithm maintains a graph during a sequence of insertions and and deletions of edges or isolated vertices. Let $m$ be the number of edges and $n$ be the number of vertices in a graph. The time per operation of the best known algorithms are $O(\sqrt{n})$ in general graphs and $O(\log n)$ in plane graphs for fully dynamic connectivity and $O(\min\{m^{2/3}, n\})$ in general graphs and $O(\sqrt{n})$ in plane graphs for fully dynamic biconnectivity. We improve the later running times to $(\min\{\sqrt{m}\log n, n \})$ in general graphs and $O(\log^{2}n)$ in plane graphs. Our algorithm for general graphs can also find the biconnected components of all vertices in time $O(n)$. The update times in general graphs are amortized. This shows that the biconnected components of a graph can be dynamically maintained almost as efficiently as the connected components.
STOC	Natural proofs.	Alexander A. Razborov,Steven Rudich	1994	Natural proofs.
STOC	Pseudorandom generators and learning algorithms for AC.	Meera Sitharam	1994	Pseudorandom generators and learning algorithms for AC.
STOC	Symmetry breaking for suffix tree construction.	Süleyman Cenk Sahinalp,Uzi Vishkin	1994	Symmetry breaking for suffix tree construction.
STOC	How to share a function securely.	Alfredo De Santis,Yvo Desmedt,Yair Frankel,Moti Yung	1994	How to share a function securely.
STOC	On the complexity of negation-limited Boolean networks.	Keisuke Tanaka,Tetsuro Nishino	1994	On the complexity of negation-limited Boolean networks.
STOC	An accelerated interior point method whose running time depends only on A (extended abstract).	Stephen A. Vavasis,Yinyu Ye	1994	An accelerated interior point method whose running time depends only on A (extended abstract).
STOC	The amazing power of pairwise independence (abstract).	Avi Wigderson	1994	The amazing power of pairwise independence (abstract).
STOC	Time bounds for mutual exclusion and related problems.	Jae-Heon Yang,James H. Anderson	1994	Time bounds for mutual exclusion and related problems.
STOC	Decision tree complexity and Betti numbers.	Andrew Chi-Chih Yao	1994	Decision tree complexity and Betti numbers.
STOC	An O(log k) approximation algorithm for the k minimum spanning tree problem in the plane.	Naveen Garg,Dorit S. Hochbaum	1994	An O(log k) approximation algorithm for the k minimum spanning tree problem in the plane.
STOC	Proceedings of the Twenty-Sixth Annual ACM Symposium on Theory of Computing, 23-25 May 1994, Montréal, Québec, Canada		1994	Proceedings of the Twenty-Sixth Annual ACM Symposium on Theory of Computing, 23-25 May 1994, Montréal, Québec, Canada
FOCS	Improved Algorithms and Analysis for Secretary Problems and Generalizations.	Miklós Ajtai,Nimrod Megiddo,Orli Waarts	1995	In the classical secretary problem, n objects from an ordered set arrive in random order, and one has to accept k of them so that the final decision about each object is made only on the basis of its rank relative to the ones already seen. Variants of the problem depend on the goal: either maximize the probability of accepting the best k objects, or minimize the expectation of the sum of the ranks (or powers of ranks) of the accepted objects. The problem and its generalizations are at the core of tasks with a large data set, in which it may be impractical to backtrack and select previous choices.Optimal algorithms for the special case of k = 1 are well known. Partial solutions for the first variant with general k are also known. In contrast, an explicit solution for the second variant with general k has not been known. It seems that the fact that the expected sum of powers of the ranks of selected items is bounded as n tends to infinity has been known to follow from standard results. We derive our results by obtaining explicit algorithms. For each $z \geq 1$, the resulting expected sum of the zth powers of the ranks of the selected objects is at most $k^{z + 1}/(z + 1) + C(z) \cdot k^{z + 0.5}\log k$, where log k \equiv \max\{1, \log_2 k\}$, whereas the best possible value at all is kz + 1/(z + 1) + O(kz). Our methods are very intuitive and apply to some generalizations. We also derive a lower bound on the trade-off between the probability of selecting the best object and the expected rank of the selected object.
FOCS	Linear Time Erasure Codes with Nearly Optimal Recovery (Extended Abstract).	Noga Alon,Jeff Edmonds,Michael Luby	1995	Linear Time Erasure Codes with Nearly Optimal Recovery (Extended Abstract).
FOCS	Sublogarithmic Searching without Multiplications.	Arne Andersson	1995	We show that a unit-cost RAM with word length w can maintain an ordered set of w-bit integers (or binary strings) under the operations search, insert, delete, nearest neighbour in O(/spl radic/(logn)) worst-case time and range queries in O(/spl radic/(logn)+size of output) worst-case time. The operations rely on AC/sup 0/ instructions only, thereby solving an open problem posed by Fredman and Willard. The data structure is simple. We also present a static data structure that can process a set of /spl Theta/O(logn) searches in O(lognloglogn) time.
FOCS	Reductions, Codes, PCPs, and Inapproximability.	Sanjeev Arora	1995	Many recent results show the hardness of approximating NP-hard functions. We formalize, in a very simple way, what these results involve: a code-like Levin reduction. Assuming a well-known complexity assumption, we show that such reductions cannot prove the NP-hardness of the following problems, where /spl epsiv/ is any positive fraction: (i) achieving an approximation ratio n/sup 1/2+/spl epsiv// for Clique, (ii) achieving an approximation ratio 1.5+/spl epsiv/ for Vertex Cover, and (iii) coloring a 3-colorable graph with O(logn) colors. In fact, we explain why current reductions cannot prove the NP-hardness of coloring 3-colorable graphs with 9 colors. Our formalization of a code-like reduction, together with our justification of why such reductions are natural, also clarifies why current proofs of inapproximability results use error-correcting codes.
FOCS	Gambling in a Rigged Casino: The Adversarial Multi-Arm Bandit Problem.	Peter Auer,Nicolò Cesa-Bianchi,Yoav Freund,Robert E. Schapire	1995	"In the multi-armed bandit problem, a gambler must decide which arm of K non-identical slot machines to play in a sequence of trials so as to maximize his reward. This classical problem has received much attention because of the simple model it provides of the trade-off between exploration (trying out each arm to find the best one) and exploitation (playing the arm believed to give the best payoff). Past solutions for the bandit problem have almost always relied on assumptions about the statistics of the slot machines. In this work, we make no statistical assumptions whatsoever about the nature of the process generating the payoffs of the slot machines. We give a solution to the bandit problem in which an adversary, rather than a well-behaved stochastic process, has complete control over the payoffs. In a sequence of T plays, we prove that the expected per-round payoff of our algorithm approaches that of the best arm at the rate O(T/sup -1/3/), and we give an improved rate of convergence when the best arm has fairly low payoff. We also consider a setting in which the player has a team of ""experts"" advising him on which arm to play; here, we give a strategy that will guarantee expected payoff close to that of the best expert. Finally, we apply our result to the problem of learning to play an unknown repeated matrix game against an all-powerful adversary."
FOCS	Tracking the Best Disjunction.	Peter Auer,Manfred K. Warmuth	1995	Littlestone developed a simple deterministic on-line learning algorithm for learning k-literal disjunctions. This algorithm (called {\sc Winnow}) keeps one weight for each of then variables and does multiplicative updates to its weights. We develop a randomized version of {\sc Winnow} and prove bounds for an adaptation of the algorithm for the case when the disjunction may change over time. In this case a possible target {\it disjunction schedule} &Tgr; is a sequence of disjunctions (one per trial) and the {\it shift size} is the total number of literals that are added/removed from the disjunctions as one progresses through the sequence.We develop an algorithm that predicts nearly as well as the best disjunction schedule for an arbitrary sequence of examples. This algorithm that allows us to track the predictions of the best disjunction is hardly more complex than the original version. However, the amortized analysis needed for obtaining worst-case mistake bounds requires new techniques. In some cases our lower bounds show that the upper bounds of our algorithm have the right constant in front of the leading term in the mistake bound and almost the right constant in front of the second leading term. Computer experiments support our theoretical findings.
FOCS	Load Balancing in the L Norm.	Baruch Awerbuch,Yossi Azar,Edward F. Grove,Ming-Yang Kao,P. Krishnan,Jeffrey Scott Vitter	1995	Load Balancing in the L Norm.
FOCS	Application-Controlled Paging for a Shared Cache (Extended Abstract).	Rakesh D. Barve,Edward F. Grove,Jeffrey Scott Vitter	1995	Application-Controlled Paging for a Shared Cache (Extended Abstract).
FOCS	Integral Geometry of Higher-Dimensional Polytopes and the Average Case in Combinatorial Optimization.	Alexander I. Barvinok	1995	We consider the average case behavior of a linear optimization problem on various series of combinatorially interesting polytopes. From general results of integral geometry it follows that for all but an asymptotically negligible fraction of linear functions a polytope can be replaced by a pair of concentric balls with asymptotically equal radii so that the optimal value of the linear function on the polytope is in the interval between the optimal values of the linear function on these balls. In particular, we show that the average case behavior of the assignment problem, traveling salesman problem, and, generally speaking, of any optimization problem on a polynomial fraction of all permutations is the same.
FOCS	Algorithms for Matrix Groups and the Tits Alternative.	Robert Beals	1995	Tits has shown that a finitely generated linear group either contains a nonabelian free group or has a solvable subgroup of finite index. We give a polynomial time algorithm for deciding which of these two conditions holds for a given finitely generated matrix group over an algebraic number field. Noting that many computational problems are undecidable for groups with nonabelian free subgroups, we investigate the complexity of problems relating to linear groups with solvable subgroups of finite index. For such a group G, we are able in polynomial time to compute a homomorphism phi such that phi(G) is a finite matrix group and the kernel of phi is solvable. If in addition G has a nilpotent subgroup of finite index, we obtain much stronger results. These include an effective encoding of elements of G such that the encoding length of an element obtained as a product of length L over the generators is 0(log L) times a polynomial in the input length. This result is the best possible; it has been shown by Tits and Wolf that if a finitely generated matrix group does not have a nilpotent subgroup of finite index, then the number of group elements expressible as words of length L over the generators grows as c^L for some constant c<1 depending on G. For groups with abelian subgroups of finite index, we obtain a Las Vegas algorithm for several basic computational tasks including membership testing and computing a presentation. This generalizes recent work of Beals and Babai, who give a Las Vegas algorithm for the case of finite groups, as well as recent work of Babai, Beals, Cai, Ivanyos, and Luks, who give a deterministic algorithm for the case of abelian groups.
FOCS	Improved Depth Lower Vounds for Small Distance Connectivity.	Paul Beame,Russell Impagliazzo,Toniann Pitassi	1995	Improved Depth Lower Vounds for Small Distance Connectivity.
FOCS	3-Coloring in Time O(1.3446): A No-MIS Algorithm.	Richard Beigel,David Eppstein	1995	3-Coloring in Time O(1.3446): A No-MIS Algorithm.
FOCS	Fault Diagnosis in a Flash.	Richard Beigel,William Hurwood,Nabil Kahale	1995	"Consider a set of n processors that can communicate with each other. Assume that each processor can be either ""good"" or ""faulty"". Also assume that the processors can test each other. We consider how to use parallel testing rounds to identify the faulty processors, given an upper bound t on their number. We prove that 4 rounds are necessary and sufficient when 2/spl radic/(2n)/spl les/0.03n (for n sufficiently large). Furthermore, at least 5 rounds are necessary when t/spl ges/0.49n (for n sufficiently large), and 10 rounds are sufficient when t>0.5n (for all n). (It is well known that no general solution is possible when t/spl ges/0.5n)."
FOCS	Lower Bounds for Monotone Span Programs.	Amos Beimel,Anna Gál,Mike Paterson	1995	Span programs provide a linear algebraic model of computation. Lower Bounds for span programs imply lower bounds for formula size, symmetric branching programs and for contact schemes. Monotone span programs correspond also to linear secret-sharing schemes. We present a new technique for proving lower bounds for monotone span programs, and prove a lower bound of /spl Omega/(m/sup 2.5/) for the 6-clique function. Our results improve on the previously known bounds for explicit functions.
FOCS	Linearity Testing in Characteristic Two.	Mihir Bellare,Don Coppersmith,Johan Håstad,Marcos A. Kiwi,Madhu Sudan	1995	Let Dist(f,g)=Pr/sub u/ [f(u)/spl ne/g(u)] denote the relative distance between functions f,g mapping from a group G to a group H, and let Dist(f) denote the minimum, over all linear functions (homomorphisms) g, of Dist(f,g). Given a function f:G/spl rarr/H we let Err(f)=Pr/sub u/,v[f(u)+f(v)/spl ne/f(u+v)] denote the rejection probability of the BLR (Blum-Luby-Rubinfeld) linearity test. Linearity testing is the study of the relationship between Err(f) and Dist(f), and in particular the study of lower bounds on Err(f) in terms of Dist(f). The case we are interested in is when the underlying groups are G=GF(2)/sup n/ and H=GF(2). The corresponding test is used in the construction of efficient PCPs and thence in the derivation of hardness of approximation results, and, in this context, improved analyses translate into better non-approximability results. However, while several analyses of the relation of Err(f) to Dist(f) are known, none is tight. We present a description of the relationship between Err(f) and Dist(f) which is nearly complete in all its aspects, and entirely complete (i.e. tight) in some. In particular we present functions L,U:[0,1]/spl rarr/[0,1] such that for all x/spl isin/[0,1] we have L(x)>Err(f)/spl les/U(x) whenever Dist(f)=x, with the upper bound being tight on the whole range, and the lower bound tight on a large part of the range and close on the rest. Part of our strengthening is obtained by showing a new connection between the linearity testing problem and Fourier analysis, a connection which may be of independent interest. Our results are used by M. Bellare et al. (1995) to present the best known hardness results for Max3SAT and other MaxSNP problems.
FOCS	Free Bits, PCPs and Non-Approximability - Towards Tight Results.	Mihir Bellare,Oded Goldreich,Madhu Sudan	1995	"The first part of this paper presents new proof systems and improved non-approximability results. In particular we present a proof system for NP using logarithmic randomness and two amortized free bits, so that Max clique is hard within N/sup 1/3/ and chromatic number within N/sup 1/5/. We also show hardness of 38/37 for Max-3-SAT, 27/26 for vertex cover, 82/81 for Max-cut, and 94/93 for Max-2-SAT. The second part of this paper presents a ""reverse"" of the FGLSS connection by showing that an NP-hardness result for the approximation of Max clique to within a factor of N/sup 1/(g+1/) would imply a probabilistic verifier for NP with logarithmic randomness and amortized free-bit complexity g. We also show that ""existing techniques"" won't yield proof systems of less than two bits in amortized free bit complexity. Finally, we initiate a comprehensive study of PCP and FPCP parameters, proving several triviality results and providing several useful transformations."
FOCS	A Representation of Cuts within 6/5 Times the Edge Connectivity with Applications.	András A. Benczúr	1995	Let G be an undirected c-edge connected graph. In this paper we give an O(n/sup 2/)-sized planar geometric representation for all edge cuts with capacity less than 6/5c. The representation can be very efficiently built, by using a single run of the Karger-Stein algorithm for finding near-mincuts. We demonstrate that the representation provides an efficient query structure for near-mincuts, as well as a new proof technique through geometric arguments. We show that in algorithms based on edge splitting, computing our representation O(log n) times substitute for one, or sometimes even /spl Omega/(n), u-/spl nu/ mincut computations; this can lead to significant savings, since our representation can be computed /spl theta//spl tilde/(m/n) times faster than the currently best known u-/spl nu/ mincut algorithm. We also improve the running time of the edge augmentation problem, provided the initial edge weights are polynomially bounded.
FOCS	The Loading Time Scheduling Problem (Extended Abstract).	Randeep Bhatia,Samir Khuller,Joseph Naor	1995	The Loading Time Scheduling Problem (Extended Abstract).
FOCS	Simple Learning Algorithms for Decision Trees and Multivariate Polynomials.	Nader H. Bshouty,Yishay Mansour	1995	In this paper we develop a new approach for learning decision trees and multivariate polynomials via interpolation of multivariate polynomials. This new approach yields simple learning algorithms for multivariate polynomials and decision trees over finite fields under any constant bounded product distribution. The output hypothesis is a (single) multivariate polynomial that is an $\epsilon$-approximation of the target under any constant bounded product distribution.The new approach demonstrates the learnability of many classes under any constant bounded product distribution and using membership queries, such as j-disjoint disjunctive normal forms (DNFs) and multivariate polynomials with bounded degree over any field.The technique shows how to interpolate multivariate polynomials with bounded term size from membership queries only. This, in particular, gives a learning algorithm for an O(log n)-depth decision tree from membership queries only and a new learning algorithm of any multivariate polynomial over sufficiently large fields from membership queries only. We show that our results for learning from membership queries only are the best possible.
FOCS	Using Autoreducibility to Separate Complexity Classes.	Harry Buhrman,Lance Fortnow,Leen Torenvliet	1995	"A language is autoreducible if it can be reduced to itself by a Turing machine that does not ask its own input to the oracle. We use autoreducibility to separate exponential space from doubly exponential space by showing that all Turing complete sets for exponential space are autoreducible but there exists some Turing complete set for doubly exponential space that is not. We immediately also get a separation of logarithmic space from polynomial space. Although we already know how to separate these classes using diagonalization, our proofs separate classes solely by showing they have different structural properties, thus applying Post's Program (E. Pos, 1944) to complexity theory. We feel such techniques may prove unknown separations in the future. In particular if we could settle the question as to whether all complete sets for doubly exponential time were autoreducible we would separate polynomial time from either logarithmic space or polynomial space. We also show several other theorems about autoreducibility."
FOCS	The Resolution of a Hartmanis Conjecture.	Jin-yi Cai,D. Sivakumar	1995	Building on the recent breakthrough by M. Ogihara (1995), we resolve a conjecture made by J. Hartmanis (1978) regarding the (non) existence of sparse sets complete for P under logspace many-one reductions. We show that if there exists a sparse hard set for P under logspace many-one reductions, then P=LOGSPACE. We further prove that if P has a sparse hard set under many-one reductions computable in NC/sup 1/, then P collapses to NC/sup 1/.
FOCS	Private Information Retrieval.	Benny Chor,Oded Goldreich,Eyal Kushilevitz,Madhu Sudan	1995	We describe schemes that enable a user to access k replicated copies of a database (k/spl ges/2) and privately retrieve information stored in the database. This means that each individual database gets no information on the identity of the item retrieved by the user. For a single database, achieving this type of privacy requires communicating the whole database, or n bits (where n is the number of bits in the database). Our schemes use the replication to gain substantial saving. In particular, we have: A two database scheme with communication complexity of O(n/sup 1/3/). A scheme for a constant number, k, of databases with communication complexity O(n/sup 1/k/). A scheme for 1/3 log/sub 2/ n databases with polylogarithmic (in n) communication complexity.
FOCS	Routing on Butterfly Networks with Random Faults.	Richard Cole,Bruce M. Maggs,Ramesh K. Sitaraman	1995	We show that even if every node or edge in an N-node butterfly network fails independently with some constant probability, p, it is still possible to identify a set of /spl Theta/(N) nodes between which packets can be routed in any permutation in O(logN) steps, with high probability. Although the analysis as complicated, the routing algorithm itself is relatively simple.
FOCS	An Optimal Algorithm for Monte Carlo Estimation (Extended Abstract).	Paul Dagum,Richard M. Karp,Michael Luby,Sheldon M. Ross	1995	An Optimal Algorithm for Monte Carlo Estimation (Extended Abstract).
FOCS	Optimal Algorithms for Curves on Surfaces.	Tamal K. Dey,Sumanta Guha	1995	We describe an optimal algorithm to decide if one closed curve on a triangulated 2-manifold can be continuously transformed to another, i.e., if they are homotopic. Our algorithm runs in O(n+k/sub 1/+k/sub 2/) time and space, where closed curves C/sub 1/ and C/sub 2/ of lengths k/sub 1/ and k/sub 2/, resp., on a genus g surface M (g/spl ne/2 if M orientable, and g/spl ne/3,4 if M is non-orientable) are presented as edge-vertex sequences in a triangulation T of size n of M. This also implies an optimal algorithm to decide if a closed curve on a surface can be continuously contracted to a point. Except for three low genus cases, our algorithm completes an investigation into the computational complexity of the two classical problems for surfaces posed by the mathematician Max Dehn at the beginning of this century. However, we make novel applications of methods from modern combinatorial group theory for an approach entirely different from previous ones, and much simpler to implement.
FOCS	Algebraic Decompositions of Non-Convex Polyhedra.	Herbert Edelsbrunner	1995	Any arbitrary polyhedron $P \subseteq R^d$ can be written as algebraic sum of simple terms, each an integer multiple of the intersection of $d$ or fewer half-spaces defined by facets of $P$. $P$ can be non-convex and can have holes of any kind. Among the consequences of this result are a short boolean formula for $P$, a fast parallel algorithm for point classification, and a new proof of the Gram-Sommerville angle relation.
FOCS	Divide-and-Conquer Approximation Algorithms via Spreading Metrics (Extended Abstract).	Guy Even,Joseph Naor,Satish Rao,Baruch Schieber	1995	Divide-and-Conquer Approximation Algorithms via Spreading Metrics (Extended Abstract).
FOCS	Optimal On-Line Search and Sublinear Time Update in String Matching.	Paolo Ferragina,Roberto Grossi	1995	This paper investigates the problem of searching on-line for the occurrences (occ) of an arbitrary pattern of length p in a text of length n subjected to some updates after its preprocessing. Each text update consists of inserting or deleting an arbitrary string of length y. We present the first dynamic algorithm that achieves optimal query time, i.e., $\Theta(p+occ)$, sublinear time per update, i.e., $O(\sqrt{n} + y)$, and optimal space, i.e., $\Theta(n)$, in the worst case. As a result, our algorithm obtains the same query time and space usage of suffix trees [McCreight, J. Assoc. Comput. Mach., 23 (1976), pp. 262--272] while improving their O(n + y) update performance.
FOCS	Competitive Access Time via Dynamic Storage Rearrangement (Preliminary Version).	Amos Fiat,Yishay Mansour,Adi Rosén,Orli Waarts	1995	Competitive Access Time via Dynamic Storage Rearrangement (Preliminary Version).
FOCS	Efficient Algorithms for Learning to Play Repeated Games Against Computationally Bounded Adversaries.	Yoav Freund,Michael J. Kearns,Yishay Mansour,Dana Ron,Ronitt Rubinfeld,Robert E. Schapire	1995	"We examine the problem of learning to play various games optimally against resource-bounded adversaries, with an explicit emphasis on the computational efficiency of the learning algorithm. We are especially interested in providing efficient algorithms for games other than penny-matching (in which payoff is received for matching the adversary's action in the current round), and for adversaries other than the classically studied finite automata. In particular, we examine games and adversaries for which the learning algorithm's past actions may strongly affect the adversary's future willingness to ""cooperate"" (that is, permit high payoff), and therefore require carefully planned actions on the part of the learning algorithm. For example, in the game we call contract, both sides play O or 1 on each round, but our side receives payoff only if we play 1 in synchrony with the adversary; unlike penny-matching, playing O in synchrony with the adversary pays nothing. The name of the game is derived from the example of signing a contract, which becomes valid only if both parties sign (play 1)."
FOCS	Improved Hardness Results for Approximating the Chromatic Number.	Martin Fürer	1995	First, a simplified geometric proof is presented for the result of C. Lund and M. Yannakakis (1994) saying that for some /spl epsiv/
FOCS	Resolving Message Complexity of Byzantine Agreement and beyond.	Zvi Galil,Alain J. Mayer,Moti Yung	1995	"Byzantine Agreement among processors is a basic primitive in distributed computing. It comes in a number of basic fault models: ""Crash"", ""Omission"" and ""Malicious"" adversarial behaviors. The message complexity of the primitive has been known for the strong failure models of Malicious and Omission adversary since the early 80's, while the question for the more benign Crash failure model has been open. We show how to solve agreement in the presence of crash failures using O(n) messages which is optimal, thus settling a thirteen year old open problem. Our solution has almost linear time and our new algorithmic techniques have further implications: a family of ""early stopping"" agreement protocols with improved message-complexity; and a new solution to ""Checkpoint"" yielding a substantial improvement of the protocol for distributed work performance under adaptive parallelism in a network of workstations."
FOCS	Finding Points on Curves over Finite Fields (Extended Abstract).	Joachim von zur Gathen,Igor Shparlinski	1995	Finding Points on Curves over Finite Fields (Extended Abstract).
FOCS	Learning Polynomials with Queries: The Highly Noisy Case.	Oded Goldreich,Ronitt Rubinfeld,Madhu Sudan	1995	"Given a function f mapping n-variate inputs from a finite field F into F, we consider the task of reconstructing a list of all n-variate degree d polynomials that agree with f on a tiny but nonnegligible fraction, $\delta$, of the input space. We give a randomized algorithm for solving this task. The algorithm accesses f as a black box and runs in time polynomial in ${\frac{n}\d}$ and exponential in d, provided $\delta$ is $\Omega(\sqrt{d/|F|})$. For the special case when d = 1, we solve this problem for all $\epsilon\eqdef\delta - \frac1{|F|} >0$. In this case the running time of our algorithm is bounded by a polynomial in $\frac1\e$ and $n$. Our algorithm generalizes a previously known algorithm, due to Goldreich and Levin [in Proceedings of the 21st Annual ACM Symposium on Theory of Computing, Seattle, WA, ACM Press, New York, 1989, pp. 25--32.], that solves this task for the case when F = GF(2) (and d = 1).In the process we provide new bounds on the number of degree $d$ polynomials that may agree with any given function on $\d \geq \sqrt{d/|F|}$ fraction of the inputs. This result is derived by generalizing a well-known bound from coding theory on the number of codewords from an error-correcting code that can be ""close"" to an arbitrary word; our generalization works for codes over arbitrary alphabets, while the previous result held only for binary alphabets."
FOCS	An Approximation Scheme for Planar Graph TSP.	Michelangelo Grigni,Elias Koutsoupias,Christos H. Papadimitriou	1995	We consider the special case of the traveling salesman problem (TSP) in which the distance metric is the shortest-path metric of a planar unweighted graph. We present a polynomial-time approximation scheme (PTAS) for this problem.
FOCS	Improved Lower Bound on Testing Membership to a Polyhedron by Algebraic Decision Trees.	Dima Grigoriev,Marek Karpinski,Nicolai Vorobjov	1995	"We introduce a new method of proving lower bounds on the depth of algebraic $d$-degree decision trees and apply it to prove a lower bound $\Omega (\log N)$ for testing membership to an $n$-dimensional convex polyhedron having $N$ faces of all dimensions, provided that $N< (nd)^{\Omega (n)}$. This bound apparently does not follow from the methods developed by M.\ Ben-Or, A.\ Bj\""orner, L.\ Lovasz, and A.\ Yao [B.\ 83], [BLY\ 93], [Y\ 94] because topological invariants used in these methods become trivial for convex polyhedra."
FOCS	Counting Bottlenecks to Show Monotone P <=> NP.	Armin Haken	1995	The method of proving lower bounds by bottleneck counting is illustrated for monotone Boolean circuits. This paper gives another proof of the result of Razborov (1985) and Andreev (1985), that monotone Boolean circuits must have exponential size when solving a problem in NP. More specifically, the paper defines a graph recognition problem called BMS. Any monotone circuit that solves BMS, must contain a quantity of gates that is exponential in the eighth root of the input size. The actual instances of the BMS problem used to prove the lower bound are easy to separate for non-monotone circuits. The proof is self-contained and uses only elementary combinatorics.
FOCS	Approximability of Flow Shop Scheduling.	Leslie A. Hall	1995	Shop scheduling problems are notorious for their intractability, both in theory and practice. In this paper, we demonstrate the existence of a polynomial approximation scheme for the flow shop scheduling problem with an arbitrary fixed number of machines. For the three common shop models (open, flow, and job), this result is the only known approximation scheme. Since none of the three models can be approximated arbitrarily closely in the general case (unless P=NP), the result demonstrates the approximability gap between the models in which the number of machines is fixed, and those in which it is part of the input of the instance. The result can be extended to flow shops with job release dates and delivery times and to flow shops with a fixed number stages, where the number of machines at any stage is fixed. We also describe a related polynomial approximation scheme for the problem of scheduling an open shop with a single bottleneck machine and an arbitrary number of non-bottleneck machines.
FOCS	Transforming Men into Mice (Polynomial Algorithm for Genomic Distance Problem).	Sridhar Hannenhalli,Pavel A. Pevzner	1995	Many people believe that transformations of humans into mice happen only in fairy tales. However, despite some differences in appearance and habits, men and mice are genetically very similar. In the pioneering paper, J.H. Nadeau and B.A. Taylor (1984) estimated that surprisingly few genomic rearrangements (178/spl plusmn/39) happened since the divergence of human and mouse 80 million years ago. However, their analysis is nonconstructive and no rearrangement scenario for human-mouse evolution has been suggested yet. The problem is complicated by the fact that rearrangements in multi chromosomal genomes include inversions, translocations, fusions and fissions of chromosomes, a rather complex set of operations. As a result, at first glance, a polynomial algorithm for the genomic distance problem with all these operations looks almost as improbable as the transformation of a (real) man into a (real) mouse. We prove a duality theorem which expresses the genomic distance in terms of easily computable parameters reflecting different combinatorial properties of sets of strings. This theorem leads to a polynomial time algorithm for computing most parsimonious rearrangement scenarios. Based on this result and the latest comparative physical mapping data we have constructed a scenario of human-mouse evolution with 131 reversals/translocaitons/fusions/fissions. A combination of the genome rearrangement algorithm with the recently proposed experimental technique called ZOO FISH suggests a new constructive approach to the 100 year old problem of reconstructing mammalian evolution.
FOCS	Computing Simulations on Finite and Infinite Graphs.	Monika Rauch Henzinger,Thomas A. Henzinger,Peter W. Kopke	1995	We present algorithms for computing similarity relations of labeled graphs. Similarity relations have applications for the refinement and verification of reactive systems. For finite graphs, we present an O(mn) algorithm for computing the similarity relation of a graph with n vertices and m edges (assuming m/spl ges/n). For effectively presented infinite graphs, we present a symbolic similarity-checking procedure that terminates if a finite similarity relation exists. We show that 2D rectangular automata, which model discrete reactive systems with continuous environments, define effectively presented infinite graphs with finite similarity relations. It follows that the refinement problem and the /spl forall/CTL* model-checking problem are decidable for 2D rectangular automata.
FOCS	Fully Dynamic Biconnectivity and Transitive Closure.	Monika Rauch Henzinger,Valerie King	1995	This paper presents an algorithm for the fully dynamic biconnectivity problem whose running time is exponentially faster than all previously known solutions. It is the first dynamic algorithm that answers biconnectivity queries in time O(log/sup 2/n) in a n-node graph and can be updated after an edge insertion or deletion in polylogarithmic time. Our algorithm is a Las-Vegas style randomized algorithm with the update time amortized update time O(log/sup 4/n). Only recently the best deterministic result for this problem was improved to O(/spl radic/nlog/sup 2/n). We also give the first fully dynamic and a novel deletions-only transitive closure (i.e. directed connectivity) algorithms. These are randomized Monte Carlo algorithms. Let n be the number of nodes in the graph and let m/spl circ/ be the average number of edges in the graph during the whole update sequence: The fully dynamic algorithms achieve (1) query time O(n/logn) and update time O(m/spl circ//spl radic/nlog/sup 2/n+n); or (2) query time O(n/logn) and update time O(nm/spl circ//sup /spl mu/-1/)log/sup 2/n=O(nm/spl circ//sup 0.58/log/sup 2/n), where /spl mu/ is the exponent for boolean matrix multiplication (currently /spl mu/=2.38). The deletions-only algorithm answers queries in time O(n/logn). Its amortized update time is O(nlog/sup 2/n).
FOCS	Hard-Core Distributions for Somewhat Hard Problems.	Russell Impagliazzo	1995	"Consider a decision problem that cannot be 1-/spl delta/ approximated by circuits of a given size in the sense that any such circuit fails to give the correct answer on at least a /spl delta/ fraction of instances. We show that for any such problem there is a specific ""hard core"" set of inputs which is at least a /spl delta/ fraction of all inputs and on which no circuit of a slightly smaller size can get even a small advantage over a random guess. More generally, our argument holds for any non uniform model of computation closed under majorities. We apply this result to get a new proof of the Yao XOR lemma (A.C. Yao, 1982), and to get a related XOR lemma for inputs that are only k wise independent."
FOCS	Speed is as Powerful as Clairvoyance.	Bala Kalyanasundaram,Kirk Pruhs	1995	We introduce resource augmentation as a method for analyzing online scheduling problems. In resource augmentation analysis the on-line scheduler is given more resources, say faster processors or more processors, than the adversary. We apply this analysis to two well-known on-line scheduling problems, the classic uniprocessor CPU scheduling problem 1 |ri, pmtn|&Sgr; Fi, and the best-effort firm real-time scheduling problem 1|ri, pmtn| &Sgr; wi( 1- Ui). It is known that there are no constant competitive nonclairvoyant on-line algorithms for these problems. We show that there are simple on-line scheduling algorithms for these problems that are constant competitive if the online scheduler is equipped with a slightly faster processor than the adversary. Thus, a moderate increase in processor speed effectively gives the on-line scheduler the power of clairvoyance. Furthermore, the on-line scheduler can be constant competitive on all inputs that are not closely correlated with processor speed. We also show that the performance of an on-line scheduler is best-effort real time scheduling can be significantly improved if the system is designed in such a way that the laxity of every job is proportional to its length.
FOCS	The Bit Vector Intersection Problem (Preliminary Version).	Richard M. Karp,Orli Waarts,Geoffrey Zweig	1995	The Bit Vector Intersection Problem (Preliminary Version).
FOCS	Disjoint Paths in Densely Embedded Graphs.	Jon M. Kleinberg,Éva Tardos	1995	"We consider the following maximum disjoint paths problem (MDPP). We are given a large network, and pairs of nodes that wish to communicate over paths through the network-the goal is to simultaneously connect as many of these pairs as possible in such a way that no two communication paths share an edge in the network. This classical problem has been brought into focus recently in papers discussing applications to routing in high-speed networks, where the current lack of understanding of the MDPP is an obstacle to the design of practical heuristics. We consider the class of densely embedded, nearly-Eulerian graphs, which includes the two-dimensional mesh and other planar and locally planar interconnection networks. We obtain a constant-factor approximation algorithm for the maximum disjoint paths problem for this class of graphs; this improves on an O(log n)-approximation for the special case of the two-dimensional mesh due to Aumann-Rabani and the authors. For networks that are not explicitly required to be ""high-capacity,"" this is the first constant-factor approximation for the MDPP in any class of graphs other than trees. We also consider the MDPP in the on-line setting, relevant to applications in which connection requests arrive over time and must be processed immediately. Here we obtain an asymptptically optimal O(log n)competitive on-line algorithm for the same class of graphs; this improves on an O(log n log log n) competitive algorithm for the special case of the mesh due to B. Awerbuch et al (1994)."
FOCS	Approximating the Volume of Definable Sets.	Pascal Koiran	1995	"The first part of this paper deals with finite-precision arithmetic. We give an upper bound on the precision that should be used in a Monte-Carlo integration method. Such bounds have been known only for convex sets; our bound applies to almost any ""reasonable"" set. In the second part of the paper, we show how to construct in polynomial time first-order formulas that approximately define the volume of definable sets. This result is based on a VC dimension hypothesis, and is inspired from the well-known complexity-theoretic result ""BPP/spl sube//sub 2/"". Finally, we show how these results can be applied to sets defined by systems of inequalities involving polynomial or exponential functions. In particular, we describe an application to a problem of structural complexity in the Blum-Shub-Smale model of computation over the reals."
FOCS	Tight Fault Locality (Extended Abstract).	Shay Kutten,David Peleg	1995	Tight Fault Locality (Extended Abstract).
FOCS	Faster Algorithms for the Construction of Parameterized Suffix Trees (Preliminary Version).	S. Rao Kosaraju	1995	Faster Algorithms for the Construction of Parameterized Suffix Trees (Preliminary Version).
FOCS	Controllability, Recognizability, and Complexity Issues in Robot Motion Planning.	Jean-Claude Latombe	1995	"Path planning has been widely studied by computer scientists. However, it is a very simplified version of the motion planning problems occurring in robotics. This paper examines extensions yielding two important issues: controllability and recognizability. The controllability issue arises when the number of controls is smaller than the number of independent parameters defining the robot's configuration: Can the motions span the configuration space? The recognizability issue occurs when there are errors in control and sensing: Can the robot recognize goal achievement? Both issues have interesting impact on the computational complexity of motion planning. This paper will also discuss a new path planning scheme based on random sampling of configuration space, to deal with many-degree-of-freedom robots. The blend of controllability, recognizability, and complexity issues discussed in this paper is unique to robotics and its study is key to the development of autonomous robots."
FOCS	On Computing Boolean Functions by Sparse Real Polynomials.	Matthias Krause,Pavel Pudlák	1995	We investigate the complexity of Boolean functions f with respect to realizations by real polynomials p (voting polynomials) in the sense that the sign of p(x) determines the value f(x). Considerable research has been done on determining the minimal degree needed for realizing or approximating particular functions. In this paper we focus our interest on estimating the minimal number of monomials, i.e. the length of realizing polynomials. Our main observation is that, in contrast to the degree, the minimal length essentially depends on whether we realize f over the domain.
FOCS	Derandomizing Semidefinite Programming Based Approximation Algorithms.	Sanjeev Mahajan,Ramesh Hariharan	1995	Derandomizing Semidefinite Programming Based Approximation Algorithms.
FOCS	Reconstructing Strings from Substrings in Rounds.	Dimitris Margaritis,Steven Skiena	1995	We establish a variety of combinatorial bounds on the tradeoffs inherent in reconstructing strings using few rounds of a given number of substring queries per round. These results lead us to propose a new approach to sequencing by hybridization (SBH), which uses interaction to dramatically reduce the number of oligonucleotides used for de novo sequencing of large DNA fragments, while preserving the parallelism which is the primary advantage of SBH.
FOCS	Spectral Methods for Matrix Rigidity with Applications to Size-Depth Tradeoffs and Communication Complexity.	Satyanarayana V. Lokam	1995	The rigidity of a matrix measures the number of entries that must be changed in order to reduce its rank below a certain value. The known lower bounds on the rigidity of explicit matrices are very weak. It is known that stronger lower bounds would have implications to complexity theory. We consider weaker forms of the rigidity problem over the complex numbers. Using spectral methods, we derive lower bounds on these variants. We then give two applications of such weaker forms. First, we show that our lower bound on a variant of rigidity implies lower bounds on size-depth tradeoffs for arithmetic circuits with bounded coefficients computing linear transformations. These bounds generalize a recent result of Nisan and Wigderson. The second application is conditional; we show that it would suffice to prove lower bounds on certain weaker forms of rigidity to conclude several separation results in communication complexity theory. Our results complement and strengthen a result of Razborov.
FOCS	Markov Chain Algorithms for Planar Lattice Structures (Extended Abstract).	Michael Luby,Dana Randall,Alistair Sinclair	1995	Markov Chain Algorithms for Planar Lattice Structures (Extended Abstract).
FOCS	Efficient Access to Optical Bandwidth - Wavelength Routing on Directed Fiber Trees, Rings, and Trees of Rings.	Milena Mihail,Christos Kaklamanis,Satish Rao	1995	Efficient Access to Optical Bandwidth - Wavelength Routing on Directed Fiber Trees, Rings, and Trees of Rings.
FOCS	Lower Bounds for Arithmetic Circuits via Partial Serivatives (Preliminary Version).	Noam Nisan,Avi Wigderson	1995	Lower Bounds for Arithmetic Circuits via Partial Serivatives (Preliminary Version).
FOCS	Sparse P-Hard Sets Yield Space-Efficient Algorithms.	Mitsunori Ogihara	1995	J. Hartmanis (1978) conjectured that there exist no sparse complete sets for P under logspace many-one reductions. In this paper, in support of the conjecture, it is shown that if P has sparse hard sets under logspace many-one reductions, then P/spl sube/DSPACE[log/sup 2/n]. The result follows from a more general statement: if P has 2/sup polylog/ sparse hard sets under poly-logarithmic space-computable many-one reductions, then P/spl sube/DSPACE[polylog].
FOCS	Amortization, Lazy Evaluation, and Persistence: Lists with Catenation via Lazy Linking.	Chris Okasaki	1995	"Amortization has been underutilized in the design of persistent data structures, largely because traditional accounting schemes break down in a persistent setting. Such schemes depend on saving ""credits"" for future use, but a persistent data structure may have multiple ""futures"", each competing for the same credits. We describe how lazy evaluation can often remedy this problem, yielding persistent data structures with good amortized efficiency. In fact, such data structures can be implemented purely functionally in any functional language supporting lazy evaluation. As can example of this technique, we present a purely functional (and therefore persistent) implementation of lists that simultaneously support catenation and all other usual list primitives in constant amortized time. This data structure is much simpler than the only existing data structure with comparable bounds, the recently discovered catenable lists of Kaplan and Tarjan, which support all operations in constant worst-case time."
FOCS	Coding for Computing.	Alon Orlitsky,James R. Roche	1995	A sender communicates with a receiver who wishes to reliably evaluate a function of their combined data. We show that if only the sender can transmit, the number of bits required is a conditional entropy of a naturally defined graph. We also determine the number of bits needed when the communicators exchange two messages.
FOCS	Synthesizers and Their Application to the Parallel Construction of Psuedo-Random Functions.	Moni Naor,Omer Reingold	1995	We present a new cryptographic primitive called pseudo-random synthesizer and show how to use it in order to get a parallel construction of a pseudo-random function. We show an NC/sup 1/ implementation of pseudo-random synthesizers based on the RSA or the Diffie-Hellman assumptions. This yields the first parallel (NC/sup 2/) pseudo-random function and the only alternative to the original construction of Goldreich, Gold-wasser and Micali (GGM). The security of our constructions is similar to the security of the underling assumptions. We discuss the connection with problems in computational learning theory.
FOCS	Splitters and Near-Optimal Derandomization.	Moni Naor,Leonard J. Schulman,Aravind Srinivasan	1995	We present a fairly general method for finding deterministic constructions obeying what we call k-restrictions; this yields structures of size not much larger than the probabilistic bound. The structures constructed by our method include (n,k)-universal sets (a collection of binary vectors of length n such that for any subset of size k of the indices, all 2/sup k/ configurations appear) and families of perfect hash functions. The near-optimal constructions of these objects imply the very efficient derandomization of algorithms in learning, of fixed-subgraph finding algorithms, and of near optimal /spl Sigma/II/spl Sigma/ threshold formulae. In addition, they derandomize the reduction showing the hardness of approximation of set cover. They also yield deterministic constructions for a local-coloring protocol, and for exhaustive testing of circuits.
FOCS	Contention Resolution with Bounded Delay.	Mike Paterson,Aravind Srinivasan	1995	When distributed processes contend for a shared resource, we need a good distributed contention resolution protocol, e.g., for multiple-access channels (ALOHA, Ethernet), PRAM emulation, and optical routing. Under a stochastic model of request generation from n synchronous processes, Raghavan & Upfal (1995) have shown a protocol which is stable for a positive request rate; their main result is that for every resource request, its expected delay (time to get serviced) is O(log n). Assuming that the initial clock times of the processes are within a known bound of each other, we present a stable protocol, wherein the expected delay for each request is O(1). We derive this by showing an analogous result for can infinite number of processes, assuming that all processes agree on the time.
FOCS	Tight Bounds for a Distributed Selection Game with Applications to Fixed-Connection Machines.	C. Greg Plaxton	1995	We define a distributed selection game that generalizes a selection problem considered by S.R. Kosaraju (1989). We offer a tight analysis of our distributed selection game, and show that the lower bound for this abstract communication game directly implies near-tight lower bounds for certain selection problems on fixed-connection machines. For example, we prove that any deterministic comparison-based selection algorithm on an (n/log n)-processor bounded-degree hypercubic machine requires /spl Omega/(log/sup 3/2/n) steps in the worst case. This lower bound implies a non-trivial separation between the power of bounded-degree hypercubic and expander-based machines. Furthermore, we show that the algorithm underlying our tight upper bound for the distributed selection game can be adapted to run in O((log/sup 3/2/n) (log log n)/sup 2/) steps on any (n/log n)-processor hypercubic machine.
FOCS	Pseudorandom Generators, Measure Theory, and Natural Proofs.	Kenneth W. Regan,D. Sivakumar,Jin-yi Cai	1995	We prove that if strong pseudorandom number generators exist, then the class of languages that have polynomial-sized circuits (P/poly) is not measurable within exponential time, in terms of the resource-bounded measure theory of Lutz. We prove our result by showing that if P/poly has measure zero in exponential time, then there is a natural proof against P/poly, in the terminology of Razborov and Rudich (1994). We also provide a partial converse of this result.
FOCS	RSPACE(S) \subseteq DSPACE(S).	Michael E. Saks,Shiyu Zhou	1995	RSPACE(S) \subseteq DSPACE(S).
FOCS	Efficient Parallel Solution of Sparse Eigenvalue and Eigenvector Problems.	John H. Reif	1995	This paper gives a new algorithm for computing the characteristic polynomial of a symmetric sparse matrix. We derive an interesting algebraic version of nested dissection, which constructs a sparse factorization the matrix A-/spl lambda/ where A is the input matrix. While nested dissection is commonly used to minimize the fill-in in the solution of sparse linear systems, our innovation is to use the separator structure to bound also the work for manipulation of rational polynomials in the recursively factored matrices. We compute the characteristic polynomial sparse symmetric matrix in polylog time using O(n(n+P(s(n))))/spl les/O(n(n+s(n)/sup 2.376/)) processors, where the sparsity graph of the matrix has separator size s(n). Our method requires only that the matrix be symmetric and nonsingular (it need not be positive definite as usual for nested dissection techniques); we use perturbation methods to avoid singularities. For the frequently occurring case where the matrix has small separator size our polylog parallel algorithm requires work bounds competitive with the best known sequential algorithms (i.e. sparse Lanczos methods), for example: (1) when the sparsity graph is a planar graph, s(n)/spl les//spl radic/n, and we require only n/sup 2.188/ processors, and (2) in the case where the input matrix is b-banded, we require only O(nP(b))=O(n) processors, for constant b.
FOCS	Faster Approximate Agreement with Multi-Writer Registers.	Eric Schenk	1995	We consider the complexity of the wait-free approximate agreement problem in an asynchronous shared memory comprised of only single-bit multi-writer multi-reader registers. For real-valued inputs x/sub 1/,...,x/sub n/ and /spl epsiv/ we show matching upper and lower bounds of /spl Theta/(log(ma.
FOCS	Minimum Coloring Random and Semi-Random Graphs in Polynomial Expected Time.	C. R. Subramanian	1995	We present new algorithms for k-coloring and minimum (/spl chi/(G)-) coloring random and semi-random k-colorable graphs in polynomial expected time. The random graphs are drawn from the G(n,p,k) model and the semi-random graphs are drawn from the G/sub SB/(n,p,k) model. In both models, an adversary initially splits the n vertices into k color classes, each of size /spl Theta/(n). Then the edges between vertices in different color classes are chosen one by one, according to some probability distribution. The model G/sub SB/(n,p,k) was introduced by A. Blum (1991) and with respect to randomness, it lies between the random model G(n,p,k) where all edges are chosen with equal probability and the worst-case model.
FOCS	A Unified Analysis of Paging and Caching.	Eric Torng	1995	Paging (caching) is the problem of managing a two-level memory hierarchy in order to minimise the time required to process a sequence of memory accesses. In order to measure this quantity, we define the system parameter miss penalty to represent the extra time required to access slow memory. In the context of paging, miss penalty is large, so most previous studies of on-line paging have implicitly set miss penalty=/spl infin/ in order to simplify the model. We show that this seemingly insignificant simplification substantially alters the precision of derived results. Consequently, we reintroduce miss penalty to the paging problem and present a more accurate analysis of on-line paging (and caching). We validate using this more accurate model by deriving intuitively appealing results for the paging problem which cannot be derived using the simplified model.
FOCS	Cognitive Computation (Extended Abstract).	Leslie G. Valiant	1995	Cognitive Computation (Extended Abstract).
FOCS	On One-Dimensional Quantum Cellular Automata.	John Watrous	1995	"Since Richard Feynman introduced the notion of quantum computation in 1982, various models of ""quantum computers"" have been proposed (R. Feynman, 1992). These models include quantum Turing machines and quantum circuits. We define another quantum computational model, one dimensional quantum cellular automata, and demonstrate that any quantum Turing machine can be efficiently simulated by a one dimensional quantum cellular automaton with constant slowdown. This can be accomplished by consideration of a restricted class of one dimensional quantum cellular automata called one dimensional partitioned quantum cellular automata. We also show that any one dimensional partitioned quantum cellular automaton can be simulated by a quantum Turing machine with linear slowdown, but the problem of efficiently simulating an arbitrary one dimensional quantum cellular automaton with a quantum Turing machine is left open. From this discussion, some interesting facts concerning these models are easily deduced."
FOCS	Perspectives on Database Theory.	Mihalis Yannakakis	1995	Database management systems address the need to store, retrieve, and manipulate large amounts of data in an organized fashion. The database held has grown tremendously in the last 25 years. It is reported that the database industry generated $7 billion in revenue in 1994 and is growing at a rate of 35% per year. Industrial and academic research have been instrumental to this growth. Theory has played an important role in defining the right abstractions and concepts, and providing a firm foundation for the field. In order to access effectively a large volume of data, one needs an abstract logical view of the data, which must be separate from the physical storage of data. The important first component of a database is therefore an abstract view of data (called the data model) and the accompanying specialized high-level language that is used to access the data. The second important component is the data structures that are used to store the data along with the algorithms to support the efficient translation from the logical to the physical world. The third important component is the mechanisms that allow the database to be accessed concurrently by many users, without violating its integrity. Theory has contributed to all three fronts, starting with what is undoubtedly the cornerstone of the area, the introduction and formal definition of the relational model by F.P. Codd (1970). It is a highly unusual compliment for theory when the major commercial products in the field have at their core a mathematically rigorous, formal model. Our primary aims in this paper will be to give a flavor of the types of problems that database theory addresses, and to review how research in the area has evolved over the years. At the end we will try to point to some topics that may be of interest to people in the FOCS community tempted to work in database theory.
FOCS	A Scheduling Model for Reduced CPU Energy.	F. Frances Yao,Alan J. Demers,Scott Shenker	1995	The energy usage of computer systems is becoming an important consideration, especially for battery-operated systems. Various methods for reducing energy consumption have been investigated, both at the circuit level and at the operating systems level. In this paper, we propose a simple model of job scheduling aimed at capturing some key aspects of energy minimization. In this model, each job is to be executed between its arrival time and deadline by a single processor with variable speed, under the assumption that energy usage per unit time, P, is a convex function, of the processor speed s. We give an off-line algorithm that computes, for any set of jobs, a minimum-energy schedule. We then consider some on-line algorithms and their competitive performance for the power function P(s)=s/sup p/ where p/spl ges/2. It is shown that one natural heuristic, called the Average Rate heuristic, uses at most a constant times the minimum energy required. The analysis involves bounding the largest eigenvalue in matrices of a special type.
FOCS	36th Annual Symposium on Foundations of Computer Science, Milwaukee, Wisconsin, 23-25 October 1995		1995	36th Annual Symposium on Foundations of Computer Science, Milwaukee, Wisconsin, 23-25 October 1995
SODA	Design of Practical and Provably Good Random Number Generators (Extended Abstract).	William Aiello,Sivaramakrishnan Rajagopalan,Ramarathnam Venkatesan	1995	Design of Practical and Provably Good Random Number Generators (Extended Abstract).
SODA	Fairness in Scheduling.	Miklós Ajtai,James Aspnes,Moni Naor,Yuval Rabani,Leonard J. Schulman,Orli Waarts	1995	Fairness in Scheduling.
SODA	Improved Randomized On-Line Algorithms for the List Update Problem.	Susanne Albers	1995	The best randomized on-line algorithms known so far for the list update problem achieve a competitiveness of $\sqrt{3} \approx 1.73$. In this paper we present a new family of randomized on-line algorithms that beat this competitive ratio. Our improved algorithms are called TIMESTAMP algorithms and achieve a competitiveness of $\max\{2-p, 1+p(2-p)\}$, for any real number $p\in[0,1]$. Setting $p = (3-\sqrt{5})/2$, we obtain a $\phi$-competitive algorithm, where $\phi = (1+\sqrt{5})/2\approx 1.62$ is the golden ratio. TIMESTAMP algorithms coordinate the movements of items using some information on past requests. We can reduce the required information at the expense of increasing the competitive ratio. We present a very simple version of the TIMESTAMP algorithms that is \mbox{$1.68$-competitive}. The family of TIME\-STAMP algorithms also includes a new deterministic 2-competitive on-line algorithm that is different from the MOVE-TO-FRONT rule.
SODA	On-line Approximate List Indexing with Applications.	Arne Andersson,Ola Petersson	1995	On-line Approximate List Indexing with Applications.
SODA	Average Case Analysis of Dynamic Graph Algorithms.	David Alberts,Monika Rauch Henzinger	1995	Average Case Analysis of Dynamic Graph Algorithms.
SODA	Improved Bounds for All Optical Routing.	Yonatan Aumann,Yuval Rabani	1995	Improved Bounds for All Optical Routing.
SODA	Sorting Permutations by Transpositions.	Vineet Bafna,Pavel A. Pevzner	1995	Sorting Permutations by Transpositions.
SODA	Parameterized Pattern Matching by Boyer-Moore-Type Algorithms.	Brenda S. Baker	1995	Parameterized Pattern Matching by Boyer-Moore-Type Algorithms.
SODA	Guaranteeing Fair Service to Persistent Dependent Tasks.	Amotz Bar-Noy,Alain J. Mayer,Baruch Schieber,Madhu Sudan	1995	"We introduce a new scheduling problem that is motivated by applications in the area of access and flow control in high-speed and wireless networks. An instance of the problem consists of a set of persistent tasks that have to be scheduled repeatedly. Each task has a demand to be scheduled ""as often as possible."" There is no explicit limit on the number of tasks that can be scheduled concurrently. However, such limits are imposed implicitly because some tasks may be in conflict and cannot be scheduled simultaneously. These conflicts are presented in the form of a conflict graph. We define parameters which quantify the fairness and regularity of a given schedule. We then proceed to show lower bounds on these parameters and present fair and efficient scheduling algorithms for the case where the conflict graph is an interval graph. Some of the results presented here extend to the case of perfect graphs and circular-arc graphs as well."
SODA	Improved Algorithms for Protein Motif Recognition.	Bonnie Berger,David Bruce Wilson	1995	Improved Algorithms for Protein Motif Recognition.
SODA	Dihedral Bounds for Mesh Generation in High Dimensions.	Marshall W. Bern,L. Paul Chew,David Eppstein,Jim Ruppert	1995	Dihedral Bounds for Mesh Generation in High Dimensions.
SODA	Path Optimization and Near-Greedy Analysis for Graph Partitioning: An Empirical Study.	Jonathan W. Berry,Mark K. Goldberg	1995	Path Optimization and Near-Greedy Analysis for Graph Partitioning: An Empirical Study.
SODA	From Valid Inequalities to Heuristics: A Unified View of Primal-Dual Approximation Algorithms in Covering Problems.	Dimitris Bertsimas,Chung-Piaw Teo	1995	In recent years approximation algorithms based on primal-dual methods have been successfully applied to a broad class of discrete optimization problems. In this paper, we propose a generic primal-dual framework to design and analyze approximation algorithms for integer programming problems of the covering type that uses valid inequalities in its design. The worst-case bound of the proposed algorithm is related to a fundamental relationship (called strength) between the set of valid inequalities and the set of minimal solutions to the covering problems. In this way, we can construct an approximation algorithm simply by constructing the required valid inequalities. We apply the proposed algorithm to several problems, such as covering problems related to totally balanced matrices, cyclic scheduling, vertex cover, general set covering, intersections of polymatroids, and several network design problems attaining (in most cases) the best worst-case bound known in the literature.
SODA	Circular Separability of Polygon.	Jean-Daniel Boissonnat,Jurek Czyzowicz,Olivier Devillers,Mariette Yvinec	1995	Circular Separability of Polygon.
SODA	Trustee-based Tracing Extensions to Anonymous Cash and the Making of Anonymous Change.	Ernest F. Brickell,Peter Gemmell,David W. Kravitz	1995	Trustee-based Tracing Extensions to Anonymous Cash and the Making of Anonymous Change.
SODA	On Algorithm Design for Metrical Task Systems.	William R. Burley,Sandy Irani	1995	On Algorithm Design for Metrical Task Systems.
SODA	Algorithms for Dynamic Closest Pair and n-Body Potential Fields.	Paul B. Callahan,S. Rao Kosaraju	1995	Algorithms for Dynamic Closest Pair and n-Body Potential Fields.
SODA	Output-Sensitive Construction of Polytopes in Four Dimensions and Clipped Voronoi Diagrams in Three.	Timothy M. Chan,Jack Snoeyink,Chee-Keng Yap	1995	Output-Sensitive Construction of Polytopes in Four Dimensions and Clipped Voronoi Diagrams in Three.
SODA	Algorithms for the Optimal Loading of Recursive Neural Nets.	Vijay Chandru,Abhi Dattasharma,S. Sathiya Keerthi,N. K. Sancheti,V. Vinay	1995	Algorithms for the Optimal Loading of Recursive Neural Nets.
SODA	On the All-Pairs Euclidean Short Path Problem.	Danny Z. Chen	1995	On the All-Pairs Euclidean Short Path Problem.
SODA	Voronoi Diagrams of Lines in 3-Space Under Polyhedral Convex Distance Functions.	L. Paul Chew,Klara Kedem,Micha Sharir,Boaz Tagansky,Emo Welzl	1995	Voronoi Diagrams of Lines in 3-Space Under Polyhedral Convex Distance Functions.
SODA	External-Memory Graph Algorithms.	Yi-Jen Chiang,Michael T. Goodrich,Edward F. Grove,Roberto Tamassia,Darren Erik Vengroff,Jeffrey Scott Vitter	1995	External-Memory Graph Algorithms.
SODA	The Statistical Adversary Allows Optimal Money-Making Trading Strategies.	Andrew Chou,Jeremy R. Cooperstock,Ran El-Yaniv,Michael Klugerman,Frank Thomson Leighton	1995	The Statistical Adversary Allows Optimal Money-Making Trading Strategies.
SODA	An Analysis of Some Heuristics for the Maximum Planar Subgraph Problem.	Robert J. Cimikowski	1995	An Analysis of Some Heuristics for the Maximum Planar Subgraph Problem.
SODA	Doing Two-Level Logic Minimization 100 Times Faster.	Olivier Coudert	1995	Doing Two-Level Logic Minimization 100 Times Faster.
SODA	Multiple Translational Containment: Approximate and Exact Algorithms.	Karen L. Daniels,Victor Milenkovic	1995	Multiple Translational Containment: Approximate and Exact Algorithms.
SODA	A New Way to Weigh Malnourished Euclidean Graphs.	Gautam Das,Giri Narasimhan,Jeffrey S. Salowe	1995	A New Way to Weigh Malnourished Euclidean Graphs.
SODA	Locally Orientable Graphs, Cell Structures, and a New Algorithm for the Incremental Maintenance of Connectivity Carcasses.	Yefim Dinitz,Alek Vainshtein	1995	Locally Orientable Graphs, Cell Structures, and a New Algorithm for the Incremental Maintenance of Connectivity Carcasses.
SODA	Selecting the Median.	Dorit Dor,Uri Zwick	1995	Improving a long-standing result of Schönhage, Paterson, and Pippenger [ J. Comput. System Sci., 13 (1976), pp. 184--199] we show that the median of a set containing $n$ elements can always be found using at most $c \cdot n$ comparisons, where c<2.95.
SODA	Localizing a Robot with Minimum Travel.	Gregory Dudek,Kathleen Romanik,Sue Whitesides	1995	We consider the problem of localizing a robot in a known environment modeled by a simple polygon P. We assume that the robot has a map of P but is placed at an unknown location inside P. From its initial location, the robot sees a set of points called the visibility polygon V of its location. In general, sensing at a single point will not suffice to uniquely localize the robot, since the set H of points in P with visibility polygon V may have more than one element. Hence, the robot must move around and use range sensing and a compass to determine its position (i.e., localize itself). We seek a strategy that minimizes the distance the robot travels to determine its exact location.We show that the problem of localizing a robot with minimum travel is NP-hard. We then give a polynomial time approximation scheme that causes the robot to travel a distance of at most (k - 1)d, where k = |H|, which is no greater than the number of reflex vertices of P, and d is the length of a minimum length tour that would allow the robot to verify its true initial location by sensing. We also show that this bound is the best possible.
SODA	Efficient Parallel Computations for Singular Band Matrices.	Wayne Eberly	1995	Efficient Parallel Computations for Singular Band Matrices.
SODA	Subgraph Isomorphism in Planar Graphs and Related Problems.	David Eppstein	1995	Subgraph Isomorphism in Planar Graphs and Related Problems.
SODA	Lower Bounds for Linear Satisfiability Problems.	Jeff Erickson	1995	Lower Bounds for Linear Satisfiability Problems.
SODA	On the Entropy of DNA: Algorithms and Measurements Based on Memory and Rapid Convergence.	Martin Farach,Michiel O. Noordewier,Serap A. Savari,Larry A. Shepp,Aaron D. Wyner,Jacob Ziv	1995	On the Entropy of DNA: Algorithms and Measurements Based on Memory and Rapid Convergence.
SODA	Fast Incremental Text Editing.	Paolo Ferragina,Roberto Grossi	1995	Fast Incremental Text Editing.
SODA	Optimal One-Way Sorting on a One-Dimensional Sub-Bus Array.	James D. Fix,Richard E. Ladner	1995	Optimal One-Way Sorting on a One-Dimensional Sub-Bus Array.
SODA	Graph Isomorphism Testing without Numberics for Graphs of Bounded Eigenvalue Multiplicity.	Martin Fürer	1995	Graph Isomorphism Testing without Numberics for Graphs of Bounded Eigenvalue Multiplicity.
SODA	Broadcast in Radio Networks.	Iris Gaber,Yishay Mansour	1995	Broadcast in Radio Networks.
SODA	Algorithms for Graphic Polymatroids and Parametric s-Sets.	Harold N. Gabow	1995	Algorithms for Graphic Polymatroids and Parametric s-Sets.
SODA	Splay Trees for Data Compression.	Dennis Grinberg,Sivaramakrishnan Rajagopalan,Ramarathnam Venkatesan,Victor K. Wei	1995	Splay Trees for Data Compression.
SODA	Online Bin Packing with Lookahead.	Edward F. Grove	1995	Online Bin Packing with Lookahead.
SODA	On the Performance of Spectral Graph Partitioning Methods.	Stephen Guattery,Gary L. Miller	1995	On the Performance of Spectral Graph Partitioning Methods.
SODA	Characterizations of k-Terminal Flow Networks and Computing Network Flows in Partial k-Trees.	Torben Hagerup,Jyrki Katajainen,Naomi Nishimura,Prabhakar Ragde	1995	Characterizations of k-Terminal Flow Networks and Computing Network Flows in Partial k-Trees.
SODA	Approximating Discrete Collections via Local Improvements.	Magnús M. Halldórsson	1995	Approximating Discrete Collections via Local Improvements.
SODA	Finding Subsets Maximizing Minimum Structures.	Magnús M. Halldórsson,Kazuo Iwano,Naoki Katoh,Takeshi Tokuyama	1995	We consider the problem of finding a set of k vertices in a graph that are in some sense remote. Stated more formally, given a graph G and an integer k, find a set P of k vertices for which the total weight of a minimum structure on P is maximized. In particular, we are interested in three problems of this type, where the structure to be minimized is a spanning tree ({\sc Remote-MST}), Steiner tree, or traveling salesperson tour.We study a natural greedy algorithm that simultaneously approximates all three problems on metric graphs. For instance, its performance ratio for {\sc Remote-MST} is exactly 4, while this problem is NP-hard to approximate within a factor of less than 2. We also give a better approximation for graphs induced by Euclidean points in the plane, present an exact algorithm for graphs whose distances correspond to shortest-path distances in a tree, and prove hardness and approximability results for general graphs.
SODA	Morphing Binary Trees.	John Hershberger,Subhash Suri	1995	Morphing Binary Trees.
SODA	Practical Methods for Approximating Shortest Paths on a Convex Polytope in R.	John Hershberger,Subhash Suri	1995	Practical Methods for Approximating Shortest Paths on a Convex Polytope in R.
SODA	The Quickest Transshipment Problem.	Bruce Hoppe,Éva Tardos	1995	The Quickest Transshipment Problem.
SODA	Greedy Dynamic Routing on Arrays.	Nabil Kahale,Frank Thomson Leighton	1995	Greedy Dynamic Routing on Arrays.
SODA	Improved Interior Point Algorithms for Exact and Approximate Solution of Multicommodity Flow Problems.	Anil Kamath,Omri Palmon	1995	Improved Interior Point Algorithms for Exact and Approximate Solution of Multicommodity Flow Problems.
SODA	Fast Approximation Algorithm for Minimum Cost Multicommodity Flow.	Anil Kamath,Omri Palmon,Serge A. Plotkin	1995	Minimum-cost multicommodity flow problem is one of the classical optimization problems that arises in a variety of contexts. Applications range from finding optimal ways to route information through communication networks to VLSI layout. In this paper, we describe an efficient deterministic approximation algorithm, which given that there exists a multicommodity flow of cost $B$ that satisfies all the demands, produces a flow of cost at most $(1+\delta)B$ that satisfies $(1-\epsilon)$-fraction of each demand. For constant $\delta$ and $\epsilon$, our algorithm runs in $O^*(kmn^2)$ time, which is an improvement over the previously fastest (deterministic) approximation algorithm for this problem due to Plotkin, Shmoys, and Tardos, that runs in $O^*(k^2m^2)$ time.
SODA	Register Allocation in Structured Programs.	Sampath Kannan,Todd A. Proebsting	1995	Register Allocation in Structured Programs.
SODA	Counting and Random Generation of Strings in Regular Languages.	Sampath Kannan,Z. Sweedyk,Stephen R. Mahaney	1995	Counting and Random Generation of Strings in Regular Languages.
SODA	A Fast Algorithm for the Computation and Enumeration of Perfect Phylogenies when the Number of Character States is Fixed.	Sampath Kannan,Tandy Warnow	1995	A Fast Algorithm for the Computation and Enumeration of Perfect Phylogenies when the Number of Character States is Fixed.
SODA	Computing the Local Consensus of Trees.	Sampath Kannan,Tandy Warnow,Shibu Yooseph	1995	The inference of consensus from a set of evolutionary trees is a fundamental problem in a number of fields such as biology and historical linguistics, and many models for inferring this consensus have been proposed. In this paper we present a model for deriving what we call a local consensus tree T from a set of trees ${\cal T}$. The model we propose presumes a function f, called a total local consensus function, which determines for every triple A of species, the form that the local consensus tree should take on A. We show that all local consensus trees, when they exist, can be constructed in polynomial time and that many fundamental problems can be solved in linear time. We also consider partial local consensus functions and study optimization problems under this model. We present linear time algorithms for several variations. Finally we point out that the local consensus approach ties together many previous approaches to constructing consensus trees.
SODA	Polynomial Methods for Separable Convex Optimization in Unimodular Spaces.	Alexander V. Karzanov,S. Thomas McCormick	1995	Polynomial Methods for Separable Convex Optimization in Unimodular Spaces.
SODA	Of Mice and Men: Algorithms for Evolutionary Distances Between Genomes with Translocation.	John D. Kececioglu,R. Ravi	1995	Of Mice and Men: Algorithms for Evolutionary Distances Between Genomes with Translocation.
SODA	Lower Bounds for Identifying Subset Members with Subset Queries.	Emanuel Knill	1995	Lower Bounds for Identifying Subset Members with Subset Queries.
SODA	Using Network Flows for Surface Modeling.	Rolf H. Möhring,Matthias Müller-Hannemann,Karsten Weihe	1995	Using Network Flows for Surface Modeling.
SODA	Average-Case Analysis of Off-Line and On-Line Knapsack Problems.	George S. Lueker	1995	Average-Case Analysis of Off-Line and On-Line Knapsack Problems.
SODA	Adapted Diameters and the Efficient Computation of Fourier Transforms on Finite Groups.	David Keith Maslen,Daniel N. Rockmore	1995	Adapted Diameters and the Efficient Computation of Fourier Transforms on Finite Groups.
SODA	Chaining Multiple-Alignment Fragments in Sub-Quadratic Time.	Gene Myers,Webb Miller	1995	Chaining Multiple-Alignment Fragments in Sub-Quadratic Time.
SODA	Computing a Minimum-Weight k-Link Path in Graphs with the Concave Monge Property.	Baruch Schieber	1995	Computing a Minimum-Weight k-Link Path in Graphs with the Concave Monge Property.
SODA	A Combinatorial Algorithm for Minimizing Symmetric Submodular Functions.	Maurice Queyranne	1995	A Combinatorial Algorithm for Minimizing Symmetric Submodular Functions.
SODA	Fast Deterministic Approximation for the Multicommodity Flow Problem.	Tomasz Radzik	1995	Fast Deterministic Approximation for the Multicommodity Flow Problem.
SODA	On the Statistical Dependencies of Coalesced Hashing and Their Implications for Both Full and Limited Independence.	Alan Siegel	1995	On the Statistical Dependencies of Coalesced Hashing and Their Implications for Both Full and Limited Independence.
SODA	David P. Williamson: An Approximation Algorithm for Minimum-Cost Vertex-Connectivity Problems.	R. Ravi	1995	David P. Williamson: An Approximation Algorithm for Minimum-Cost Vertex-Connectivity Problems.
SODA	The P-range Tree: A New Data Structure for Range Searching in Secondary Memory.	Sairam Subramanian,Sridhar Ramaswamy	1995	The P-range Tree: A New Data Structure for Range Searching in Secondary Memory.
SODA	Randomized Rounding Without Solving the Linear Program.	Neal E. Young	1995	Randomized Rounding Without Solving the Linear Program.
SODA	Finding Optimal Edge-Rankings of Trees.	Xiao Zhou,Takao Nishizeki	1995	Finding Optimal Edge-Rankings of Trees.
SODA	Proceedings of the Sixth Annual ACM-SIAM Symposium on Discrete Algorithms, 22-24 January 1995. San Francisco, California.	Kenneth L. Clarkson	1995	Proceedings of the Sixth Annual ACM-SIAM Symposium on Discrete Algorithms, 22-24 January 1995. San Francisco, California.
STOC	Parallel randomized load balancing (Preliminary Version).	Micah Adler,Soumen Chakrabarti,Michael Mitzenmacher,Lars Eilstrup Rasmussen	1995	Parallel randomized load balancing (Preliminary Version).
STOC	Wait-free made fast (Extended Abstract).	Yehuda Afek,Dalia Dauber,Dan Touitou	1995	Wait-free made fast (Extended Abstract).
STOC	Motion planning for a steering-constrained robot through moderate obstacles.	Pankaj K. Agarwal,Prabhakar Raghavan,Hisao Tamaki	1995	Motion planning for a steering-constrained robot through moderate obstacles.
STOC	Distinguishing tests for nondeterministic and probabilistic machines.	Rajeev Alur,Costas Courcoubetis,Mihalis Yannakakis	1995	Distinguishing tests for nondeterministic and probabilistic machines.
STOC	Computing faces in segment and simplex arrangements (Preliminary Version).	Nancy M. Amato,Michael T. Goodrich,Edgar A. Ramos	1995	Computing faces in segment and simplex arrangements (Preliminary Version).
STOC	Knowledge on the average-perfect, statistical and logarithmic.	William Aiello,Mihir Bellare,Ramarathnam Venkatesan	1995	Knowledge on the average-perfect, statistical and logarithmic.
STOC	Sorting in linear time?	Arne Andersson,Torben Hagerup,Stefan Nilsson,Rajeev Raman	1995	Sorting in linear time?
STOC	A tight lower bound for searching a sorted array.	Arne Andersson,Johan Håstad,Ola Petersson	1995	A tight lower bound for searching a sorted array.
STOC	Polynomial time approximation schemes for dense instances of -hard problems.	Sanjeev Arora,David R. Karger,Marek Karpinski	1995	Polynomial time approximation schemes for dense instances of -hard problems.
STOC	Euclidean spanners: short, thin, and lanky.	Sunil Arya,Gautam Das,David M. Mount,Jeffrey S. Salowe,Michiel H. M. Smid	1995	Euclidean spanners: short, thin, and lanky.
STOC	Improved approximation guarantees for minimum-weight -trees and prize-collecting salesmen.	Baruch Awerbuch,Yossi Azar,Avrim Blum,Santosh Vempala	1995	"Consider a salesperson that must sell some quota of brushes in order to win a trip to Hawaii. This salesperson has a map (a weighted graph) in which each city has an attached demand specifying the number of brushes that can be sold in that city. What is the best route to take to sell the quota while traveling the least distance possible? Notice that unlike the standard traveling salesman problem, not only do we need to figure out the order in which to visit the cities, but we must decide the more fundamental question: which cities do we want to visit? In this paper we give the first approximation algorithms with poly-logarithmic performance guarantees for this problem, as well as for the slightly more general PCTSP problem of Balas, and a variation we call the ""bank-robber problem"" (also called the ""orienteering problem"" by Golden, Levi, and Vohra). We do this by providing an O(log^2 k) approximation to the k-MST problem which is defined as follows. Given an undirected graph on n nodes with non-negative edge weights and an integer k > n, find the tree of least weight that spans k vertices. (If desired, one may specify in the problem a ""root vertex"" that must be in the tree as well.) Our result improves on the previous best bound of O(k^0.5) of Ravi et al. and comes quite close to the bound of O(log k) of Garg and Hochbaum for the special case of points in 2-dimensional Euclidean space."
STOC	Bandwidth allocation with preemption.	Amotz Bar-Noy,Ran Canetti,Shay Kutten,Yishay Mansour,Baruch Schieber	1995	"Bandwidth allocation is a fundamental problem in the design of networks where bandwidth has to be reserved for connections in advance. The problem is intensified when the requested bandwidth exceeds the capacity and not all requests can be served. Furthermore, acceptance/rejection decisions regarding connections have to be made on-line, without knowledge of future requests. We show that the ability to preempt (i.e., abort) connections while in service in order to be able to schedule ``more valuable'''' connections substantially improves the overall throughput of some networks. We present bandwidth allocation strategies that use preemption and show that they achieve constant competiveness with respect to the throughput, given that any single call occupies only a constant fraction of the bandwidth. Our results should be contrasted with recent works showing that nonpreemptive strategies have at most logarithmic competitiveness."
STOC	More on the complexity of negation-limited circuits.	Robert Beals,Tetsuro Nishino,Keisuke Tanaka	1995	More on the complexity of negation-limited circuits.
STOC	The relative complexity of NP search problems.	Paul Beame,Stephen A. Cook,Jeff Edmonds,Russell Impagliazzo,Toniann Pitassi	1995	The relative complexity of NP search problems.
STOC	Incremental cryptography and application to virus protection.	Mihir Bellare,Oded Goldreich,Shafi Goldwasser	1995	Incremental cryptography and application to virus protection.
STOC	Provably secure session key distribution: the three party case.	Mihir Bellare,Phillip Rogaway	1995	Provably secure session key distribution: the three party case.
STOC	A constant-factor approximation for the -MST problem in the plane.	Avrim Blum,Prasad Chalasani,Santosh Vempala	1995	A constant-factor approximation for the -MST problem in the plane.
STOC	Lower bounds for cutting planes proofs with small coefficients.	Maria Luisa Bonet,Toniann Pitassi,Ran Raz	1995	Lower bounds for cutting planes proofs with small coefficients.
STOC	The k-Steiner ratio in graphs.	Al Borchers,Ding-Zhu Du	1995	A Steiner minimum tree (SMT) is the shortest-length tree in a metric space interconnecting a set of points, called the regular points, possibly using additional vertices. A k-size Steiner minimum tree (kSMT) is one that can be split into components where all regular points are leaves and all components have at most k leaves. The k-Steiner ratio, $\rho_{k}$, is the infimum of the ratios SMT/kSMT over all finite sets of regular points in all possible metric spaces, where the distances are given by a complete graph. Previously, only $\rho_{2}$ and $\rho_{3}$ were known exactly in graphs, and some bounds were known for other values of k. In this paper, we determine $\rho_{k}$ exactly for all k. From this we prove a better approximation ratio for the Steiner tree problem in graphs.
STOC	On the Fourier spectrum of monotone functions (Extended Abstract).	Nader H. Bshouty,Christino Tamon	1995	On the Fourier spectrum of monotone functions (Extended Abstract).
STOC	Bounding the power of preemption in randomized scheduling.	Ran Canetti,Sandy Irani	1995	"We study on-line scheduling in overloaded systems. Requests for jobs arrive one by one as time proceeds; the serving agents have limited capacity and not all requests can be served. Still, we want to serve the ""best"" set of requests according to some criterion. In this situation, the ability to preempt (i.e., abort) jobs in service in order to make room for better jobs that would otherwise be rejected has proven to be of great help in some scenarios. We show that, surprisingly, in many other scenarios this is not the case. In a simple, generic model, we prove a polylogarithmic lower bound on the competitiveness of randomized and preemptive on-line scheduling algorithms. Our bound applies to several recently studied problems. In fact, in certain scenarios our bound is quite close to the competitiveness achieved by known deterministic, nonpreemptive algorithms."
STOC	Lower bounds for off-line range searching.	Bernard Chazelle	1995	Lower bounds for off-line range searching.
STOC	On real Turing machines that toss coins.	Felipe Cucker,Marek Karpinski,Pascal Koiran,Thomas Lickteig,Kai Werther	1995	On real Turing machines that toss coins.
STOC	Work-time-optimal parallel algorithms for string problems.	Artur Czumaj,Zvi Galil,Leszek Gasieniec,Kunsoo Park,Wojciech Plandowski	1995	Work-time-optimal parallel algorithms for string problems.
STOC	What do we know about the Metropolis algorithm?	Persi Diaconis,Laurent Saloff-Coste	1995	What do we know about the Metropolis algorithm?
STOC	A 2-level cactus model for the system of minimum and minimum+1 edge-cuts in a graph and its incremental maintenance.	Yefim Dinitz,Zeev Nutov	1995	A 2-level cactus model for the system of minimum and minimum+1 edge-cuts in a graph and its incremental maintenance.
STOC	Bubbles: adaptive routing scheme for high-speed dynamic networks (Extended Abstract).	Shlomi Dolev,Evangelos Kranakis,Danny Krizanc,David Peleg	1995	Bubbles: adaptive routing scheme for high-speed dynamic networks (Extended Abstract).
STOC	A nearly optimal time-space lower bound for directed -connectivity on the NNJAG model.	Jeff Edmonds,Chung Keung Poon	1995	A nearly optimal time-space lower bound for directed -connectivity on the NNJAG model.
STOC	Geometric lower bounds for parametric matroid optimization.	David Eppstein	1995	Geometric lower bounds for parametric matroid optimization.
STOC	Testing multivariate linear functions: overcoming the generator bottleneck.	Funda Ergün	1995	The problem of testing program correctness has received considerable attention in computer science. One approach to this problem is the notion of self-testing programs \cite{BlumLubyRubinfeld}. Self-testing usually becomes more costly in the case of testing multivariate functions. In this paper we present efficient methods for self-testing multivariate linear functions. We then apply these methods to several multivariate linear problems to construct efficient self-testers.
STOC	String matching in Lempel-Ziv compressed strings.	Martin Farach,Mikkel Thorup	1995	String matching in Lempel-Ziv compressed strings.
STOC	Randomized graph products, chromatic numbers, and Lovasz theta-function.	Uriel Feige	1995	Randomized graph products, chromatic numbers, and Lovasz theta-function.
STOC	Impossibility results for recycling random bits in two-prover proof systems.	Uriel Feige,Joe Kilian	1995	Impossibility results for recycling random bits in two-prover proof systems.
STOC	A fully-dynamic data structure for external substring search (Extended Abstract).	Paolo Ferragina,Roberto Grossi	1995	A fully-dynamic data structure for external substring search (Extended Abstract).
STOC	Randomized and multipointer paging with locality of reference.	Amos Fiat,Anna R. Karlin	1995	Randomized and multipointer paging with locality of reference.
STOC	Secure hypergraphs: privacy from partial broadcast (Extended Abstract).	Matthew K. Franklin,Moti Yung	1995	Secure hypergraphs: privacy from partial broadcast (Extended Abstract).
STOC	"Short length versions of Menger's theorem (Extended Abstract)."	Zvi Galil,Xiangdong Yu	1995	"Short length versions of Menger's theorem (Extended Abstract)."
STOC	Tight analyses of two local load balancing algorithms.	Bhaskar Ghosh,Frank Thomson Leighton,Bruce M. Maggs,S. Muthukrishnan,C. Greg Plaxton,Rajmohan Rajaraman,Andréa W. Richa,Robert Endre Tarjan,David Zuckerman	1995	This paper presents an analysis of the following load balancing algorithm. At each step, each node in a network examines the number of tokens at each of its neighbors and sends a token to each neighbor with at least 2d+1 fewer tokens, where d is the maximum degree of any node in the network. We show that within $O(\Delta / \alpha)$ steps, the algorithm reduces the maximum difference in tokens between any two nodes to at most $O((d^2 \log n)/\alpha)$, where $\Delta$ is the global imbalance in tokens (i.e., the maximum difference between the number of tokens at any node initially and the average number of tokens), n is the number of nodes in the network, and $\alpha$ is the edge expansion of the network. The time bound is tight in the sense that for any graph with edge expansion $\alpha$, and for any value $\Delta$, there exists an initial distribution of tokens with imbalance $\Delta$ for which the time to reduce the imbalance to even $\Delta/2$ is at least $\Omega(\Delta/\alpha)$. The bound on the final imbalance is tight in the sense that there exists a class of networks that can be locally balanced everywhere (i.e., the maximum difference in tokens between any two neighbors is at most 2d), while the global imbalance remains $\Omega((d^2 \log n) / \alpha)$. Furthermore, we show that upon reaching a state with a global imbalance of $O((d^2 \log n)/\alpha)$, the time for this algorithm to locally balance the network can be as large as $\Omega(n^{1/2})$. We extend our analysis to a variant of this algorithm for dynamic and asynchronous networks. We also present tight bounds for a randomized algorithm in which each node sends at most one token in each step.
STOC	Monotone circuits for connectivity have depth (log n) (Extended Abstract).	Mikael Goldmann,Johan Håstad	1995	Monotone circuits for connectivity have depth (log n) (Extended Abstract).
STOC	Descriptive complexity theory over the real numbers.	Erich Grädel,Klaus Meer	1995	Descriptive complexity theory over the real numbers.
STOC	Transforming cabbage into turnip: polynomial algorithm for sorting signed permutations by reversals.	Sridhar Hannenhalli,Pavel A. Pevzner	1995	"Genomes frequently evolve by reversals &rgr;(i,j) that transform a gene order &pgr;1 &hellip; &pgr;i&pgr;i+1 &hellip; &pgr;j-1&pgr;j &hellip; &pgr;n into &pgr;1 &hellip; &pgr;i&pgr;j-1 &hellip; &pgr;i+1&pgr;j &hellip; &pgr;n. Reversal distance between permutations &pgr; and &sgr;is the minimum number of reversals to transform &pgr; into &Agr;. Analysis of genome rearrangements in molecular biology started in the late 1930's, when Dobzhansky and Sturtevant published a milestone paper presenting a rearrangement scenario with 17 inversions between the species of Drosophilia. Analysis of genomes evolving by inversions leads to a combinatorial problem of sorting by reversals studied in detail recently. We study sorting of signed permutations by reversals, a problem that adequately models rearrangements in a small genomes like chloroplast or mitochondrial DNA. The previously suggested approximation algorithms for sorting signed permutations by reversals compute the reversal distance between permutations with an astonishing accuracy for both simulated and biological data. We prove a duality theorem explaining this intriguing performance and show that there exists a &ldquo;hidden&rdquo; parameter that allows one to compute the reversal distance between signed permutations in polynomial time."
STOC	Bounding delays in packet-routing networks.	Mor Harchol-Balter,David Wolfe	1995	Bounding delays in packet-routing networks.
STOC	Fast protein folding in the hydrophobic-hydrophilic model within three-eights of optimal (Extended Abstract).	William E. Hart,Sorin Istrail	1995	Fast protein folding in the hydrophobic-hydrophilic model within three-eights of optimal (Extended Abstract).
STOC	How many queries are needed to learn?	Lisa Hellerstein,Krishnan Pillaipakkamnatt,Vijay V. Raghavan,Dawn Wilkins	1995	We investigate the query complexity of exact learning in the membership and (proper) equivalence query model. We give a complete characterization of concept classes that are learnable with a polynomial number of polynomial sized queries in this model. We give applications of this characterization, including results on learning a natural subclass of DNF formulas, and on learning with membership queries alone. Query complexity has previously been used to prove lower bounds on the time complexity of exact learning. We show a new relationship between query complexity and time complexity in exact learning: If any &ldquo;honest&rdquo; class is exactly and properly learnable with polynomial query complexity, but not learnable in polynomial time, then P = NP. In particular, we show that an honest class is exactly polynomial-query learnable if and only if it is learnable using an oracle for &Ggr;p4.
STOC	Randomized dynamic graph algorithms with polylogarithmic time per operation.	Monika Rauch Henzinger,Valerie King	1995	Randomized dynamic graph algorithms with polylogarithmic time per operation.
STOC	"What's decidable about hybrid automata?"	Thomas A. Henzinger,Peter W. Kopke,Anuj Puri,Pravin Varaiya	1995	Hybrid automata model systems with both digital and analog components, such as embedded control programs. Many verification tasks for such programs can be expressed as reachability problems for hybrid automata. By improving on previous decidability and undecidability results, we identify the precise boundary between decidability and undecidability of the reachability problem for hybrid automata. On the positive side, we give an (optimal) PSPACE reachability algorithm for the case of initialized rectangular automata, where all analog variables follow trajectories within piecewise-linear envelopes and are reinitialized whenever the envelope changes. Our algorithm is based on the construction of a timed automaton that contains all reachability information about a given initialized rectangular automaton. The translation has practical significance for verification, because it guarantees the termination of symbolic procedures for the reachability analysis of initialized rectangular automata. The translation also preserves the $\omega$-languages of initialized rectangular automata with bounded nondeterminism. On the negative side, we show that several slight generalizations of initialized rectangular automata lead to an undecidable reachability problem. In particular, we prove that the reachability problem is undecidable for timed automata augmented with a single stopwatch.
STOC	Lower bounds for sorting networks.	Nabil Kahale,Frank Thomson Leighton,Yuan Ma,C. Greg Plaxton,Torsten Suel,Endre Szemerédi	1995	Lower bounds for sorting networks.
STOC	Subquadratic-time factoring of polynomials over finite fields.	Erich Kaltofen,Victor Shoup	1995	Subquadratic-time factoring of polynomials over finite fields.
STOC	Persistent lists with catenation via recursive slow-down.	Haim Kaplan,Robert Endre Tarjan	1995	Persistent lists with catenation via recursive slow-down.
STOC	A randomized fully polynomial time approximation scheme for the all terminal network reliability problem.	David R. Karger	1995	The classic all-terminal network reliability problem posits a graph, each of whose edges fails independently with some given probability. The goal is to determine the probability that the network becomes disconnected due to edge failures. This problem has obvious applications in the design of communication networks. Since the problem is ${\sharp {\cal P}}$-complete and thus believed hard to solve exactly, a great deal of research has been devoted to estimating the failure probability. In this paper, we give a fully polynomial randomized approximation scheme that, given any n-vertex graph with specified failure probabilities, computes in time polynomial in n and $1/\epsilon$ an estimate for the failure probability that is accurate to within a relative error of $1\pm\epsilon$ with high probability. We also give a deterministic polynomial approximation scheme for the case of small failure probabilities. Some extensions to evaluating probabilities of $k$-connectivity, strong connectivity in directed Eulerian graphs and $r$-way disconnection, and to evaluating the Tutte polynomial are also described. This version of the paper corrects several errata that appeared in the previous journal publication [D. R. Karger, SIAM J. Comput., 29 (1999), pp. 492--514].
STOC	Adding multiple cost constraints to combinatorial optimization problems, with applications to multicommodity flows.	David R. Karger,Serge A. Plotkin	1995	Adding multiple cost constraints to combinatorial optimization problems, with applications to multicommodity flows.
STOC	Polynomial bounds for VC dimension of sigmoidal neural networks.	Marek Karpinski,Angus Macintyre	1995	We introduce a new method for proving explicit upper bounds on the VC Dimension of general functional basis networks, and prove as an application, for the first time, the VC Dimension of analog neural networks with the sigmoid activation function $\sigma(y)=1/1+e^{-y}$ to be bounded by a quadratic polynomial in the number of programmable parameters.
STOC	Randomized query processing in robot path planning (Extended Abstract).	Lydia E. Kavraki,Jean-Claude Latombe,Rajeev Motwani,Prabhakar Raghavan	1995	Randomized query processing in robot path planning (Extended Abstract).
STOC	Improved approximation algorithms for uniform connectivity problems.	Samir Khuller,Balaji Raghavachari	1995	Improved approximation algorithms for uniform connectivity problems.
STOC	Additive versus exponentiated gradient updates for linear prediction.	Jyrki Kivinen,Manfred K. Warmuth	1995	Additive versus exponentiated gradient updates for linear prediction.
STOC	Approximations for the disjoint paths problem in high-diameter planar networks.	Jon M. Kleinberg,Éva Tardos	1995	Approximations for the disjoint paths problem in high-diameter planar networks.
STOC	Optimal (up to polylog factors) sequential and parallel algorithms for approximating complex polynomial zeros.	Victor Y. Pan	1995	Optimal (up to polylog factors) sequential and parallel algorithms for approximating complex polynomial zeros.
STOC	Large-scale assembly of DNA strings and space-efficient construction of suffix trees.	S. Rao Kosaraju,Arthur L. Delcher	1995	Large-scale assembly of DNA strings and space-efficient construction of suffix trees.
STOC	On randomized one-round communication complexity.	Ilan Kremer,Noam Nisan,Dana Ron	1995	On randomized one-round communication complexity.
STOC	Log-space polynomial end-to-end communication.	Eyal Kushilevitz,Rafail Ostrovsky,Adi Rosén	1995	Communication between processors is the essence of distributed computing: clearly, without communication, distributed computation is impossible. However, as networks become larger and larger, the frequency of link failures increases. The end-to-end communication problem asks how to efficiently carry out fault-free communication between two processors over a network, in spite of such frequent link failures. The sole minimum assumption is that the two processors that are trying to communicate are not permanently disconnected (i.e., the communication should proceed even when there does not (ever) simultaneously exist an operational path between the two processors that are trying to communicate).We present a protocol to solve the end-to-end problem with logarithmic-space and polynomial communication at the same time. This is an exponential memory improvement to all previous polynomial communication solutions. That is, all previous polynomial communication solutions needed at least linear (in n, the size of the network) amount of memory per link.Our protocol transfers packets over the network, maintains a simple-to-compute O(log n)-bits potential function at each link in order to perform routing, and uses a novel technique of packet canceling which allows us to keep only one packet per link. The computations of both our potential function and our packet-canceling policy are totally local in nature.
STOC	Efficient stopping rules for Markov chains.	László Lovász,Peter Winkler	1995	Efficient stopping rules for Markov chains.
STOC	Many-to-one packet routing on grids (Extended Abstract).	Yishay Mansour,Boaz Patt-Shamir	1995	Many-to-one packet routing on grids (Extended Abstract).
STOC	A Delaunay based numerical method for three dimensions: generation, formulation, and partition.	Gary L. Miller,Dafna Talmor,Shang-Hua Teng,Noel Walkington	1995	A Delaunay based numerical method for three dimensions: generation, formulation, and partition.
STOC	On data structures and asymmetric communication complexity.	Peter Bro Miltersen,Noam Nisan,Shmuel Safra,Avi Wigderson	1995	On data structures and asymmetric communication complexity.
STOC	Symmetric logspace is closed under complement.	Noam Nisan,Amnon Ta-Shma	1995	We present a Logspace, many-one reduction from the undirected s-t connectivity problem to its complement. This shows that SL=coSL.
STOC	On the complexity of bilinear forms: dedicated to the memory of Jacques Morgenstern.	Noam Nisan,Avi Wigderson	1995	On the complexity of bilinear forms: dedicated to the memory of Jacques Morgenstern.
STOC	A lower bound for integer multiplication with read-once branching programs.	Stephen Ponzio	1995	We prove that read-once branching programs computing integer multiplication require size $2^{\Omega(\sqrt{n})}$. This is the first nontrivial lower bound for multiplication on branching programs that are not oblivious. By the appropriate problem reductions, we obtain the same lower bound for other arithmetic functions.
STOC	Two Steiner tree packing problems (Extended Abstract).	William R. Pulleyblank	1995	Two Steiner tree packing problems (Extended Abstract).
STOC	A computational view of population genetics.	Yuval Rabani,Yuri Rabinovich,Alistair Sinclair	1995	A computational view of population genetics.
STOC	Stochastic contention resolution with short delays.	Prabhakar Raghavan,Eli Upfal	1995	We study contention resolution protocols under a stochastic model of continuous request generation from a set of contenders. The performance of such a protocol is characterized by two parameters: the maximum arrival rate for which the protocol is stable and the expected delay of a request from arrival to service. Known solutions are either unstable for any constant injection rate, or have polynomial (in the number of contenders) expected delay. Our main contribution is a protocol that is stable for a constant injection rate, while achieving logarithmic expected delay. We extend our results to the case of multiple servers, with each request being targeted for a specific server. This is related to the optically connected parallel computer (or OCPC ) model. Finally, we prove a lower bound showing that long delays are inevitable in a class of protocols including backoff-style protocols, if the arrival rate is large enough (but still smaller than 1).
STOC	Recognition of graphs with threshold dimension two.	Thomas Raschle,Klaus Simon	1995	Recognition of graphs with threshold dimension two.
STOC	A parallel repetition theorem.	Ran Raz	1995	We show that a parallel repetition of any two-prover one-round proof system (MIP(2,1)) decreases the probability of error at an exponential rate. No constructive bound was previously known. The constant in the exponent (in our analysis) depends only on the original probability of error and on the total number of possible answers of the two provers. The dependency on the total number of possible answers is logarithmic, which was recently proved to be almost the best possible [U. Feige and O. Verbitsky, Proc.11th Annual IEEE Conference on Computational Complexity, IEEE Computer Society Press, Los Alamitos, CA, 1996, pp. 70--76].
STOC	Work efficient parallel solution of Toeplitz systems and polynomial GCD.	John H. Reif	1995	Work efficient parallel solution of Toeplitz systems and polynomial GCD.
STOC	Explicit dispersers with polylog degree.	Michael E. Saks,Aravind Srinivasan,Shiyu Zhou	1995	Explicit dispersers with polylog degree.
STOC	Linear-time encodable and decodable error-correcting codes.	Daniel A. Spielman	1995	Linear-time encodable and decodable error-correcting codes.
STOC	Improved approximations of packing and covering problems.	Aravind Srinivasan	1995	Improved approximations of packing and covering problems.
STOC	Average-case completeness of a word problem for groups.	Jie Wang	1995	Average-case completeness of a word problem for groups.
STOC	Security of quantum protocols against coherent measurements.	Andrew Chi-Chih Yao	1995	Security of quantum protocols against coherent measurements.
STOC	Proceedings of the Twenty-Seventh Annual ACM Symposium on Theory of Computing, 29 May-1 June 1995, Las Vegas, Nevada, USA		1995	Proceedings of the Twenty-Seventh Annual ACM Symposium on Theory of Computing, 29 May-1 June 1995, Las Vegas, Nevada, USA
FOCS	New Coding Techniques for Improved Bandwidth Utilization.	Micah Adler	1996	The introduction of parallel models that account for communication between processors has shown that interprocessor bandwidth is often the limiting factor in parallel computing. In this paper, we introduce a new coding technique for transmitting the XOR of carefully selected patterns of bits to be communicated which greatly reduces bandwidth requirements in some settings. This technique has broader applications. For example, we demonstrate that the coding technique has a surprising application to a simple I/O (Input/Output) complexity problem related to finding the transpose of a matrix. Our main results are developed in the PRAM(M) model, a limited bandwidth PRAM model where P processors communicate through a small globally shared memory of M bits. We provide new algorithms for the problems of sorting and permutation routing. For the concurrent read PRAM(M), as P grows with M held constant, our sorting algorithm outperforms any previous algorithm by O(logc P) for any constant c. The combination of a known lower bound for sorting in the exclusive read PRAM(M) model and this algorithm implies that the concurrent read PRAM(M) is strictly more powerful than the exclusive read PRAM(M).
FOCS	Binary Search Partitions for Fat Rectangles.	Pankaj K. Agarwal,Edward F. Grove,T. M. Murali,Jeffrey Scott Vitter	1996	We consider the practical problem of constructing binary space partitions (BSPs) for a set S of n orthogonal, nonintersecting, two-dimensional rectangles in ${\Bbb R}^3$ such that the aspect ratio of each rectangle in $S$ is at most $\alpha$, for some constant $\alpha \geq 1$. We present an $n2^{O(\sqrt{\log n})}$-time algorithm to build a binary space partition of size $n2^{O(\sqrt{\log n})}$ for $S$. We also show that if $m$ of the $n$ rectangles in $S$ have aspect ratios greater than $\alpha$, we can construct a BSP of size $n\sqrt{m}2^{O(\sqrt{\log n})}$ for $S$ in $n\sqrt{m}2^{O(\sqrt{\log n})}$ time. The constants of proportionality in the big-oh terms are linear in $\log \alpha$. We extend these results to cases in which the input contains nonorthogonal or intersecting objects.
FOCS	The Boolean Isomorphism Problem.	Manindra Agrawal,Thomas Thierauf	1996	The Boolean Isomorphism Problem.
FOCS	Polynomial Simulations of Decohered Quantum Computers.	Dorit Aharonov,Michael Ben-Or	1996	"Recently it has become clear, that a key issue in quantum computation is understanding how interaction with the environment, or ""decoherence"", affects the computational power of quantum computers. We adopt the standard physical method of describing systems which are interwound with their environment by ""density matrices"", and within this framework define a model of decoherence in quantum computation. Our results show that the computational power of decohered quantum computers depends strongly on the amount of parallelism in the computation. We first present a simulation of decohered sequential quantum computers, on a classical probabilistic Turing machine, and prove that the expected slowdown of this simulation is polynomial in time and space of the quantum computation, for any non zero decoherence rate. Similar results hold for quantum computers that are allowed to operate on logarithmic number of qubits at a time. For decohered quantum circuits (with local gates), the situation is more subtle and depends on the decoherence rate, /spl eta/. We find that our simulation is efficient for circuits with decoherence rate /spl eta/ higher than some constant /spl eta//sub 1/ but exponential for a general (random) circuit subjected to decoherence rate lower than some constant /spl eta//sub 2/. The transition from exponential cost to polynomial cost happens in a short range of decoherence rates. We use computer experiments to exhibit the phase transitions in various quantum circuits."
FOCS	The Geometry of Coin-Weighing Problems.	Noga Alon,Dmitry N. Kozlov,Van H. Vu	1996	The Geometry of Coin-Weighing Problems.
FOCS	Potential of the Approximation Method (extended abstract).	Kazuyuki Amano,Akira Maruoka	1996	Potential of the Approximation Method (extended abstract).
FOCS	Tree Data Structures for N-Body Simulation.	Richard J. Anderson	1996	"In this paper, we study data structures for use in N-body simulation. We concentrate on the spatial decomposition tree used in particle-cluster force evaluation algorithms such as the Barnes-Hut algorithm. We prove that a k-d tree is asymptotically inferior to a spatially balanced tree. We show that the worst case complexity of the force evaluation algorithm using a k-d tree is T(n log3 n log L) compared with T (n log L) for an oct-tree. (L is the separation ratio of the set of points.) We also investigate improving the constant factor of the algorithm, and present several methods which improve over the standard oct-tree decomposition. Finally, we consider whether or not the bounding box of a point set should be ""tight"", and show that it is only safe to use tight bounding boxes for binary decompositions. The results are all directly applicable to practical implementations of N-body algorithms."
FOCS	Faster Deterministic Sorting and Searching in Linear Space.	Arne Andersson	1996	We present a significant improvement on linear space deterministic sorting and searching. On a unit-cost RAM with word size w, an ordered set of n w-bit keys (viewed as binary strings or integers) can be maintained in O(min{[/spl radic/(logn)][logn/logw+loglogn][logwloglogn]}) time per operation, including insert, delete, member search, and neighbour search. The cost for searching is worst-case while the cost for updates is amortized. As an application, n keys can be sorted in linear at O(n/spl radic/(logn)) worst-case cost. The best previous method for deterministic sorting and searching in linear space has been the fusion trees which supports updates and queries in O(logn/loglogn) amortized time and sorting in O(nlogn/loglogn) worst-case time. We also make two minor observations on adapting our data structure to the input distribution and on the complexity of perfect hashing.
FOCS	Static Dictionaries on AC RAMs: Query Time Theta(sqrt(log n/log log n)) is Necessary and Sufficient.	Arne Andersson,Peter Bro Miltersen,Søren Riis,Mikkel Thorup	1996	Static Dictionaries on AC RAMs: Query Time Theta(sqrt(log n/log log n)) is Necessary and Sufficient.
FOCS	Universal Stability Results for Greedy Contention-Resolution Protocols.	Matthew Andrews,Baruch Awerbuch,Antonio Fernández,Jon M. Kleinberg,Frank Thomson Leighton,Zhiyong Liu	1996	Universal Stability Results for Greedy Contention-Resolution Protocols.
FOCS	New Algorithms for the Disk Scheduling Problem.	Matthew Andrews,Michael A. Bender,Lisa Zhang	1996	Processor speed and memory capacity are increasing several times faster than disk speed. This disparity suggests that disk I/O performance will become an important bottleneck. Methods are needed for using disks more efficiently. Past analysis of disk scheduling algorithms has largely been experimental and little attempt has been made to develop algorithms with provable performance guarantees. We consider the following disk scheduling problem. Given a set of requests on a computer disk and a convex reachability function which determines how fast the disk head travels between tracks, our goal is to schedule the disk head so that it services all the requests in the shortest time possible. We present a 3/2-approximation algorithm (with a constant additive term). For the special case in which the reachability function is linear we present an optimal polynomial-time solution. The disk scheduling problem is related to the special case of the asymmetric Traveling Salesman Problem with the triangle inequality (ATSP-/spl Delta/) in which all distances are either 0 or some constant /spl alpha/. We show how to find the optimal tour in polynomial time and describe how this gives another approximation algorithm for the disk scheduling problem. Finally we consider the on-line version of the problem in which uniformly-distributed requests arrive over time. We present an algorithm (related to the above ATSP-/spl Delta/) that appears to give higher throughput than previously existing head scheduling algorithms.
FOCS	Optimal Dynamic Interval Management in External Memory (extended abstract).	Lars Arge,Jeffrey Scott Vitter	1996	Optimal Dynamic Interval Management in External Memory (extended abstract).
FOCS	Discrepancy Sets and Pseudorandom Generators for Combinatorial Rectangles.	Roy Armoni,Michael E. Saks,Avi Wigderson,Shiyu Zhou	1996	A common subproblem of DNF approximate counting and derandomizing RL is the discrepancy problem for combinatorial rectangles. We explicitly construct a poly(n)-size sample space that approximates the volume of any combinatorial rectangle in [n]/sup n/ to within o(1) error. The construction extends the previous techniques for the analogous hitting set problem, most notably via discrepancy preserving reductions.
FOCS	Polynomial Time Approximation Schemes for Euclidean TSP and Other Geometric Problems.	Sanjeev Arora	1996	We present a polynomial time approximation scheme for Euclidean TSP in /spl Rfr//sup 2/. Given any n nodes in the plane and /spl epsiv/>0, the scheme finds a (1+/spl epsiv/)-approximation to the optimum traveling salesman tour in time n/sup 0(1//spl epsiv/)/. When the nodes are in /spl Rfr//sup d/, the running time increases to n(O/spl tilde/(log/sup d-2/n)//spl epsiv//sup d-1/) The previous best approximation algorithm for the problem (due to Christofides (1976)) achieves a 3/2-approximation in polynomial time. We also give similar approximation schemes for a host of other Euclidean problems, including Steiner Tree, k-TSP, Minimum degree-k, spanning tree, k-MST, etc. (This list may get longer; our techniques are fairly general.) The previous best approximation algorithms for all these problems achieved a constant-factor approximation. All our algorithms also work, with almost no modification, when distance is measured using any geometric norm (such as l/sub p/ for p/spl ges/1 or other Minkowski norms).
FOCS	A New Rounding Procedure for the Assignment Problem with Applications to Dense Graph Arrangement Problems.	Sanjeev Arora,Alan M. Frieze,Haim Kaplan	1996	A New Rounding Procedure for the Assignment Problem with Applications to Dense Graph Arrangement Problems.
FOCS	Fault Tolerant Data Structures.	Yonatan Aumann,Michael A. Bender	1996	The authors consider the tolerance of data structures to memory faults. They observe that many pointer-based data structures (e.g. linked lists, trees, etc.) are highly nonresilient to faults. A single fault in a linked list or tree may result in the loss of the entire set of data. They present a formal framework for studying the fault tolerance properties of pointer-based data structures, and provide fault tolerant versions of the stack, the linked list, and the dictionary tree.
FOCS	Probabilistic Approximations of Metric Spaces and Its Algorithmic Applications.	Yair Bartal	1996	"This paper provides a novel technique for the analysis of randomized algorithms for optimization problems on metric spaces, by relating the randomized performance ratio for any, metric space to the randomized performance ratio for a set of ""simple"" metric spaces. We define a notion of a set of metric spaces that probabilistically-approximates another metric space. We prove that any metric space can be probabilistically-approximated by hierarchically well-separated trees (HST) with a polylogarithmic distortion. These metric spaces are ""simple"" as being: (1) tree metrics; (2) natural for applying a divide-and-conquer algorithmic approach. The technique presented is of particular interest in the context of on-line computation. A large number of on-line algorithmic problems, including metrical task systems, server problems, distributed paging, and dynamic storage rearrangement are defined in terms of some metric space. Typically for these problems, there are linear lower bounds on the competitive ratio of deterministic algorithms. Although randomization against an oblivious adversary has the potential of overcoming these high ratios, very little progress has been made in the analysis. We demonstrate the use of our technique by obtaining substantially improved results for two different on-line problems."
FOCS	Simplified and Improved Resolution Lower Bounds.	Paul Beame,Toniann Pitassi	1996	We give simple new lower bounds on the lengths of resolution proofs for the pigeonhole principle and for randomly generated formulas. For random formulas, our bounds significantly extend the range of formula sizes for which non-trivial lower bounds are known. For example, we show that with probability approaching 1, any resolution refutation of a randomly chosen 3-CNF formula with at most n/sup 6/5-/spl epsiv// clauses requires exponential size. Previous bounds applied only when the number of clauses was at most linear in the number of variables. For the pigeonhole principle our bound is a small improvement over previous bounds. Our proofs are more elementary than previous arguments, and establish a connection between resolution proof size and maximum clause size.
FOCS	On the Applications of Multiplicity Automata in Learning.	Amos Beimel,Francesco Bergadano,Nader H. Bshouty,Eyal Kushilevitz,Stefano Varricchio	1996	On the Applications of Multiplicity Automata in Learning.
FOCS	Pseudorandom Functions Revisited: The Cascade Construction and Its Concrete Security.	Mihir Bellare,Ran Canetti,Hugo Krawczyk	1996	"Pseudorandom function families are a powerful cryptographic primitive, yielding, in particular simple solutions for the main problems in private key cryptography. Their existence based on general assumptions (namely the existence of one-way functions) has been established. The authors investigate new ways of designing pseudorandom function families. The goal is to find constructions that are both efficient and secure, and thus eventually to bring the benefits of pseudorandom functions to practice. The basic building blocks in the design are certain limited versions of pseudorandom function families, called finite length input pseudorandom function families, for which very efficient realizations exist impractical cryptography. Thus rather than starting from one-way functions, they propose constructions of ""full-fledged"" pseudorandom function families from these limited ones. In particular they propose the cascade construction, and provide a concrete security analysis which relates the strength of the cascade to that of the underlying finite pseudorandom function family in a precise and quantitative way."
FOCS	A Polynomial-Time Algorithm for Learning Noisy Linear Threshold Functions.	Avrim Blum,Alan M. Frieze,Ravi Kannan,Santosh Vempala	1996	A Polynomial-Time Algorithm for Learning Noisy Linear Threshold Functions.
FOCS	A General Approach to Dynamic Packet Routing with Bounded Buffers (extended abstract).	Andrei Z. Broder,Alan M. Frieze,Eli Upfal	1996	A General Approach to Dynamic Packet Routing with Bounded Buffers (extended abstract).
FOCS	Approximating Minimum-Size k-Connected Spanning Subgraphs via Matching (extended abstract).	Joseph Cheriyan,Ramakrishna Thurimella	1996	Approximating Minimum-Size k-Connected Spanning Subgraphs via Matching (extended abstract).
FOCS	Incoercible Multiparty Computation (extended abstract).	Ran Canetti,Rosario Gennaro	1996	Incoercible Multiparty Computation (extended abstract).
FOCS	Approximate Option Pricing.	Prasad Chalasani,Somesh Jha,Isaac Saias	1996	Approximate Option Pricing.
FOCS	Universal Data Compression and Portfolio Selection.	Thomas M. Cover	1996	The authors consider universal data compression, universal portfolio selection (online portfolio algorithms) and the relationship of both to information theory. Apparently the fundamental minimax redundancy game in data compression and the minimax regret game for the growth rate of wealth in investment have the same answer. There is also a duality between entropy rate and the growth rate of wealth.
FOCS	The Optimal Path-Matching Problem.	William H. Cunningham,James F. Geelen	1996	We describe a common generalization of the weighted matching problem and the weighted matroid intersection problem. In this context we present results implying the polynomial-time solvability of the two problems. We also use our results to give the first strongly polynomial separation algorithm for the convex hull of matchable sets of a graph, and the first polynomial-time algorithm to compute the rank of a certain matrix of indeterminates. Our algorithmic results are based on polyhedral characterizations, and on the equivalence of separation and optimization.
FOCS	All Pairs Almost Shortest Paths.	Dorit Dor,Shay Halperin,Uri Zwick	1996	"Let G=(V,E) be an unweighted undirected graph on n vertices. A simple argument shows that computing all distances in G with an additive one-sided error of at most 1 is as hard as Boolean matrix multiplication. Building on recent work of Aingworth et al. [SIAM J. Comput., 28 (1999), pp. 1167--1181], we describe an $\Ot(\min\{n^{3/2}m^{1/2},n^{7/3}\})$-time algorithm APASP2 for computing all distances in G with an additive one-sided error of at most 2. Algorithm APASP2 is simple, easy to implement, and faster than the fastest known matrix-multiplication algorithm. Furthermore, for every even k>2, we describe an ${\tilde{O}}(\min\{n^{2-{2}/{(k+2)}}m^{{2}/{(k+2)}}, n^{2+{2}/{(3k-2)}}\})$-time algorithm APASPk for computing all distances in G with an additive one-sided error of at most k. We also give an ${\tilde{O}}(n^2)$-time algorithm ${\bf APASP}_\infty$ for producing stretch 3 estimated distances in an unweighted and undirected graph on n vertices. No constant stretch factor was previously achieved in ${\tilde{O}}(n^2)$ time.We say that a weighted graph F=(V,E') k-emulates an unweighted graph G=(V,E) if for every $u,v\in V$ we have $\delta_G(u,v)\le \delta_F(u,v)\le \delta_G(u,v)+k$. We show that every unweighted graph on n vertices has a 2-emulator with ${\tilde{O}}(n^{3/2})$ edges and a 4-emulator with ${\tilde{O}}(n^{4/3})$ edges. These results are asymptotically tight.Finally, we show that any weighted undirected graph on n vertices has a 3-spanner with ${\tilde{O}}(n^{3/2})$ edges and that such a 3-spanner can be built in ${\tilde{O}}(mn^{1/2})$ time. We also describe an ${\tilde{O}}(n(m^{2/3}+n))$-time algorithm for estimating all distances in a weighted undirected graph on n vertices with a stretch factor of at most 3."
FOCS	Median Selection Requires (2+epsilon)n Comparisons.	Dorit Dor,Uri Zwick	1996	Improving a long standing result of Bent and John [Proceedings of the 17th Annual ACM Symposium on Theory of Computing, Providence, RI, 1985, pp. 213--216], and extending a recent result of Dor, Håstad, Ulfberg, and Zwick [ SIAM J. Discrete Math., 14 (2001), pp. 299--311], we obtain a $(2{+}\epsilon)n$ lower bound (for some fixed $\epsilon>0$) on the number of comparisons required, in the worst case, for selecting the median of n elements.
FOCS	A Decision Procedure for Unitary Linear Quantum Cellular Automata.	Christoph Dürr,Miklos Santha	1996	Linear quantum cellular automata were introduced recently as one of the models of quantum computing. A basic postulate of quantum mechanics imposes a strong constraint on any quantum machine: it has to be unitary; that is, its time evolution operator has to be a unitary transformation. In this paper we give an efficient algorithm to decide if a linear quantum cellular automaton is unitary. The complexity of the algorithm is O(n(3r-1)/(r+1)) = O(n3) in the algebraic computational model if the automaton has a continuous neighborhood of size r, where n is the size of the input.
FOCS	Approximate Checking of Polynomials and Functional Equations (extended abstract).	Funda Ergün,Ravi Kumar,Ronitt Rubinfeld	1996	Approximate Checking of Polynomials and Functional Equations (extended abstract).
FOCS	Better Lower Bounds for Halfspace Emptiness.	Jeff Erickson	1996	Better Lower Bounds for Halfspace Emptiness.
FOCS	Efficient Information Gathering on the Internet (extended abstract).	Oren Etzioni,Steve Hanks,Tao Jiang,Richard M. Karp,Omid Madani,Orli Waarts	1996	Efficient Information Gathering on the Internet (extended abstract).
FOCS	An 8-Approximation Algorithm for the Subset Feedback Vertex Set Problem.	Guy Even,Joseph Naor,Leonid Zosin	1996	An 8-Approximation Algorithm for the Subset Feedback Vertex Set Problem.
FOCS	Learning Linear Transformations.	Alan M. Frieze,Mark Jerrum,Ravi Kannan	1996	Learning Linear Transformations.
FOCS	The Regularity Lemma and Approximation Schemes for Dense Problems.	Alan M. Frieze,Ravi Kannan	1996	The Regularity Lemma and Approximation Schemes for Dense Problems.
FOCS	A 3-Approximation for the Minimum Tree Spanning k Vertices.	Naveen Garg	1996	In this paper we give a 3-approximation algorithm for the problem of finding a minimum tree spanning any k-vertices in a graph. Our algorithm extends to a 3-approximation algorithm for the minimum tour that visits any k-vertices.
FOCS	Property Testing and Its Connection to Learning and Approximation.	Oded Goldreich,Shafi Goldwasser,Dana Ron	1996	In this paper, we consider the question of determining whether a function f has property P or is &egr;-far from any function with property P. A property testing algorithm is given a sample of the value of f on instances drawn according to some distribution. In some cases, it is also allowed to query f on instances of its choice. We study this question for different properties and establish some connections to problems in learning theory and approximation.In particular, we focus our attention on testing graph properties. Given access to a graph G in the form of being able to query whether an edge exists or not between a pair of vertices, we devise algorithms to test whether the underlying graph has properties such as being bipartite, k-Colorable, or having a p-Clique (clique of density p with respect to the vertex set). Our graph property testing algorithms are probabilistic and make assertions that are correct with high probability, while making a number of queries that is independent of the size of the graph. Moreover, the property testing algorithms can be used to efficiently (i.e., in time linear in the number of vertices) construct partitions of the graph that correspond to the property being tested, if it holds for the input graph.
FOCS	Equivalence in Finite-Variable Logics is Complete for Polynomial Time.	Martin Grohe	1996	How difficult is it to decide whether two finite structures can be distinguished in a given logic? For first order logic, this question is equivalent to the graph isomorphism problem with its well-known complexity theoretic difficulties. Somewhat surprisingly, the situation is much clearer when considering the fragments L/sup k/ of first-order logic whose formulae contain at most k (free or bound) variables (for some k/spl ges/1). We show that for each k/spl ges/2, equivalence in the k-variable logic L/sup k/ is complete for polynomial time under quantifier-free reductions (a weak form of NC/sub 0/ reductions). Moreover, we show that the same completeness result holds for the powerful extension C/sup k/ of L/sup k/ with counting quantifiers (for every k/spl ges/2).
FOCS	Deterministic Routing with Bounded Buffers: Turning Offline into Online Protocols.	Friedhelm Meyer auf der Heide,Christian Scheideler	1996	Deterministic Routing with Bounded Buffers: Turning Offline into Online Protocols.
FOCS	Computing Vertex Connectivity: New Bounds from Old Techniques.	Monika Rauch Henzinger,Satish Rao,Harold N. Gabow	1996	Computing Vertex Connectivity: New Bounds from Old Techniques.
FOCS	Clique is Hard to Approximate Within n.	Johan Håstad	1996	Clique is Hard to Approximate Within n.
FOCS	Solving Systems of Polynomial Congruences Modulo a Large Prime (extended abstract).	Ming-Deh A. Huang,Yiu-Chung Wong	1996	Solving Systems of Polynomial Congruences Modulo a Large Prime (extended abstract).
FOCS	Sampling According to the Multivariate Normal Density.	Ravi Kannan,Guangxing Li	1996	This paper deals with the normal density of n dependent random variables. This is a function of the form: ce(-x/sup T/Ax) where A is an n/spl times/n positive definite matrix, a: is the n-vector of the random variables and c is a suitable constant. The first problem we consider is the (approximate) evaluation of the integral of this function over the positive orthant /spl int/(x/sub 1/=0)/sup /spl infin///spl int/(x/sub 2/=0)/sup /spl infin///spl middot//spl middot//spl middot//spl int/(x/sub n/=0)/sup /spl infin//ce(-x/sup T/Ax). This problem has a long history and a substantial literature. Related to it is the problem of drawing a sample from the positive orthant with probability density (approximately) equal to ce(-x/sup T/Ax). We solve both these problems here in polynomial time using rapidly mixing Markov Chains. For proving rapid convergence of the chains to their stationary distribution, we use a geometric property called the isoperimetric inequality. Such an inequality has been the subject of recent papers for general log-concave functions. We use these techniques, but the main thrust of the paper is to exploit the special property of the normal density to prove a stronger inequality than for general log-concave functions. We actually consider first the problem of drawing a sample according to the normal density with A equal to the identity matrix from a convex set K in R/sup n/ which contains the unit ball. This problem is motivated by the problem of computing the volume of a convex set in a way we explain later. Also, the methods used in the solution of this and the orthant problem are similar.
FOCS	Approximate Strip Packing.	Claire Kenyon,Eric Rémila	1996	Approximate Strip Packing.
FOCS	Near-Optimal Parallel Prefetching and Caching.	Tracy Kimbrel,Anna R. Karlin	1996	Recently there has been a great deal of interest in the operating systems research community in prefetching and caching data from parallel disks, as a technique for enabling serial applications to improve input--output (I/O) performance. In this paper, algorithms are considered for integrated prefetching and caching in a model with a fixed-size cache and any number of backing storage devices (disks). The integration of caching and prefetching with a single disk was previously considered by Cao, Felten, Karlin, and Li. Here, it is shown that the natural extension of their aggressive algorithm to the parallel disk case is suboptimal by a factor near the number of disks in the worst case. The main result is a new algorithm, reverse aggressive, with near-optimal performance for integrated prefetching and caching in the presence of multiple disks.
FOCS	Single-Source Unsplittable Flow.	Jon M. Kleinberg	1996	"The max-flow min-cut theorem of Ford and Fulkerson is based on an even more foundational result, namely Menger's theorem on graph connectivity Menger's theorem provides a good characterization for the following single-source disjoint paths problem: given a graph G, with a source vertex s and terminals t1,...,tk, decide whether there exist edge-disjoint s-ti paths for i=1,...,k.We consider a natural, NP-hard generalization of this problem, which we call the single-source unsplittable flow problem. We are given a source and terminals as before; but now each terminal ti has a demand pi = 1, and each edge e of G has a capacity ce = 1. The problem is to decide whether one can choose a single s-ti path for each i, so that the resulting set of paths respects the capacity constraints-the total amount of demand routed across any edge e must be bounded by the capacity ce. The main results of this paper are constant-factor approximation algorithms for three natural optimization versions of this problem, in arbitrary directed and undirected graphs. The development of these algorithms requires a number of new techniques for rounding fractional solutions to network flow problems; for two of the three problems we consider, there were no previous techniques capable of providing an approximation in the general case, and for the third, the randomized rounding algorithm of Raghavan and Thompson provides a logarithmic approximation. Our techniques are also of interest from the perspective of a family of NP-hard load balancing and machine scheduling problems that can be reduced to the single-source unsplittable flow problem."
FOCS	Short Paths in Expander Graphs.	Jon M. Kleinberg,Ronitt Rubinfeld	1996	Graph expansion has proved to be a powerful general tool for analyzing the behavior of routing algorithms and the inter-connection networks on which they run. We develop new routing algorithms and structural results for bounded-degree expander graphs. Our results are unified by the fact that they are all based upon, and extend, a body of work: asserting that expanders are rich in short, disjoint paths. In particular, our work has consequences for the disjoint paths problem, multicommodity flow, and graph minor containment. We show:(i) A greedy algorithm for approximating the maximum disjoint paths problem achieves a polylogarithmic approximation ratio in bounded-degree expanders. Although our algorithm is both deterministic and on-line, its performance guarantee is an improvement over previous bounds in expanders. (ii) For a multicommodity flow problem with arbitrary demands on a bounded-degree expander there is a (1 + )-optimal solution using only flow paths of polylogarithmic length. It follows that the multicommodity flow algorithm of Awerbuch and Leighton runs in nearly linear time per commodity in expanders. Our analysis is based on establishing the following: given edge weights on an expander G, one can increase some of the weights very slightly so the resulting shortest-path metric is smooth-the min-weight path between any pair of nodes uses a polylogarithmic number of edges. (iii) Every bounded-degree expander on n nodes contains every graph with O(n/log0(1) n) nodes and edges as a minor.
FOCS	Efficient Self-Testing/Self-Correction of Linear Recurrences.	Ravi Kumar,D. Sivakumar	1996	Efficient Self-Testing/Self-Correction of Linear Recurrences.
FOCS	Computing Permanents over Fields of Characteristic 3: Where and Why It Becomes Difficult (extended abstract).	Grigory Kogan	1996	Computing Permanents over Fields of Characteristic 3: Where and Why It Becomes Difficult (extended abstract).
FOCS	Factoring Graphs to Bound Mixing Rates.	Neal Madras,Dana Randall	1996	"This paper develops a new technique for bounding the mixing rate of a Markov chain by decomposing the state space into factors. The first application is an efficient Monte Carlo Markov chain algorithm for generating random three-colorings of 2-dimensional lattice regions. This provides a rigorous tool for studying some properties of the 3-state Potts model and the ice model from statistical mechanics. As a second application, we develop similar techniques to bound the mixing rate of a Metropolis sampling algorithm by a type of ""temperature factorization"". Both factorization theorems work by using known mixing properties of related Markov chains to establish the efficiency of a new sampling algorithm."
FOCS	Load Balancing and Density Dependent Jump Markov Processes (extended abstract).	Michael Mitzenmacher	1996	Load Balancing and Density Dependent Jump Markov Processes (extended abstract).
FOCS	On the Knowledge Complexity of NP.	Erez Petrank,Gábor Tardos	1996	On the Knowledge Complexity of NP.
FOCS	Fast Fault-Tolerant Concurrent Access to Shared Objects.	C. Greg Plaxton,Rajmohan Rajaraman	1996	"We consider a synchronous model of distributed computation in which n nodes communicate via point-to-point messages, subject to the following constraints: (i) in a single ""step,"" a node can only send or receive log n words, and (ii) communication is unreliable in that a constant fraction of all messages may be lost at each step due to node and/or link failures. We design and analyze a simple local protocol for providing fast concurrent access to shared objects in this faulty network environment. In our protocol, clients use a hashing-based method to access shared objects. When a large number of clients attempt to read a given object at the same time, the object is rapidly replicated to an appropriate number of servers. Once the necessary level of replication has been achieved, each remaining request for the object is serviced within O (1) expected steps. Our protocol has practical potential for supporting high levels of concurrency in distributed file systems over wide area networks."
FOCS	Path Coloring on the Mesh.	Yuval Rabani	1996	In the minimum path coloring problem, we are given a list of pairs of vertices of a graph. We are asked to connect each pair by a colored path. Paths of the same color must be edge disjoint. Our objective is to minimize the number of colors used. This problem was raised by A. Aggarwal et al. (1994) and P. Raghavan and E. Upfal (1994) as a model for routing in all-optical networks. It is also related to questions in circuit routing. In this paper, we improve the O(ln N) approximation result of J. Kleinberg and E. Tardos (1995) for path coloring on the N/spl times/N mesh. We give an O(1) approximation algorithm to the number of colors needed, and a poly(ln ln N) approximation algorithm to the choice of paths and colors. To the best of our knowledge, these are the first sub-logarithmic bounds for any network other than trees, rings, or trees of rings. Our results are based on developing new techniques for randomized rounding. These techniques iteratively improve a fractional solution until it approaches integrality. They are motivated by the method used by F.T. Leighton, B.M. Maggs, and S.B. Rao (1994) for packet routing.
FOCS	Computationally Hard Algebraic Problems (extended abstract).	Michael O. Rabin	1996	Computationally Hard Algebraic Problems (extended abstract).
FOCS	Verifying Identities (extended abstract).	Sridhar Rajagopalan,Leonard J. Schulman	1996	Verifying Identities (extended abstract).
FOCS	Efficient Approximate and Dynamic Matching of Patterns Using a Labeling Paradigm (extended abstract).	Süleyman Cenk Sahinalp,Uzi Vishkin	1996	Efficient Approximate and Dynamic Matching of Patterns Using a Labeling Paradigm (extended abstract).
FOCS	Fault-Tolerant Quantum Computation.	Peter W. Shor	1996	It has recently been realized that use of the properties of quantum mechanics might speed up certain computations dramatically. Interest in quantum computation has since been growing. One of the main difficulties in realizing quantum computation is that decoherence tends to destroy the information in a superposition of states in a quantum computer making long computations impossible. A further difficulty is that inaccuracies in quantum state transformations throughout the computation accumulate, rendering long computations unreliable. However, these obstacles may not be as formidable as originally believed. For any quantum computation with t gates, we show how to build a polynomial size quantum circuit that tolerates O(1/logc t) amounts of inaccuracy and decoherence per gate, for some constant c; the previous bound was O(1/t). We do this by showing that operations can be performed on quantum data encoded by quantum error-correcting codes without decoding this data.
FOCS	Highly Fault-Tolerant Parallel Computation (extended abstract).	Daniel A. Spielman	1996	Highly Fault-Tolerant Parallel Computation (extended abstract).
FOCS	Spectral Partitioning Works: Planar Graphs and Finite Element Meshes.	Daniel A. Spielman,Shang-Hua Teng	1996	Spectral partitioning methods use the Fiedler vector---the eigenvector of the second-smallest eigenvalue of the Laplacian matrix---to find a small separator of a graph. These methods are important components of many scientific numerical algorithms and have been demonstrated by experiment to work extremely well. In this paper, we show that spectral partitioning methods work well on bounded-degree planar graphs and finite element meshes--- the classes of graphs to which they are usually applied. While naive spectral bisection does not necessarily work, we prove that spectral partitioning techniques can be used to produce separators whose ratio of vertices removed to edges cut is $\O{\sqrt{n}}$ for bounded-degree planar graphs and two-dimensional meshes and $\O{n^{1/d}}$ for well-shaped $d$-dimensional meshes. The heart of our analysis is an upper bound on the second-smallest eigenvalues of the Laplacian matrices of these graphs.
FOCS	Maximum Likelihood Decoding of Reed Solomon Codes.	Madhu Sudan	1996	Maximum Likelihood Decoding of Reed Solomon Codes.
FOCS	Temporal Logic and Semidirect Products: An Effective Characterization of the Until Hierarchy.	Denis Thérien,Thomas Wilke	1996	We reveal an intimate connection between semidirect products of finite semigroups and substitution of formulas in linear temporal logic. We use this connection to obtain an algebraic characterization of the until hierarchy of linear temporal logic. (The kth level of that hierarchy is comprised of all temporal properties that are expressible by a formula of nesting depth k in the until operator.) Applying deep results from finite semigroup theory we are able to prove that each level of the until hierarchy is decidable. By means of Ehrenfeucht--Fraissé games, we extend the results from linear temporal logic over finite sequences to linear temporal logic over infinite sequences.
FOCS	Gadgets, Approximation, and Linear Programming (extended abstract).	Luca Trevisan,Gregory B. Sorkin,Madhu Sudan,David P. Williamson	1996	Gadgets, Approximation, and Linear Programming (extended abstract).
FOCS	An Efficient Algorithm for Constructing Minimal Trellises for Codes over Finite Abelian Groups.	Vijay V. Vazirani,Huzur Saran,B. Sundar Rajan	1996	An Efficient Algorithm for Constructing Minimal Trellises for Codes over Finite Abelian Groups.
FOCS	"37th Annual Symposium on Foundations of Computer Science, FOCS '96, Burlington, Vermont, USA, 14-16 October, 1996"		1996	"37th Annual Symposium on Foundations of Computer Science, FOCS '96, Burlington, Vermont, USA, 14-16 October, 1996"
SODA	Fast Estimation of Diameter and Shortest Paths (without Matrix Multiplication).	Donald Aingworth,Chandra Chekuri,Rajeev Motwani	1996	Fast Estimation of Diameter and Shortest Paths (without Matrix Multiplication).
SODA	Efficient Generation of k-Directional Assembly Sequences.	Pankaj K. Agarwal,Mark de Berg,Dan Halperin,Micha Sharir	1996	Efficient Generation of k-Directional Assembly Sequences.
SODA	On the Approximability of Numerical Taxonomy (Fitting Distances by Tree Metrics).	Richa Agarwala,Vineet Bafna,Martin Farach,Babu O. Narayanan,Mike Paterson,Mikkel Thorup	1996	On the Approximability of Numerical Taxonomy (Fitting Distances by Tree Metrics).
SODA	An Empirical Study of Dynamic Graph Algorithms (Extended Abstract).	David Alberts,Giuseppe Cattaneo,Giuseppe F. Italiano	1996	An Empirical Study of Dynamic Graph Algorithms (Extended Abstract).
SODA	Optimization Problems Related to Zigzag Pocket Machining (Extended Abstract).	Esther M. Arkin,Martin Held,Christopher L. Smith	1996	Optimization Problems Related to Zigzag Pocket Machining (Extended Abstract).
SODA	Polynomial-Time Solutions to Image Segmentation.	Tetsuo Asano,Danny Z. Chen,Naoki Katoh,Takeshi Tokuyama	1996	Polynomial-Time Solutions to Image Segmentation.
SODA	On-line Generalized Steiner Problem.	Baruch Awerbuch,Yossi Azar,Yair Bartal	1996	The generalized Steiner problem (GSP) is defined as follows. We are given a graph with non-negative edge weights and a set of pairs of vertices. The algorithm has to construct minimum weight subgraph such that the two nodes of each pair are connected by a path.Off-line GSP approximation algorithms were given in Agarwal et al. (SIAM J. Comput. 24(3) (1995) 440) and Goemans and Williamson (SIAM J. Comput. 24(2) (1995) 296). We consider the on-line GSP, in which pairs of vertices arrive on-line and are needed to be connected immediately.We show that the online Min-Cost (i.e. greedy) strategy for this problem has O(log2 n) competitive ratio. The previous best algorithm was O(√nlog n) competitive (Workshop on Algorithms and Data Structures, 1993, pp. 622-633). Following this work a different (non-greedy) algorithm has been shown to achieve an O(log n) competitive ratio (Proceedings of the 29th ACM Symposium on Theory of Computing, 1997, pp. 344-353).We also consider the network connectivity leasing problem which is a generalization of the GSP. Here, edges of the graph can be either bought or leased for different costs. We provide simple randomized algorithm based on on-line generalized Steiner algorithms whose competitive ratio is within a constant factor of the best competitive algorithm for the on-line GSP.
SODA	Distributed Paging for General Networks.	Baruch Awerbuch,Yair Bartal,Amos Fiat	1996	Distributed Paging for General Networks.
SODA	Multiplicative Equations over Commuting Matrices.	László Babai,Robert Beals,Jin-yi Cai,Gábor Ivanyos,Eugene M. Luks	1996	"We consider the solvability of the equation A_1^x_1 * ... * X_k^x_k = B and generalizations, where the A_i and B are given commuting matrices over an algebraic number field F. In the semigroup membership problem, the variables x_i are constrained to be nonnegative integers. While this problem is NP-complete for variable k, we give a polynomial time algorithm if k is fixed. In the group membership problem, the matrices are assumed to be invertible, and the variables x_i may take on negative values. In this case we give a polynomial time algorithm for variable k and give an explicit description of the set of all solutions (as an affine lattice). The results generalize recent work of Cai, Lipton, and Zalcstein [CLZ] where the case k=2 is solved using Jordan Normal Forms (JNF). We achieve greater clarity simplicity, and generality by eliminating the use of JNF''s and referring to elementary concepts of the structure theory of algebras instead (notably, the radical and the local decomposition. Partial solutions are combined using algorithms for (affine lattices. The special case of 1*1 matrices was recently solved by G. Ge and we heavily rely on his results."
SODA	Multiprocessor Scheduling with Rejection.	Yair Bartal,Stefano Leonardi,Alberto Marchetti-Spaccamela,Jiri Sgall,Leen Stougie	1996	We consider a version of multiprocessor scheduling with the special feature that jobs may be rejected at a certain penalty. An instance of the problem is given by $m$ identical parallel machines and a set of $n$ jobs, with each job characterized by a processing time and a penalty. In the on-line version the jobs become available one by one and we have to schedule or reject a job before we have any information about future jobs. The objective is to minimize the makespan of the schedule for accepted jobs plus the sum of the penalties of rejected jobs.The main result is a $1+\phi\approx 2.618$ competitive algorithm for the on-line version of the problem, where $\phi$ is the golden ratio. A matching lower bound shows that this is the best possible algorithm working for all $m$. For fixed $m$ we give improved bounds; in particular, for $m=2$ we give a $\phi\approx 1.618$ competitive algorithm, which is best possible.For the off-line problem we present a fully polynomial approximation scheme for fixed $m$ and a polynomial approximation scheme for arbitrary $m$. Moreover, we present an approximation algorithm which runs in time $O(n\log n)$ for arbitrary $m$ and guarantees a $2-\frac{1}{m}$ approximation ratio.
SODA	Randomized Robot Navigation Algorithms.	Piotr Berman,Avrim Blum,Amos Fiat,Howard J. Karloff,Adi Rosén,Michael E. Saks	1996	Randomized Robot Navigation Algorithms.
SODA	The Complexity of Flat Origami.	Marshall W. Bern,Barry Hayes	1996	The Complexity of Flat Origami.
SODA	Worst-Case Efficient Priority Queues.	Gerth Stølting Brodal	1996	Worst-Case Efficient Priority Queues.
SODA	An Efficient Algorithm for the Vertex-Disjoint Paths Problem in Random Graphs.	Andrei Z. Broder,Alan M. Frieze,Stephen Suen,Eli Upfal	1996	An Efficient Algorithm for the Vertex-Disjoint Paths Problem in Random Graphs.
SODA	Selecting Training Inputs via Greedy Rank Covering.	Adam L. Buchsbaum,Jan P. H. van Santen	1996	Selecting Training Inputs via Greedy Rank Covering.
SODA	A Better Approximation Algorithm for Finding Planar Subgraphs.	Gruia Calinescu,Cristina G. Fernandes,Ulrich Finkler,Howard J. Karloff	1996	A Better Approximation Algorithm for Finding Planar Subgraphs.
SODA	Isomorphism Testing and Display of Symmetries in Dynamic Trees.	Siu-Wing Cheng,Moon-Pun Ng	1996	Isomorphism Testing and Display of Symmetries in Dynamic Trees.
SODA	Improving Biconnectivity Approximation via Local Optimization.	Ka Wong Chong,Tak Wah Lam	1996	Improving Biconnectivity Approximation via Local Optimization.
SODA	Efficient Suffix Trees on Secondary Storage (extended Abstract).	David R. Clark,J. Ian Munro	1996	Efficient Suffix Trees on Secondary Storage (extended Abstract).
SODA	An O(n log n) Algorithm for the Maximum Agreement Subtree Problem for Binary Trees.	Richard Cole,Ramesh Hariharan	1996	An O(n log n) Algorithm for the Maximum Agreement Subtree Problem for Binary Trees.
SODA	Preemptive Scheduling of Parallel Jobs on Multiprocessors.	Xiaotie Deng,Nian Gu,Tim Brecht,KaiCheng Lu	1996	We study the problem of processor scheduling for n parallel jobs applying the method of competitive analysis. We prove that for jobs with a single phase of parallelism, a preemptive scheduling algorithm without information about job execution time can achieve a mean completion time within $2-{2\over n+1}$ times the optimum. In other words, we prove a competitive ratio of $2-{2\over n+1}$. The result is extended to jobs with multiple phases of parallelism (which can be used to model jobs with sublinear speedup) and to interactive jobs (with phases during which the job has no CPU requirements) to derive solutions guaranteed to be within $4-{4\over n+1}$ times the optimum. In comparison with previous work, our assumption that job execution times are unknown prior to their completion is more realistic, our multiphased job model is more general, and our approximation ratio (for jobs with a single phase of parallelism) is tighter and cannot be improved. While this work presents theoretical results obtained using competitive analysis, we believe that the results provide insight into the performance of practical multiprocessor scheduling algorithms that operate in the absence of complete information.
SODA	Optimal Placement of Convex Polygons to Maximize Point Containment.	Matthew Dickerson,Daniel Scharstein	1996	Optimal Placement of Convex Polygons to Maximize Point Containment.
SODA	Fast String Searching in Secondary Storage: Theoretical Developments And Experimental Results.	Paolo Ferragina,Roberto Grossi	1996	Fast String Searching in Secondary Storage: Theoretical Developments And Experimental Results.
SODA	Increasing the Weight of Minimum Spanning Trees.	Greg N. Frederickson,Roberto Solis-Oba	1996	Increasing the Weight of Minimum Spanning Trees.
SODA	Fully Dynamic Output Bounded Single Source Shortest Path Problem (Extended Abstract).	Daniele Frigioni,Alberto Marchetti-Spaccamela,Umberto Nanni	1996	Fully Dynamic Output Bounded Single Source Shortest Path Problem (Extended Abstract).
SODA	Perfect Arborescence Packing in Preflow Mincut Graphs.	Harold N. Gabow	1996	Perfect Arborescence Packing in Preflow Mincut Graphs.
SODA	An Improved Approximation Ratio for the Minimum Latency Problem.	Michel X. Goemans,Jon M. Kleinberg	1996	An Improved Approximation Ratio for the Minimum Latency Problem.
SODA	Analysis of Practical Backoff Protocols for Contention Resolution with Multiple Servers.	Leslie Ann Goldberg,Philip D. MacKenzie	1996	Analysis of Practical Backoff Protocols for Contention Resolution with Multiple Servers.
SODA	Limit Theorems for Minimum-Weight Triangulations, Other Euclidean Functionals, and Probabilistic Recurrence Relations (Extended Abstract).	Mordecai J. Golin	1996	Limit Theorems for Minimum-Weight Triangulations, Other Euclidean Functionals, and Probabilistic Recurrence Relations (Extended Abstract).
SODA	Fixed-Dimensional Parallel Linesr Programming via epsilon-Relative-Approximations.	Michael T. Goodrich	1996	Fixed-Dimensional Parallel Linesr Programming via epsilon-Relative-Approximations.
SODA	Scheduling to Minimize Average Completion Time: Off-line and On-line Algorithms.	Leslie A. Hall,David B. Shmoys,Joel Wein	1996	Scheduling to Minimize Average Completion Time: Off-line and On-line Algorithms.
SODA	Optimal randomized EREW PRAM Algorithms for Finding Spanning Forests and for other Basic Graph Connectivity Problems.	Shay Halperin,Uri Zwick	1996	Optimal randomized EREW PRAM Algorithms for Finding Spanning Forests and for other Basic Graph Connectivity Problems.
SODA	To Cut... or Not to Cut (Applications of Comparative Physical Maps in Molecular Evolution).	Sridhar Hannenhalli,Pavel A. Pevzner	1996	To Cut... or Not to Cut (Applications of Comparative Physical Maps in Molecular Evolution).
SODA	Constructing a Tree from Homeomorphic Subtrees, with Applications to Computational Evolutionary Biology.	Monika Rauch Henzinger,Valerie King,Tandy Warnow	1996	Constructing a Tree from Homeomorphic Subtrees, with Applications to Computational Evolutionary Biology.
SODA	Interpolation of Sparse Multivariate Polynomials over Large Finite Fields with Applications.	Ming-Deh A. Huang,Ashwin J. Rao	1996	Interpolation of Sparse Multivariate Polynomials over Large Finite Fields with Applications.
SODA	Scheduling with Conflicts, and Applications to Traffic Signal Control.	Sandy Irani,Vitus J. Leung	1996	Scheduling with Conflicts, and Applications to Traffic Signal Control.
SODA	A Capacity Scaling Algorithm for Convex Cost Submodular Flows.	Satoru Iwata	1996	A Capacity Scaling Algorithm for Convex Cost Submodular Flows.
SODA	Asymptotic Experimental Analysis for the Held-Karp Traveling Salesman Bound.	David S. Johnson,Lyle A. McGeoch,Edward E. Rothberg	1996	Asymptotic Experimental Analysis for the Held-Karp Traveling Salesman Bound.
SODA	Games, Computers, and O.R.	Ehud Kalai	1996	Games, Computers, and O.R.
SODA	Routing and Admission Control in General Topology Networks with Poisson Arrivals.	Anil Kamath,Omri Palmon,Serge A. Plotkin	1996	"Emerging high speed networks will carry traffic for services such as video-on-demand and video teleconferencing -- that require resource reservation along the path on which the traffic is sent. High bandwidth-delay product of these networks prevents circuit rerouting, i.e. once a circuit is routed on a certain path, the bandwidth taken by this circuit remains unavailable for the duration (holding time) of this circuit. As a result, such networks will need effective routing and admission control strategies. Recently developed online routing and admission control strategies have logarithmic competitive ratios with respect to the admission ratio (the fraction of admitted circuits). Such guarantees on performance are rather weak in the most interesting case where the rejection ratio of the optimum algorithm is very small or even 0. Unfortunately, these guarantees can not be improved in the context of the considered models, making it impossible to use these models to identify algorithms that are going to perform well in practice. In this paper we develop routing and admission control strategies for a more realistic model, where the requests for virtual circuits between any two points arrive according to a Poisson process and where the circuit holding times are exponentially distributed. Our model is close to the one that was developed to analyse and tune the (currently used) strategies for managing traffic in long-distance telephone networks. We strengthen this model by assuming that the rates of the Poisson processes (the ``traffic matrix'''') are unknown to the algorithm and are chosen by the adversary. Our strategy is competitive with respect to the expected rejection ratio. More precisely, it achieves expected rejection ratio of at most R+epsilon, where R is the optimum expected rejection ratio. The expectations are taken over the distribution of the request sequences, and epsilon=Sqrt(r log n), where r is the maximum fraction of an edge bandwidth that can be requested by a single circuit."
SODA	Error-Resilient DNA Computation.	Richard M. Karp,Claire Kenyon,Orli Waarts	1996	Error-Resilient DNA Computation.
SODA	Sequential and Parallel Subquadratic Work Algorithms for Constructing Approximately Optimal Binary Search Trees.	Marek Karpinski,Lawrence L. Larmore,Wojciech Rytter	1996	Sequential and Parallel Subquadratic Work Algorithms for Constructing Approximately Optimal Binary Search Trees.
SODA	Best-Fit Bin-Packing with Random Order.	Claire Kenyon	1996	Best-Fit Bin-Packing with Random Order.
SODA	Biased Random Walks, Lyapunov Functions, and Stochastic Analysis of Best Fit Bin Packing (Preliminary Version).	Claire Kenyon,Yuval Rabani,Alistair Sinclair	1996	Biased Random Walks, Lyapunov Functions, and Stochastic Analysis of Best Fit Bin Packing (Preliminary Version).
SODA	On Certificates and Lookahead in Dynamic Graph Problems.	Sanjeev Khanna,Rajeev Motwani,Randall H. Wilson	1996	On Certificates and Lookahead in Dynamic Graph Problems.
SODA	Matching Nuts and Bolts in O(n log n) Time (Extended Abstract).	János Komlós,Yuan Ma,Endre Szemerédi	1996	Matching Nuts and Bolts in O(n log n) Time (Extended Abstract).
SODA	Quasi-Greedy Triangulations Approximating the Minimum Weight Triangulation.	Christos Levcopoulos,Drago Krznaric	1996	Quasi-Greedy Triangulations Approximating the Minimum Weight Triangulation.
SODA	A Commercial Application of Survivable Network Design: ITP/INPLANS CCS Network Topology Analyzer.	Milena Mihail,David Shallcross,Nate Dean,Marco Mostrel	1996	A Commercial Application of Survivable Network Design: ITP/INPLANS CCS Network Topology Analyzer.
SODA	Guillotine Subdivisions Approximate Polygonal Subdivisions: A Simple New Method for the Geometric k-MST Problem.	Joseph S. B. Mitchell	1996	Guillotine Subdivisions Approximate Polygonal Subdivisions: A Simple New Method for the Geometric k-MST Problem.
SODA	Data Collection for the Sloan Digital Sky Survey - A Network-Flow Heuristic.	Robert Lupton,F. Miller Maley,Neal E. Young	1996	Data Collection for the Sloan Digital Sky Survey - A Network-Flow Heuristic.
SODA	Time and Space Efficient Method-Lookup for Object-Oriented Programs (Extended Abstract).	S. Muthukrishnan,Martin Müller	1996	Time and Space Efficient Method-Lookup for Object-Oriented Programs (Extended Abstract).
SODA	Self-Stabilizing Algorithms for Synchronous Unidirectional Rings.	Alain J. Mayer,Rafail Ostrovsky,Moti Yung	1996	Self-Stabilizing Algorithms for Synchronous Unidirectional Rings.
SODA	A Polynomial Algorithm for Abstract Maximum Flow.	S. Thomas McCormick	1996	A Polynomial Algorithm for Abstract Maximum Flow.
SODA	A Polynomial Time Primal Network Simplex Algorithm for Minimum Cost Flows (An Extended Abstract).	James B. Orlin	1996	A Polynomial Time Primal Network Simplex Algorithm for Minimum Cost Flows (An Extended Abstract).
SODA	A New Approach to Parallel Computation of Polynomial GCD and to Related Parallel Computations over Fields and Integer Rings.	Victor Y. Pan	1996	A New Approach to Parallel Computation of Polynomial GCD and to Related Parallel Computations over Fields and Integer Rings.
SODA	Electrostatic Fields without Singularities: Theory and Algorithms.	Marco Pellegrini	1996	Electrostatic Fields without Singularities: Theory and Algorithms.
SODA	Depth Optimal Sorting Networks Resistant to k Passive Faults.	Marek Piotrów	1996	"We study the problem of constructing a sorting network that is tolerant to faults and whose running time (i.e., depth) is as small as possible. We consider the scenario of worst-case comparator faults and follow the model of passive comparator failure proposed by Yao and Yao SIAM J. Comput., 14 (1985), pp. 120--128], in which a faulty comparator outputs its inputs directly without comparison. Our main result is the first construction of an N-input k-fault-tolerant sorting network with an asymptotically optimal depth $\theta$(log N + k). That improves over the result of Leighton and Ma [Proceedings of the 5th Annual ACM Symposium on Parallel Algorithms and Architectures, Velen, Germany, 1993, ACM, New York, pp. 30--41], whose network is of depth O(log N + klog\frac{log N}{log k})$.Actually, we present a fault-tolerant correction network that can be added after any N-input sorting network to correct its output in the presence of at most k faulty comparators. Since the depth of the network is O(log N + k) and the constants hidden behind the ""O"" notation are small, the construction can be of practical use.Developing the techniques necessary to show the main result, we construct a fault-tolerant network for the insertion problem. As a by-product, we get an N-input O(log N)-depth INSERT-network that is tolerant to random faults, thereby answering a question posed by Ma in his Ph. D. thesis [Fault-Tolerant Sorting Network, Department of Mathematics, Massachusetts Institute of Technology, Cambridge, MA, 1994].The results are based on a new notion of constant delay comparator networks, that is, networks in which each register is used (compared) only in a period of time of a constant length. Copies of such networks can be pipelined with only a constant increase in the total depth per copy."
SODA	Tiling a Figure Using a Height in a Tree.	Eric Rémila	1996	Tiling a Figure Using a Height in a Tree.
SODA	An Extension of the Lovász Local Lemma, and its Applications to Integer Programming.	Aravind Srinivasan	1996	An Extension of the Lovász Local Lemma, and its Applications to Integer Programming.
SODA	On RAM Priority Queues.	Mikkel Thorup	1996	"Priority queues are some of the most fundamental data structures. For example, they are used directly for task scheduling in operating systems. Moreover, they are essential to greedy algorithms. We study the complexity of integer priority queue operations on a RAM with arbitrary word size, modeling the possibilities in standard imperative programming languages such as C. We present exponential improvements over previous bounds, and we show tight relations to sorting.Our first result is a RAM priority queue supporting find-min in constant time and insert and delete-min in time O(log log n), where n is the current number of keys in the queue. This is an exponential improvement over the $O(\sqrt{\log n})$ bound of Fredman and Willard [ Proceedings of the 22nd ACM Symposium on the Theory of Computing, Baltimore, MD, pp. 1--7]. Plugging this priority queue into Dijkstra's algorithm gives an O(mlog log m) algorithm for the single source shortest path problem on a graph with m edges, as compared with the previous $O(m\sqrt{\log m})$ bound based on Fredman and Willard's priority queue. The above bounds assume $O(n 2^{{\varepsilon} w})$ space, where w is the word length and ${\varepsilon}>0$. They can, however, be achieved in linear space using randomized hashing.Our second result is a general equivalence between sorting and priority queues. A priority queue is monotone if the minimum is nondecreasing over time, as in many greedy algorithms. We show that on a RAM, the amortized operation cost of a monotone priority queue is equivalent to the per-key cost of sorting. For example, the equivalence implies that the single source shortest paths problem on a graph with m edges is no harder than that of sorting m keys. With the current RAM sorting, this gives an O(m log log m) time bound, as above, but the relation holds regardless of the future developments in RAM sorting.From the equivalence result, for any fixed ${\varepsilon}>0$, we derive a randomized monotone $O(\sqrt{\log n}^{1+{\varepsilon}})$ priority queue with expected constant time decrease-key. Plugging this into Dijkstra's algorithm gives an $O(n\sqrt{\log n}^{1+{\varepsilon}}+m)$ algorithm for the single source shortest path problem on a graph with n nodes and m edges, complementing the above O(mlog log m) algorithm if $m\gg n$. This improves the O(nlog n/log log n + m) bound by Fredman and Willard [Proceedings of the 31st IEEE Symposium on the Foundations of Computer Science, St. Louis, MO, 1990, pp. 719--725], based on their O(log n/log log n) priority queue with constant decrease-key."
SODA	An O(log* n) Approximation Algorithm for the Asymmetric p-Center Problem.	Sundar Vishwanathan	1996	An O(log* n) Approximation Algorithm for the Asymmetric p-Center Problem.
SODA	Approximation Algorithms for Curvature-Constrained Shortest Paths.	Hongyan Wang,Pankaj K. Agarwal	1996	Approximation Algorithms for Curvature-Constrained Shortest Paths.
SODA	Reconstructing the Evolutionary History of Natural Languages.	Tandy Warnow,Donald Ringe,Ann Taylor	1996	Reconstructing the Evolutionary History of Natural Languages.
SODA	How to Get an Exact Sample From a Generic Markov Chain and Sample a Random Spanning Tree From a Directed Graph, Both Within the Cover Time.	David Bruce Wilson,James Gary Propp	1996	How to Get an Exact Sample From a Generic Markov Chain and Sample a Random Spanning Tree From a Directed Graph, Both Within the Cover Time.
SODA	RNC Algorithms for the Uniform Generation of Combinatorial Structures.	Michele Zito,Ida Pu,Martyn Amos,Alan Gibbons	1996	RNC Algorithms for the Uniform Generation of Combinatorial Structures.
SODA	Proceedings of the Seventh Annual ACM-SIAM Symposium on Discrete Algorithms, 28-30 January 1996, Atlanta, Georgia.	Éva Tardos	1996	Proceedings of the Seventh Annual ACM-SIAM Symposium on Discrete Algorithms, 28-30 January 1996, Atlanta, Georgia.
STOC	Generating Hard Instances of Lattice Problems (Extended Abstract).	Miklós Ajtai	1996	Generating Hard Instances of Lattice Problems (Extended Abstract).
STOC	Modular Coloring Formulas Are Hard for Cutting Planes Proofs.	Xudong Fu	1996	Modular Coloring Formulas Are Hard for Cutting Planes Proofs.
STOC	Convergence Complexity of Optimistic Rate Based Flow Control Algorithms (Extended Abstract).	Yehuda Afek,Yishay Mansour,Zvi Ostfeld	1996	Convergence Complexity of Optimistic Rate Based Flow Control Algorithms (Extended Abstract).
STOC	The Complexity of Matrix Rank and Feasible Systems of Linear Equations (Extended Abstract).	Eric Allender,Robert Beals,Mitsunori Ogihara	1996	The Complexity of Matrix Rank and Feasible Systems of Linear Equations (Extended Abstract).
STOC	The Space Complexity of Approximating the Frequency Moments.	Noga Alon,Yossi Matias,Mario Szegedy	1996	The Space Complexity of Approximating the Frequency Moments.
STOC	Node-Disjoint Paths on the Mesh and a New Trade-Off in VLSI Layout.	Alok Aggarwal,Jon M. Kleinberg,David P. Williamson	1996	A number of basic models for VLSI layout are based on the construction of node-disjoint paths between terminals on a multilayer grid. In this setting, one is interested in minimizing both the number of layers required and the area of the underlying grid. Building on work of Cutler and Shiloach [ Networks, 8 (1978), pp. 253--278], Aggarwal et al. [ Proc. 26th IEEE Symposium on Foundations of Computer Science , Portland, OR, 1985; Algorithmica, 6 (1991), pp. 241--255], and Aggarwal, Klawe, and Shor [ Algorithmica}, 6 (1991), pp. 129--151], we prove an upper-bound trade-off between these two quantities in a general multilayer grid model. As a special case of our main result, we obtain significantly improved bounds for the problem of routing a full permutation on the mesh using node-disjoint paths; our new bound here is within polylogarithmic factors of the bisection bound. Our algorithms involve some new techniques for analyzing the structure of node-disjoint paths in planar graphs and indicate some respects in which this problem, at least in the planar case, is fundamentally different from its edge-disjoint counterpart.
STOC	Automatic Methods for Hiding Latency in High Bandwidth Networks (Extended Abstract).	Matthew Andrews,Frank Thomson Leighton,Panagiotis Takis Metaxas,Lisa Zhang	1996	Automatic Methods for Hiding Latency in High Bandwidth Networks (Extended Abstract).
STOC	Robot Navigation with Range Queries.	Dana Angluin,Jeffery Westbrook,Wenhong Zhu	1996	Robot Navigation with Range Queries.
STOC	Modular Competitiveness for Distributed Algorithms.	James Aspnes,Orli Waarts	1996	Modular Competitiveness for Distributed Algorithms.
STOC	Making Commitments in the Face of Uncertainty: How to Pick a Winner Almost Every Time (Extended Abstract).	Baruch Awerbuch,Yossi Azar,Amos Fiat,Frank Thomson Leighton	1996	Making Commitments in the Face of Uncertainty: How to Pick a Winner Almost Every Time (Extended Abstract).
STOC	Extremal Bipartite Graphs and Superpolynomial Lower Bounds for Monotone Span Programs.	László Babai,Anna Gál,János Kollár,Lajos Rónyai,Tibor Szabó,Avi Wigderson	1996	Extremal Bipartite Graphs and Superpolynomial Lower Bounds for Monotone Span Programs.
STOC	Lower Bounds for On-line Graph Problems with Application to On-line Circuit and Optical Routing.	Yair Bartal,Amos Fiat,Stefano Leonardi	1996	We present lower bounds on the competitive ratio of randomized algorithms for a wide class of on-line graph optimization problems, and we apply such results to on-line virtual circuit and optical routing problems. Lund and Yannakakis [The approximation of maximum subgraph problems, in Proceedings of the 20th International Colloquium on Automata, Languages and Programming, 1993, pp. 40-51] give inapproximability results for the problem of finding the largest vertex induced subgraph satisfying any nontrivial, hereditary property pi--e.g., independent set, planar, acyclic, bipartite. We consider the on-line version of this family of problems, where some graph G is fixed and some subgraph H of G is presented on-line, vertex by vertex. The on-line algorithm must choose a subset of the vertices of H, choosing or rejecting a vertex when it is presented, whose vertex induced subgraph satisfies property pi. Furthermore, we study the on-line version of graph coloring whose off-line version has also been shown to be inapproximable [C. Lund and M. Yannakakis, On the hardness of approximating minimization problems, in Proceedings of the 25th ACM Symposium on Theory of Computing, 1993], on-line max edge-disjoint paths, and on-line path coloring problems. Irrespective of the time complexity, we show an Omega(nepsilon) lower bound on the competitive ratio of randomized on-line algorithms for any of these problems. As a consequence, we obtain an Omega(nepsilon) lower bound on the competitive ratio of randomized on-line algorithms for virtual circuit routing on general networks, in contrast to the known results for some specific networks. Similar lower bounds are obtained for on-line optical routing as well.
STOC	On Bounding the Betti Numbers and Computing the Euler Characteristic of Semi-Algebraic Sets.	Saugata Basu	1996	On Bounding the Betti Numbers and Computing the Euler Characteristic of Semi-Algebraic Sets.
STOC	Computing Roadmaps of Semi-Algebraic Sets (Extended Abstract).	Saugata Basu,Richard Pollack,Marie-Françoise Roy	1996	Computing Roadmaps of Semi-Algebraic Sets (Extended Abstract).
STOC	Correlated Pseudorandomness and the Complexity of Private Computations.	Donald Beaver	1996	Correlated Pseudorandomness and the Complexity of Private Computations.
STOC	Adaptive Zero Knowledge and Computational Equivocation (Extended Abstract).	Donald Beaver	1996	Adaptive Zero Knowledge and Computational Equivocation (Extended Abstract).
STOC	A Constant-factor Approximation Algorithm for the MST Problem (Extended Abstract).	Avrim Blum,R. Ravi,Santosh Vempala	1996	A Constant-factor Approximation Algorithm for the MST Problem (Extended Abstract).
STOC	Approximating Minimum Cuts in () Time.	András A. Benczúr,David R. Karger	1996	Approximating Minimum Cuts in () Time.
STOC	Learning Sat--DNF Formulas from Membership Queries.	Francesco Bergadano,Dario Catalano,Stefano Varricchio	1996	Learning Sat--DNF Formulas from Membership Queries.
STOC	Reconstructing a Three-Dimensional Model with Arbitrary Errors.	Bonnie Berger,Jon M. Kleinberg,Frank Thomson Leighton	1996	A number of current technologies allow for the determination of interatomic distance information in structures such as proteins and RNA. Thus, the reconstruction of a three-dimensional set of points using information about its interpoint distances has become a task of basic importance in determining molecular structure. The distance measurements one obtains from techniques such as NMR are typically sparse and error-prone, greatly complicating the reconstruction task. Many of these errors result in distance measurements that can be safely assumed to lie within certain fixed tolerances. But a number of sources of systematic error in these experiments lead to inaccuracies in the data that are very hard to quantify; in effect, one must treat certain entries of the measured distance matrix as being arbitrarily &ldquo;corrupted.&rdquo;The existence of arbitrary errors leads to an interesting sort of error-correction problem&mdash;how many corrupted entries in a distance matrix can be efficiently corrected to produce a consistent three-dimensional structure? For the case of an n &times; n matrix in which every entry is specified, we provide a randomized algorithm running in time O(n log n) that enumerates all structures consistent with at most (1/2-&egr;)n errors per row, with high probability. In the case of randomly located errors, we can correct errors of the same density in a sparse matrix-one in which only a &bgr; fraction of the entries in each row are given, for any constant &bgr;gt;0.
STOC	Constructing Evolutionary Trees in the Presence of Polymorphic Characters.	Maria Luisa Bonet,Cynthia A. Phillips,Tandy Warnow,Shibu Yooseph	1996	Most phylogenetics literature and construction methods based upon characters presume monomorphism (one state per character per species), yet polymorphism (multiple states per character per species) is well documented in both biology and historical linguistics. In this paper we consider the problem of inferring evolutionary trees for polymorphic characters. We show efficient algorithms for the construction of perfect phylogenies from polymorphic data. These methods have been used to help construct the evolutionary tree proposed by Warnow, Ringe, and Taylor for the Indo-European family of languages and presented by invitation at the National Academy of Sciences in November 1995.
STOC	Pushing Disks Together - The Continuous-Motion Case.	Marshall W. Bern,Amit Sahai	1996	Pushing Disks Together - The Continuous-Motion Case.
STOC	Adversarial Queueing Theory.	Allan Borodin,Jon M. Kleinberg,Prabhakar Raghavan,Madhu Sudan,David P. Williamson	1996	We consider packet routing when packets are injected continuously into a network. We develop an adversarial theory of queuing aimed at addressing some of the restrictions inherent in probabilistic analysis and queuing theory based on time-invariant stochastic generation. We examine the stability of queuing networks and policies when the arrival process is adversarial, and provide some preliminary results in this direction. Our approach sheds light on various queuing policies in simple networks, and paves the way for a systematic study of queuing with few or no probabilistic assumptions.
STOC	Dynamic Deflection Routing on Arrays (Preliminary Version).	Andrei Z. Broder,Eli Upfal	1996	Dynamic Deflection Routing on Arrays (Preliminary Version).
STOC	Towards the Learnability of DNF Formulae.	Nader H. Bshouty	1996	Towards the Learnability of DNF Formulae.
STOC	Noise-Tolerant Distribution-Free Learning of General Geometric Concepts.	Nader H. Bshouty,Sally A. Goldman,H. David Mathias,Subhash Suri,Hisao Tamaki	1996	We present an efficient algorithm for PAC-learning a very general class of geometric concepts over R d for fixed d. More specifically, let T be any set of s halfspaces. Let x =(x1, &hellip;, xd) be an arbitrary point in R d. With each t&isin;T we associate a boolean indicator function It(x) which is 1 if and only if x is in the halfspace t. The concept class, Cds , that we study consists of all concepts formed by any Boolean function over It1, &hellip;, Its for ti &isin;T . This class is much more general than any geometric concept class known to be PAC-learnable. Our results can be extended easily to learn efficiently any Boolean combination of a polynomial number of concepts selected from any concept class C over R given that the VC-dimension of C has dependence only on d and there is a polynomial time algorithm to determine if there is a concept from C consistent with a given set of labeled examples. We also present a statistical query version of our algorithm that can tolerate random classification noise. Finally we present a generalization of the standard &egr;-net result of Haussler and Welzl [1987] and apply it to give an alternative noise-tolerant algorithm for d = 2 based on geometric subdivisions.
STOC	Adaptively Secure Multi-Party Computation.	Ran Canetti,Uriel Feige,Oded Goldreich,Moni Naor	1996	"A fundamental problem in designing secure multi-party protocols is how to deal with adaptive adversaries (i.e., adversaries that may choose the corrupted parties during the course of the computation), in a setting where the channels are insecure and secure communication is achieved by cryptographic primitives based on computational limitations of the adversary. It turns out that the power of an adaptive adversary is greatly affected by the amount of information gathered upon the corruption of the party. This amount of information models the extent to which uncorrupted parties are trusted to carry out instructions that cannot be externally verified, such as erasing records of past configurations. It has been shown that if the parties are trusted to erase such records, then adaptivity secure computation can be carried out using known primitives. However, this total trust in parties may be unrealistic in many scenarios. An important question, open since 1986, is whether adaptively secure multi-party computation can be carried out in the ""insecure channel"" setting, even if no party is thoroughly trusted. Our main result is an affirmative resolution of this question for the case where even uncorrupted parties may deviate from the protocol by keeping record of all past configurations. We first propose a novel property of encryption protocols and show that if an encryption protocol enjoying this property is used, instead of a standard encryption scheme, then known constructions become adaptively secure. Next we constructed, based on standard RSA assumption, an encryption protocol that enjoys this property. We also consider parties that, even when corrupted, may internally deviate from their protocols in arbitrary ways, as long as no external test can detect faulty behavior. We show that in this case no non-trivial protocol can be proven adaptively secure using black-box simulation. This holds even if the communication channels are totally secure."
STOC	Noise-Tolerant Learning Near the Information-Theoretic Bound.	Nicolò Cesa-Bianchi,Eli Dichterman,Paul Fischer,Hans-Ulrich Simon	1996	Noise-Tolerant Learning Near the Information-Theoretic Bound.
STOC	Deterministic Restrictions in Circuit Complexity.	Shiva Chaudhuri,Jaikumar Radhakrishnan	1996	Deterministic Restrictions in Circuit Complexity.
STOC	Fast Algorithms for -Shredders and -Node Connectivity Augmentation (Extended Abstract).	Joseph Cheriyan,Ramakrishna Thurimella	1996	Fast Algorithms for -Shredders and -Node Connectivity Augmentation (Extended Abstract).
STOC	Using the Groebner Basis Algorithm to Find Proofs of Unsatisfiability.	Matthew Clegg,Jeff Edmonds,Russell Impagliazzo	1996	Using the Groebner Basis Algorithm to Find Proofs of Unsatisfiability.
STOC	Universal Algorithms for Store-and-Forward and Wormhole Routing.	Robert Cypher,Friedhelm Meyer auf der Heide,Christian Scheideler,Berthold Vöcking	1996	Universal Algorithms for Store-and-Forward and Wormhole Routing.
STOC	Algorithms for Manifolds and Simplicial Complexes in Euclidean 3-Space (Preliminary Version).	Tamal K. Dey,Sumanta Guha	1996	Algorithms for Manifolds and Simplicial Complexes in Euclidean 3-Space (Preliminary Version).
STOC	Towards an Analysis of Local Optimization Algorithms.	Tassos Dimitriou,Russell Impagliazzo	1996	Towards an Analysis of Local Optimization Algorithms.
STOC	Digital Signets: Self-Enforcing Protection of Digital Information (Preliminary Version).	Cynthia Dwork,Jeffrey B. Lotspiech,Moni Naor	1996	Digital Signets: Self-Enforcing Protection of Digital Information (Preliminary Version).
STOC	An ( )-Size Fault-Tolerant Sorting Network (Extended Abstract).	Yuan Ma	1996	An ( )-Size Fault-Tolerant Sorting Network (Extended Abstract).
STOC	Lower Bounds for Noisy Boolean Decision Trees.	William S. Evans,Nicholas Pippenger	1996	"We present a new method for deriving lower bounds to the expected number of queries made by noisy decision trees computing Boolean functions. The new method has the feature that expectations are taken with respect to a uniformly distributed random input, as well as with respect to the random noise, thus yielding stronger lower bounds. It also applies to many more functions than do previous results. The method yields a simple proof of the result (previously established by Reischuk and Schmeltz) that almost all Boolean functions of n arguments require Omega(n log n) queries, and strengthens this bound from the worst-case over inputs to the average over inputs. The method also yields bounds for specific Boolean functions in terms of their spectra (their Fourier transforms). The simplest instance of this spectral bound yields the result (previously established by Feige, Peleg, Raghavan and Upfal) that the parity function of n arguments requires Omega(n log n) queries, and again strengthens this bound from the worst-case over inputs to the average over inputs. In its full generality, the spectral bound applies to the ""highly resilient"" functions introduced by Chor, Friedman, Goldreich, Hastad, Rudich and Smolensky, and it yields non-linear lower bounds whenever the resiliency is asymptotic to the number of arguments."
STOC	Efficient Algorithms for Inverting Evolution.	Martin Farach,Sampath Kannan	1996	Evolution can be mathematically modelled by a stochastic process that operates on the DNA of species. Such models are based on the established theory that the DNA sequences, or genomes, of all extant species have been derived from the genome of the common ancestor of all species by a process of random mutation and natural selection.A stochastic model of evolution can be used to construct phylogenies, or evolutionary trees, for a set of species. Maximum Likelihood Estimation (MLE) methods seek the evolutionary tree which is most likely to have produced the DNA under consideration. While these methods are intellectually satisfying, they have not been widely accepted because of their computational intractability.In this paper, we address the intractability of MLE methods as follows: We introduce a metric on stochastic process models of evolution. We show that this metric is meaningful by proving that in order for any algorithm to distinguish between two stochastic models that are close according to this metric, it needs to be given many observations. We complement this result with a simple and efficient algorithm for inverting the stochastic process of evolution, that is, for building a tree from observations on two-state characters. (We will use the same techniques in a subsequent paper to solve the problem for multistate characters, and hence for building a tree from DNA sequence data.) The tree we build is provably close, in our metric, to the tree generating the data and gets closer as more observations become available.Though there have been many heuristics suggested for the problem of finding good approximations to the most likely tree, our algorithm is the first one with a guaranteed convergence rate, and further, this rate is within a polynomial of the lower-bound rate we establish. Ours is also the first polynomial-time algorithm that is proven to converge at all to the correct tree.
STOC	A Threshold of ln for Approximating Set Cover (Preliminary Version).	Uriel Feige	1996	A Threshold of ln for Approximating Set Cover (Preliminary Version).
STOC	Witness-Based Cryptographic Program Checking and Robust Function Sharing.	Yair Frankel,Peter Gemmell,Moti Yung	1996	Witness-Based Cryptographic Program Checking and Robust Function Sharing.
STOC	Computing Betti Numbers via Combinatorial Laplacians.	Joel Friedman	1996	Computing Betti Numbers via Combinatorial Laplacians.
STOC	Communication-Efficient Parallel Sorting (Preliminary Version).	Michael T. Goodrich	1996	Communication-Efficient Parallel Sorting (Preliminary Version).
STOC	A Lower Bound for Randomized Algebraic Decision Trees.	Dima Grigoriev,Marek Karpinski,Friedhelm Meyer auf der Heide,Roman Smolensky	1996	We extend the lower bounds on the depth of algebraic decision trees to the case of randomized algebraic decision trees (with two-sided error) for languages being finite unions of hyperplanes and the intersections of halfspaces. As an application, among other things, we derive, for the first time, $\Omega(n^2)$ randomized lower bound for the {\em knapsack problem} (which was previously only known for deterministic algebraic decision trees).
STOC	A Fast Quantum Mechanical Algorithm for Database Search.	Lov K. Grover	1996	A Fast Quantum Mechanical Algorithm for Database Search.
STOC	Testing of the Long Code and Hardness for Clique.	Johan Håstad	1996	Testing of the Long Code and Hardness for Clique.
STOC	Nondeterministic Communication with a Limited Number of Advice Bits.	Juraj Hromkovic,Georg Schnitger	1996	"We present a new technique for differentiating deterministic from nondeterministic communication complexity. As a consequence we give almost tight lower bounds for the nondeterministic communication complexity with a restricted number of advice bits. In particular, for any function $t : \mathbb{N} \rightarrow \mathbb{N}$ with $t(n) \leq n/2$ we construct a family $(L_{n,t(n)} : n \in \mathbb{N})$ of languages such that $L_{n,t(n)} \subseteq \{0,1\}^{2n}$, ${\rm nc}(L_{n,t(n)}) = O(t(n) \cdot \log_2 \frac{n}{t(n)})$ and ${\rm nc}(\overline{L_{n,t(n)}}) = O\bigl(\frac{n}{t(n) \cdot \log_2 \frac{n}{t(n)}} + \log_2 t(n)\bigr)$, but ${\rm nc}_{o(t(n))}(L_{n,t(n)}) = \Omega\bigl(\frac{n}{\log_2 \frac{n}{t(n)}}\bigr)$. Here ${\rm nc}_r(L)$ is the nondeterministic communication complexity of L, assuming that at most r advice bits are utilized. Thus, in contrast to probabilistic communication complexity, a small reduction in the number of advice bits results in almost maximal communication. As a special case we obtain a family $L_n \subseteq \{0,1\}^{2n}$ of languages with {\rm nc}_{o(\sqrt{n}/\log_2 n)}(L_n) &=& \Omega\biggl(\frac{n}{\log_2 n}\biggr),\\ {\rm nc}(L_n) + {\rm nc}(\overline{L_n}) &=& O(\sqrt{n}), and hence nondeterministic communication with slightly restricted access to advice bits is almost quadratically weaker than nondeterminism that always gives correct answers (from the set {yes, no, ?}). As a consequence we obtain an almost optimal separation between Monte-Carlo communication and ""correct"" nondeterminism and answer a question of Beame and Lawry."
STOC	Purely Functional Representations of Catenable Sorted Lists.	Haim Kaplan,Robert Endre Tarjan	1996	The power of purely functional programming in the construction of data structures has received much attention, not only because functional languages have many desirable properties, but because structures built purely functionally are automatically {\em fully persistent}: any and all versions of a structure can coexist indefinitely. Recent results illustrate the surprising power of pure functionality. One such result was the development of a representation of double-ended queues with catenation that supports all operations, including catenation, in worst-case constant time~\cite{KaTar}. This paper is a continuation of our study of pure functionality, especially as it relates to persistence. For one purposes, a purely functional data structure is one built only with the LISP functions car, cons, cdr. We explore purely functional representations of sorted lists, implemented as finger search trees. We describe three implementations. The most efficient of these achieves logarithmic access, insertion, and deletion time, and double-logarithmic catenation time. It uses one level of structural bootstrapping to obtain its efficiency. The bounds for find, insert, and delete are the same as the best known bounds for an ephemeral implementation of these operations using finger search trees. The representations we present are the first that address the issues of persistence and pure functionality, and the first for which fast implementations of catenation and split are presented. They are simple to implement and could be efficient in practice, especially for applications that require worst-case time bounds or persistence.
STOC	Sparsity Considerations in Dixon Resultants.	Deepak Kapur,Tushar Saxena	1996	Sparsity Considerations in Dixon Resultants.
STOC	Minimum Cuts in Near-Linear Time.	David R. Karger	1996	"We significantly improve known time bounds for solving the minimum cut problem on undirected graphs. We use a ""semiduality"" between minimum cuts and maximum spanning tree packings combined with our previously developed random sampling techniques. We give a randomized (Monte Carlo) algorithm that finds a minimum cut in an m-edge, n-vertex graph with high probability in O(m log3 n) time. We also give a simpler randomized algorithm that finds all minimum cuts with high probability in O(m log3 n) time. This variant has an optimal RNC parallelization. Both variants improve on the previous best time bound of O(n2 log3 n). Other applications of the tree-packing approach are new, nearly tight bounds on the number of near-minimum cuts a graph may have and a new data structure for representing them in a space-efficient manner."
STOC	How Good is the Goemans-Williamson MAX CUT Algorithm?	Howard J. Karloff	1996	The celebrated semidefinite programming algorithm for MAX CUT introduced by Goemans and Williamson was known to have a performance ratio of at least $\alpha=\frac 2 {\pi} \min_{0
STOC	On the Boosting Ability of Top-Down Decision Tree Learning Algorithms.	Michael J. Kearns,Yishay Mansour	1996	On the Boosting Ability of Top-Down Decision Tree Learning Algorithms.
STOC	Approximability and Nonapproximability Results for Minimizing Total Flow Time on a Single Machine.	Hans Kellerer,Thomas Tautenhahn,Gerhard J. Woeginger	1996	We consider the problem of scheduling n jobs that are released over time on a single machine in order to minimize the total flow time. This problem is well known to be NP-complete, and the best polynomial-time approximation algorithms constructed so far had (more or less trivial) worst-case performance guarantees of O(n). In this paper, we present one positive and one negative result on polynomial-time approximations for the minimum total flow time problem: The positive result is the first approximation algorithm with a sublinear worst-case performance guarantee of $O(\sqrt{n})$. This algorithm is based on resolving the preemptions of the corresponding optimum preemptive schedule. The performance guarantee of our approximation algorithm is not far from best possible, as our second, negative result demonstrates: Unless P=NP, no polynomial-time approximation algorithm for minimum total flow time can have a worst-case performance guarantee of $O(n^{1/2-\eps})$ for any $\eps>0$.
STOC	Towards a Syntactic Characterization of PTAS.	Sanjeev Khanna,Rajeev Motwani	1996	Towards a Syntactic Characterization of PTAS.
STOC	Efficient Approximation Algorithms for Semidefinite Programs Arising from MAX CUT and COLORING.	Philip N. Klein,Hsueh-I Lu	1996	The best known approximation algorithm for graph MAX CUT, due to Goemans and Williamson, first finds the optimal solution a semidefinite program and then derives a graph cut from that solution. Building on this result, Karger, Motwani, and Sudan gave an approximation algorithm for graph coloring that also involves solving a semidefinite program. Solving these semidefinite programs using known methods (ellipsoid, interior-point), though polynomial-time, is quite expensive. We show how they can be approximately solved in $\tilde O(nm)$ time for graphs with $n$ nodes and $m$ edges.
STOC	Large-Scale Assembly of DNA Strings and Space-Efficient Construction of Suffix Trees (Correction).	S. Rao Kosaraju,Arthur L. Delcher	1996	Large-Scale Assembly of DNA Strings and Space-Efficient Construction of Suffix Trees (Correction).
STOC	The Linear-Array Conjecture in Communication Complexity is False.	Eyal Kushilevitz,Nathan Linial,Rafail Ostrovsky	1996	The Linear-Array Conjecture in Communication Complexity is False.
STOC	Characterizing Linear Size Circuits in Terms of Privacy.	Eyal Kushilevitz,Rafail Ostrovsky,Adi Rosén	1996	Characterizing Linear Size Circuits in Terms of Privacy.
STOC	Non-Expansive Hashing.	Nathan Linial,Ori Sasson	1996	Non-Expansive Hashing.
STOC	Fast Algorithms for Parametric Scheduling Come from Extensions to Parametric Maximum Flow.	S. Thomas McCormick	1996	Fast Algorithms for Parametric Scheduling Come from Extensions to Parametric Maximum Flow.
STOC	Translational Polygon Containment and Minimal Enclosure using Linear Programming Based Restriction.	Victor Milenkovic	1996	Translational Polygon Containment and Minimal Enclosure using Linear Programming Based Restriction.
STOC	Embedding Graphs in an Arbitrary Surface in Linear Time.	Bojan Mohar	1996	Embedding Graphs in an Arbitrary Surface in Linear Time.
STOC	Deterministic (nm) Time Edge-Splitting in Undirected Graphs.	Hiroshi Nagamochi,Toshihide Ibaraki	1996	Deterministic (nm) Time Edge-Splitting in Undirected Graphs.
STOC	Evaluation May Be Easier Than Generation (Extended Abstract).	Moni Naor	1996	Evaluation May Be Easier Than Generation (Extended Abstract).
STOC	Public vs. Private Coin Flips in One Round Communication Games (Extended Abstract).	Ilan Newman,Mario Szegedy	1996	Public vs. Private Coin Flips in One Round Communication Games (Extended Abstract).
STOC	The PL Hierarchy Collapses.	Mitsunori Ogihara	1996	It is shown that the PL hierarchy PLH = PL ,\bigcup\limits\, PLPL ,\bigcup\limits\, PLPLPL ,\bigcup\limits\, \cdots$, defined in terms of the Ruzzo--Simon--Tompa relativization, collapses to PL.
STOC	On Relationships between Statistical Zero-Knowledge Proofs.	Tatsuaki Okamoto	1996	On Relationships between Statistical Zero-Knowledge Proofs.
STOC	Distributed Packet Switching in Arbitrary Networks.	Yuval Rabani,Éva Tardos	1996	Distributed Packet Switching in Arbitrary Networks.
STOC	Efficiently Four-Coloring Planar Graphs.	Neil Robertson,Daniel P. Sanders,Paul D. Seymour,Robin Thomas	1996	Efficiently Four-Coloring Planar Graphs.
STOC	A Tight Analysis of the Greedy Algorithm for Set Cover.	Petr Slavík	1996	A Tight Analysis of the Greedy Algorithm for Set Cover.
STOC	Faster Isomorphism Testing of Strongly Regular Graphs.	Daniel A. Spielman	1996	Faster Isomorphism Testing of Strongly Regular Graphs.
STOC	On Extracting Randomness From Weak Random Sources (Extended Abstract).	Amnon Ta-Shma	1996	On Extracting Randomness From Weak Random Sources (Extended Abstract).
STOC	Efficient 3-D Range Searching in External Memory.	Darren Erik Vengroff,Jeffrey Scott Vitter	1996	Efficient 3-D Range Searching in External Memory.
STOC	Randomness-Optimal Sampling, Extractors, and Constructive Leader Election.	David Zuckerman	1996	Randomness-Optimal Sampling, Extractors, and Constructive Leader Election.
STOC	Generating Random Spanning Trees More Quickly than the Cover Time.	David Bruce Wilson	1996	Generating Random Spanning Trees More Quickly than the Cover Time.
STOC	Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, Philadelphia, Pennsylvania, USA, May 22-24, 1996	Gary L. Miller	1996	Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, Philadelphia, Pennsylvania, USA, May 22-24, 1996
FOCS	The Analysis of a List-Coloring Algorithm on a Random Graph.	Dimitris Achlioptas,Michael S. O. Molloy	1997	We introduce a natural k-coloring algorithm and analyze its performance on random graphs with constant expected degree c (G/sub n,p=c/n/). For k=3 our results imply that almost all graphs with n vertices and 1.923 n edges are 3-colorable. This improves the lower bound on the threshold for random 3-colorability significantly and settles the last case of a long-standing open question of Bollobas. We also provide a tight asymptotic analysis of the algorithm. We show that for all k/spl ges/3, if c/spl les/k In k-3/2k then the algorithm almost surely succeeds, while for any /spl epsiv/>0, and k sufficiently large, if c/spl ges/(1+/spl epsiv/)k In k then the algorithm almost surely fails. The analysis is based on the use of differential equations to approximate the mean path of certain Markov chains.
FOCS	Improved Bounds on Planar k-sets and k-levels.	Tamal K. Dey	1997	We prove an O(nk/sup 1/3/) upper bound for planar k-sets. This is the first considerable improvement on this bound after its early solutions approximately twenty seven years ago. Our proof technique also applies to improve the current bounds on the combinatorial complexities of k-levels in arrangements of line segments, k convex polygons in the union of n lines, parametric minimum spanning trees and parametric matroids in general.
FOCS	Alternating-time Temporal Logic.	Rajeev Alur,Thomas A. Henzinger,Orna Kupferman	1997	Alternating-time Temporal Logic.
FOCS	Nearly Tight Bounds on the Learnability of Evolution.	Andris Ambainis,Richard Desper,Martin Farach,Sampath Kannan	1997	Evolution is often modeled as a stochastic process which modifies DNA. One of the most popular and successful such processes are the Cavender-Farris (CF) trees, which are represented as edge weighted trees. The Phylogeny Construction Problem is that of, given /spl kappa/ samples drawn from a CF tree, output a CF tree which is close to the original. Each CF tree naturally defines a random variable, and the gold standard for reconstructing such trees is the maximum likelihood estimator of this variable. This approach is notoriously computationally expensive. We show that a very simple algorithm, which is a variant on one of the most popular algorithms used by practitioners, converges on the true tree at a rate which differs from the optimum by a constant. We do this by analyzing upper and lower bounds for the convergence rate of learning very simple CF trees, and then show that the learnability of each CF tree is sandwiched between two such simpler trees. Our results rely on the fact that, if the right metric is used, the likelihood space of CF trees is smooth.
FOCS	Pattern Matching with Swaps.	Amihood Amir,Yonatan Aumann,Gad M. Landau,Moshe Lewenstein,Noa Lewenstein	1997	"Let a text string T of n symbols and a pattern string P of m symbols from alphabet /spl Sigma/ be given. A swapped version T' of T is a length n string derived from T by a series of local swaps, (i.e. t/sup '//sub l//spl larr/t/sub l+1/ and t'/sub l+1//spl larr/t/sub l/) where each element can participate in no more than one swap. The Pattern Matching with Swaps problem is that of finding all locations i for which there exists a swapped version T' of T where there is an exact matching of P in location i of T'. It has been an open problem whether swapped matching can be done in less than O(mn) time. In this paper we show the first algorithm that solves the pattern matching with swaps problem in time O(mn). We present an algorithm whose time complexity is O(nm/sup 1/3/ log m log/sup 2/ /spl sigma/) for a general alphabet /spl Sigma/, where /spl sigma/=min(m, |/spl Sigma/|)."
FOCS	Weak Random Sources, Hitting Sets, and BPP Simulations.	Alexander E. Andreev,Andrea E. F. Clementi,José D. P. Rolim,Luca Trevisan	1997	We show how to simulate any BPP algorithm in polynomial time by using a weak random source of r bits and min-entropy $r^{\gamma}$ for any $\gamma >0$. This follows from a more general result about sampling with weak random sources. Our result matches an information-theoretic lower bound and solves a question that has been open for some years. The previous best results were a polynomial time simulation of RP [M. Saks, A. Srinivasan, and S. Zhou, Proc. 27th ACM Symp. on Theory of Computing, 1995, pp. 479--488] and a quasi-polynomial time simulation of BPP [A. Ta-Shma, Proc. 28th ACM Symp. on Theory of Computing, 1996, pp. 276--285].Departing significantly from previous related works, we do not use extractors; instead, we use the OR-disperser of Saks, Srinivasan, and Zhou in combination with a tricky use of hitting sets borrowed from [Andreev, Clementi, and Rolim, J. ACM, 45 (1998), pp. 179--213].
FOCS	General Dynamic Routing with Per-Packet Delay Guarantees of O(distance + 1 / session rate).	Matthew Andrews,Antonio Fernández,Mor Harchol-Balter,Frank Thomson Leighton,Lisa Zhang	1997	A central issue in the design of modern communication networks is that of providing performance guarantees. This issue is particularly important if the networks support real-time traffic such as voice and video. The most critical performance parameter to bound is the delay experienced by a packet as it travels from its source to its destination.We study dynamic routing in a connection-oriented packet-switching network. We consider a network with arbitrary topology on which a set of sessions is defined. For each session i, packets are injected at a rate ri to follow a predetermined path of length di. Due to limited bandwidth, only one packet at a time may advance on an edge (link). Session paths may overlap subject to the constraint that the total rate of sessions using any particular edge is at most $1-\varepsilon$ for any constant $\varepsilon \in (0,1)$.We address the problem of scheduling the sessions at each switch, so as to minimize worst-case packet delay and queue buildup at the switches. We show the existence of a periodic schedule that achieves a delay bound of O(1/ri+di) with only constant-size queues at the switches. This bound is asymptotically optimal for periodic schedules.A consequence of this result is an asymptotically optimal schedule for the static routing problem, wherein all packets are present at the outset. We obtain a delay bound of O(ci + di) for packets on path Pi, where di is the number of edges in Pi and ci is the maximum congestion along edges in Pi. This improves upon the previous known bound of O(c + d), where d = maxi di and c = maxi ci.We also present a simple distributed algorithm that, with high probability, delivers every session-i packet to its destination within O(1/ri+di\log(m/rmin)) steps of its injection, where r min is the minimum session rate and m is the number of edges in the network. Our results can be generalized to (leaky-bucket constrained) bursty traffic, where session i tolerates a burst size of bi. In this case, our delay bounds become O(bi/ri + di) and O(bi/ri+di\log(m/rmin)), respectively.
FOCS	Nearly Linear Time Approximation Schemes for Euclidean TSP and other Geometric Problems.	Sanjeev Arora	1997	We present a randomized polynomial time approximation scheme for Euclidean TSP in R/sup 2/ that is substantially more efficient than our earlier scheme (1996) (and the scheme of Mitchell (1996)). For any fixed c>1 and any set of n nodes in the plane, the new scheme finds a (1+1/c)-approximation to the optimum traveling salesman tour in O(n(logn)/sup O(c)/) time. (Our earlier scheme ran in n/sup O(C)/ time.) For points in R/sup d/ the algorithm runs in O(n(logn)/sup (O(/spl radic/dc)/d-1)) time. This time is polynomial (actually nearly linear) for every fixed c, d. Designing such a polynomial-time algorithm was an open problem (our earlier algorithm (1996) ran in superpolynomial time for d/spl ges/3). The algorithm generalizes to the same set of Euclidean problems handled by the previous algorithm, including Steiner Tree, /spl kappa/-TSP, /spl kappa/-MST, etc, although for /spl kappa/-TSP and /spl kappa/-MST the running time gets multiplied by /spl kappa/. We also use our ideas to design nearly-linear time approximation schemes for Euclidean versions of problems that are known to be in P, such as Minimum Spanning Tree and Min Cost Perfect Matching. All our algorithms can be derandomized, though the running time then increases by O(n/sup d/) in R/sup d/. They also have simple parallel implementations (say, in NC/sup 2/).
FOCS	Buy-at-Bulk Network Design.	Baruch Awerbuch,Yossi Azar	1997	"The essence of the simplest buy-at-bulk network design problem is buying network capacity ""wholesale"" to guarantee connectivity from all network nodes to a certain central network switch. Capacity is sold with ""volume discount"": the more capacity is bought, the cheaper is the price per unit of bandwidth. We provide O(log/sup 2/n) randomized approximation algorithm for the problem. This solves the open problem in Salman et al. (1997). The only previously known solutions were restricted to special cases (Euclidean graphs). We solve additional natural variations of the problem, such as multi-sink network design, as well as selective network design. These problems can be viewed as generalizations of the the Generalized Steiner Connectivity and Prize-collecting salesman (K-MST) problems. In the selective network design problem, some subset of /spl kappa/ wells must be connected to the (single) refinery, so that the total cost is minimized."
FOCS	Edge-Connectivity Augmentation Preserving Simplicity.	Jørgen Bang-Jensen,Tibor Jordán	1997	Given a simple graph G=(V,E), the goal is to find a smallest set F of new edges such that G=(V,E+F) is k-edge-connected and simple. Very recently this problem was shown to be NP-hard by the second author. In this paper we prove that if OPT_P^k is high enough -- depending on k only -- then OPT_S^k=OPT_P^k holds, where OPT_S^k (OPT_P^k) is the size of an optimal solution of the augmentation problem with (without) the simplicity-preserving requirement, respectively. Furthermore, OPT_S^k-OPT_P^k
FOCS	Global Optimization Using Local Information with Applications to Flow Control.	Yair Bartal,John W. Byers,Danny Raz	1997	Flow control in high speed networks requires distributed routers to make fast decisions based only on local information in allocating bandwidth to connections. While most previous work on this problem focuses on achieving local objective functions, in many cases it may be necessary to achieve global objectives such as maximizing the total flow. This problem illustrates one of the basic aspects of distributed computing: achieving global objectives using local information. Papadimitriou and Yannakakis \cite{PY} initiated the study of such problems in a framework of solving positive linear programs by distributed agents. We take their model further, by allowing the distributed agents to acquire more information over time. We therefore turn attention to the tradeoff between the running time and the quality of the solution to the linear program. We give a distributed algorithm that obtains a (1 + \epsilon) approximation to the global optimum solution and runs in a polylogarithmic number of distributed rounds. While comparable in running time, our results exhibit a significant improvement on the logarithmic ratio previously obtained by \cite{AA}. Our algorithm, which draws from techniques developed by Luby and Nisan \cite{LN}, is considerably simpler than previous approximation algorithms for positive linear programs, and thus may have practical value in both centralized and distributed settings.
FOCS	An Improved Algorithm for Quantifier Elimination Over Real Closed Fields.	Saugata Basu	1997	In this paper we give a new algorithm for quantifier elimination in the first order theory of real closed fields that improves the complexity of the best known algorithm for this problem till now. Unlike previously known algorithms the combinatorial part of the complexity of this new algorithm is independent of the number of free variables. Moreover, under the assumption that each polynomial in the input depend only on a constant number of the free variables, the algebraic part of the complexity can also be made independent of the number of free variables. This new feature of our algorithm allows us to obtain a new algorithm for a variant of the quantifier elimination problem. We give an almost optimal algorithm for this new problem, which we call the uniform quantifier elimination problem and apply it to solve a problem arising in the field of constraint databases. No algorithm with reasonable complexity bound was known for this latter problem till now. We also point out interesting logical consequences of this algorithmic result, concerning the expressive power of a constraint query language over the reals. Moreover, our improved algorithm for performing quantifier elimination immediately leads to improved algorithms for several problems for which quantifier elimination is a basic step, for example, the problem of computing the closure of a given semi-algebraic set.
FOCS	A Concrete Security Treatment of Symmetric Encryption.	Mihir Bellare,Anand Desai,E. Jokipii,Phillip Rogaway	1997	We study notions and schemes for symmetric (ie.~private key) encryption in a concrete security framework. We give four different notions of security against chosen plaintext attack and analyze the concrete complexity of reductions among them, providing both upper and lower bounds, and obtaining tight relations. In this way we classify notions (even though polynomially reducible to each other) as stronger or weaker in terms of concrete security. Next we provide concrete security analyses of methods to encrypt using a block cipher, including the most popular encryption method, CBC. We establish tight bounds (meaning matching upper bounds and attacks) on the success of adversaries as a function of their resources.
FOCS	Does Parallel Repetition Lower the Error in Computationally Sound Protocols?	Mihir Bellare,Russell Impagliazzo,Moni Naor	1997	Whether or not parallel repetition lowers the error has been a fundamental question in the theory of protocols, with applications in many different areas. It is well known that parallel repetition reduces the error at an exponential rate in interactive proofs and Arthur-Merlin games. It seems to have been taken for granted that the same is true in arguments, or other proofs where the soundness only holds with respect to computationally bounded parties. We show that this is not the case. Surprisingly, parallel repetition can actually fail in this setting. We present four-round protocols whose error does not decrease under parallel repetition. This holds for any (polynomial) number of repetitions. These protocols exploit non-malleable encryption and can be based on any trapdoor permutation. On the other hand we show that for three-round protocols the error does go down exponentially fast. The question of parallel error reduction is particularly important when the protocol is used in cryptographic settings like identification, and the error represent the probability that an intruder succeeds.
FOCS	No Feasible Interpolation for TC0-Frege Proofs.	Maria Luisa Bonet,Toniann Pitassi,Ran Raz	1997	No Feasible Interpolation for TC0-Frege Proofs.
FOCS	Parallelizing Elimination Orders with Linear Fill.	Claudson F. Bornstein,Bruce M. Maggs,Gary L. Miller,R. Ravi	1997	This paper presents an algorithm for finding parallel elimination orders for Gaussian elimination. Viewing a system of equations as a graph, the algorithm can be applied directly to interval graphs and chordal graphs. For general graphs, the algorithm can be used to parallelize the order produced by some other heuristic such as minimum degree. In this case, the algorithm is applied to the chordal completion that the heuristic generates from the input graph. In general, the input to the algorithm is a chordal graph G with n nodes and m edges. The algorithm produces an order with height at most O(log^3 n) times optimal, fill at most O(m), and work at most O(W*(G)), where W*(G) is the minimum possible work over all elimination orders for G. Experimental results show that when applied after some other heuristic, the increase in work and fill is usually small. In some instances the algorithm obtains an order that is actually better, in terms of work and fill, than the original one. We also present an algorithm that produces an order with a factor of log n less height, but with a factor of O(sqrt(log n)) more fill.
FOCS	Path Coupling: A Technique for Proving Rapid Mixing in Markov Chains.	Russ Bubley,Martin E. Dyer	1997	"The main technique used in algorithm design for approximating #P-hard counting problems is the Markov chain Monte Carlo method. At the heart of the method is the study of the convergence (mixing) rates of particular Markov chains of interest. In this paper we illustrate a new approach to the coupling technique, which we call path coupling, for bounding mixing rates. Previous applications of coupling have required detailed insights into the combinatorics of the problem at hand, and this complexity can make the technique extremely difficult to apply successfully. Path coupling helps to minimize the combinatorial difficulty and in all cases provides simpler convergence proofs than does the standard coupling method. However the true power of the method is that the simplification obtained may allow coupling proofs which were previously unknown, or provide significantly better bounds than those obtained using the standard method. We apply the path coupling method to several hard combinatorial problems, obtaining new or improved results. We examine combinatorial problems such as graph colouring and TWICE-SAT, and problems from statistical physics, such as the antiferromagnetic Potts model and the hard-core lattice gas model. In each case we provide either a proof of rapid mixing where none was known previously, or substantial simplification of existing proofs with consequent gains in the performance of the resulting algorithms."
FOCS	A Faster Deterministic Algorithm for Minimum Spanning Trees.	Bernard Chazelle	1997	"A deterministic algorithm for computing a minimum spanning tree of a connected graph is presented. Its running time is O( m \alpha\log\alpha ), where \alpha= \alpha(m,n) is a functional inverse of Ackermann's function and n (resp. m) is the number of vertices (resp. edges). This improves on the previous, ten-year old bound of (roughly) O(m\log\log^*m)."
FOCS	An Improved Worst-Case to Average-Case Connection for Lattice Problems.	Jin-yi Cai,Ajay Nerurkar	1997	We improve a connection of the worst-case complexity and the average-case complexity of some well-known lattice problems. This fascinating connection was first discovered by Ajtai in 1996. We improve the exponent of this connection from 8 to 3.5+\epsilon.
FOCS	Constant Depth Circuits and the Lutz Hypothesis.	Jin-yi Cai,D. Sivakumar,Martin Strauss	1997	Resource-bounded measure theory is a study of complexity classes via an adaptation of the probabilistic method. The central hypothesis in this theory is the assertion that NP does not have measure zero in Exponential Time. This is a quantitative strengthening of NP/spl ne/P. We show that the analog in P of this hypothesis fails dramatically. In fact, we show that NTIME[n/sup 1/11/] has measure zero in P. These follow as consequences of our main theorem that the collection of languages accepted by constant-depth nearly exponential-size circuits has measure zero at polynomial time. In contrast, we show that the class AC/sup 0//sub 4/[/spl oplus/] of languages accepted by depth-4 polynomial-size circuits with AND, OR, NOT, and PARITY gates does not have measure zero at polynomial time. Our proof is based on techniques from circuit complexity theory and pseudorandom generators.
FOCS	Learning Noisy Perceptrons by a Perceptron in Polynomial Time.	Edith Cohen	1997	Learning perceptrons (linear threshold functions) from labeled examples is an important problem in machine learning. We consider the problem where labels are subjected to random classification noise. The problem was known to be PAC learnable via a hypothesis that consists of a polynomial number of linear thresholds (due to A. Blum, A. Frieze, R. Kannan, and S. Vempala (1996)). The question of whether a hypothesis that is itself a perceptron (a single threshold function) can be found in polynomial time was open. We show that indeed, noisy perceptrons are PAC learnable with a hypothesis that is a perceptron.
FOCS	Finding an Even Hole in a Graph.	Michele Conforti,Gérard Cornuéjols,Ajai Kapoor,Kristina Vuskovic	1997	A hole in a graph is a chordless cycle of length greater than three. In this paper we present a decomposition theorem for graphs that contain no even hole.This theorem yields a polytime algorithm to recognize whether a graph contains an even hole.
FOCS	Randomized Allocation Processes.	Artur Czumaj,Volker Stemann	1997	We investigate various randomized processes allocating balls into bins that arise in applications in dynamic resource allocation and on-line load balancing. We consider the scenario when m balls arriving sequentially are to be allocated into n bins on-line and without using a global controller. Traditionally, the main aim of allocation processes is to place the balls into bins to minimize the maximum load in bins. However, in many applications it is equally important to minimize the number of trails performed by the balls (the allocation time). We study adaptive allocation schemes that achieve optimal tradeoffs between the maximum load, the maximum allocation time, and the average allocation time. We investigate allocation processes that may reallocate the balls. We provide a tight analysis of the maximum load of processes that during placing a new ball may reassign the balls in up to d randomly chosen bins. We study infinite processes, in which in each step a random ball is removed and a new ball is placed according to some scheduling rule. We present a novel approach that establishes a tight estimation of the time needed for the infinite process to be in the state near to its equilibrium. Finally, we provide a tight analysis of the maximum load of the off-line process in which each ball may be placed into one of d randomly chosen bins. We apply this result to competitive analysis of on-line load balancing processes.
FOCS	Optimal Suffix Tree Construction with Large Alphabets.	Martin Farach	1997	The suffix tree of a string is the fundamental data structure of combinatorial pattern matching. In this paper, we present a novel, deterministic algorithm for the construction of suffix trees. We settle the main open problem in the construction of suffix trees: we build suffix trees in linear time for integer alphabet.
FOCS	Lower Bounds for the Signature Size of Incremental Schemes.	Marc Fischlin	1997	We show lower bounds for the signature size of incremental schemes which are secure against substitution attacks and support single block replacement. We prove that for documents of n blocks such schemes produce signatures of /spl Omega/(n/sup 1/(2+c)/) bits for any constant c>0. For schemes accessing only a single block resp. A constant number of blocks for each replacement this bound can be raised to /spl Omega/(n) resp. /spl Omega/(/spl radic/n). Additionally, we show that our technique yields a new lower bound for memory checkers.
FOCS	Truly Online Paging with Locality of Reference.	Amos Fiat,Manor Mendel	1997	"The access graph model for paging, defined by (Borodin et al., 1991) and studied in (Irani et al., 1992) has a number of troubling aspects. The access graph has to be known in advance to the paging algorithm and the memory required to represent the access graph itself may be very large. We present a truly online strongly competitive paging algorithm in the access graph model that does not have any prior information on the access sequence. We give both strongly competitive deterministic and strongly competitive randomized algorithms. Our algorithms need only O(k log n) bits of memory, where k is the number of page slots available and n is the size of the virtual address space, i.e., no more memory than needed to store the virtual translation tables for pages in memory. In fact, we can reduce this to O(k log k) bits using appropriate probabilistic data structures. We also extend the locality of reference concept captured by the access graph model to allow changes in the behavior of the underlying process. We formalize this by introducing the concept of an ""extended access graph"". We consider a graph parameter /spl Delta/ that captures the degree of change allowed. We study this new model and give algorithms that are strongly competitive for the (unknown) extended access graph. We can do so for almost all values of /spl Delta/ for which it is possible."
FOCS	Optimal Resilience Proactive Public-Key Cryptosystems.	Yair Frankel,Peter Gemmell,Philip D. MacKenzie,Moti Yung	1997	"We introduce new efficient techniques for sharing cryptographic functions in a distributed dynamic fashion. These techniques dynamically and securely transform a distributed function (or secret sharing) representation between t-out-of-l (polynomial sharing) and t-out-of-t (additive sharing). We call the techniques poly-to-sum and sum-to-poly, respectively. Employing these techniques, we solve a number of open problems in the area of cryptographic function sharing. We design a threshold function sharing scheme with proactive security for general functions with a ""homomorphic property"" (a class which includes all RSA variants and Discrete logarithm variants). The sharing has ""optimal resilience"" (server redundancy) and enables computation of the function by the servers assuring high availability, security and efficiency. Proactive security enables function sharing among servers while tolerating an adversary which is mobile and which dynamically corrupts and abandons servers (and perhaps visits all of them over the lifetime of the system, as long as the number of corruptions (faults) is bounded within a time period). Optimal resilience assures that the adversary can corrupt any minority of servers at any time-period."
FOCS	Reliable Cellular Automata with Self-Organization.	Péter Gács	1997	"Abstract In a probabilistic cellular automaton in which all local transitions have positive probability, the problem of keeping a bit of information for more than a constant number of steps is nontrivial, even in an infinite automaton. Still, there is a solution in 2 dimensions, and this solution can be used to construct a simple 3-dimensional discrete-time universal fault-tolerant cellular automaton. This technique does not help much to solve the following problems: remembering a bit of information in 1 dimension; computing in dimensions lower than 3; computing in any dimension with non-synchronized transitions. Our more complex technique organizes the cells in blocks that perform a reliable simulation of a second (generalized) cellular automaton. The cells of the latter automaton are also organized in blocks, simulating even more reliably a third automaton, etc. Since all this (a possibly infinite hierarchy) is organized in ``software'''', it must be under repair all the time from damage caused by errors. A large part of the problem is essentially self-stabilization recovering from a mess of arbitrary-size and content caused by the faults. The present paper constructs an asynchronous one-dimensional fault-tolerant cellular automaton, with the further feature of ``self-organization''''. The latter means that unless a large amount of input information must be given, the initial configuration can be chosen to be periodical with a small period."
FOCS	Contention Resolution with Guaranteed Constant Expected Delay.	Leslie Ann Goldberg,Philip D. MacKenzie	1997	We study contention resolution in multiple-access channels such as the Ethernet. Under a stochastic model of continuous packet generation from a set of n processors, we construct a protocol which guarantees constant expected delay for generation rates up to a fixed constant which is less than 1. Previous protocols which are stable for constant arrival rates do not guarantee constant expected delay. The two protocols that achieved results closest to this are one by Raghavan and Upfal, which only guarantees logarithmic (in n) expected delay, and one by Paterson and Srinivasan, which only guarantees constant expected delay with high probability. (In the latter protocol, there is a non-zero probability that the initial clock synchronization might fail and cause the expected delay to grow unboundedly.) Although those protocols do not guarantee constant expected delay, we have used ideas from them in the construction of our protocol, which does guarantee constant expected delay. We achieve our results using a technique called Robust Synchronization which is applied periodically in our protocol. The introduction of this technique and the analysis of this technique are the major contributions of the paper.
FOCS	Beyond the Flow Decomposition Barrier.	Andrew V. Goldberg,Satish Rao	1997	We introduce a new approach to the maximum flow problem. This approach is based on assigning arc lengths based on the residual flow value and the residual arc capacities. Our approach leads to an O(min(n2/3, m1/2)m log(n2/m) log U) time bound for a network with n vertices, m arcs, and integral arc capacities in the range [1, &hellip;, U]. This is a fundamental improvement over the previous time bounds. We also improve bounds for the Gomory-Hu tree problem, the parametric flow problem, and the approximate s-t cut problem.
FOCS	Flows in Undirected Unit Capacity Networks.	Andrew V. Goldberg,Satish Rao	1997	We describe an O(min(m,n3/2)m1/2)-time algorithm for finding maximum flows in undirected networks with unit capacities and no parallel edges. This improves upon the previous bound of Karzanov and Even and Tarjan when $m = \omega(n^{3/2})$, and upon a randomized bound of Karger when $v = \Omega(n^{7/4}/m^{1/2})$.
FOCS	New Directions in Cryptography: Twenty Some Years Later.	Shafi Goldwasser	1997	New Directions in Cryptography: Twenty Some Years Later.
FOCS	Computable Obstructions to Wait-free Computability.	John Havlicek	1997	We present an algorithmic test for deterministic wait-free solvability of decision tasks in asynchronous distributed systems whose processes communicate via read-write shared memory. Input to the test is a formal representation of the decision task as a triple (<i>I, O</i>, Δ), where <i>I</i> and <i>O</i> are simplicial complexes specifying the inputs and outputs of the task and Δ is the input-output relation of the task. The form of <i>I, O</i>, and Δ fixes the system size (i.e., number of processes). The result of the test is either (1) that there is no wait-free solution to the decision task for the given system size or (2) inconclusive Incompleteness of the test is unavoidable since wait-free solvability of decision tasks is undecidable for a system of size at least three. The test is shown to detect the impossibility of wait-free consensus for all systems, and experimental results show that the test detects the impossibility of wait-free set consensus for systems of size at most five. A more complete description of the efficacy of the test remains open. The key new ingredient underlying the test is a simplicial complex <i>T</i>, the task complex, associated to Δ. There is a simplicial projection map α from <i>T</i> to <i>I</i>, and α induces a homomorphism α<inf>*</inf>, from <i>H</i><inf>*</inf>(<i>T</i>) to <i>H</i><inf>*</inf>(<i>I</i>), where <i>H</i><inf>*</inf> denotes simplicial homology. Failure of α<inf>*</inf>, to surject on <i>H</i><inf>*</inf>(<i>I</i>) implies that no wait-free protocol can solve the task. Put another way, the elements of <i>H</i><inf>*</inf>(<i>I</i>) that are not in the image of α<inf>*</inf> are obstructions to solvability of the task. These obstructions are computable when using suitable homology coefficients. By passing to quotients of <i>T</i> and <i>I</i> by well-behaved group actions, the test can be adapted to check the impossibility of solution of a decision task by any wait-free protocol that is symmetric or anonymous relative to the group.
FOCS	The Minimization Problem for Boolean Formulas.	Edith Hemaspaandra,Gerd Wechsung	1997	More than a quarter of a century ago, the question of the complexity of determining whether a given Boolean formula is minimal motivated Meyer and Stockmeyer to define the polynomial hierarchy. This problem (in the standard formalized version---that of Garey and Johnson) has been known for decades to be coNP-hard and in NPNP, and yet no one had even been able to establish (many-one) NP-hardness. In this paper, we show that and more: The problem in fact is (many-one) hard for parallel access to NP.
FOCS	The Computational Complexity of Knot and Link Problems.	Joel Hass,J. C. Lagarias,Nicholas Pippenger	1997	The Computational Complexity of Knot and Link Problems Joel Hass Department of Mathematics University of California, Davis Davis, CA 95616 USA hass@math.ucdavis.edu Jeffrey C. Lagarias Information Sciences Research A T & T Labs 180 Park Avenue Florham Park NJ 07932-0971 USA jcl@research.att.com Nicholas Pippenger Department of Computer Science University of British Columbia Vancouver, BC V6T 1Z4 CANADA nicholas@cs.ubs.ca We consider the problem of deciding whether a polygonal knot in three dimensional space, or alternatively a knot diagram, is unknotted (that is, whether it is capable of being deformed continuously without self-intersection so that it lies in a plane.) We show that the problem, UNKNOTTING PROBLEM, is in NP. We also consider the problem, SPLITTING PROBLEM, of determining whether two or more such polygons can be split (that is, whether they are capable of being continuously deformed without self-intersection so that they occupy both sides of a plane without intersecting it) and show that it is also in NP. We show that the problem of determining the genus of a polygonal knot (a generalization of the problem of determining whether it is unknotted) is in PSPACE. We also give exponential worst-case running time bounds for deterministic algorithms to solve each of these problems. These algorithms are based on the use of normal surfaces and decision procedures due to W. Haken, with recent extensions by W. Jaco and J. F. Tollefson.
FOCS	Deterministic Superimposed Coding with Applications to Pattern Matching.	Piotr Indyk	1997	"A superimposed code is a set of binary vectors having the property that no vector is contained in a boolean sum (i.e. bitwise OR) of a small number of others. Such codes are used in information retrieval for constructing so-called signature files; they also have applications in other areas. In this paper we introduce a new notion of data-dependent superimposed codes and give a deterministic algorithm for constructing short such codes. We then show that these codes can be used to achieve an almost optimal derandomization of several pattern matching algorithms, including the almost-linear time algorithm for tree pattern matching developed recently by Cole and Hariharan, STOC'97. Thus, we give the first almost-linear time deterministic algorithms for these problems."
FOCS	Minimizing Flow Time Nonclairvoyantly.	Bala Kalyanasundaram,Kirk Pruhs	1997	"We consider the problem of scheduling a collection of dynamically arriving jobs with unknown execution times so as to minimize the average response/flow time. This is the classic CPU scheduling problem faced by time sharing operating systems. In the standard 3-field scheduling notation this is the nonclairvoyant version of 1|pmtn, r/sub j/|/spl Sigma/F/sub j/. Its easy to see that every algorithm that doesn't unnecessarily idle the processor is at worst n-competitive, where n is the number of jobs. Yet there is no known nonclairvoyant algorithm, deterministic or randomized, with a competitive ratio provably o(n). We present a randomized nonclairvoyant algorithm, RMLF, that has competitive ratio /spl theta/(lognloglogn) against an adaptive adversary. RMLF is a slight variation of the multi level feedback (MLF) algorithm used by the Unix operating system, further justifying the adoption of this algorithm. R. Motwani et al. (1994) showed that every randomized nonclairvoyant algorithm is /spl Omega/2(log n)competitive, and that every deterministic nonclairvoyant algorithm is /spl Omega/2(n/sup 1/3/)-competitive."
FOCS	A 7/8-Approximation Algorithm for MAX 3SAT?	Howard J. Karloff,Uri Zwick	1997	We describe a randomized approximation algorithm which takes an instance of MAX 3SAT as input. If the instance---a collection of clauses each of length at most three---is satisfiable, then the expected weight of the assignment found is at least 7/8 of optimal. We provide strong evidence (but not a proof) that the algorithm performs equally well on arbitrary MAX 3SAT instances. Our algorithm uses semidefinite programming and may be seen as a sequel to the MAX CUT algorithm of Goemans and Williamson and the MAX 2SAT algorithm of Feige and Goemans. Though the algorithm itself is fairly simple, its analysis is quite complicated as it involves the computation of volumes of spherical tetrahedra. Hastad has recently shown that, assuming P
FOCS	Computing Integral Points in Convex Semi-algebraic Sets.	Leonid Khachiyan,Lorant Porkolab	1997	"Let $Y$ be a convex set in $R^k$ defined by polynomial inequalities and equations of degree $d \ge 2$ with integer coefficients of binary length $l$. We show that if $Y \cap Z^k \ne \emptyset$, then $Y$ contains an integral point of binary length $ld^{O(k^4)}$. For fixed $k$, our bound implies a polynomial-time algorithm for computing an integral point $y \in Y$. In particular, we extend Lenstra''s theorem on the polynomial-time solvability of linear integer programming in fixed dimension to semidefinite integer programming."
FOCS	Storage Management for Evolving Databases.	Jon M. Kleinberg,Rajeev Motwani,Prabhakar Raghavan,Suresh Venkatasubramanian	1997	The problem of maintaining data that arrives continuously over time is increasingly prevalent in databases and digital libraries. Building on a model for sliding-window indices developed, we devise efficient algorithms for some of the central problems that arise. We also show connections between the problems in this model and some fundamental problems in optimization and graph theory.
FOCS	Randomized and Deterministic Algorithms for the Dimension of Algebraic Varieties.	Pascal Koiran	1997	We prove old and new results on the complexity of computing the dimension of algebraic varieties. In particular, we show that this problem is NP-complete in the Blum-Shub-Smale model of computation over C, that it admits a s/sup O(1)/D/sup O(n)/ deterministic algorithm, and that for systems with integer coefficients it is in the Arthur-Merlin class under the Generalized Riemann Hypothesis. The first two results are based on a general derandomization argument.
FOCS	Improved Approximation Algorithms for Unsplittable Flow Problems.	Stavros G. Kolliopoulos,Clifford Stein	1997	In the single-source unsplittable flow problem we are given a graph G, a source vertex s and a set of sinks t_1,\ldots,t_k with associated demands. We seek a single s-t_i flow path for each commodity i so that the demands are satisfied and the total flow routed across any edge e is bounded by its capacity c_e. The problem is an NP-hard variant of max flow and a generalization of single-source edge-disjoint paths with applications to scheduling, load balancing and virtual-circuit routing problems. In a significant development, Kleinberg gave recently constant-factor approximation algorithms for several natural optimization versions of the problem \cite{Kleinberg96}. In this paper we give a generic framework that yields simpler algorithms and significant improvements upon the constant factors. Our framework, with appropriate subroutines, applies to all optimization versions previously considered and treats in a unified manner directed and undirected graphs. To give a flavor of our results, consider minimizing relative congestion, i.e. the maximum ratio over all edges e of the flow through e divided by the capacity c_e. This metric was a primary testbed for randomized rounding techniques and has been studied extensively. We give a simple (3.23+o(1))-approximation algorithm for both directed and undirected graphs. The previously known bounds were 16 for the directed and 8.25 for the undirected case. Our approach also gives the first constant-factor approximation for minimum-cost unsplittable flow on directed graphs and improves considerably upon the approximation ratio for the minimum cost version on undirected graphs. The algorithmic techniques we introduce are quite general and apply to related problems as well. For example we use them to give a constructive proof of the following fact. If there exists an algorithm {\cal A} for (multisource) edge-disjoint paths such that {\cal A} outputs an approximation for relative congestion that is \rho times the fractional optimum, then a corresponding O(\rho)-approximation algorithm exists for multisource unsplittable flow with arbitrary demands and capacities. On the negative side we show that for the problem with two sources, no \rho-approximation with \rho0. We give a best possible, unless P=NP, 3/2-approximation for this restricted unsplittable flow problem and generalizations to other restricted sets of demands.
FOCS	Replication is NOT Needed: SINGLE Database, Computationally-Private Information Retrieval.	Eyal Kushilevitz,Rafail Ostrovsky	1997	We establish the following, quite unexpected, result: replication of data for the computational private information retrieval problem is not necessary. More specifically, based on the quadratic residuosity assumption, we present a single database, computationally private information retrieval scheme with O(n/sup /spl epsiv//) communication complexity for any /spl epsiv/>0.
FOCS	On the Power of Quantum Finite State Automata.	Attila Kondacs,John Watrous	1997	"In this paper, we introduce 1-way and 2-way quantum finite state automata (1qfa's and 2qfa's), which are the quantum analogues of deterministic, nondeterministic and probabilistic 1-way and 2-way finite state automata. We prove the following facts regarding 2qfa's. 1. For any /spl epsiv/>0, there is a 2qfa M which recognizes the non-regular language L={a/sup m/b/sup m/|m/spl ges/1} with (one-sided) error bounded by E, and which halts in linear time. Specifically, M accepts any string in L with probability 1 and rejects any string not in L with probability at least 1-/spl epsiv/. 2. For every regular language L, there is a reversible (and hence quantum) 2-way finite state automaton which recognizes L and which runs in linear time. In fact, it is possible to define 2qfar's which recognize the non-context-free language {a/sup m/b/sup m/c/sup m/|m/spl ges/1}, based on the same technique used for 1. Consequently, the class of languages recognized by linear time, bounded error 2qfa's properly includes the regular languages. Since it is known that 2-way deterministic, nondeterministic and polynomial expected time, bounded error probabilistic finite automata can recognize only regular languages, it follows that 2qfa's are strictly more powerful than these ""classical"" models. In the case of 1-way automata, the situation is reversed. We prove that the class of languages recognizable by bounded error 1qfa's is properly contained in the class of regular languages."
FOCS	On the Complexity of a Set-Union Problem.	Richard J. Lipton,Paul J. Martino,Andy Neitzke	1997	"We consider a simple data structure supporting the following operations: (i) create a new singleton set; (ii) create a new set which is the union of two pre-existing sets; (iii) determine whether a given element is in a particular set. We prove both lower and upper bounds for an implementation of such a data structure. In a restricted model we show that no deterministic implementation can be better than the ""trivial"" one that takes O(n^2) time. In a parallel model where the operations come in at most O(lg n) stages we exhibit a sub-quadratic implementation."
FOCS	Exploiting Locality for Data Management in Systems of Limited Bandwidth.	Bruce M. Maggs,Friedhelm Meyer auf der Heide,Berthold Vöcking,Matthias Westermann	1997	This paper deals with data management in computer systems in which the computing nodes are connected by a relatively sparse network. We consider the problem of placing and accessing a set of shared objects that are read and written from the nodes in the network. These objects are, e.g., global variables in a parallel program, pages or cache lines in a virtual shared memory system, or shared files in a distributed file system. %It is assumed that each node has its own local memory module such %that the shared objects have to be distributed among the nodes. A data mangement strategy consists of a placement strategy that maps the objects (possibly dynamically and with redundancy) to the nodes, and an access strategy that describes how reads and writes are handled by the system (including the routing). We investigate static and dynamic data management strategies. In the static model, we assume that we are given an application for which the rates of read and write acesses for all node--object pairs are known. The goal is to calculate a static placement of the objects to the nodes in the network and to specify the routing such that the network congestion is minimized. We introduce efficient algorithms that calculate optimal or close--to--optimal solutions for tree--connected networks, meshes of arbitrary dimension and internet--like clustered networks. These algorithms take time only linear in the input size. In the dynamic model, we assume no knowledge about the access pattern. An adversary specifies accesses at runtime. Here we devolop dynamic caching strategies that also aim to minimize the congestion on trees, meshes and clustered networks. These strategies are investigated in an competitive model. For example, we achieve competitive ratio 3 for tree--connected networks and competitive ratio O(d \cdot \log n) for d--dimensional meshes of size n. Further, we present an \Omega(\log n / d) lower bound for the competitive ratio for on--line routing in meshes, which implies that the achieved upper bound on the competive ratio for meshes of constant dimension is optimal.
FOCS	Succinct Representation of Balanced Parentheses, Static Trees and Planar Graphs.	J. Ian Munro,Venkatesh Raman	1997	We consider the implementation of abstract data types for the static objects: binary tree, rooted ordered tree and balanced parenthesis expression. Our representations use an amount of space within a lower order term of the information theoretic minimum and support, in constant time, a richer set of navigational operations than has previously been considered in similar work. In the case of binary trees, for instance, we can move from a node to its left or right child or to the parent in constant time while retaining knowledge of the size of the subtree at which we are positioned. The approach is applied to produce succinct representation of planar graphs in which one can test adjacency in constant time.
FOCS	Number-theoretic Constructions of Efficient Pseudo-random Functions.	Moni Naor,Omer Reingold	1997	"We describe efficient constructions for various cryptographic primitives in private-key as well as public-key cryptography. Our main results are two new constructions of pseudo-random functions. We prove the pseudo-randomness of one construction under the assumption that factoring (Blum integers) is hard while the other construction is pseudo-random if the decisional version of the Diffie--Hellman assumption holds. Computing the value of our functions at any given point involves two subset products. This is much more efficient than previous proposals. Furthermore, these functions have the advantage of being in TC0 (the class of functions computable by constant depth circuits consisting of a polynomial number of threshold gates). This fact has several interesting applications. The simple algebraic structure of the functions implies additional features such as a zero-knowledge proof for statements of the form ""y &equals; fs(x)"" and ""y &neq; fs(x)"" given a commitment to a key s of a pseudo-random function fs."
FOCS	Improved Approximations for Shallow-Light Spanning Trees.	Joseph Naor,Baruch Schieber	1997	We consider the bicriteria optimization problem of computing a shallow-light tree. Given a directed graph with two unrelated cost functions defined on its edges: weight and length, and a designated root vertex, the goal is to find a minimum weight spanning tree such that the path lengths from its root to the rest of the vertices are bounded. This problem has several applications in network and VLSI design, and information retrieval. We give a polynomial time algorithm for finding a spanning tree whose weight is O(log |V|) times the weight of an optimal shallow-light tree, where the path lengths from the root to the rest of the vertices are at most twice the given bounds. We extend our technique to handle two variants of the problem: one in which the length bound is given on the average length of a path from the root to a vertex, and another tricriteria budgeted version. Our paper provides the first non-trivial approximation factors for directed graphs, and improves on previous results for undirected graphs.
FOCS	A 2-Approximation Algorithm for the Directed Multiway Cut Problem.	Joseph Naor,Leonid Zosin	1997	A directed multiway cut separates a set of terminals s/sub 1/,...,s/sub /spl kappa// in a directed capacitated graph G=(V, E). Finding a minimum capacity directed multiway cut is an NP-complete problem. We give a polynomial-time algorithm that achieves an approximation factor of 2 for this problem. This improves the result of Garg, Vazirani and Yannakakis (1994) who gave an algorithm that achieves an approximation factor of 2 log /spl kappa/. Our approximation algorithm uses a novel technique for relaxing a multiway flow function in order to find a directed multiway cut. It also implies that the integrality gap of the linear program for the directed multiway cut problem is at most 2.
FOCS	Satisfiability Coding Lemma.	Ramamohan Paturi,Pavel Pudlák,Francis Zane	1997	We present and analyze two simple algorithms for finding satisfying assignments of /spl kappa/-CNFs (Boolean formulae in conjunctive normal form with at most /spl kappa/ literals per clause). The first is a randomized algorithm which, with probability approaching 1, finds a satisfying assignment of a satisfiable /spl kappa/-CNF formula F in time O(n/sup 2/|F|2/sup n-n//spl kappa//). The second algorithm is deterministic, and its running time approaches 2/sup n-n/2/spl kappa// for large n and /spl kappa/. The randomized algorithm is the best known algorithm for /spl kappa/>3; the deterministic algorithm is the best known deterministic algorithm for /spl kappa/>4. We also show an /spl Omega/(n/sup 1/4/2/sup /spl radic/n/) lower bound on the size of depth 3 circuits of AND and OR gates computing the parity function. This bound is tight up to a constant factor. The key idea used in these upper and lower bounds is what we call the Satisfiability Coding Lemma. This basic lemma shows how to encode satisfying solutions of a /spl kappa/-CNF succinctly.
FOCS	Two Decades of Temporal Logic: Achievements and Challenges (Abstract).	Amir Pnueli	1997	Two Decades of Temporal Logic: Achievements and Challenges (Abstract).
FOCS	Making Nondeterminism Unambiguous.	Klaus Reinhardt,Eric Allender	1997	We show that in the context of nonuniform complexity, nondeterministic logarithmic space bounded computation can be made unambiguous. An analogous result holds for the class of problems reducible to context-free languages. In terms of complexity classes, this can be stated as: NL/poly = UL/poly LogCFL/poly = UAuxPDA(log n, poly)/poly
FOCS	Tight Bounds for Depth-two Superconcentrators.	Jaikumar Radhakrishnan,Amnon Ta-Shma	1997	We show that the minimum size of a depth-two N-superconcentrator is /spl Theta/(Nlog/sup 2/N/loglogN). Before this work, optimal bounds were known for all depths except two. For the upper bound, we build superconcentrators by putting together a small number of disperser graphs; these disperser graphs are obtained using a probabilistic argument. We present two different methods for showing lower bounds. First, we show that superconcentrators contain several disjoint disperser graphs. When combined with the lower bound for disperser graphs due to Kovari, Sos and Turan, this gives an almost optimal lower bound of /spl Omega/(N(log N/loglog N)/sup 2/) on the size of N-superconcentrators. The second method, based on the work of Hansel (1964), gives the optimal lower bound. The method of the Kovari, Sos and Turan can be extended to give tight lower bounds for extractors, both in terms of the number of truly random bits needed to extract one additional bit and in terms of the unavoidable entropy loss in the system. If the input is an n-bit source with min-entropy /spl kappa/ and the output is required to be within a distance of E from uniform distribution, then to extract even a constant number of additional bits, one must invest at least log(n-/spl kappa/)+2 log(1//spl epsiv/)-O(1) truly random bits; to obtain m output bits one must invest at least m-/spl kappa/+2 log(1//spl epsiv/)-O(1). Thus, there is a loss of 2 log(1//spl epsiv/) bits during the extraction. Interestingly in the case of dispersers this loss in entropy is only about loglog(1//spl epsiv/).
FOCS	Separation of the Monotone NC Hierarchy.	Ran Raz,Pierre McKenzie	1997	"We prove tight lower bounds, of up to n/sup /spl epsiv//, for the monotone depth of functions in monotone-P. As a result we achieve the separation of the following classes. 1. Monotone-NC/spl ne/monotone-P. 2. /spl forall/i/spl ges/1, monotone-NC/sup i//spl ne/monotone-NC/sup i+1/. 3. More generally: For any integer function D(n), up to n/sup /spl epsiv// (for some /spl epsiv/>0), we give an explicit example of a monotone Boolean function, that can be computed by polynomial size monotone Boolean circuits of depth D(n), but that cannot be computed by any (fan-in 2) monotone Boolean circuits of depth less than Const/spl middot/D(n) (for some constant Const). Only a separation of monotone-NC/sup 1/ from monotone-NC/sup 2/ was previously known. Our argument is more general: we define a new class of communication complexity search problems, referred to below as DART games, and we prove a tight lower bound for the communication complexity of every member of-this class. As a result we get lower bounds for the monotone depth of many functions. In particular, we get the following bounds: 1. For st-connectivity, we get a tight lower bound of /spl Omega/(log/sup 2/ n). That is, we get a new proof for Karchmer-Wigderson's theorem, as an immediate corollary of our general result. 2. For the k-clique function, with k/spl les/n/sup /spl epsiv//, we get a tight lower bound of /spl Omega/(k log n). Only a bound of /spl Omega/(k) was previously known."
FOCS	A Complete Promise Problem for Statistical Zero-Knowledge.	Amit Sahai,Salil P. Vadhan	1997	We present a complete promise problem for SZK, the class of languages possessing statistical zero-knowledge proofs (against an honest verifier). The problem is to decide whether two efficiently samplable distributions are either statistically close or far apart. This characterizes SZK with no reference to interaction or zero-knowledge. From this theorem and its proof, we are able to establish several other results about SZK, knowledge complexity, and efficiently samplable distributions.
FOCS	Deciding Properties of Polynomials Without Factoring.	Tomas Sander,Mohammad Amin Shokrollahi	1997	The polynomial time algorithm of Lenstra, Lenstra, and Lovasz (1982) for factoring integer polynomials and variants thereof have been widely used to show that various computational problems in number theory have polynomial time solutions. Among them is the problem of factoring polynomials over algebraic number fields, which is used itself as a major subroutine for several other algorithms. Although a theoretical breakthrough, algorithms based on factorization of polynomials are notoriously slow and hard to implement, with running times ranging between O(n/sup 12/) and O(n/sup 18/) depending on which variant of the lattice basis reduction is used. Here, n is an upper bound for the maximum of the degrees and the bit-lengths of the coefficients of the polynomials involved. On the other hand, in many situations one does not need the full power of factorization, so one may ask whether there exist faster algorithms in these cases. In this paper we develop more efficient Monte Carlo algorithms to decide certain properties of roots of integer polynomials, without factoring them. Such problems arise, e.g., when solving systems of algebraic equations. Our methods applied to this situation thus give information about the solutions of such systems of equations.
FOCS	Improved Approximations for Edge-Disjoint Paths, Unsplittable Flow, and Related Routing Problems.	Aravind Srinivasan	1997	We present improved approximation algorithms for a family of problems involving edge-disjoint paths and unsplittable flow, and for some related routing problems. The central theme of all our algorithms is the underlying multi-commodity flow relaxation.
FOCS	Undirected Single Source Shortest Path in Linear Time.	Mikkel Thorup	1997	"The single source shortest paths problem (SSSP) is one of the classic problems in algorithmic graph theory: given a weighted graph G with a source vertex s, find the shortest path from s to all other vertices in the graph. Since 1959 all theoretical developments in SSSP have been based on Dijkstra's algorithm, visiting the vertices in order of increasing distance from s. Thus, any implementation of Dijkstra's algorithm sorts the vertices according to their distances from s. However, we do not know how to sort in linear time. Here, a deterministic linear time and linear space algorithm is presented for the undirected single source shortest paths problem with integer weights. The algorithm avoids the sorting bottle-neck by building a hierarchical bucketing structure, identifying vertex pairs that may be visited in any order."
FOCS	Hamiltonian Cycles in Solid Grid Graphs.	Christopher Umans,William Lenhart	1997	Hamiltonian Cycles in Solid Grid Graphs.
FOCS	Approximating Shortest Paths on an Nonconvex Polyhedron.	Kasturi R. Varadarajan,Pankaj K. Agarwal	1997	We present an approximation algorithm that, given the boundary P of a simple, nonconvex polyhedron in ${\mathbb R}^3$ and two points s and t on P, constructs a path on P between s and t whose length is at most ${7(1+{\varepsilon})} dP(s,t), where dP(s,t) is the length of the shortest path between s and t on P, and ${\varepsilon} > 0$ is an arbitrarily small positive constant. The algorithm runs in O(n5/3 log5/3 n) time, where n is the number of vertices in P. We also present a slightly faster algorithm that runs in O(n8/5 log8/5 n) time and returns a path whose length is at most ${15(1+{\varepsilon})} d_{P}(s,t)$.
FOCS	A Random Sampling Based Algorithm for Learning the Intersection of Half-spaces.	Santosh Vempala	1997	"We present an algorithm for learning the intersection of half-spaces in n dimensions. Over nearly-uniform distributions, it runs in polynomial time for up to O(log n /log log n) half-spaces or, more generally, for any number of half-spaces whose normal vectors lie in an O(log n / log log n) dimensional subspace. Over less restricted ``non-concentrated'' distributions it runs in polynomial time for a constant number of half-spaces. This generalizes an earlier result of Blum and Kannan. The algorithm is simple and is based on random sampling."
FOCS	The Competitive Analysis of Risk Taking with Applications to Online Trading.	Sabah al-Binali	1997	"Competitive analysis is concerned with minimizing a relative measure of performance. When applied to financial trading strategies, competitive analysis leads to the development of strategies with minimum relative performance risk. This approach is too inflexible. Many investors are interested in managing their risk: they may be willing to increase their risk for some form of reward. They may also have some forecast of the future. In this paper, we extend competitive analysis to provide a framework in which investors can develop optimal trading strategies based on their risk tolerance and forecast.We first define notions of risk and reward that are smooth extensions of classical competitive analysis. We then illustrate our ideas using the ski-rental problem. Finally, we analyze a financial game, the unidirectional conversion problem. In particular, we present an optimal risk-tolerant algorithm for the forecast that prices will reach a certain level at some point during the game, and give numerical results of the investor's reward for making such a forecast."
FOCS	"38th Annual Symposium on Foundations of Computer Science, FOCS '97, Miami Beach, Florida, USA, October 19-22, 1997"		1997	"38th Annual Symposium on Foundations of Computer Science, FOCS '97, Miami Beach, Florida, USA, October 19-22, 1997"
SODA	Approximation Schemes for Scheduling.	Noga Alon,Yossi Azar,Gerhard J. Woeginger,Tal Yadid	1997	Approximation Schemes for Scheduling.
SODA	Self-Stabilizing Unidirectional Network Algorithms by Power-Supply (Extended Abstract).	Yehuda Afek,Anat Bremler-Barr	1997	Self-Stabilizing Unidirectional Network Algorithms by Power-Supply (Extended Abstract).
SODA	Line Traversals of Balls and Smallest Enclosing Cylinders in Three Dimensions.	Pankaj K. Agarwal,Boris Aronov,Micha Sharir	1997	Line Traversals of Balls and Smallest Enclosing Cylinders in Three Dimensions.
SODA	An Efficient Algorithm for Terraine Simplification.	Pankaj K. Agarwal,Pavan K. Desikan	1997	An Efficient Algorithm for Terraine Simplification.
SODA	Experimental Analysis of Dynamic Minimum Spanning Tree Algorithms (Extended Abstract).	Giuseppe Amato II,Giuseppe Cattaneo,Giuseppe F. Italiano	1997	Experimental Analysis of Dynamic Minimum Spanning Tree Algorithms (Extended Abstract).
SODA	Optimal Point Placement for Mesh Smoothing.	Nina Amenta,Marshall W. Bern,David Eppstein	1997	Optimal Point Placement for Mesh Smoothing.
SODA	Computing a Minimum Biclique Cover is Polynomial for Bipartite Domino-Free Graphs.	Jérôme Amilhastre,Philippe Janssen,Marie-Catherine Vilarem	1997	Computing a Minimum Biclique Cover is Polynomial for Bipartite Domino-Free Graphs.
SODA	Local Rules for Protein Folding on a Triangular Lattice and Generalized Hydrophobicity in the HP Model.	Richa Agarwala,Serafim Batzoglou,Vlado Dancík,Scott E. Decatur,Martin Farach,Sridhar Hannenhalli,Steven Skiena	1997	Local Rules for Protein Folding on a Triangular Lattice and Generalized Hydrophobicity in the HP Model.
SODA	Shortest Path in Complete Bipartite Digraph Problem and its Applications.	Xin He,Zhi-Zhong Chen	1997	Shortest Path in Complete Bipartite Digraph Problem and its Applications.
SODA	The Angular-Metric Traveling Salesman Problem.	Alok Aggarwal,Don Coppersmith,Sanjeev Khanna,Rajeev Motwani,Baruch Schieber	1997	Motivated by applications in robotics, we formulate the problem of minimizing the total angle cost of a TSP tour for a set of points in Euclidean space, where the angle cost of a tour is the sum of the direction changes at the points. We establish the NP-hardness of both this problem and its relaxation to the cycle cover problem. We then consider the issue of designing approximation algorithms for these problems and show that both problems can be approximated to within a ratio of O(log n) in polynomial time. We also consider the problem of simultaneously approximating both the angle and the length measure for a TSP tour. In studying the resulting tradeoff, we choose to focus on the sum of the two performance ratios and provide tight bounds on the sum. Finally, we consider the extremal value of the angle measure and obtain essentially tight bounds for it. In this paper we restrict our attention to the planar setting, but all our results are easily extended to higher dimensions.
SODA	The -Client Problem.	Houman Alborzi,Eric Torng,Patchrawat Uthaisombut,Stephen Wagner	1997	The -Client Problem.
SODA	On the Maximum Scatter TSP (Extended Abstract).	Esther M. Arkin,Yi-Jen Chiang,Joseph S. B. Mitchell,Steven Skiena,Tae-Cheon Yang	1997	On the Maximum Scatter TSP (Extended Abstract).
SODA	The Growth Rate of Vertex-Transitive Planar Graphs.	László Babai	1997	The Growth Rate of Vertex-Transitive Planar Graphs.
SODA	Online List Accessing Algorithms and Their Applications: Recent Empirical Evidence.	Ran Bachrach,Ran El-Yaniv	1997	Online List Accessing Algorithms and Their Applications: Recent Empirical Evidence.
SODA	On Page Migration and Other Related Task Systems.	Yair Bartal,Moses Charikar,Piotr Indyk	1997	This paper is concerned with the page migration (or file migration) problem (Black and Sleator, Technical Report CMU-CS-89-201, Department of Computer Science, Carnegie-Mellon University, 1989) as part of a large class of on-line problems. The page migration problem deals with the management of pages residing in a network of processors. In the classical problem there is only one copy of each page which is accessed by different processors over time. The page is allowed to be migrated between processors. However a migration incurs higher communication cost than an access (proportionally to the page size). The problem is that of deciding when and where to migrate the page in order to lower access costs. A more general setting is the k-page migration problem where we wish to maintain k copies of the page. The page migration problems are concerned with a dilemma common to many on-line problems: determining when it is beneficial to make configuration changes. We deal with the relaxed task systems model which captures a large class of problems of this type, that can be described as the generalization of some original task system problem (Borodin et al., J. ACM 39(4) (1992) 745-763). Given a c-competitive algorithm for a task system we show how to obtain a deterministic O(c2) and randomized O(c) competitive algorithms for the corresponding relaxed task system. The result implies deterministic algorithms for k-page migration by using k-server (Manasse et al., J. Algorithms 11(2) (1990) 208-230) algorithms, and for network leasing by using generalized Steiner tree algorithms (Awerbuch et al., Proc 7th Ann. ACM-SIAM Symp. on Discrete Algorithms, January 1996, pp. 68-74), as well as providing solutions for natural generalizations of other problems (e.g. storage rearrangement (Fiat et al., Proc. 36th Ann. IEEE Symp. on Foundations of Computer Science, October 1995, pp. 392-403)). We further study some special cases of the k-page migration problem and get optimal deterministic algorithms. For the classical page migration problem we present a deterministic algorithm that achieves a competitive ratio of ~ 4:086, improving upon the previously best competitive ratio of 7 (Awerbuch et al., Proc. 25th ACM Symp. on Theory of Computing, May 1993, pp. 164-173). (The current lower bound on the problem is ~ 3:148 (Chrobak et al., J. Algorithms 24(1) (1997) 124-157). Copyright 2001 Elsevier Science B.V.
SODA	Data Structures for Mobile Data.	Julien Basch,Leonidas J. Guibas,John Hershberger	1997	Data Structures for Mobile Data.
SODA	Optimal Search in Trees: Extended Abstract + Appendix.	Yosi Ben-Asher,Eitan Farchi,Ilan Newman	1997	Optimal Search in Trees: Extended Abstract + Appendix.
SODA	Fast Algorithms for Sorting and Searching Strings.	Jon Louis Bentley,Robert Sedgewick	1997	Fast Algorithms for Sorting and Searching Strings.
SODA	The Algorithmic Aspects of Uncrowded Hypergraphs (Extended Abstract).	Claudia Bertram-Kretzberg,Hanno Lefmann	1997	The Algorithmic Aspects of Uncrowded Hypergraphs (Extended Abstract).
SODA	Rounding in Lattices and its Cryptographic Applications.	Dan Boneh,Ramarathnam Venkatesan	1997	Rounding in Lattices and its Cryptographic Applications.
SODA	"Graph Orientations with No Sink and an Approximation for a Hard Case of 	SAT."	Russ Bubley,Martin E. Dyer	1997
SODA	A Strong and Easily Computable Separation Bound for Arithmetic Expressions Involving Square Roots.	Christoph Burnikel,Rudolf Fleischer,Kurt Mehlhorn,Stefan Schirra	1997	A Strong and Easily Computable Separation Bound for Arithmetic Expressions Involving Square Roots.
SODA	Deterministic Algorithms for 2-d Convex Programming and 3-d Online Linear Programming.	Timothy M. Chan	1997	Deterministic Algorithms for 2-d Convex Programming and 3-d Online Linear Programming.
SODA	Efficient Algorithms for Finding Disjoint Paths in Grids (Extended Abstract).	Wun-Tat Chan,Francis Y. L. Chin	1997	Efficient Algorithms for Finding Disjoint Paths in Grids (Extended Abstract).
SODA	Approximation Algorithms for the Achromatic Number.	Amitabh Chaudhary,Sundar Vishwanathan	1997	Approximation Algorithms for the Achromatic Number.
SODA	Experimental Study of Minimum Cut Algorithms.	Chandra Chekuri,Andrew V. Goldberg,David R. Karger,Matthew S. Levine,Clifford Stein	1997	Experimental Study of Minimum Cut Algorithms.
SODA	Approximation Techniques for Average Completion Time Scheduling.	Chandra Chekuri,Rajeev Motwani,B. Natarajan,Clifford Stein	1997	"We consider the problem of nonpreemptive scheduling to minimize average (weighted) completion time, allowing for release dates, parallel machines, and precedence constraints. Recent work has led to constant-factor approximations for this problem based on solving a preemptive or linear programming relaxation and then using the solution to get an ordering on the jobs. We introduce several new techniques which generalize this basic paradigm. We use these ideas to obtain improved approximation algorithms for one-machine scheduling to minimize average completion time with release dates. In the process, we obtain an optimal randomized on-line algorithm for the same problem that beats a lower bound for deterministic on-line algorithms. We consider extensions to the case of parallel machine scheduling, and for this we introduce two new ideas: first, we show that a preemptive one-machine relaxation is a powerful tool for designing parallel machine scheduling algorithms that simultaneously produce good approximations and have small running times; second, we show that a nongreedy ""rounding"" of the relaxation yields better approximations than a greedy one. We also prove a general theorem relating the value of one-machine relaxations to that of the schedules obtained for the original m-machine problems. This theorem applies even when there are precedence constraints on the jobs. We apply this result to obtain improved approximation ratios for precedence graphs such as in-trees, out-trees, and series-parallel graphs."
SODA	Buckets, Heaps, Lists, and Monotone Priority Queues.	Boris V. Cherkassky,Andrew V. Goldberg,Craig Silverstein	1997	"We introduce the heap-on-top (hot) priority queue data structure that combines the multilevel bucket data structure of Denardo and Fox with a heap. Our data structure has superior operation bounds than either structure taken alone. We use the new data structure to obtain an improved bound for Dijkstra's shortest path algorithm. We also discuss a practical implementation of hot queues. Our experimental results in the context of Dijkstra's algorithm show that this implementation of hot queues performs very well and is more robust than implementations based only on heap or multilevel bucket data structures."
SODA	Approximation Algorithms for Precedence-Constrained Scheduling Problems on Parallel Machines That Run at Fifferent Speeds (Extended Abstract).	Fabián A. Chudak,David B. Shmoys	1997	Approximation Algorithms for Precedence-Constrained Scheduling Problems on Parallel Machines That Run at Fifferent Speeds (Extended Abstract).
SODA	Numerical Taxonomy on Data: Experimental Results.	Jaime Cohen,Martin Farach	1997	Numerical Taxonomy on Data: Experimental Results.
SODA	Partial Matching of Planar Polylines Under Similarity Transformations.	Scott D. Cohen,Leonidas J. Guibas	1997	Partial Matching of Planar Polylines Under Similarity Transformations.
SODA	Approximating Matrix Multiplication for Pattern Recognition Tasks.	Edith Cohen,David D. Lewis	1997	Approximating Matrix Multiplication for Pattern Recognition Tasks.
SODA	All-Pairs Small-Stretch Paths.	Edith Cohen,Uri Zwick	1997	All-Pairs Small-Stretch Paths.
SODA	Coloring with Defect.	Lenore Cowen,Wayne Goddard,C. E. Jesurum	1997	Coloring with Defect.
SODA	Efficient and Practical Modular Decomposition.	Elias Dahlhaus,Jens Gustedt,Ross M. McConnell	1997	Efficient and Practical Modular Decomposition.
SODA	On Distances between Phylogenetic Trees (Extended Abstract).	Bhaskar DasGupta,Xin He,Tao Jiang,Ming Li,John Tromp,Louxin Zhang	1997	On Distances between Phylogenetic Trees (Extended Abstract).
SODA	Combinatorial Optimization Games.	Xiaotie Deng,Toshihide Ibaraki,Hiroshi Nagamochi	1997	Combinatorial Optimization Games.
SODA	Map Labeling and Its Generalizations.	Srinivas Doddi,Madhav V. Marathe,Andy Mirzaian,Bernard M. E. Moret,Binhai Zhu	1997	Map Labeling and Its Generalizations.
SODA	Efficient Approximation and Optimization Algorithms for Computational Metrology.	Christian A. Duncan,Michael T. Goodrich,Edgar A. Ramos	1997	Efficient Approximation and Optimization Algorithms for Computational Metrology.
SODA	Faster Construction of Planar Two-Centers.	David Eppstein	1997	Faster Construction of Planar Two-Centers.
SODA	Fast Approximate Graph Partitioning Algorithms.	Guy Even,Joseph Naor,Satish Rao,Baruch Schieber	1997	Fast Approximate Graph Partitioning Algorithms.
SODA	Markov Chains for Linear Extensions, the Two-Dimensional Case.	Stefan Felsner,Lorenz Wernisch	1997	Markov Chains for Linear Extensions, the Two-Dimensional Case.
SODA	A Better Approximation Ratio for the Minimum k-Edge-Connected Spanning Subgraph Problem.	Cristina G. Fernandes	1997	A Better Approximation Ratio for the Minimum k-Edge-Connected Spanning Subgraph Problem.
SODA	Experimental Studies of Access Graph Based Heuristics: Beating the LRU Standard?	Amos Fiat,Ziv Rosen	1997	Experimental Studies of Access Graph Based Heuristics: Beating the LRU Standard?
SODA	Runtime Prediction of Real Programs on Real Machines.	Ulrich Finkler,Kurt Mehlhorn	1997	Runtime Prediction of Real Programs on Real Machines.
SODA	Efficient Algorithms for Robustness in Matroid Optimization.	Greg N. Frederickson,Roberto Solis-Oba	1997	Efficient Algorithms for Robustness in Matroid Optimization.
SODA	Improved Approximation Algorithms for Scheduling with Release Dates.	Michel X. Goemans	1997	Improved Approximation Algorithms for Scheduling with Release Dates.
SODA	Randomly Sampling Molecules.	Leslie Ann Goldberg,Mark Jerrum	1997	We give the first polynomial-time algorithm for the following problem: Given a degree sequence in which each degree is bounded from above by a constant, select, uniformly at random, an unlabelled connected multigraph with the given degree sequence. We also give the first polynomial-time algorithm for the following related problem: Given a molecular formula, select, uniformly at random, a structural isomer having the giver formula.
SODA	Better Approximation Guarantees for Job-shop Scheduling.	Leslie Ann Goldberg,Mike Paterson,Aravind Srinivasan,Elizabeth Sweedyk	1997	Job-shop scheduling is a classical NP-hard problem. Shmoys, Stein, and Wein presented the first polynomial-time approximation algorithm for this problem that has a good (polylogarithmic) approximation guarantee. We improve the approximation guarantee of their work and present further improvements for some important NP-hard special cases of this problem (e.g., in the preemptive case where machines can suspend work on operations and later resume). We also present NC algorithms with improved approximation guarantees for some NP-hard special cases.
SODA	Randomized Fully-Scalable BSP Techniques for Multi-Searching and Convex Hull Construction (Preliminary Version).	Michael T. Goodrich	1997	Randomized Fully-Scalable BSP Techniques for Multi-Searching and Convex Hull Construction (Preliminary Version).
SODA	Methods for Achieving Fast Query Times in Point Location Data Structures.	Michael T. Goodrich,Mark W. Orletsky,Kumar Ramaiyer	1997	Methods for Achieving Fast Query Times in Point Location Data Structures.
SODA	Nearly Optimal Distributed Edge Colouring in O(log log n) Rounds.	David A. Grable,Alessandro Panconesi	1997	Nearly Optimal Distributed Edge Colouring in O(log log n) Rounds.
SODA	The Path Resistance Method for Bounding lambda of a Laplacian.	Stephen Guattery,Frank Thomson Leighton,Gary L. Miller	1997	The Path Resistance Method for Bounding lambda of a Laplacian.
SODA	A Competitive Strategy for Learning a Polygon.	Frank Hoffmann,Christian Icking,Rolf Klein,Klaus Kriegel	1997	A Competitive Strategy for Learning a Polygon.
SODA	Probabilistic Analysis for Scheduling with Conflicts.	Sandy Irani,Vitus J. Leung	1997	"In this paper, we consider scheduling jobs that may be competing for mutually exclusive resources. We model the conflicts between jobs with a conflict graph, so that all concurrently running jobs must form an independent set in the graph. Our goal is to bound the maximum response time of any job in the system. We adopt a discrete model of time and assume that each job requires one time unit to be completed once it is started. It has been previously shown [S. Irani, V. Leung, Scheduling with conflicts, and applications to traffic signal control, in: Proceedings of the Seventh Annual ACM-SIAM Symposium on Discrete Algorithms, SIAM, 1996] that the best competitive ratio achievable by any online algorithm is @W(n), where n is the number of nodes in the graph. As a result, we study scheduling with conflicts under probabilistic assumptions about the input. Each node i has a value p""i such that a job arrives at node i in any given time unit with probability p""i. Arrivals at different nodes and during different time periods are independent. Under reasonable assumptions on the value for the p""i's, we are able to obtain a bounded competitive ratio for an arbitrary conflict graph. In addition, if the conflict graph is a perfect graph, we give an algorithm whose competitive ratio converges to 1."
SODA	Mapping Clones with a Given Ordering or Interleaving (Extended Abstract).	Tao Jiang,Richard M. Karp	1997	Mapping Clones with a Given Ordering or Interleaving (Extended Abstract).
SODA	Simple Markov-Chain Algorithms for Generating Bipartite Graphs and Tournaments (Extended Abstract).	Ravi Kannan,Prasad Tetali,Santosh Vempala	1997	Simple Markov-Chain Algorithms for Generating Bipartite Graphs and Tournaments (Extended Abstract).
SODA	On-Line Difference Maximization.	Ming-Yang Kao,Stephen R. Tate	1997	In this paper we examine problems motivated by on-line financial problems and stochastic games. In particular, we consider a sequence of entirely arbitrary distinct values arriving in random order, and must devise strategies for selecting low values followed by high values in such a way as to maximize the expected gain in rank from low values to high values.First, we consider a scenario in which only one low value and one high value may be selected. We give an optimal on-line algorithm for this scenario, and analyze it to show that, surprisingly, the expected gain is n-O(1), and so differs from the best possible off-line gain by only a constant additive term (which is, in fact, fairly small---at most 15).In a second scenario, we allow multiple nonoverlapping low/high selections, where the total gain for our algorithm is the sum of the individual pair gains. We also give an optimal on-line algorithm for this problem, where the expected gain is $n^2/8-\Theta(n\log n)$. An analysis shows that the optimal expected off-line gain is $n^2/6+\Theta(1)$, so the performance of our on-line algorithm is within a factor of 3/4 of the best off-line strategy.
SODA	Faster and Simpler Algorithm for Sorting Signed Permutations by Reversals.	Haim Kaplan,Ron Shamir,Robert Endre Tarjan	1997	Faster and Simpler Algorithm for Sorting Signed Permutations by Reversals.
SODA	Implementing a Fully Polynomial Time Approximation Scheme for All Terminal Network Reliability.	David R. Karger,Ray P. Tai	1997	Implementing a Fully Polynomial Time Approximation Scheme for All Terminal Network Reliability.
SODA	Inferring Evolutionary Trees from Ordinal Data.	Paul E. Kearney,Ryan Hayward,Henk Meijer	1997	Inferring Evolutionary Trees from Ordinal Data.
SODA	Improved Access to Optimal Bandwidth in Trees.	Vijay Kumar,Eric J. Schwabe	1997	Improved Access to Optimal Bandwidth in Trees.
SODA	The Influence of Caches on the Performance of Sorting.	Anthony LaMarca,Richard E. Ladner	1997	The Influence of Caches on the Performance of Sorting.
SODA	From Sir Isaac to the Sloan Survey: Calculating the Structure and Chaos Owing to Gravity in the Universe.	George Lake,Thomas Quinn,Derek C. Richardson	1997	From Sir Isaac to the Sloan Survey: Calculating the Structure and Chaos Owing to Gravity in the Universe.
SODA	Approximating Shallow-Light Trees (Extended Abstract).	Guy Kortsarz,David Peleg	1997	Approximating Shallow-Light Trees (Extended Abstract).
SODA	A Near-Optimal Heuristic for Minimum Weight Triangulation of Convex Polygons (Extended Abstract).	Christos Levcopoulos,Drago Krznaric	1997	A Near-Optimal Heuristic for Minimum Weight Triangulation of Convex Polygons (Extended Abstract).
SODA	Optimal Good-Aspect-Ratio Coarsening for Unstructured Meshes.	Gary L. Miller,Dafna Talmor,Shang-Hua Teng	1997	Optimal Good-Aspect-Ratio Coarsening for Unstructured Meshes.
SODA	A Combinatorial Algorithm for the Determinant.	Meena Mahajan,V. Vinay	1997	A Combinatorial Algorithm for the Determinant.
SODA	A Practical Approximation Algorithm for the LMS Line Estimator.	David M. Mount,Nathan S. Netanyahu,Kathleen Romanik,Ruth Silverman,Angela Y. Wu	1997	"The problem of fitting a straight line to a finite collection of points in the plane is an important problem in statistical estimation. Robust estimators are widely used because of their lack of sensitivity to outlying data points. The least median-of-squares (LMS) regression line estimator is among the best known robust estimators. Given a set of n points in the plane, it is defined to be the line that minimizes the median squared residual or, more generally, the line that minimizes the residual of any given quantile q, where 0=0, and a quantile approximation, which approximates the fraction of points that lie within the strip to within a given error bound @e""q>=0. We present two randomized approximation algorithms for the LMS line estimator. The first is a conceptually simple quantile approximation algorithm, which given fixed q and @e""q>0 runs in O(nlogn) time. The second is a practical algorithm, which can solve both types of approximation problems or be used as an exact algorithm. We prove that when used as a quantile approximation, this algorithm's expected running time is O(nlog^2n). We present empirical evidence that the latter algorithm is quite efficient for a wide variety of input distributions, even when used as an exact algorithm."
SODA	Improving the Discrepancy Bound for Sparse Matrices: Better Approximations for Sparse Lattice Approximation Problems.	Aravind Srinivasan	1997	Improving the Discrepancy Bound for Sparse Matrices: Better Approximations for Sparse Lattice Approximation Problems.
SODA	Computing Edge-Connectivity Augmentation Function in Õ(nm) Time.	Hiroshi Nagamochi,Takashi Shiraki,Toshihide Ibaraki	1997	Computing Edge-Connectivity Augmentation Function in Õ(nm) Time.
SODA	Linear-Time Transitive Orientation.	Ross M. McConnell,Jeremy Spinrad	1997	Linear-Time Transitive Orientation.
SODA	Practical Toroidality Testing.	Eugene Neufeld,Wendy J. Myrvold	1997	Practical Toroidality Testing.
SODA	Polynomial Algorithms for Multiprocessor Scheduling with a Small Number of Job Lengths.	S. Thomas McCormick,Scott R. Smallwood,Frits C. R. Spieksma	1997	Polynomial Algorithms for Multiprocessor Scheduling with a Small Number of Job Lengths.
SODA	Buy-at-Bulk Network Design: Approximating the Single-Sink Edge Installation Problem.	F. Sibel Salman,Joseph Cheriyan,R. Ravi,S. Subramanian	1997	Buy-at-Bulk Network Design: Approximating the Single-Sink Edge Installation Problem.
SODA	Asymptotically Good Codes Correcting Insertions, Deletions, and Transpositions (Preliminary Version).	Leonard J. Schulman,David Zuckerman	1997	Asymptotically Good Codes Correcting Insertions, Deletions, and Transpositions (Preliminary Version).
SODA	Information Retrieval Algorithms: A Survey.	Prabhakar Raghavan	1997	Information Retrieval Algorithms: A Survey.
SODA	Approximation Algorithms for the Discrete Time-Cost Tradeoff Problem.	Martin Skutella	1997	Approximation Algorithms for the Discrete Time-Cost Tradeoff Problem.
SODA	LP Based Approach to Optimal Stable Matchings.	Chung-Piaw Teo,Jay Sethuraman	1997	LP Based Approach to Optimal Stable Matchings.
SODA	Decremental Dynamic Connectivity.	Mikkel Thorup	1997	Decremental Dynamic Connectivity.
SODA	Randomized sorting in O(n log log n) Time and Linear Space Using Addition, Shift, and Bit-Wise Boolean Operations.	Mikkel Thorup	1997	Randomized sorting in O(n log log n) Time and Linear Space Using Addition, Shift, and Bit-Wise Boolean Operations.
SODA	On-line Algorithms for Compressing Planar Curves.	Gordon T. Wilfong	1997	On-line Algorithms for Compressing Planar Curves.
SODA	Determinant Algorithms for Random Planar Structures.	David Bruce Wilson	1997	Determinant Algorithms for Random Planar Structures.
SODA	The Variance of Two Game Tree Algorithms.	Yanjun Zhang	1997	The Variance of Two Game Tree Algorithms.
SODA	Optimal Bounds for Matching Routing on Trees.	Louxin Zhang	1997	The permutation routing problem is studied for trees under the matching model. By introducing a novel and useful (so-called) caterpillar tree partition, we prove that any permutation on an n-node tree (and thus graph) can be routed in $\frac{3}{2}n + O(\log n)$ steps. This answers an open problem of Alon, Chung, and Graham [ SIAM J. Discrete Math., 7 (1994), pp. 516--530].
SODA	Proceedings of the Eighth Annual ACM-SIAM Symposium on Discrete Algorithms, 5-7 January 1997, New Orleans, Louisiana.	Michael E. Saks	1997	Proceedings of the Eighth Annual ACM-SIAM Symposium on Discrete Algorithms, 5-7 January 1997, New Orleans, Louisiana.
STOC	A Public-Key Cryptosystem with Worst-Case/Average-Case Equivalence.	Miklós Ajtai,Cynthia Dwork	1997	A Public-Key Cryptosystem with Worst-Case/Average-Case Equivalence.
STOC	Better Bounds for Online Scheduling.	Susanne Albers	1997	We study a classical problem in online scheduling. A sequence of jobs must be scheduled on m identical parallel machines. As each job arrives, its processing time is known. The goal is to minimize the makespan. Bartal et al. [ J. Comput. System Sci., 51 (1995), pp. 359--366] gave a deterministic online algorithm that is 1.986-competitive. Karger, Phillips, and Torng [ J. Algorithms, 20 (1996), pp. 400--430] generalized the algorithm and proved an upper bound of 1.945. The best lower bound currently known on the competitive ratio that can be achieved by deterministic online algorithms is equal to 1.837. In this paper we present an improved deterministic online scheduling algorithm that is 1.923-competitive; for all $m\geq 2$. The algorithm is based on a new scheduling strategy, i.e., it is not a generalization of the approach by Bartal et al. Also, the algorithm has a simple structure. Furthermore, we develop a better lower bound. We prove that, for general m, no deterministic online scheduling algorithm can be better than 1.852-competitive.
STOC	Exploring Unknown Environments.	Susanne Albers,Monika Rauch Henzinger	1997	"We consider exploration problems where a robot has to construct a complete map of an unknown environment. We assume that the environment is modeled by a directed, strongly connected graph. The robot's task is to visit all nodes and edges of the graph using the minimum number R of edge traversals. Deng and Papadimitriou [ Proceedings of the 31st Symposium on the Foundations of Computer Science, 1990, pp. 356--361] showed an upper bound for R of dO(d) m and Koutsoupias (reported by Deng and Papadimitriou) gave a lower bound of $\Omega(d^2 m)$, where m is the number of edges in the graph and d is the minimum number of edges that have to be added to make the graph Eulerian. We give the first subexponential algorithm for this exploration problem, which achieves an upper bound of dO(log d) m. We also show a matching lower bound of $d^{\Omega(\log d)}m$ for our algorithm. Additionally, we give lower bounds of $2^{\Omega(d)}m$, respectively, $d^{\Omega(\log d)}m$ for various other natural exploration algorithms."
STOC	Is Linear Hashing Good?	Noga Alon,Martin Dietzfelbinger,Peter Bro Miltersen,Erez Petrank,Gábor Tardos	1997	Is Linear Hashing Good?
STOC	Reducing the Complexity of Reductions.	Manindra Agrawal,Eric Allender,Russell Impagliazzo,Toniann Pitassi,Steven Rudich	1997	Reducing the Complexity of Reductions.
STOC	Fault-Tolerant Quantum Computation With Constant Error.	Dorit Aharonov,Michael Ben-Or	1997	Fault-Tolerant Quantum Computation With Constant Error.
STOC	On Sorting Strings in External Memory (Extended Abstract).	Lars Arge,Paolo Ferragina,Roberto Grossi,Jeffrey Scott Vitter	1997	On Sorting Strings in External Memory (Extended Abstract).
STOC	SL <= L.	Roy Armoni,Amnon Ta-Shma,Avi Wigderson,Shiyu Zhou	1997	SL <= L.
STOC	Improved Low-Degree Testing and its Applications.	Sanjeev Arora,Madhu Sudan	1997	Improved Low-Degree Testing and its Applications.
STOC	Covering Points in the Plane by -Tours: Towards a Polynomial Time Approximation Scheme for General .	Tetsuo Asano,Naoki Katoh,Hisao Tamaki,Takeshi Tokuyama	1997	Covering Points in the Plane by -Tours: Towards a Polynomial Time Approximation Scheme for General .
STOC	Lower Bounds for Distributed Coin-Flipping and Randomized Consensus.	James Aspnes	1997	We examine a class of collective coin-flipping games that arises from randomized distributed algorithms with halting failures. In these games, a sequence of local coin flips is generated, which must be combined to form a single global coin flip. An adversary monitors the game and may attempt to bias its outcome by hiding the result of up to t local coin flips. We show that to guarantee at most constant bias, &ohgr;(t2) local coins are needed, even if (a) the local coins can have arbitrary distributions and ranges, (b) the adversary is required to decide immediately wheter to hide or reveal each local coin, and (c) the game can detect which local coins have been hidden. If the adversary is permitted to control the outcome of the coin except for cases whose probability is polynomial in t, &ohgr;(t2/log2t) local coins are needed. Combining this fact with an extended version of the well-known Fischer-Lynch-Paterson impossibility proof of deterministic consensus, we show that given an adaptive adversary, any t-resilient asynchronous consensus protocol requires &ohgr;(t2/log2t) local coin flips in any model that can be simulated deterministically using atomic registers. This gives the first nontrivial lower bound on the total work required by wait-free consensus and is tight to within logarithmic factors.
STOC	Approximating Hyper-Rectangles: Learning and Pseudo-Random Sets.	Peter Auer,Philip M. Long,Aravind Srinivasan	1997	Approximating Hyper-Rectangles: Learning and Pseudo-Random Sets.
STOC	Online Algorithms for Selective Multicast and Maximal Dense Trees.	Baruch Awerbuch,Tripurari Singh	1997	Online Algorithms for Selective Multicast and Maximal Dense Trees.
STOC	Paul Erdös (1913-1996): His Influence on the Theory of Computing.	László Babai	1997	Paul Erdös (1913-1996): His Influence on the Theory of Computing.
STOC	A polylog()-Competitive Algorithm for Metrical Task Systems.	Yair Bartal,Avrim Blum,Carl Burch,Andrew Tomkins	1997	A polylog()-Competitive Algorithm for Metrical Task Systems.
STOC	Quantum Computation of Fourier Transforms over Symmetric Groups.	Robert Beals	1997	Quantum Computation of Fourier Transforms over Symmetric Groups.
STOC	Commodity-Based Cryptography (Extended Abstract).	Donald Beaver	1997	Commodity-Based Cryptography (Extended Abstract).
STOC	Combinatorial Complexity of the Central Curve.	Peter A. Beling,Sushil Verma	1997	Combinatorial Complexity of the Central Curve.
STOC	A Composition Theorem for Learning Algorithms with Applications to Geometric Concept Classes.	Shai Ben-David,Nader H. Bshouty,Eyal Kushilevitz	1997	A Composition Theorem for Learning Algorithms with Applications to Geometric Concept Classes.
STOC	On Floorplans of Planar Graphs.	Xin He	1997	On Floorplans of Planar Graphs.
STOC	On-Line Algorithms for Steiner Tree Problems (Extended Abstract).	Piotr Berman,Chris Coulston	1997	On-Line Algorithms for Steiner Tree Problems (Extended Abstract).
STOC	Static and Dynamic Path Selection on Expander Graphs: A Random Walk Approach (Preliminary Version).	Andrei Z. Broder,Alan M. Frieze,Eli Upfal	1997	Static and Dynamic Path Selection on Expander Graphs: A Random Walk Approach (Preliminary Version).
STOC	Fast and Precise Computations of Discrete Fourier Transforms Using Cyclotomic Integers.	Joe Buhler,Mohammad Amin Shokrollahi,Volker Stemann	1997	Fast and Precise Computations of Discrete Fourier Transforms Using Cyclotomic Integers.
STOC	Incremental Clustering and Dynamic Information Retrieval.	Moses Charikar,Chandra Chekuri,Tomás Feder,Rajeev Motwani	1997	Motivated by applications such as document and image classification in information retrieval, we consider the problem of clustering dynamic point sets in a metric space. We propose a model called incremental clustering which is based on a careful analysis of the requirements of the information retrieval application, and which should also be useful in other applications. The goal is to efficiently maintain clusters of small diameter as new points are inserted. We analyze several natural greedy algorithms and demonstrate that they perform poorly. We propose new deterministic and randomized incremental clustering algorithms which have a provably good performance, and which we believe should also perform well in practice. We complement our positive results with lower bounds on the performance of incremental algorithms. Finally, we consider the dual clustering problem where the clusters are of fixed diameter, and the goal is to minimize the number of clusters.
STOC	Reducing Randomness via Irrational Numbers.	Zhi-Zhong Chen,Ming-Yang Kao	1997	We propose a general methodology for testing whether a given polynomial with integer coefficients is identically zero. The methodology evaluates the polynomial at efficiently computable approximations of suitable irrational points. In contrast to the classical technique of DeMillo, Lipton, Schwartz, and Zippel, this methodology can decrease the error probability by increasing the precision of the approximations instead of using more random bits. Consequently, randomized algorithms that use the classical technique can generally be improved using the new methodology. To demonstrate the methodology, we discuss two nontrivial applications. The first is to decide whether a graph has a perfect matching in parallel. Our new NC algorithm uses fewer random bits while doing less work than the previously best NC algorithm by Chari, Rohatgi, and Srinivasan. The second application is to test the equality of two multisets of integers. Our new algorithm improves upon the previously best algorithms by Blum and Kannan and can speed up their checking algorithm for sorting programs on a large range of inputs.
STOC	Computationally Private Information Retrieval (Extended Abstract).	Benny Chor,Niv Gilboa	1997	Computationally Private Information Retrieval (Extended Abstract).
STOC	Eigenvalues, Flows and Separators of Graphs.	Fan R. K. Chung,S.-T. Yau	1997	Eigenvalues, Flows and Separators of Graphs.
STOC	All of Us are Smarter Than Any of Us: Wait-Free Hierarchies are not Robust.	Wai-Kau Lo,Vassos Hadzilacos	1997	All of Us are Smarter Than Any of Us: Wait-Free Hierarchies are not Robust.
STOC	Nearest Neighbor Queries in Metric Spaces.	Kenneth L. Clarkson	1997	Nearest Neighbor Queries in Metric Spaces.
STOC	Tree Pattern Matching and Subset Matching in Randomized O(n logm) Time.	Richard Cole,Ramesh Hariharan	1997	Tree Pattern Matching and Subset Matching in Randomized O(n logm) Time.
STOC	Linear Zero-Knowledge - A Note on Efficient Zero-Knowledge Proofs and Arguments.	Ronald Cramer,Ivan Damgård	1997	Linear Zero-Knowledge - A Note on Efficient Zero-Knowledge Proofs and Arguments.
STOC	The Linear-Array Problem in Communication Complexity Resolved.	Martin Dietzfelbinger	1997	The Linear-Array Problem in Communication Complexity Resolved.
STOC	Approximation of -Set Cover by Semi-Local Optimization.	Rong-chii Duh,Martin Fürer	1997	Approximation of -Set Cover by Semi-Local Optimization.
STOC	Non-clairvoyant Multiprocessor Scheduling of Jobs with Changing Execution Characteristics (Extended Abstract).	Jeff Edmonds,Donald D. Chinn,Tim Brecht,Xiaotie Deng	1997	Non-clairvoyant Multiprocessor Scheduling of Jobs with Changing Execution Characteristics (Extended Abstract).
STOC	Making Games Short (Extended Abstract).	Uriel Feige,Joe Kilian	1997	Making Games Short (Extended Abstract).
STOC	An Interruptible Algorithm for Perfect Sampling via Markov Chains.	James Allen Fill	1997	An Interruptible Algorithm for Perfect Sampling via Markov Chains.
STOC	Retraction of Probabilistic Computation and Linear Time.	Lance Fortnow,Michael Sipser	1997	Retraction of Probabilistic Computation and Linear Time.
STOC	Using and Combining Predictors That Specialize.	Yoav Freund,Robert E. Schapire,Yoram Singer,Manfred K. Warmuth	1997	Using and Combining Predictors That Specialize.
STOC	Property Testing in Bounded Degree Graphs.	Oded Goldreich,Dana Ron	1997	Property Testing in Bounded Degree Graphs.
STOC	The Swendsen-Wang Process Does Not Always Mix Rapidly.	Vivek Gore,Mark Jerrum	1997	The Swendsen-Wang Process Does Not Always Mix Rapidly.
STOC	Randomized Omega(n) Lower Bound for Knapsack.	Dima Grigoriev,Marek Karpinski	1997	Randomized Omega(n) Lower Bound for Knapsack.
STOC	Some Optimal Inapproximability Results.	Johan Håstad	1997	We prove optimal, up to an arbitrary &epsilon; > 0, inapproximability results for Max-E k-Sat for k &ge; 3, maximizing the number of satisfied linear equations in an over-determined system of linear equations modulo a prime p and Set Splitting. As a consequence of these results we get improved lower bounds for the efficient approximability of many optimization problems studied previously. In particular, for Max-E2-Sat, Max-Cut, Max-di-Cut, and Vertex cover.
STOC	The Decidability of Distributed Decision Tasks (Extended Abstract).	Maurice Herlihy,Sergio Rajsbaum	1997	The Decidability of Distributed Decision Tasks (Extended Abstract).
STOC	if Requires Exponential Circuits: Derandomizing the XOR Lemma.	Russell Impagliazzo,Avi Wigderson	1997	if Requires Exponential Circuits: Derandomizing the XOR Lemma.
STOC	Locality-Preserving Hashing in Multidimensional Spaces.	Piotr Indyk,Rajeev Motwani,Prabhakar Raghavan,Santosh Vempala	1997	Locality-Preserving Hashing in Multidimensional Spaces.
STOC	Page Replacement with Multi-Size Pages and Applications to Web Caching.	Sandy Irani	1997	Page Replacement with Multi-Size Pages and Applications to Web Caching.
STOC	Sampling Lattice Points.	Ravi Kannan,Santosh Vempala	1997	Sampling Lattice Points.
STOC	General Techniques for Comparing Unrooted Evolutionary Trees.	Ming-Yang Kao,Tak Wah Lam,Teresa M. Przytycka,Wing-Kin Sung,Hing-Fung Ting	1997	General Techniques for Comparing Unrooted Evolutionary Trees.
STOC	Using Random Sampling to Find Maximum Flows in Uncapacitated Undirected Graphs.	David R. Karger	1997	Using Random Sampling to Find Maximum Flows in Uncapacitated Undirected Graphs.
STOC	Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web.	David R. Karger,Eric Lehman,Frank Thomson Leighton,Rina Panigrahy,Matthew S. Levine,Daniel Lewin	1997	Consistent Hashing and Random Trees: Distributed Caching Protocols for Relieving Hot Spots on the World Wide Web.
STOC	A Complete Classification of the Approximability of Maximization Problems Derived from Boolean Constraint Satisfaction.	Sanjeev Khanna,Madhu Sudan,David P. Williamson	1997	A Complete Classification of the Approximability of Maximization Problems Derived from Boolean Constraint Satisfaction.
STOC	Probabilistically Checkable Proofs with Zero Knowledge.	Joe Kilian,Erez Petrank,Gábor Tardos	1997	"We construct PCPs with strong zero-knowledge properties. First, we construct polynomially bounded (in size) PCP''s for {\sf NP} which can be checked using poly-logarithmic queries, with polynomially low error, yet are statistical zero-knowledge against an adversary that makes $U$ arbitrary queries, where $U$ can be set to any polynomial. Second, we construct PCPs for {\sf{NEXPTIME}} that can be checked using polynomially many queries, yet are statistically zero-knowledge against any polynomially bounded adversary. These PCPs are exponential in size and have exponentially low error. Previously, it was only known how to construct zero-knowledge PCPs with a constant error probability. \par In the course of constructing these PCP''s we abstract a tool we call {\em locking systems}. We provide the definition and also a locking system with very efficient parameters. This mechanism may be useful in other settings as well."
STOC	Two Algorithms for Nearest-Neighbor Search in High Dimensions.	Jon M. Kleinberg	1997	Two Algorithms for Nearest-Neighbor Search in High Dimensions.
STOC	Allocating Bandwidth for Bursty Connections.	Jon M. Kleinberg,Yuval Rabani,Éva Tardos	1997	"In this paper, we undertake the first study of statistical multiplexing from the perspective of approximation algorithms. The basic issue underlying statistical multiplexing is the following: in high-speed networks, individual connections (i.e., communication sessions) are very bursty, with transmission rates that vary greatly over time. As such, the problem of packing multiple connections together on a link becomes more subtle than in the case when each connection is assumed to have a fixed demand.We consider one of the most commonly studied models in this domain: that of two communicating nodes connected by a set of parallel edges, where the rate of each connection between them is a random variable. We consider three related problems: (1) stochastic load balancing, (2) stochastic bin-packing, and (3) stochastic knapsack. In the first problem the number of links is given and we want to minimize the expected value of the maximum load. In the other two problems the link capacity and an allowed overflow probability p are given, and the objective is to assign connections to links, so that the probability that the load of a link exceeds the link capacity is at most $p$. In bin-packing we need to assign each connection to a link using as few links as possible. In the knapsack problem each connection has a value, and we have only one link. The problem is to accept as many connections as possible.For the stochastic load balancing problem we give an O(1)-approximation algorithm for arbitrary random variables. For the other two problems we have algorithms restricted to on-off sources (the most common special case studied in the statistical multiplexing literature), with a somewhat weaker range of performance guarantees.A standard approach that has emerged for dealing with probabilistic resource requirements is the notion of effective bandwidth---this is a means of associating a fixed demand with a bursty connection that ""represents"" its distribution as closely as possible. Our approximation algorithms make use of the standard definition of effective bandwidth and also a new one that we introduce; the performance guarantees are based on new results showing that a combination of these measures can be used to provide bounds on the optimal solution."
STOC	Spectral Techniques for Expander Codes.	John D. Lafferty,Daniel N. Rockmore	1997	Spectral Techniques for Expander Codes.
STOC	Approximating Total Flow Time on Parallel Machines.	Stefano Leonardi,Danny Raz	1997	We consider the problem of optimizing the total flow time of a stream of jobs that are released over time in a multiprocessor setting. This problem is NP-hard even when there are only two machines and preemption is allowed. Although the total (or average) flow time is widely accepted as a good measurement of the overall quality of service, no approximation algorithms were known for this basic scheduling problem. This paper contains two main results. We first prove that when preemption is allowed, Shortest Remaining Processing Time (SRPT) is an O(log(min{nm,P})) approximation algorithm for the total flow time, where n is the number of jobs, m is the number of machines, and P is the ratio between the maximum and the minimum processing time of a job. We also provide an @W(log(nm+P)) lower bound on the (worst case) competitive ratio of any randomized algorithm for the on-line problem in which jobs are known at their release times. Thus, we show that up to a constant factor SRPT is an optimal on-line algorithm. Our second main result addresses the non-preemptive case. We present a general technique that allows to transform any preemptive solution into a non-preemptive solution at the expense of an O(nm) factor in the approximation ratio of the total flow time. Combining this technique with our previous result yields an O(nmlognm) approximation algorithm for this case. We also show an @W(n^1^3^-^@e) lower bound on the approximability of this problem (assuming P
STOC	Practical Loss-Resilient Codes.	Michael Luby,Michael Mitzenmacher,Mohammad Amin Shokrollahi,Daniel A. Spielman,Volker Stemann	1997	Practical Loss-Resilient Codes.
STOC	Approximately Counting Up To Four (Extended Abstract).	Michael Luby,Eric Vigoda	1997	Approximately Counting Up To Four (Extended Abstract).
STOC	On ACC[] Frege Proofs.	Alexis Maciel,Toniann Pitassi	1997	On ACC[] Frege Proofs.
STOC	Improved Routing and Sorting on Multibutterflies.	Bruce M. Maggs,Berthold Vöcking	1997	Improved Routing and Sorting on Multibutterflies.
STOC	Byzantine Quorum Systems.	Dahlia Malkhi,Michael K. Reiter	1997	Quorum systems are well-known tools for ensuring the consistency and availability of replicated data despite the benign failure of data repositories. In this paper we consider the arbitrary (Byzantine) failure of data repositories and present the first study of quorum system requirements and constructions that ensure data availability and consistency despite these failures. We also consider the load associated with our quorum systems, i.e., the minimal access probability of the busiest server. For services subject to arbitrary failures, we demonstrate quorum systems over <i>n</i> servers with a load of <i>O</i>(1/√<i>n</i>), thus meeting the lower bound on load for benignly fault-tolerant quorum systems. We explore several variations of our quorum systems and extend our constructions to cope with arbitrary client failures.
STOC	Permanents, Pfaffian Orientations, and Even Directed Circuits (Extended Abstract).	William McCuaig,Neil Robertson,Paul D. Seymour,Robin Thomas	1997	Permanents, Pfaffian Orientations, and Even Directed Circuits (Extended Abstract).
STOC	Faster Solution of the Key Equation for Decoding BCH Error-Correcting Codes.	Victor Y. Pan	1997	Faster Solution of the Key Equation for Decoding BCH Error-Correcting Codes.
STOC	Oblivious Data Structures: Applications to Cryptography.	Daniele Micciancio	1997	Oblivious Data Structures: Applications to Cryptography.
STOC	Is There an Algebraic Proof for ? (Extended Abstract).	Ketan Mulmuley	1997	Is There an Algebraic Proof for ? (Extended Abstract).
STOC	On the Construction of Pseudo-Random Permutations: Luby-Rackoff Revisited (Extended Abstract).	Moni Naor,Omer Reingold	1997	On the Construction of Pseudo-Random Permutations: Luby-Rackoff Revisited (Extended Abstract).
STOC	Pointer Jumping Requires Concurrent Read.	Noam Nisan,Ziv Bar-Yossef	1997	Pointer Jumping Requires Concurrent Read.
STOC	Universal (Congestion + Dilation + log) Local Control Packet Switching Algorithms.	Rafail Ostrovsky,Yuval Rabani	1997	Universal (Congestion + Dilation + log) Local Control Packet Switching Algorithms.
STOC	Private Information Storage (Extended Abstract).	Rafail Ostrovsky,Victor Shoup	1997	Private Information Storage (Extended Abstract).
STOC	Direct Product Results and the GCD Problem, in Old and New Communication Models.	Itzhak Parnafes,Ran Raz,Avi Wigderson	1997	Direct Product Results and the GCD Problem, in Old and New Communication Models.
STOC	Exponential Lower Bounds for Depth 3 Boolean Circuits.	Ramamohan Paturi,Michael E. Saks,Francis Zane	1997	Exponential Lower Bounds for Depth 3 Boolean Circuits.
STOC	Optimal Time-Critical Scheduling via Resource Augmentation (Extended Abstract).	Cynthia A. Phillips,Clifford Stein,Eric Torng,Joel Wein	1997	Optimal Time-Critical Scheduling via Resource Augmentation (Extended Abstract).
STOC	A Sub-Constant Error-Probability Low-Degree Test, and a Sub-Constant Error-Probability PCP Characterization of NP.	Ran Raz,Shmuel Safra	1997	A Sub-Constant Error-Probability Low-Degree Test, and a Sub-Constant Error-Probability PCP Characterization of NP.
STOC	Read-Once Branching Programs, Rectangular Proofs of the Pigeonhole Principle and the Transversal Calculus.	Alexander A. Razborov,Avi Wigderson,Andrew Chi-Chih Yao	1997	"We investigate read-once branching programs for the following search problem: given a Boolean m &#x00d7; n matrix with m > n, &#xfb01;nd either an all-zero row, or two 1&#x2019;s in some column. Our primary motivation is that this models regular resolution proofs of the pigeonhole principle $$PHP^{m}_{n}$$, and that for m > n2 no lower bounds are known for the length of such proofs. We prove exponential lower bounds (for arbitrarily large m!) if we further restrict this model by requiring the branching program either to finish one row of queries before asking queries about another row (the row model) or put the dual column restriction (the column model).Then we investigate a special class of resolution proofs for $$PHP^{m}_{n}$$ that operate with positive clauses of rectangular shape; we call this fragment the rectangular calculus. We show that all known upper bounds on the size of resolution proofs of $$PHP^{m}_{n}$$ actually give rise to proofs in this calculus and, inspired by this fact, also give a remarkably simple &#x201c;rectangular&#x201d; reformulation of the Haken&#x2013;Buss&#x2013;Tur&#x00e1;n lower bound for the case m &#x226a; n2. Finally we show that the rectangular calculus is equivalent to the column model on the one hand, and to transversal calculus on the other hand, where the latter is a natural proof system for estimating from below the transversal size of set families. In particular, our exponential lower bound for the column model translates both to the rectangular and transversal calculi."
STOC	Approximate Complex Polynomial Evaluation in Near Constant Work Per Point.	John H. Reif	1997	"Given the n complex coefficients of a degree n-1 complex polynomial, we wish to evaluate the polynomial at a large number $m \ge n$ of points on the complex plane. This problem is required by many algebraic computations and so is considered in most basic algorithm texts (e.g., [A. V. Aho, J. E. Hopcroft, and J. D. Ullman, The Design and Analysis of Computer Algorithms, Addison-Wesley, 1974]). We assume an arithmetic model of computation, where on each step we can execute an arithmetic operation, which is computed exactly. All previous exact algorithms [C. M. Fiduccia, Proceeding} 4th Annual ACM Symposium on Theory of Computing, 1972, pp. 88--93; H. T. Kung, Fast Evaluation and Interpolation, Carnegie-Mellon, 1973; A. B. Borodin and I. Munro, The Computational Complexity of Algebraic and Numerical Problems, American Elsevier, 1975; V. Pan, A. Sadikou, E. Landowne, and O. Tiga, Comput. Math. Appl., 25 (1993), pp. 25--30] cost at least work $\Omega(\log^2 n)$ per point, and previously, there were no known approximation algorithms for complex polynomial evaluation within the unit circle with work bounds better than the fastest known exact algorithms. There are known approximation algorithms [V. Rokhlin, J. Complexity, 4 (1988), pp. 12--32; V. Y. Pan, J. H. Reif, and S. R. Tate, in Proceedings 32nd Annual IEEE Symposium on Foundations of Computer Science, 1992, pp. 703--713] for polynomial evaluation at real points, but these do not extend to evaluation at general points on the complex plane.We provide approximation algorithms for complex polynomial evaluation that cost, in many cases, near constant amortized work per point. Let $k = \log(|P|/\epsilon)$, where |P| is the sum of the moduli of the coefficients of the input polynomial P(z). Let {\it ${\tilde{P}}(z_j)$ be an $\epsilon$-approx of $P(z)$} if $\epsilon$ upper bounds the modulus of the error of the approximation ${\tilde{P}}(z_j)$ at each evaluation point zj, that is, $|P(z_j)-{\tilde{P}}(z_j)| \le \epsilon;$ note that $\epsilon$ is an absolute error bound rather than a relative error bound. In many applications (particularly in signal processing) the evaluation points zj are fixed and require only polylogarithmic $k = \log(|P|/\epsilon) = O(\log^{O(1)} n)$; for these cases we get a surprising reduction in work by use of approximation algorithms, as compared to the fastest known exact algorithms. We $\epsilon$-approx complex degree n-1 polynomial evaluation at $m \ge n\log n/\log^2 k $ fixed points on or within the unit disk in the complex plane in amortized work O(log2 k) per point, which is O(log2 log n) for polylogarithmic k. If the m points are not fixed, then we have increased amortized work O(log2 k + log m) per point, which is O(log m) for polylogarithmic k and $m \ge n\log n/\log k,$ and is still substantially below the previous bound of $\Omega(\log^2 m)$ for known exact algorithms. We further reduce our amortized bounds for special sets of evaluation points widely used in signal processing applications. The chirp transform is equivalent to evaluating a complex degree n-1 polynomial at the chirp points, which are $\zeta^j, j = 0,\dots,m-1$, for some fixed complex number $\zeta.$ We $\epsilon$-approx complex degree $n-1$ polynomial evaluation at these $m$ chirp points, where $m \ge n \log n/\log^2 k$ and $|\zeta| \le 1$ % or (ii) $m \ge n$ and $|\zeta| \le $ a function that limits to $1$ %for %$k = o(n)$ and large $n$) in amortized work O(log k) per point, whereas the previous best bounds for exact evaluation (via the chirp transform) were $\Omega(\log m)$ per point [A. V. Aho, K. Steiglitz, and J. D. Ullman, SIAM J. Comput., 4 (1975), pp. 533--539]. Using instead a reduction to approximate real polynomial evaluation (by interpolation at the Chebyshev points), in total work O(n log k), we $\epsilon$-approx the evaluation of a degree n polynomial at the first n powers of the n'th root of unity, where $n' \ge \Omega(n^2/k), $ and $\epsilon$-approx the n-point DFT for certain inputs with descending coefficient magnitude. All of our results require polylogarithmic (that is, logO(1)n)depth with the same work bounds.We also provide a lower bound for a wide class of schemes for approximate evaluation of a degree n-1 polynomial on the unit circle; namely, we prove that if a scheme uses an approximation polynomial of degree k-1, then it can be convergent only over a small fraction O(k/n) of the unit circle. We believe this is the first lower bound of this sort proved, and the proof uses an interesting reduction to the approximation of a matrix product by a matrix of reduced rank."
STOC	A Constant-Factor Approximation Algorithm for Packet Routing, and Balancing Local vs. Global Criteria.	Aravind Srinivasan,Chung-Piaw Teo	1997	We present the first constant-factor approximation algorithm for a fundamental problem: the store-and-forward packet routing problem on arbitrary networks. Furthermore, the queue sizes required at the edges are bounded by an absolute constant. Thus, this algorithm balances a global criterion (routing time) with a local criterion (maximum queue size) and shows how to get simultaneous good bounds for both. For this particular problem, approximating the routing time well, even without considering the queue sizes, was open. We then consider a class of such local vs. global problems in the context of covering integer programs and show how to improve the local criterion by a logarithmic factor by losing a constant factor in the global criterion.
STOC	Approximation Algorithms for Facility Location Problems (Extended Abstract).	David B. Shmoys,Éva Tardos,Karen Aardal	1997	Approximation Algorithms for Facility Location Problems (Extended Abstract).
STOC	When Hamming Meets Euclid: The Approximability of Geometric TSP and MST (Extended Abstract).	Luca Trevisan	1997	When Hamming Meets Euclid: The Approximability of Geometric TSP and MST (Extended Abstract).
STOC	Algorithmic Complexity in Coding Theory and the Minimum Distance Problem.	Alexander Vardy	1997	Algorithmic Complexity in Coding Theory and the Minimum Distance Problem.
STOC	Proceedings of the Twenty-Ninth Annual ACM Symposium on the Theory of Computing, El Paso, Texas, USA, May 4-6, 1997	Frank Thomson Leighton,Peter W. Shor	1997	Proceedings of the Twenty-Ninth Annual ACM Symposium on the Theory of Computing, El Paso, Texas, USA, May 4-6, 1997
FOCS	Quantum Oracle Interrogation: Getting All Information for Almost Half the Price.	Wim van Dam	1998	"Consider a quantum computer in combination with a binary oracle of domain size N. It is shown how N/2+sqrt(N) calls to the oracle are sufficient to guess the whole content of the oracle (being an N bit string) with probability greater than 95%. This contrasts the power of classical computers which would require N calls to achieve the same task. From this result it follows that any function with the N bits of the oracle as input can be calculated using N/2+sqrt(N) queries if we allow a small probability of error. It is also shown that this error probability can be made arbitrary small by using N/2+O(sqrt(N)) oracle queries. In the second part of the article `approximate interrogation' is considered. This is when only a certain fraction of the N oracle bits are requested. Also for this scenario does the quantum algorithm outperform the classical protocols. An example is given where a quantum procedure with N/10 queries returns a string of which 80% of the bits are correct. Any classical protocol would need 6N/10 queries to establish such a correctness ratio."
FOCS	Delayed Information and Action in On-line Algorithms.	Susanne Albers,Moses Charikar,Michael Mitzenmacher	1998	Most on-line analysis assumes that, at each time step, all relevant information up to that time step is available and a decision has an immediate effect. In many on-line problems, however, the time when relevant information is available and the time a decision has an effect may be decoupled. For example, when making an investment, one might not have completely up-to-date information on market prices. Similarly, a buy or sell order might only be executed some time in the future. We introduce and explore natural delayed models for several well-known on-line problems. Our analyses demonstrate the importance of considering timeliness in determining the competitive ratio of an on-line algorithm. For many problems, we demonstrate that there exist algorithms with small competitive ratios even when large delays affect the timeliness of information and the effect of decisions. Copyright 2001 Academic Press.
FOCS	Protocols for Asymmetric Communication Channels.	Micah Adler,Bruce M. Maggs	1998	In this paper we examine the problem of sending an $n$-bit data item from a client to a server across an asymmetric communication channel. We demonstrate that there are scenarios in which a high-speed link from the server to the client can be used to greatly reduce the number of bits sent from the client to the server across a slower link. In particular, we assume that the data item is drawn from a probability distribution $D$ that is known to the server but not to the client. We present several protocols in which the expected number of bits transmitted by the server and client are $O(n)$ and $O(H(D)+1)$, respectively, where $H(D)$ is the binary entropy of $D$ (and can range from $0$ to $n$). These protocols are within a small constant factor of optimal in terms of the number of bits sent by the client. The expected number of rounds of communication between the server and client in the simplest of our protocols is $O(H(D))$. We also give a protocol for which the expected number of rounds is only $O(1)$, but which requires more computational effort on the part of the server. A third technique provides a tradeoff between the computational effort and the number of rounds. These protocols are complemented by several lower bounds and impossibility results. We demonstrate that all of our protocols are existentially optimal in terms of the number of bits sent by the server, i.e., there are distributions for which the total number of bits exchanged has to be at least $n$. In addition, we show that there is no protocol that is optimal for every distribution (as opposed to just existentially optimal) in terms of bits sent by the server. We demonstrate this by proving that it is undecidable to compute (even approximately), for an arbitrary distribution $D$, how many expected bits must be exchanged by the server and client on the distribution $D$.
FOCS	Concurrent Reachability Games.	Luca de Alfaro,Thomas A. Henzinger,Orna Kupferman	1998	We consider concurrent two-player games with reachability objectives. In such games, at each round, player 1 and player 2 independently and simultaneously choose moves, and the two choices determine the next state of the game. The objective of player 1 is to reach a set of target states; the objective of player 2 is to prevent this. These are zero-sum games, and the reachability objective is one of the most basic objectives: determining the set of states from which player 1 can win the game is a fundamental problem in control theory and system verification. There are three types of winning states, according to the degree of certainty with which player 1 can reach the target. From type-1 states, player 1 has a deterministic strategy to always reach the target. From type-2 states, player 1 has a randomized strategy to reach the target with probability 1. From type-3 states, player 1 has for every real @e>0 a randomized strategy to reach the target with probability greater than 1-@e. We show that for finite state spaces, all three sets of winning states can be computed in polynomial time: type-1 states in linear time, and type-2 and type-3 states in quadratic time. The algorithms to compute the three sets of winning states also enable the construction of the winning and spoiling strategies.
FOCS	Parametric and Kinetic Minimum Spanning Trees.	Pankaj K. Agarwal,David Eppstein,Leonidas J. Guibas,Monika Rauch Henzinger	1998	We consider the parametric minimum spanning tree problem, in which we are given a graph with edge weights that are linear functions of a parameter $\lambda$ and wish to compute the sequence of minimum spanning trees generated as $\lambda$ varies. We also consider the kinetic minimum spanning tree problem, in which $\lambda$ represents time and the graph is subject in addition to changes such as edge insertions, deletions, and modifications of the weight functions as time progresses. We solve both problems in time $O(n^{2/3}\log^{4/3}n)$ per combinatorial change in the tree (or randomized $O(n^{2/3}\log n)$ per change). Our time bounds reduce to $O(n^{1/2}\log^{3/2} n)$ per change ($O(n^{1/2}\log n)$ randomized) for planar graphs or other minor-closed families of graphs, and $O(n^{1/4}\log^{3/2} n)$ per change ($O(n^{1/4}\log n)$ randomized) for planar graphs with weight changes but no insertions or deletions.
FOCS	Marked Ancestor Problems.	Stephen Alstrup,Thore Husfeldt,Theis Rauhe	1998	Consider a rooted tree whose nodes can be in two states: marked or unmarked. The marked ancestor problem is to maintain a data structure with the following operations: Mark(v) marks node v; unmark(v) removes any marks from node v; findfirst(v) returns the first marked node on the path from v to the root.We show tight upper and lower bounds for the marked ancestor problem. The lower bounds are proved in the cell probe model, the algorithms run on a unit-cost RAM.As easy corollaries we prove (often optimal) lower bounds on a number of problems. These include planar range searching, including the existential or emptiness problem, priority search trees, static tree union--find, and several problems from dynamic computational geometry, including segment intersection, interval maintenance, and ray shooting in the plane. Our upper bounds improve algorithms from various fields, including coloured ancestor problems and maintenance of balanced parentheses.
FOCS	1-Way Quantum Finite Automata: Strengths, Weaknesses and Generalizations.	Andris Ambainis,Rusins Freivalds	1998	We study 1-way quantum finite automata (QFAs).First, we compare them with their classical counterparts. We show that, if an automaton is required to give the correct answer with a large probability (greater than 7/9), then any 1-way QFAs can be simulated by a 1-way reversible automaton. However, quantum automata giving the correct answer with smaller probabilities are more powerful than reversible automata.Second, we show that 1-way QFAs can be very space-efficient. We construct a 1-way QFA that is exponentially smaller than any equivalent classical (even randomized) finite automaton. We think that this construction may be useful for design of other space-efficient quantum algorithms.Third, we consider several generalizations of 1-way QFAs. Here, our goal is to find a model which is more powerful than 1-way QFAs keeping the quantum part as simple as possible.
FOCS	The Quantum Communication Complexity of Sampling.	Andris Ambainis,Leonard J. Schulman,Amnon Ta-Shma,Umesh V. Vazirani,Avi Wigderson	1998	Sampling is an important primitive in probabilistic and quantum algorithms. In the spirit of communication complexity, given a function $f: X \times Y \rightarrow \{0,1\}$ and a probability distribution ${\cal D}$ over $X \times Y$, we define the sampling complexity of $(f, {\cal D})$ as the minimum number of bits that Alice and Bob must communicate for Alice to pick $x \in X$ and Bob to pick $y \in Y$ as well as a value $z$ such that the resulting distribution of $(x,y,z)$ is close to the distribution $({\cal D}, f({\cal D}))$.In this paper we initiate the study of sampling complexity, in both the classical and quantum models. We give several variants of a definition. We completely characterize some of these variants and give upper and lower bounds on others. In particular, this allows us to establish an exponential gap between quantum and classical sampling complexity for the set-disjointness function.
FOCS	The Access Network Design Problem.	Matthew Andrews,Lisa Zhang	1998	We consider the problem of designing a minimum cost access network to carry traffic from a set of endnodes to a core network. A set of trunks of $K$ differing types are available for leasing or buying. Some trunk-types have a high initial overhead cost but a low cost per unit bandwidth. Others have a low overhead cost but a high cost per unit bandwidth.When the central core is given, we show how to construct an access network whose cost is within $O(K^2)$ of optimal, under weak assumptions on the cost structure. In contrast with previous bounds, this bound is independent of the network and the traffic. Typically, the value of $K$ is small. Our approach uses a linear programming relaxation and is motivated by a rounding technique of Shmoys, Tardos and Aardal~\cite{ShmoysTA97}.Our techniques extend to a more complex situation in which the core is not given {\em a priori}. In this case we aim to minimize the switch cost of the core in addition to the trunk cost of the access network. We provide the same performance bound.
FOCS	On the Combinatorial and Topological Complexity of a Single Cell.	Saugata Basu	1998	On the Combinatorial and Topological Complexity of a Single Cell.
FOCS	Quantum Lower Bounds by Polynomials.	Robert Beals,Harry Buhrman,Richard Cleve,Michele Mosca,Ronald de Wolf	1998	We examine the number of queries to input variables that a quantum algorithm requires to compute Boolean functions on {0,1}N in the black-box model. We show that the exponential quantum speed-up obtained for partial functions (i.e., problems involving a promise on the input) by Deutsch and Jozsa, Simon, and Shor cannot be obtained for any total function: if a quantum algorithm computes some total Boolean function f with small error probability using T black-box queries, then there is a classical deterministic algorithm that computes f exactly with O(Ts6) queries. We also give asymptotically tight characterizations of T for all symmetric f in the exact, zero-error, and bounded-error settings. Finally, we give new precise bounds for AND, OR, and PARITY. Our results are a quantum extension of the so-called polynomial method, which has been successfully applied in classical complexity theory, and also a quantum extension of results by Nisan about a polynomial relationship between randomized and deterministic decision tree complexity.
FOCS	Time-Space Tradeoffs for Branching Programs.	Paul Beame,Michael E. Saks,Jayram S. Thathachar	1998	We obtain the first non-trivial time-space tradeoff lower bound for functions f:{0,1}^n ->{0,1} on general branching programs by exhibiting a Boolean function f that requires exponential size to be computed by any branching program of length (1+c)n, for some constant c>0. We also give the first separation result between the syntactic and semantic read-k models for k>1 by showing that polynomial-size semantic read-twice branching programs can compute functions that require exponential size on any syntactic read-k branching program. In addition we show a time-space tradeoff result on the more general R-way branching program model: for any k, we exhibit a function that requires exponential size to be computed by length kn q-way branching programs, for some q=q(k).
FOCS	Bivariate Polynomial Multiplication.	Markus Bläser	1998	"Inspired by the discussion in [A. Schoenhage, Bivariate polynomial multiplication patterns, LNCS 948, 70-81, Springer, 1995], we study the multiplicative complexity and the rank of the multiplication in the local algebras $R_{m,n} = k[x,y]/(x^{m+1},y^{n+1})$ and $T_n = k[x,y]/(x^{n+1}, x^n y,\dots,y^{n+1})$ of bivariate polynomials. We obtain the lower bounds $(2\frac 13 - o(1)) \dim R_{m,n}$ and $(2\frac 12 - o(1)) \dim T_n$ for the multiplicative complexity of the multiplication in $R_{m,n}$ and $T_n$, respectively. On the other hand, we derive the upper bounds $3 \dim T_n - 2n - 2$ and $3 \dim R_{m,n} - m - n - 3$ for the rank of the multiplication in $T_n$ and $R_{m,n}$, respectively, provided that the ground field $k$ admits ""fast"" univariate polynomial multiplication $\mod x^N - 1$. Our results are also applicable to arbitrary finite dimensional algebras of truncated bivariate polynomials $k[x,y]/I$, where the ideal $I = (x^{d_0+1},x^{d_1+1}y,\dots,x^{d_n+1}y^n,y^{n+1})$ is described by a degree pattern $d_0 \ge d_1 \ge \dots \ge d_n \ge 0$."
FOCS	On Learning Monotone Boolean Functions.	Avrim Blum,Carl Burch,John Langford	1998	On Learning Monotone Boolean Functions.
FOCS	Exponential Separations between Restricted Resolution and Cutting Planes Proof Systems.	Maria Luisa Bonet,Juan Luis Esteban,Nicola Galesi,Jan Johannsen	1998	We prove an exponential lower bound for tree-like Cutting Planes refutations of a set of clauses which has polynomial size resolution refutations. This implies an exponential separation between tree-like and dag-like proofs for both Cutting Planes and resolution; in both cases only superpolynomial separations were known before. In order to prove this, we extend the lower bounds on the depth of monotone circuits of Raz and McKenzie (FOCS 1997) to monotone real circuits.In the case of resolution, we further improve this result by giving an exponential separation of tree-like resolution from (dag-like) regular resolution proofs. In fact, the refutation provided to give the upper bound respects the stronger restriction of being a Davis-Putnam resolution proof. This extends the corresponding superpolynomial separation of Urquhart (Bull. Symb. Logic 1, 1995).Finally, we prove an exponential separation between Davis-Putnam resolution and unrestricted resolution proofs; only a superpolynomial separation was previously known from Goerdt (Ann. Math. Artificial Intelligence 6, 1992).
FOCS	A Primitive Recursive Algorithm for the General Petri Net Reachability Problem.	Zakaria Bouziane	1998	A Primitive Recursive Algorithm for the General Petri Net Reachability Problem.
FOCS	"Approximation of Diameters: Randomization Doesn't Help."	Andreas Brieden,Peter Gritzmann,Ravi Kannan,Victor Klee,László Lovász,Miklós Simonovits	1998	"Approximation of Diameters: Randomization Doesn't Help."
FOCS	Information Retrieval on the Web.	Andrei Z. Broder,Monika Rauch Henzinger	1998	The Web explosion offers a bonanza of algorithmic problems. In particular, information retrieval in the web context requires methods and ideas that have not been addressed in the classic IR literature. This tutorial will survey emerging techniques for IR in the web context and discuss some of the pertinent open problems.The list of topics includes search engine technology, ranking and classification methods, web measurements (usage, size, connectivity), and new graph and data structure problems arising in the web IR context.
FOCS	Oblivious Transfer with a Memory-Bounded Receiver.	Christian Cachin,Claude Crépeau,Julien Marcil	1998	"We propose a protocol for oblivious transfer that is unconditionally secure under the sole assumption that the memory size of the receiver is bounded. The model assumes that a random bit string slightly larger than the receiver's memory is broadcast (either by the sender or by a third party). In our construction, both parties need memory of size in $\theta(n^{2-2\alpha})$ for some $\alpha\beta>0$, whereas a malicious receiver can have up to $\gamma N$ bits of memory for any $\gamma"
FOCS	A TDI System and its Application to Approximation Algorithms.	Mao-cheng Cai,Xiaotie Deng,Wenan Zang	1998	We obtain a necessary and sufficient condition for tournaments to possess a min-max relation on packing and covering directed cycles, together with strongly polynomial time algorithms for the feedback vertex set problem and the cycle packing problem in this class of tournaments; the condition and the algorithms are all based on a totally dual integral (TDI) system, a theoretical framework introduced by Edmonds and Giles for establishing min-max results. As a consequence, we find a $2.5$-approximation polynomial time algorithm for the feedback vertex set problem in any tournament.
FOCS	Pattern Matching for Spatial Point Sets.	David E. Cardoze,Leonard J. Schulman	1998	Two sets of points in $d$-dimensional space are given: a {\it data set\/} $D$ consisting of $N$ points, and a {\it pattern set\/} or {\it probe\/} $P$ consisting of $k$ points. We address the problem of determining whether there is a transformation, among a specified group of transformations of the space, carrying $P$ into or near (meaning at a small directed Hausdorff distance of) $D$. The groups we consider are translations and rigid motions. Runtimes of approximately $O(n \log n)$ and $O(n^d \log n)$ respectively are obtained (letting $n=\max\{N,k\}$ and omitting the effects of several secondary parameters). For translations, a runtime of approximately $O(n(ak+1)\log^2 n)$ is obtained for the case that a constant fraction $a
FOCS	Towards an Optimal Bit-Reversal Permutation Program.	Larry Carter,Kang Su Gatlin	1998	"The speed of many computations is limited not by the number of arithmetic operations but by the time it takes to move and rearrange data in the increasingly complicated memory hierarchies of modern computers. Array transpose and the bit-reversal permutation -- trivial operations on a RAM -- present non-trivial problems when designing highly-tuned scientific library functions, particular for the Fast Fourier Transform. We prove a precise bound for RoCol, a simple pebble-type game that is relevant to implementing these permutations. We use RoCol to give lower bounds on the amount of memory traffic in a computer with four-levels of memory (registers, cache, TLB, and memory), taking into account such ``messy'' features as block moves and set-associative caches. The insights from this analysis lead to a bit-reversal algorithm whose performance is close to the theoretical minimum. Experiments show it performs significantly better than every program in a comprehensive study of 30 published algorithms."
FOCS	Sampling, Halfspace Range Reporting, and Construction of (<= k)-Levels in Three Dimensions.	Timothy M. Chan	1998	Sampling, Halfspace Range Reporting, and Construction of (<= k)-Levels in Three Dimensions.
FOCS	Approximating a Finite Metric by a Small Number of Tree Metrics.	Moses Charikar,Chandra Chekuri,Ashish Goel,Sudipto Guha,Serge A. Plotkin	1998	"Bartal gave a randomized polynomial time algorithm that given any n point metric G, constructs a tree T such that the expected stretch (distortion) of any edge is at most O(log n log log n). His result has found several applications and in particular has resulted in approximation algorithms for many graph optimization problems. However approximation algorithms based on his result are inherently randomized. In this paper we derandomize the use of Bartal's algorithm in the design of approximation algorithms.We give an efficient polynomial time algorithm that given a finite n point metric G, constructs O(n log n) trees and a probability distribution \mu on them such that the expected stretch of any edge of G in a tree chosen according to \mu is at most O(log n log log n). Our result establishes that finite metrics can be probabilistically approximated by a small number of tree metrics. We obtain the first deterministic approximation algorithms for buy-at-bulk network design and vehicle routing; in addition we subsume results from our earlier work on derandomization. Our main result is obtained by a novel view of probabilistic approximation of metric spaces as a deterministic optimization problem via linear programming. This view also provides a new proof of Bartal's result that might be easier to generalize.We also show that graphs induced by points in \Re^d_p (d-dimensional real normed space equipped with the l_p norm) can be O(f(d,p) log n)- -probabilistically approximated by tree metrics where f(d,p) = d^{1/p} for 1"
FOCS	The Finite Capacity Dial-A-Ride Problem.	Moses Charikar,Balaji Raghavachari	1998	"We give the first non-trivial approximation algorithm for the Capacitated Dial-a-Ride problem: given a collection of objects located at points in a metric space, a specified destination point for each object, and a vehicle with a capacity of at most k objects, the goal is to compute a shortest tour for the vehicle in which all objects can be delivered to their destinations while ensuring that the vehicle carries at most k objects at any point in time. The problem is known under several names, including the Stacker Crane problem and the Dial-a-Ride problem. No theoretical approximation guarantees were known for this problem other than for the cases k=1,\infty and the trivial O(k) approximation for general capacity k. We give an algorithm with approximation ratio O(sqrt{k}) for special instances on a class of tree metrics called height-balanced trees. Using Bartal's recent results on the probabilistic approximation of metric spaces by tree metrics, we obtain an approximation ratio of O(sqrt{k} log n log log n)$ for arbitrary n point metric spaces. When the points lie on a line (line metric), we provide a 2-approximation algorithm.We also consider the Dial-a-Ride problem in another framework: when the vehicle is allowed to leave objects at intermediate locations and pick them up at a later time and deliver them. For this model, we design an approximation algorithm whose performance ratio is O(1) for tree metrics and O(log n log log n) for arbitrary metrics.We also study the ratio between the values of the optimal solutions for the two versions of the problem. We show that unlike in k-delivery TSP in which all the objects are identical, this ratio is not bounded by a constant for the Dial-a-Ride problem, and it could be as large as \Omega(k^{2/3})."
FOCS	Evolutionary Trees can be Learned in Polynomial Time in the Two-State General Markov Model.	Mary Cryan,Leslie Ann Goldberg,Paul W. Goldberg	1998	"The j-State General Markov Model of evolution (due to Steel) is a stochastic model concerned with the evolution of strings over an alphabet of size j. In particular, the Two-State General Markov Model of evolution generalises the well-known Cavender-Farris-Neyman model of evolution by removing the symmetry restriction (which requires that the probability that a `0'' turns into a `1'' along an edge is the same as the probability that a `1'' turns into a `0'' along the edge). Farach and Kannan showed how to PAC-learn Markov Evolutionary Trees in the Cavender-Farris-Neyman model provided that the target tree satisfies the additional restriction that all pairs of leaves have a sufficiently high probability of being the same. We show how to remove both restrictions and thereby obtain the first polynomial-time PAC-learning algorithm (in the sense of Kearns et al.) for the general class of Two-State Markov Evolutionary Trees."
FOCS	On the Single-Source Unsplittable Flow Problem.	Yefim Dinitz,Naveen Garg,Michel X. Goemans	1998	Let $G=(V,E)$ be a capacitated directed graph with a source $s$ and $k$ terminals $t_i$ with demands $d_i$, $1\le i\le k$. We would like to concurrently route every demand on a single path from $s$ to the corresponding terminal without violating the capacities. There are several interesting and important variations of this unsplittable flow problem.If the necessary cut condition is satisfied, we show how to compute an unsplittable flow satisfying the demands such that the total flow through any edge exceeds its capacity by at most the maximum demand. For graphs in which all capacities are at least the maximum demand, we therefore obtain an unsplittable flow with congestion at most 2, and this result is best possible. Furthermore, we show that all demands can be routed unsplittably in 5 rounds, i.e., all demands can be collectively satisfied by the union of 5 unsplittable flows. Finally, we show that 22.6\% of the total demand can be satisfied unsplittably.These results are extended to the case when the cut condition is not necessarily satisfied. We derive a 2-approximation algorithm for congestion, a 5-approximation algorithm for the number of rounds and a $4.43=1/0.226$-approximation algorithm for the maximum routable demand.
FOCS	Approximating-CVP to Within Almost-Polynomial Factors is NP-Hard.	Irit Dinur,Guy Kindler,Shmuel Safra	1998	This paper shows the closest vector in a lattice to be NP-hard to approximate to within any factor up to $2^{(\log{n})^{1-\epsilon}}$ where $\epsilon = (\log\log{n})^{-c} $ for any constant $c
FOCS	Overcoming the Memory Bottleneck in Suffix Tree Construction.	Martin Farach,Paolo Ferragina,S. Muthukrishnan	1998	The suffix tree of a string is the fundamental data structure of string processing. Recent focus on massive data sets has sparked interest in overcoming the memory bottlenecks of known algorithms for building and using suffix trees.Our main contribution is a new algorithm for suffix tree construction in which we choreograph almost all disk accesses to be via the sort and scan primitives. This algorithm achieves optimal results in a variety of sequential and parallel computational models. Two of our results are:1) In the traditional external memory model, in which only the number of disk accesses is counted, we achieve an optimal algorithm, both for single and multiple disk cases. This is the first optimal algorithm known for either model. 2) Traditional disk page access counting does not differentiate between random page accesses and block transfers involving several consecutive pages. This difference is routinely exploited by expert programmers to get fast algorithms on real machines. We adopt a simplweb accounting scheme and show that our algorithm achieves the same optimal tradeoff for block versus random page accesses as the one we establish for sorting.
FOCS	Heuristics for Finding Large Independent Sets, with Applications to Coloring Semi-Random Graphs.	Uriel Feige,Joe Kilian	1998	We study a semi-random graph model for finding independent sets. For q>0, an n-vertex graph with an independent set S of size qn is constructed by blending random and adversarial decisions. Randomly and independently with probability p, each pair of vertices, such that one is in S and the other is not, is connected by an edge. An adversary can then add edges arbitrarily (provided that S remains an independent set). The smaller p is, the larger the control the adversary has over the semi-random graph. We design heuristics that with high probability recover S when p>(1+e)ln(n)/|S|, for any constant e>0. We show that when p
FOCS	Fast Monte-Carlo Algorithms for Finding Low-Rank Approximations.	Alan M. Frieze,Ravi Kannan,Santosh Vempala	1998	"We consider the problem of approximating a given m &times; n matrix A by another matrix of specified rank k, which is smaller than m and n. The Singular Value Decomposition (SVD) can be used to find the ""best"" such approximation. However, it takes time polynomial in m, n which is prohibitive for some modern applications. In this article, we develop an algorithm that is qualitatively faster, provided we may sample the entries of the matrix in accordance with a natural probability distribution. In many applications, such sampling can be done efficiently. Our main result is a randomized algorithm to find the description of a matrix D* of rank at most k so that holds with probability at least 1 &minus; &delta; (where &verbar;&middot;&verbar;F is the Frobenius norm). The algorithm takes time polynomial in k,1/&epsi;, log(1/&delta;) only and is independent of m and n. In particular, this implies that in constant time, it can be determined if a given matrix of arbitrary size has a good low-rank approximation."
FOCS	Stability of Adversarial Queues via Fluid Models.	David Gamarnik	1998	The subject of this paper is stability properties of adversarial queueing networks. Such queueing systems are used to model packet switch communication networks, in which packets are generated and routed dynamically, and have become a subject of research focus recently. Adversarial queueing networks are defined to be stable, if the number of packets stays bounded over time. A central question is determining which adversarial queueing networks are stable, when an arbitrary greedy packet routing policy is implemented. In this paper we show how stability of a queueing network can be determined by considering an associated fluid models. Our main result is that the stability of the fluid model implies the stability of an underlying adversarial queueing network. This opens an opportunity for analyzing stability of adversarial networks, using established stability methods from continuous time processes, for example, the method of Lyapunov function or trajectory decomposition. We demonstrate the use of these methods on several examples.
FOCS	Faster and Simpler Algorithms for Multicommodity Flow and Other Fractional Packing Problems.	Naveen Garg,Jochen Könemann	1998	This paper considers the problem of designing fast, approximate, combinatorial algorithms for multicommodity flows and other fractional packing problems. We present new, faster, and much simpler algorithms for these problems.
FOCS	Testing Monotonicity.	Oded Goldreich,Shafi Goldwasser,Eric Lehman,Dana Ron	1998	We present a (randomized) test for monotonicity of Boolean functions. Namely, given the ability to query an unknown function f : {0,1}^n -> {0,1} at arguments of its choice, the test always accepts a monotone f, and rejects f with high probability if it is epsilon-far from being monotone (i.e., every monotone function differs from f on more than an epsilon fraction of the domain). The complexity of the test is poly(n/epsilon).The analysis of our algorithm relates two natural combinatorial quantities that can be measured with respect to a Boolean function; one being global to the function and the other being local to it.We also consider the problem of testing monotonicity based only on random examples labeled by the function. We show an Omega(\sqrt{2^n/epsilon}) lower bound on the number of required examples, and provide a matching upper bound (via an algorithm).
FOCS	A Tight Characterization of NP with 3 Query PCPs.	Venkatesan Guruswami,Daniel Lewin,Madhu Sudan,Luca Trevisan	1998	"It is known that there exists a PCP characterization of NP where the verifier makes 3 queries and has a one-sided error that is bounded away from 1; and also that 2 queries do not suffice for such a characterization. Thus PCPs with 3 queries possess non-trivial verification power and motivate the task of determining the lowest error that can be achieved with a 3-query PCP. Recently, Hastad [STOC '97] has shown a tight characterization of NP by constructing a 3-query PCP verifier with ``error'' arbitrarily close to 1/2. Unfortunately, this verifier makes two-sided error and Hastad makes essential use of this feature. One-sided error, on the other hand, is a natural notion to associate with a proof system, since it has the desirable property that every rejected proof has a short counterexample. The question of determining the smallest error for which there exists a 3-query PCP verifier making one-sided error and accepting an NP-complete language, however, remained open.We resolve this question by showing that NP has a 3-query PCP with a one-sided error that is arbitrarily close to 1/2. This characterization is tight, i.e., the error cannot be lower. This result is in seeming contradiction with the results of Trevisan [ESA'97] and Zwick [SODA '98] who show that in order to recognize an NP-complete language, the error probability of a PCP verifier making 3 ""non-adaptive"" queries and having one-sided error must be at least 5/8. We get around this bottleneck by designing an ""adaptive"" 3-query PCP for NP. Our result yields the first tight analysis of an adaptive PCP; and reveals a previously unsuspected separation between the powers of adaptive and non-adaptive PCPs.Our design and analysis of adaptive PCPs can be extended to higher number of queries as well and we give an example of such a proof system with 5 queries. Our adaptive verifiers yield proof systems whose error probabilities match those of previous constructions, while also achieving one-sidedness in the error. This raises new questions about the power of adaptive PCPs, which deserve further study."
FOCS	The Complexity of Acyclic Conjunctive Queries.	Georg Gottlob,Nicola Leone,Francesco Scarcello	1998	This paper deals with the evaluation of acyclic Boolean conjunctive queries in relational databases. By well-known results of Yannakakis[1981], this problem is solvable in polynomial time; its precise complexity, however, has not been pinpointed so far. We show that the problem of evaluating acyclic Boolean conjunctive queries is complete for LOGCFL, the class of decision problems that are logspace-reducible to a context-free language. Since LOGCFL is contained in AC1 and NC2, the evaluation problem of acyclic Boolean conjunctive queries is highly parallelizable. We present a parallel database algorithm solving this problem with alogarithmic number of parallel join operations. The algorithm is generalized to computing the output of relevant classes of non-Boolean queries. We also show that the acyclic versions of the following well-known database and AI problems are all LOGCFL-complete: The Query Output Tuple problem for conjunctive queries, Conjunctive Query Containment, Clause Subsumption, and Constraint Satisfaction. The LOGCFL-completeness result is extended to the class of queries of bounded tree width and to other relevant query classes which are more general than the acyclic queries.
FOCS	"Tseitin's Tautologies and Lower Bounds for Nullstellensatz Proofs."	Dima Grigoriev	1998	"We use the known linear lower bound for Tseitin's tautologies for establishing linear lower bounds on the degree of Nullstellensatz proofs (in the usual boolean setting) for explicitly constructed systems of polynomials of a constant (in our construction 6) degree. It holds over any field of characteristic distinct from 2. Previously, a linear lower bound was proved for an explicitly constructed system of polynomials of a logarithmic degree"
FOCS	Exponential Complexity Lower Bounds for Depth 3 Arithmetic Circuits in Algebras of Functions Over Finite Fields.	Dima Grigoriev,Alexander A. Razborov	1998	A depth 3 arithmetic circuit can be viewed as a sum of products of linear functions. We prove an exponential complexity lower bound on depth 3 arithmetic circuits computing some natural symmetric functions over a finite field $F$. Also, we study the complexity of the functions $f : D^n \to F$ for subsets $D \subset F$. In particular, we prove an exponential lower bound on the complexity of a depth 3 arithmetic circuit which computes the determinant or the permanent of a matrix considered as functions $f : (F^*)^{n^2} \to F$
FOCS	Lower Bounds for (MOD p - MOD m) Circuits.	Vince Grolmusz,Gábor Tardos	1998	Modular gates are known to be immune for the random restriction techniques of Ajtai, Furst, Saxe, Sipser, Yao and Hastad. We demonstrate here a random clustering technique which overcomes this difficulty and is capable to prove generalizations of several known modular circuit lower bounds of Barrington, Straubing, Therien; Krause and Pudlak; and others, characterizing symmetric functions computable by small (MOD p, AND, MOD m) circuits. Applying a degree-decreasing technique together with random restriction methods for the AND gates at the bottom level, we also prove a hard special case of the Constant Degree Hypothesis of Barrington, Straubing, Therien, and other related lower bounds for certain (MOD p, MOD m, AND) circuits.Most of the previous lower bounds on circuits with modular gates used special definitions of the modular gates (i.e., the gate outputs one if the sum of its inputs is divisible by m, or is not divisible by m), and were not valid for more general MOD m gates. Our methods are applicable - and our lower bounds are valid - for the most general modular gates as well.
FOCS	Improved Decoding of Reed-Solomon and Algebraic-Geometric Codes.	Venkatesan Guruswami,Madhu Sudan	1998	"Given an error-correcting code of block length n and an arbitrary input string also of length n, the list decoding problem is that of finding all codewords within a specified Hamming distance from the input string. We present an improved list decoding algorithm for decoding Reed-Solomon codes. The list decoding problem for Reed-Solomon codes reduces to the following ``curve-fitting'' problem over a field F: Given n points (x[i].y[i]), 1 1/3, where the result yields the first asymptotic improvement since Peterson's original algorithm nearly four decades ago.The algorithm generalizes to solve the list decoding problem for other algebraic codes, specifically alternant codes (a class of codes including BCH codes) and algebraic-geometric codes. In both cases, we obtain a list decoding algorithm that corrects up to n - sqrt{n(n-d')} errors, where n is the block length and d' is the designed distance of the code. The improvement for the case of algebraic-geometric codes extends the methods of Shokrollahi and Wasserman [STOC '98] and improves upon their bound for every choice of n and d'. We also present some other consequences of our algorithm including a solution to a weighted curve fitting problem, which is of use in soft-decision decoding algorithms for Reed-Solomon codes."
FOCS	Satisfiability of Word Equations with Constants is in Exponential Space.	Claudio Gutiérrez	1998	"In this paper we study solvability of equations over free semigroups, known as word equations, particularly Makanin's algorithm, a general procedure to decide if a word equation has a solution. The upper bound time-complexity of Makanin's original decision procedure (1977) was quadruple exponential in the length of the equation, as shown by Jaffar. In 1990 Ko\'scielski and Pacholski reduced it to triple exponential, and conjectured that it could be brought down to double exponential. The present paper proves this conjecture. In fact we prove the stronger fact that its space-complexity is single exponential."
FOCS	The Security of Individual RSA Bits.	Johan Håstad,Mats Näslund	1998	We study the security of individual bits in an RSA encrypted message $E_N(x)$. We show that given $E_N(x)$, predicting any single bit in $x$ with only a non-negligible advantage over the trivial guessing strategy, is (through a polynomial time reduction) as hard as breaking RSA. We briefly discuss a related result for bit security of the discrete logarithm.
FOCS	Which Problems Have Strongly Exponential Complexity?	Russell Impagliazzo,Ramamohan Paturi,Francis Zane	1998	Which Problems Have Strongly Exponential Complexity?
FOCS	Randomness vs. Time: De-Randomization under a Uniform Assumption.	Russell Impagliazzo,Avi Wigderson	1998	Randomness vs. Time: De-Randomization under a Uniform Assumption.
FOCS	On Approximate Nearest Neighbors in Non-Euclidean Spaces.	Piotr Indyk	1998	On Approximate Nearest Neighbors in Non-Euclidean Spaces.
FOCS	Faster Algorithms for String Matching Problems: Matching the Convolution Bound.	Piotr Indyk	1998	Faster Algorithms for String Matching Problems: Matching the Convolution Bound.
FOCS	Factor 2 Approximation Algorithm for the Generalized Steiner Network Problem.	Kamal Jain	1998	Factor 2 Approximation Algorithm for the Generalized Steiner Network Problem.
FOCS	Orchestrating Quartets: Approximation and Data Correction.	Tao Jiang,Paul E. Kearney,Ming Li	1998	Inferring evolutionary trees has long been a challenging problem both for biologists and computer scientists. In recent years research has concentrated on the quartet method paradigm for inferring evolutionary trees. Quartet methods proceed by first inferring the evolutionary history for every set of four species (resulting in a set Q of inferred quartet topologies) and then recombining these inferred quartet topologies to form an evolutionary tree. This paper presents two results on the quartet method paradigm. The first is a polynomial time approximation scheme (PTAS) for recombining the inferred quartet topologies optimally. This is an important result since, to date, there have been no polynomial time algorithms with performance guarantees for quartet methods. In fact, this is the first known PTAS for inferring evolutionary trees under any paradigm. To achieve this result the natural denseness of the set Q is exploited. The second result is a new technique, called quartet cleaning, that detects and corrects errors in the set Q with performance guarantees. This result has particular significance since quartet methods are usually very sensitive to errors in the data. It is shown how quartet cleaning can dramatically increase the accuracy of quartet methods.
FOCS	Local Search in Smooth Convex Sets.	Ravi Kannan,Andreas Nolte	1998	In this paper we analyse two very simple techniques to minimize a linear function over a convex set.The first is a deterministic algorithm based on gradient descent. The second is a randomized algorithm which makes a small local random change at every step The second method can be used when the convex set is presented by just a membership oracle whereas the first requires something similar to a separation oracle.We define a simple notion of smoothness of convex sets and show that both algorithms provide a near optimal solution for smooth convex sets in polynomial time. We describe several application examples from Linear and Stochastic Programming where the relevant sets are indeed smooth and thus our algorithms apply.The main point of the paper is that such simple algorithms yield good running time bounds for natural problems.
FOCS	Theoretical Issues in Probabilistic Artificial Intelligence.	Michael J. Kearns	1998	Theoretical Issues in Probabilistic Artificial Intelligence.
FOCS	Lower Bounds for Zero Knowledge on the Internet.	Joe Kilian,Erez Petrank,Charles Rackoff	1998	We consider zero knowledge interactive proofs in a richer, more realistic communication environment. In this setting, one may simultaneously engage in many interactive proofs, and these proofs may take place in an asynchronous fashion. It is known that zero-knowledge is not necessarily preserved in such an environment; we show that for a large class of protocols, it cannot be preserved. Any 4 round (computational) zero-knowledge interactive proof (or argument) for a non-trivial language L is not black-box simulatable in the asynchronous setting.
FOCS	Recommendation Systems: A Probabilistic Analysis.	Ravi Kumar,Prabhakar Raghavan,Sridhar Rajagopalan,Andrew Tomkins	1998	A recommendation system tracks past actions of a group of users to make recommendations to individual members of the group. The growth of computer-mediated marketing and commerce has led to increased interest in such systems.We introduce a simple analytical framework for recommendation systems, including a basis for defining the utility of such a system. We perform probabilistic analyses of algorithmic methods within this framework. These analyses yield insights into how much utility can be derived from the memory of past actions and on how this memory can be exploited.
FOCS	A Characterization of NC by Tree Recurrence.	Daniel Leivant	1998	We show that a boolean valued function is in NC iff it is defined by ramified schematic recurrence over trees. This machine-independent characterization uses no initial functions other than basic tree operations, and no bounding conditions on the recurrence.Aside from its technical interest, our result evidences the foundational nature of NC, thereby illustrating the merits of implicit (i.e. machine independent) computational complexity theory.
FOCS	Jitter Control in QoS Networks.	Yishay Mansour,Boaz Patt-Shamir	1998	We study jitter control in networks with guaranteed quality of service (QoS) from the competitive analysis point of view: we propose on-line algorithms that control jitter and compare their performance to the best possible (by an off-line algorithm) for any given arrival sequence. For delay jitter, where the goal is to minimize the difference between delay times of different packets, we show that a simple on-line algorithm using a buffer of B slots guarantees the same delay jitter as the best off-line algorithm using buffer space B/2. We prove that the guarantees made by our on-line algorithm hold, even for simple distributed implementations, where the total buffer space is distributed along the path of the connection, provided that the input stream satisfies a certain simple property. For rate jitter, where the goal is to minimize the difference between inter-arrival times, we develop an on-line algorithm using a buffer of size 2B + h for any h &ge; 1, and compare its jitter to the jitter of an optimal off-line algorithm using buffer size B. We prove that our algorithm guarantees that the difference is bounded by a term proportional to B/h.
FOCS	Geometric Computation and the Art of Sampling.	Jirí Matousek	1998	Geometric Computation and the Art of Sampling.
FOCS	Quantum Cryptography with Imperfect Apparatus.	Dominic Mayers,Andrew Chi-Chih Yao	1998	"Quantum key distribution, first proposed by Bennett and Brassard, provides a possible key distribution scheme whose security depends only on the quantum laws of physics. So far the protocol has been proved secure even under channel noise and detector faults of the receiver, but is vulnerable if the photon source used is imperfect. In this paper we propose and give a concrete design for a new concept, ""self-checking source"", which requires the manufacturer of the photon source to provide certain tests; these tests are designed such that, if passed, the source is guaranteed to be adequate for the security of the quantum key distribution protocol, even though the testing devices may not be built to the original specification. The main mathematical result is a structural theorem which states that, for any state in a Hilbert space, if certain EPR-type equations are satisfied, the state must be essentially the orthogonal sum of EPR pairs."
FOCS	The Shortest Vector in a Lattice is Hard to Approximate to Within Some Constant.	Daniele Micciancio	1998	"We show that approximating the shortest vector problem (in any $\ell_p$ norm) to within any constant factor less than $\sqrt[p]2$ is hard for NP under reverse unfaithful random reductions with inverse polynomial error probability. In particular, approximating the shortest vector problem is not in RP (random polynomial time), unless NP equals RP. We also prove a proper NP-hardness result (i.e., hardness under deterministic many-one reductions) under a reasonable number theoretic conjecture on the distribution of square-free smooth numbers. As part of our proof, we give an alternative construction of Ajtai's constructive variant of Sauer's lemma that greatly simplifies Ajtai's original proof."
FOCS	A Linguistic Characterization of Bounded Oracle Computation and Probabilistic Polynomial Time.	John C. Mitchell,Mark Mitchell,Andre Scedrov	1998	A Linguistic Characterization of Bounded Oracle Computation and Probabilistic Polynomial Time.
FOCS	A Unified Superfast Algorithm for Boundary Rational Tangential Interpolation Problems and for Inversion and Factorization of Dense Structured Matrices.	Vadim Olshevsky,Victor Y. Pan	1998	The classical scalar Nevanlinna-Pick interpolation problem has a long and distinguished history, appearing in a variety of applications in mathematics and electrical engineering. There is a vast literature on this problem and on its various far reaching generalizations. It is widely known that the now classical algorithm for solving this problem proposed by Nevanlinna in 1929 can be seen as a way of computing the Cholesky factorization for the corresponding Pick matrix. Moreover, the classical Nevanlinna algorithm takes advantage of the special structure of the Pick matrix to compute this triangular factorization in only $O(n^2)$ arithmetic operations, where $n$ is the number of interpolation points, or, equivalently, the size of the Pick matrix. Since the structure-ignoring standard Cholesky algorithm [though applicable to the wider class of general matrices] has much higher complexity $O(n^3)$, the Nevanlinna algorithm is an example of what is now called fast algorithms. In this paper we use a divide-and-conquer approach to propose a new superfast $O(n \log^3 n)$ algorithm to construct solutions for the more general boundary tangential Nevanlinna-Pick problem. This dramatic speed-up is achieved via a new divide-and-conquer algorithm for factorization of rational matrix functions; this superfast algorithm seems to have a practical and theoretical significance itself. It can be used to solve similar rational interpolation problems [e.g., the matrix Nehari problem], and a variety of engineering problems. It can also be used for inversion and triangular factorization of matrices with displacement structure, including Hankel-like, Vandermonde-like, and Cauchy-like matrices.
FOCS	Which Crossing Number is it, Anyway?	János Pach,Géza Tóth	1998	A drawing of a graph $G$ is a mapping which assigns to each vertex a point of the plane and to each edge a simple continuous arc connecting the corresponding two points. The crossing number of $G$ is the minimum number of crossing points in any drawing of $G$. We define two new parameters, as follows. The pairwise crossing number (resp. the odd-crossing number) of $G$ is the minimum number of pairs of edges that cross (resp. cross an odd number of times) over all drawings of $G$. We prove that the determination of each of these parameters is an NP-complete problem. We also prove that the largest of these numbers (the crossing number) cannot exceed twice the square of the smallest (the odd-crossing number). Our proof is based on the following generalization of an old result of Hanani, which is of independent interest. Let $G$ be a graph and let $E_0$ be a subset of its edges such that there is a drawing of $G$, in which every edge belonging $E_0$ crosses any other edge an even number of times. Then $G$ can be redrawn so that the elements of $E_0$ are not involved in any crossing.
FOCS	Optimal Time-Space Trade-Offs for Sorting.	Jakob Pagter,Theis Rauhe	1998	We study the fundamental problem of sorting in a sequential model of computation and in particular consider the time-space trade-off (product of time and space) for this problem.Beame has shown a lower bound of $\Omega(n^2)$ for this product leaving a gap of a logarithmic factor up to the previously best known upper bound of $O(n^2\log n)$ due to Frederickson. Since then, no progress has been made towards tightening this gap.The main contribution of this paper is a comparison based sorting algorithm which closes the gap by meeting the lower bound of Beame. The time-space product $O(n^2)$ upper bound holds for the full range of space bounds between $\log n$ and $n/\log n$. Hence in this range our algorithm is optimal for comparison based models as well as for the very powerful general models considered by Beame.
FOCS	An Improved Exponential-Time Algorithm for -SAT.	Ramamohan Paturi,Pavel Pudlák,Michael E. Saks,Francis Zane	1998	We propose and analyze a simple new randomized algorithm, called ResolveSat, for finding satisfying assignments of Boolean formulas in conjunctive normal form. The algorithm consists of two stages: a preprocessing stage in which resolution is applied to enlarge the set of clauses of the formula, followed by a search stage that uses a simple randomized greedy procedure to look for a satisfying assignment. Currently, this is the fastest known probabilistic algorithm for k-CNF satisfiability for k &geq; 4 (with a running time of O(20.5625n) for 4-CNF). In addition, it is the fastest known probabilistic algorithm for k-CNF, k &geq; 3, that have at most one satisfying assignment (unique k-SAT) (with a running time O(2(2 ln 2 &minus; 1)n &plus; o(n)) &equals; O(20.386 &hellip; n) in the case of 3-CNF). The analysis of the algorithm also gives an upper bound on the number of the codewords of a code defined by a k-CNF. This is applied to prove a lower bounds on depth 3 circuits accepting codes with nonconstant distance. In particular we prove a lower bound &Omega;(21.282&hellip;&radic;>i<n>/i<) for an explicitly given Boolean function of n variables. This is the first such lower bound that is asymptotically bigger than 2&radic;>i<n>/i< &plus; o(&radic;>i<n>/i<).
FOCS	Local Divergence of Markov Chains and the Analysis of Iterative Load Balancing Schemes.	Yuval Rabani,Alistair Sinclair,Rolf Wanka	1998	We develop a general technique for the quantitative analysis of iterative distributed load balancing schemes. We illustrate the technique by studying two simple, intuitively appealing models that are prevalent in the literature: the diffusive paradigm, and periodic balancing circuits (or the dimension exchange paradigm). It is well known that such load balancing schemes can be roughly modeled by Markov chains, but also that this approximation can be quite inaccurate. Our main contribution is an effective way of characterizing the deviation between the actual loads and the distribution generated by a related Markov chain, in terms of a natural quantity which we call the local divergence. We apply this technique to obtain bounds on the number of rounds required to achieve coarse balancing in general networks, cycles and meshes in these models. For balancing circuits, we also present bounds for the stronger requirement of perfect balancing, or counting.
FOCS	Improved Bounds and Algorithms for Hypergraph Two-Coloring.	Jaikumar Radhakrishnan,Aravind Srinivasan	1998	"We show that for all large n, every n-uniform hypergraph with at most 0.7 sqrt{n/ln n} * 2^n edges can be two-colored. We, in fact, present fast algorithms that output a proper two-coloring with high probability for such hypergraphs. We also derandomize and parallelize these algorithms, to derive NC^1 versions of these results. This makes progress on a problem of Erdos (1963), improving the previous-best bound of n^{1/3-o(1)} * 2^n due to Beck (1978). We further generalize this to a ``local'' version, improving on one of the first applications of the Lovasz Local Lemma."
FOCS	Perfect Information Leader Election in log* + (1) Rounds.	Alexander Russell,David Zuckerman	1998	In the leader election problem, n players wish to elect a random leader. The difficulty is that some coalition of players may conspire to elect one of its own members. We adopt the perfect information model: all communication is by broadcast, and the bad players have unlimited computational power. Within a round, they may also wait to see the inputs of the good players. A protocol is called resilient if a good leader is elected with probability bounded away from 0.We give a simple, constructive leader election protocol that is resilient against coalitions of size bn, for any b 2.
FOCS	Multiplicative Complexity of Taylor Shifts and a New Twist of the Substitution Method.	Arnold Schönhage	1998	Let $C_n = C_n(K)$ denote the minimum number of essential multiplications/divisions required for shifting a general $n$-th degree polynomial $A(t)= \sum a_i t^i$ to some new origin $x$, which means to compute the coefficients $b_k$ of the Taylor expansion $A(x+t)= B(t)= \sum b_k t^k$ as elements of $K(x,a_0, \ldots, a_n)$ with indeterminates $a_i$ and $x$ over some ground field $K$. For $K$ of characteristic zero, a new refined version of the substitution method combined with a dimension argument enables us to prove $C_n \ge n + \lceil n/2 \rceil - 1$ opposed to an upper bound of $C_n \le 2n + \lceil n/2 \rceil - 4$ valid for all $n \ge 3$.
FOCS	Decidability of Bisimulation Equivalence for Equational Graphs of Finite Out-Degree.	Géraud Sénizergues	1998	The bisimulation problem for equational graphs of finite out-degree is shown to be decidable. We reduce this problem to the eta-bisimulation problem for deterministic rational (vectors of) boolean series on the alphabet of a dpda M. We then exhibit a complete formal system for deducing equivalent pairs of such vectors.
FOCS	Semidefinite Relaxations for Parallel Machine Scheduling.	Martin Skutella	1998	We consider the problem of scheduling unrelated parallel machines so as to minimize the total weighted completion time of jobs. Whereas the best previously known approximation algorithms for this problem are based on LP relaxations, we give a $3/2$--approximation algorithm that relies on a convex quadratic programming relaxation. For the special case of two machines we present a further improvement to a $1.2752$--approximation; we introduce a more sophisticated semidefinite programming relaxation and apply the random hyperplane technique introduced by Goemans and Williamson for the MaxCut problem and its refined version of Feige and Goemans. To the best of our knowledge, this is the first time that convex and semidefinite programming techniques (apart from LPs) are used in the area of scheduling.
FOCS	Geometric Separator Theorems & Applications.	Warren D. Smith,Nicholas C. Wormald	1998	Geometric Separator Theorems & Applications.
FOCS	Probabilistically Checkable Proofs with Low Amortized Query Complexity.	Madhu Sudan,Luca Trevisan	1998	Probabilistically Checkable Proofs with Low Amortized Query Complexity.
FOCS	Algorithms to Tile the Infinite Grid with Finite Clusters.	Mario Szegedy	1998	Algorithms to Tile the Infinite Grid with Finite Clusters.
FOCS	Map Graphs in Polynomial Time.	Mikkel Thorup	1998	"Chen, Grigni, and Papadimitriou (WADS'97 and STOC'98) have introduced a modified notion of planarity, where two faces are considered adjacent if they share at least one point. The corresponding abstract graphs are called map graphs. Chen et.al. raised the question of whether map graphs can be recognized in polynomial time. They showed that the decision problem is in NP and presented a polynomial time algorithm for the special case where we allow at most 4 faces to intersect in any point --- if only 3 are allowed to intersect in a point, we get the usual planar graphs.Chen et.al. conjectured that map graphs can be recognized in polynomial time, and in this paper, their conjecture is settled affirmatively."
FOCS	The Minimum Equivalent DNF Problem and Shortest Implicants.	Christopher Umans	1998	We prove that the Minimum Equivalent DNF problem is Sigma/sub 2//sup p/ complete, resolving a conjecture due to Stockmeyer. The proof involves as an intermediate step a variant of a related problem in logic minimization, namely, that of finding the shortest implicant of a Boolean function. We also obtain certain results concerning the complexity of the Shortest Implicant problem that may be of independent interest. When the input is a formula, the Shortest Implicant problem is Sigma/sub 2//sup p/ complete, and Sigma/sub 2//sup p/ hard to approximate to within an n/sup 1/2 - epsilon/ factor. When the input is a circuit, approximation is Sigma/sub 2//sup p/ hard to within an n/sup 1 - epsilon/ factor. However, when the input is a DNF formula, the Shortest Implicant problem cannot be Sigma/sub 2//sup p/ complete unless Sigma/sub 2//sup p/ = NP[log/sup 2/ n]/sup NP/.
FOCS	The Complexity of the Approximation of the Bandwidth Problem.	Walter Unger	1998	The bandwidth problem has a long history and a number of important applications. It is the problem of enumerating the vertices of a given graph $G$ such that the maximum difference between the numbers of adjacent vertices is minimal. We will show for any constant $k\in\nat$ that there is no polynomial time approximation algorithm with an approximation factor of $k$. Furthermore, we will show that this result holds also for caterpillars, a class of restricted trees. We construct for any $x,\epsilon\in\rel$ with $x>1$ and $\epsilon>0$ a graph class for which an approximation algorithm with an approximation factor of $x+\epsilon$ exists, but the approximation of the bandwidth problem within a factor of $x-\epsilon$ is NP-complete. The best previously known approximation factors for the intractability of the bandwidth approximation problem were $1.5$ for general graphs and $4/3$ for trees.
FOCS	A Divide-and-Conquer Algorithm for Min-Cost Perfect Matching in the Plane.	Kasturi R. Varadarajan	1998	"Given a set V of 2n points in the plane, the min-cost perfect matching problem is to pair up the points (into n pairs) so that the sum of the Euclidean distances between the paired points is minimized. We present an O(n^(3/2) log^5 n)-time algorithm for computing a min-cost perfect matching in the plane, which is an improvement over the previous best algorithm of Vaidya by nearly a factor of n. Vaidya's algorithm is an implementation of the algorithm of Edmonds, which runs in n phases, and computes a matching with i edges at the end of the i-th phase. Vaidya shows that geometry can be exploited to implement a single phase in roughly O(n^(3/2)) time, thus obtaining an O(n^(5/2) \log^4 n)-time algorithm. We improve upon this in two major ways. First, we develop a variant of Edmonds' algorithm that uses geometric divide-and-conquer, so that in the conquer step we need only O(n^(1/2)) phases. Second, we show that a single phase can be implemented in O(n \log^5 n) time."
FOCS	A Randomized Approximation Scheme for Metric MAX-CUT.	Wenceslas Fernandez de la Vega,Claire Kenyon	1998	Metric MAX-CUT is the problem of dividing a set of points in metric space into two parts so as to maximize the sum of the distances between points belonging to distinct parts. We show that metric MAX-CUT has a polynomial time randomized approximation scheme.
FOCS	Random Projection: A New Approach to VLSI Layout.	Santosh Vempala	1998	We show that Random Projection, the technique of projecting a set of points to a randomly chosen low-dimensional subspace, can be used to solve problems in VLSI layout. Specifically, for the problem of laying out a graph on a 2-dimensional grid so as to minimize the maximum edge length, we obtain an O(log^{3.5} n) approximation algorithm (this is the first o(n) approximation), and for the bicriteria problem of minimizing the total edge length while keeping the maximum length bounded, we obtain an O(log^3 n, log^{3.5} n) approximation. Our algorithms also work for d-dimensional versions of these problems (for any fixed d) with polylog approximation guarantees. Besides random projection, the main components of the algorithms are a linear programming relaxation, and volume-respecting Euclidean embeddings (introduced by Feige).
FOCS	Unsatisfiable Systems of Equations, Over a Finite Field.	Alan R. Woods	1998	The properties of any system of k simultaneous equations in n variables over GF(q), are studied, with a particular emphasis on unsatisfiable systems. A general formula for the number of solutions is given, which can actually be useful for computing that number in the special case where all the equations are of degree 2. When such a quadratic system has no solution, there is always a proof of unsatisfiability of size q^{n/2} times a polynomial in n and q, which can be checked deterministically in time satisfying a similar bound. Such a proof can be found by a probabilistic algorithm in time asymptotic to that required to test, by substitution in k quadratic equations, all q^n potential solutions.
FOCS	All Pairs Shortest Paths in Weighted Directed Graphs ¾ Exact and Almost Exact Algorithms.	Uri Zwick	1998	We present two new algorithms for solving the ALL PAIRS SHORTEST PATHS (APSP) problem for weighted directed graphs. Both algorithms use fast matrix multiplication algorithms.The first algorithm solves the APSP problem for weighted directed graphs in which the edge weights are integers of small absolute value in $\Ot(n^{2+\mu})$ time, where $\mu$ satisfies the equation $\omega(1,\mu,1)=1+2\mu$ and $\omega(1,\mu,1)$ is the exponent of the multiplication of an $n\times n^\mu$ matrix by an $n^\mu \times n$ matrix. The currently best available bounds on $\omega(1,\mu,1)$, obtained by Coppersmith and Winograd, and by Huang and Pan, imply that $\mu0$ is an error parameter and~$W$ is the largest edge weight in the graph, after the edge weights are scaled so that the smallest non-zero edge weight in the graph is~1. It returns estimates of all the distances in the graph with a stretch of at most $1+\eps$. Corresponding paths can also be found efficiently.
FOCS	"39th Annual Symposium on Foundations of Computer Science, FOCS '98, November 8-11, 1998, Palo Alto, California, USA"		1998	"39th Annual Symposium on Foundations of Computer Science, FOCS '98, November 8-11, 1998, Palo Alto, California, USA"
SODA	On the Exact Worst Case Query Complexity of Planar Point Location.	Udo Adamy,Raimund Seidel	1998	On the Exact Worst Case Query Complexity of Planar Point Location.
SODA	Finding a Large Hidden Clique in a Random Graph.	Noga Alon,Michael Krivelevich,Benny Sudakov	1998	Finding a Large Hidden Clique in a Random Graph.
SODA	I/O-Efficient Algorithms for Contour-line Extraction and Planar Graph Blocking (Extended Abstract).	Pankaj K. Agarwal,Lars Arge,T. M. Murali,Kasturi R. Varadarajan,Jeffrey Scott Vitter	1998	I/O-Efficient Algorithms for Contour-line Extraction and Planar Graph Blocking (Extended Abstract).
SODA	Direct Routing on Trees (Extended Abstract).	Stephen Alstrup,Jacob Holm,Kristian de Lichtenberg,Mikkel Thorup	1998	Direct Routing on Trees (Extended Abstract).
SODA	Kinetic Binary Space Partitions for Intersecting Segments and Disjoint Triangles (Extended Abstract).	Pankaj K. Agarwal,Jeff Erickson,Leonidas J. Guibas	1998	Kinetic Binary Space Partitions for Intersecting Segments and Disjoint Triangles (Extended Abstract).
SODA	Exact and Approximation Algorithms for Clustering (Extended Abstract).	Pankaj K. Agarwal,Cecilia Magdalena Procopiuc	1998	Exact and Approximation Algorithms for Clustering (Extended Abstract).
SODA	Identification of Gene Regulatory Networks by Strategic Gene Disruptions and Gene Overexpressions.	Tatsuya Akutsu,Satoru Kuhara,Osamu Maruyama,Satoru Miyano	1998	Identification of Gene Regulatory Networks by Strategic Gene Disruptions and Gene Overexpressions.
SODA	Average-Case Analyses of First Fit and Random Fit Bin Packing.	Susanne Albers,Michael Mitzenmacher	1998	Average-Case Analyses of First Fit and Random Fit Bin Packing.
SODA	Theory and Practice of I/O-Efficient Algorithms for Multidimensional Batched Searching Problems (Extended Abstract).	Lars Arge,Octavian Procopiuc,Sridhar Ramaswamy,Torsten Suel,Jeffrey Scott Vitter	1998	Theory and Practice of I/O-Efficient Algorithms for Multidimensional Batched Searching Problems (Extended Abstract).
SODA	A Polynomial-Time Approximation Scheme for Weighted Planar Graph TSP.	Sanjeev Arora,Michelangelo Grigni,David R. Karger,Philip N. Klein,Andrzej Woloszyn	1998	A Polynomial-Time Approximation Scheme for Weighted Planar Graph TSP.
SODA	Ancient and New Algorithms for Load Balancing in the L Norm.	Adi Avidor,Yossi Azar,Jiri Sgall	1998	Ancient and New Algorithms for Load Balancing in the L Norm.
SODA	Edge-Connectivity Augmentation with Partition Constraints.	Jørgen Bang-Jensen,Harold N. Gabow,Tibor Jordán,Zoltán Szigeti	1998	"In the well-solved edge-connectivity augmentation problem we must find a minimum cardinality set $F$ of edges to add to a given undirected graph to make it $k$-edge-connected. This paper solves the generalization where every edge of $F$ must go between two different sets of a given partition of the vertex set. A special case of this partition-constrained problem, previously unsolved, is increasing the edge-connectivity of a bipartite graph to $k$ while preserving bipartiteness. Based on this special case we present an application of our results in statics. Our solution to the general partition-constrained problem gives a min-max formula for $|F|$ which includes as a special case the original min-max formula of Cai and Sun \cite{cai} for the problem without partition constraints. When $k$ is even the min-max formula for the partition-constrained problem is a natural generalization of \cite{cai}. However this generalization fails when $k$ is odd. We show that at most one more edge is needed when $k$ is odd and we characterize the graphs that require such an extra edge. We give a strongly polynomial algorithm that solves our problem in time $O(n(m+n\log n)$ $\log n)$. Here $n$ and $m$ denote the number of vertices and distinct edges of the graph respectively. This bound is identical to the best-known time bound for the problem without partition constraints. Our algorithm is based on the splitting off technique of Lov\''asz, like several known efficient algorithms for the unconstrained problem. However unlike previous splitting algorithms, when $k$ is odd our algorithm must handle ``obstacles'''' that prevent all edges from being split off. Our algorithm is of interest even when specialized to \nopagebreak the unconstrained problem, because it produces an asymptotically optimum number of distinct splits."
SODA	Minimizing Service and Operation Costs of Periodic Scheduling (Extended Abstract).	Amotz Bar-Noy,Randeep Bhatia,Joseph Naor,Baruch Schieber	1998	Minimizing Service and Operation Costs of Periodic Scheduling (Extended Abstract).
SODA	Augmenting Undirected Edge Connectivity in Õ(n) Time.	András A. Benczúr,David R. Karger	1998	Augmenting Undirected Edge Connectivity in Õ(n) Time.
SODA	Flow and Stretch Metrics for Scheduling Continuous Job Streams.	Michael A. Bender,Soumen Chakrabarti,S. Muthukrishnan	1998	Flow and Stretch Metrics for Scheduling Continuous Job Streams.
SODA	Sparse 0-1-Matrices and Forbidden Hypergraphs (Extended Abstract).	Claudia Bertram-Kretzberg,Thomas Hofmeister,Hanno Lefmann	1998	Sparse 0-1-Matrices and Forbidden Hypergraphs (Extended Abstract).
SODA	An Efficient Algorithm for the Three-Dimensional Diameter Problem.	Sergei Bespamyatnikh	1998	An Efficient Algorithm for the Three-Dimensional Diameter Problem.
SODA	Learning Deterministic Finite Automata from Smallest Counterexamples.	Andreas Birkendorf,Andreas Böker,Hans-Ulrich Simon	1998	We show in this paper (which appeared in a preliminary form as an extended abstract in [Proceedings of the 9th International ACM--SIAM Symposium on Discrete Algorithms, ACM, 1998]) that deterministic finite automata (DFAs) with n states and input alphabet $\Sigma$ can efficiently be learned from less than $|\Sigma|n^2$ smallest counterexamples. This improves on an earlier result of Ibarra and Jiang who required $|\Sigma|n^3$ smallest counterexamples. We present a general strategy which learns a finite concept class ${\cal F}$ from $\lfloor\log{\cal F}\rfloor$ smallest counterexamples (but not necessarily efficiently). An application to DFAs with at most $n$ states shows that $(1+o(1))|\Sigma|n\log n$ smallest counterexamples are sufficient (if efficiency is not an issue). We show next that the special DFAs operating on input words of an arbitrary but fixed length (the so-called leveled DFAs) are efficiently learnable from $(1+o(1))|\Sigma|n\log n$ smallest counterexamples. This improves on an earlier result of Ibarra and Jiang who required $|\Sigma|n^2$ smallest counterexamples. Furthermore, we present a general lower bound on the number of smallest counterexamples (required by any learning algorithm). This bound can be stated in terms of a (new) combinatorial dimension associated with the target class. A computation of this dimension for leveled or arbitrary DFAs leads to a lower bound of the form $(\frac{1}{4}+o(1))|\Sigma|n\log n$. This bound matches the aforementioned upper bounds modulo a constant of approximately 4. Finally, we present a general conversion of algorithms learning from smallest counterexamples into algorithms performing self-directed learning. For the particular classes of leveled or arbitrary DFAs, this conversion leads to self-directed learners making the smallest possible number of mistakes (modulo a constant of approximately 4). A similar remark is valid for the class of multiplicity automata (MAs).
SODA	Linear-Time Register Allocation for a Fixed Number of Registers.	Hans L. Bodlaender,Jens Gustedt,Jan Arne Telle	1998	Linear-Time Register Allocation for a Fixed Number of Registers.
SODA	Finger Search Trees with Constant Insertion Time.	Gerth Stølting Brodal	1998	Finger Search Trees with Constant Insertion Time.
SODA	Faster Random Generation of Linear Extensions.	Russ Bubley,Martin E. Dyer	1998	Faster Random Generation of Linear Extensions.
SODA	Beating the 2 Delta Bound for Approximately Counting Colourings: A Computer-Assisted Proof of Rapid Mixing.	Russ Bubley,Martin E. Dyer,Catherine S. Greenhill	1998	Beating the 2 Delta Bound for Approximately Counting Colourings: A Computer-Assisted Proof of Rapid Mixing.
SODA	Mutual Search (Extended Abstract).	Harry Buhrman,Matthew K. Franklin,Juan A. Garay,Jaap-Henk Hoepman,John Tromp,Paul M. B. Vitányi	1998	Mutual Search (Extended Abstract).
SODA	Output-Sensitive Generation of Random Events.	Paul B. Callahan	1998	Output-Sensitive Generation of Random Events.
SODA	Approximation Algorithms for Directed Steiner Problems.	Moses Charikar,Chandra Chekuri,To-Yat Cheung,Zuo Dai,Ashish Goel,Sudipto Guha,Ming Li	1998	Approximation Algorithms for Directed Steiner Problems.
SODA	The Dynamic Servers Problem.	Moses Charikar,Dan Halperin,Rajeev Motwani	1998	The Dynamic Servers Problem.
SODA	A 3/2-Approximation Algorithm for Sorting by Reversals.	David A. Christie	1998	A 3/2-Approximation Algorithm for Sorting by Reversals.
SODA	LRU is Better than FIFO.	Marek Chrobak,John Noga	1998	LRU is Better than FIFO.
SODA	Competive Algorithms for Multilevel Caching and Relaxed List Update (Extended Abstract).	Marek Chrobak,John Noga	1998	Competive Algorithms for Multilevel Caching and Relaxed List Update (Extended Abstract).
SODA	The Analysis of Hybrid Trie Structures.	Julien Clément,Philippe Flajolet,Brigitte Vallée	1998	The Analysis of Hybrid Trie Structures.
SODA	Approximate String Matching: A Simpler Faster Algorithm.	Richard Cole,Ramesh Hariharan	1998	We give two algorithms for finding all approximate matches of a pattern in a text, where the edit distance between the pattern and the matching text substring is at most k. The first algorithm, which is quite simple, runs in time $O(\frac{nk^3}{m}+n+m)$ on all patterns except k-break periodic strings (defined later). The second algorithm runs in time $O(\frac{nk^4}{m}+n+m)$ on k-break periodic patterns. The two classes of patterns are easily distinguished in O(m)time.
SODA	The Ultimate Interval Graph Recognition Algorithm? (Extended Abstract).	Derek G. Corneil,Stephan Olariu,Lorna Stewart	1998	The Ultimate Interval Graph Recognition Algorithm? (Extended Abstract).
SODA	Go with the Winners for Graph Bisection.	Tassos Dimitriou,Russell Impagliazzo	1998	Go with the Winners for Graph Bisection.
SODA	Fast Hierarchical Clustering and Other Applications of Dynamic Closest Pairs.	David Eppstein	1998	We develop data structures for dynamic closest pair problems with arbitrary distance functions, that do not necessarily come from any geometric structure on the objects. Based on a technique previously used by the author for Euclidean closest pairs, we show how to insert and delete objects from an <i>n</i>-object set, maintaining the closest pair, in <i>O</i>(<i>n</i> log<sup>2</sup> <i>n</i>) time per update and <i>O</i>(<i>n</i>) space. With quadratic space, we can instead use a quadtree-like structure to achieve an optimal time bound, <i>O</i>(<i>n</i>) per update. We apply these data structures to hierarchical clustering, greedy matching, and TSP heuristics, and discuss other potential applications in machine learning, Gröbner bases, and local improvement algorithms for partition and placement problems. Experiments show our new methods to be faster in practice than previously used heuristics.
SODA	A Probabilistic Algorithm for Updating Files over a Communication Link.	Alexandre V. Evfimievski	1998	A Probabilistic Algorithm for Updating Files over a Communication Link.
SODA	On Local Register Allocation.	Martin Farach,Vincenzo Liberatore	1998	In this paper, we consider the problem of Local Register Allocation (LRA): given a sequence of instructions (basic block) and a number of general purpose registers, find the schedule of variables in registers that minimizes the total traffic between CPU and the memory system. Local register allocation has been studied for more than thirty years in the theory and compiler communities. It was not known if LRA is NP-hard, but no subexponential time algorithm was known. Furthermore, the most popular heuristics in use in compilers can perform arbitrarily poorly in the worst case. In this paper, we present the following results: We show that the Local Register Allocation problem is NP-hard. We show that a variant of the furthest-first heuristic achieves a good approximation ratio. We give a 2-approximation algorithm for LRA. We report the experimental performance of a branch-and-bound algorithm and both approximation algorithms on standard benchmarks.
SODA	A New Approximation Algorithm for the Planar Augmentation Problem.	Sergej Fialko,Petra Mutzel	1998	A New Approximation Algorithm for the Planar Augmentation Problem.
SODA	Faster Algorithms for the Quickest Transshipment Problem with Zero Transit Times.	Lisa Fleischer	1998	Faster Algorithms for the Quickest Transshipment Problem with Zero Transit Times.
SODA	A Polylogarithmic Approximation Algorithm for the Group Steiner Tree Problem.	Naveen Garg,Goran Konjevod,R. Ravi	1998	A Polylogarithmic Approximation Algorithm for the Group Steiner Tree Problem.
SODA	Exact Arithmetic at Low Cost - A Case Study in Linear Programming.	Bernd Gärtner	1998	Exact Arithmetic at Low Cost - A Case Study in Linear Programming.
SODA	Online Throughput-Competitive Algorithm for Multicast Routing and Admission Control.	Ashish Goel,Monika Rauch Henzinger,Serge A. Plotkin	1998	We present the first polylog-competitive online algorithm for the general multicast problem in the throughput model. The ratio of the number of requests accepted by the optimum offline algorithm to the expected number of requests accepted by our algorithm is polylogarithmic in M and n, where M is the number of multicast groups and n is the number of nodes in the graph. We show that this is close to optimum by presenting an Omega(log n log M) lower bound on this ratio for any randomized online algorithm against an oblivious adversary. We also show that it is impossible to be competitive against an adaptive online adversary. As in the previous online routing algorithms, our algorithm uses edge-costs when deciding on which is the best path to use. In contrast to the previous competitive algorithms in the throughput model, our cost is not a direct function of the edge load. The new new cost definition allows us to decouple the effects of routing and admission decisions of different multicast groups.
SODA	Fast Distributed Algorithms for {Brooks-Vizing} Colourings.	David A. Grable,Alessandro Panconesi	1998	Fast Distributed Algorithms for {Brooks-Vizing} Colourings.
SODA	Greedy Strikes Back: Improved Facility Location Algorithms.	Sudipto Guha,Samir Khuller	1998	Greedy Strikes Back: Improved Facility Location Algorithms.
SODA	On the Distributed Complexity of Computing Maximal Matchings.	Michal Hanckowiak,Michal Karonski,Alessandro Panconesi	1998	"We show that maximal matchings can be computed deterministically in O(log4 n) rounds in the synchronous, message-passing model of computation. This is one of the very few cases known of a nontrivial graph structure, and the only ""classical"" one, which can be computed distributively in polylogarithmic time without recourse to randomization."
SODA	Two New Upper Bounds for SAT.	Edward A. Hirsch	1998	Two New Upper Bounds for SAT.
SODA	Extended Hilbert Irreducibility and its Applications.	Ming-Deh A. Huang,Yiu-Chung Wong	1998	Extended Hilbert Irreducibility and its Applications.
SODA	Optimal Augmentation to Make a Graph k-Edge-Connected and Triconnected.	Toshimasa Ishii,Hiroshi Nagamochi,Toshihide Ibaraki	1998	Optimal Augmentation to Make a Graph k-Edge-Connected and Triconnected.
SODA	A Faster Algorithm for Minimum Cost Submodular Flows.	Satoru Iwata,S. Thomas McCormick,Maiko Shigeno	1998	A Faster Algorithm for Minimum Cost Submodular Flows.
SODA	Hiding Cliques for Cryptographic Security.	Ari Juels,Marcus Peinado	1998	"We demonstrate how a well studied combinatorial optimization problem may be used as a new cryptographic primitive. The problem in question is that of finding a ""large"" clique in a random graph. While the largest clique in a random graph with n vertices and edge probability p is very likely to be of size about 2 \log_{1/p}{n}, it is widely conjectured that no polynomial-time algorithm exists which finds a clique of size \geq (1 + \epsilon)\log_{1/p}n with significant probability for any constant \epsilon > 0. We present a very simple method of exploiting this conjecture by ``hiding'' large cliques in random graphs. In particular, we show that if the conjecture is true, then when a large clique&mdash;of size, say, (1 + 2 \epsilon) \log_{1/p}{n}&mdash;is randomly inserted (``hidden'') in a random graph, finding a clique of size \geq (1 + \epsilon)\log_{1/p}{n} remains hard. Our analysis also covers the case of high edge probabilities which allows us to insert cliques of size up to n^{1/4-\epsilon} ( \epsilon>0). Our result suggests several cryptographic applications, such as a simple one-way function."
SODA	Better Random Sampling Algorithms for Flows in Undirected Graphs.	David R. Karger	1998	Better Random Sampling Algorithms for Flows in Undirected Graphs.
SODA	On Approximating Rectangle Tiling and Packing.	Sanjeev Khanna,S. Muthukrishnan,Mike Paterson	1998	"Our study of tiling and packing with rectangles in two-dimensional regions is strongly motivated by applications in database mining, histogram-based estimation of query sizes, data partitioning, and motion estimation in video compression by block matching, among others. An example of the problems that we tackle is the following: given an n by n array A of positive numbers, find a tiling using at most p rectangles (that is, no two rectangles must overlap, and each array element must fall within some rectangle) that minimizes the maximum weight of any rectangle; here the ""weight"" of a rectangle is the sum of the array elements that fall within it. If the array A were one-dimensional, this problem could be easily solved by dynamic programming. We prove that in the two-dimensional case it is NP-hard to approximate this problem to within a factor of 1.25. On the other hand, we provide a near-linear time algorithm that returns a solution at most 2.5 times the optimal. Other rectangle tiling and packing problems that we study have similar properties: while it is easy to solve them optimally in one dimension, the two-dimensional versions become NP-hard. We design efficient approximation algorithms for these problems."
SODA	Authoritative Sources in a Hyperlinked Environment.	Jon M. Kleinberg	1998	The network structure of a hyperlinked environment can be a rich source of information about the content of the environment, provided we have effective means for understanding it. We develop a set of algorithmic tools for extracting information from the link structures of such environments, and report on experiments that demonstrate their effectiveness in a variety of context on the World Wide Web. The central issue we address within our framework is the distillation of broad search topics, through the discovery of &ldquo;authorative&rdquo; information sources on such topics. We propose and test an algorithmic formulation of the notion of authority, based on the relationship between a set of relevant authoritative pages and the set of &ldquo;hub pages&rdquo; that join them together in the link structure. Our formulation has connections to the eigenvectors of certain matrices associated with the link graph; these connections in turn motivate additional heuristrics for link-based analysis.
SODA	Computation in Noisy Radio Networks.	Eyal Kushilevitz,Yishay Mansour	1998	In this paper, we examine noisy radio (broadcast) networks in which every bit transmitted has a certain probability of being flipped. Each processor has some initial input bit, and the goal is to compute a function of these input bits. In this model, we show a protocol to compute any threshold function using only a linear number of transmissions.
SODA	Optimal Edge Ranking of Trees in Linear Time.	Tak Wah Lam,Fung Ling Yue	1998	Optimal Edge Ranking of Trees in Linear Time.
SODA	The Power of Migration in Multi-Processor Scheduling of Real-Time Systems.	Gilad Koren,Amihood Amir,Emanuel Dar	1998	The Power of Migration in Multi-Processor Scheduling of Real-Time Systems.
SODA	On-line Randomized Call Control Revisited.	Stefano Leonardi,Alberto Marchetti-Spaccamela,Alessio Presciutti,Adi Rosén	1998	"We consider the problem of on-line call admission and routing on trees and meshes. Previous work gave randomized on-line algorithms for these problems and proved that they have optimal (up to constant factors) competitive ratios. However, these algorithms can obtain very low profit with high probability. We investigate the question of devising for these problems on-line competitive algorithms that also guarantee a ""good"" solution with ""good"" probability.We give a new family of randomized algorithms with asymptotically optimal competitive ratios and ""good"" probability to get a profit close to the expectation. We complement these results by providing bounds on the probability of any optimally competitive randomized on-line algorithm for the problems we consider to get a profit close to the expectation. To the best of our knowledge, this is the first study of the relationship between the tail distribution and the competitive ratio of randomized on-line benefit algorithms."
SODA	Analysis of a Local Search Heuristic for Facility Location Problems.	Madhukar R. Korupolu,C. Greg Plaxton,Rajmohan Rajaraman	1998	In this paper, we study approximation algorithms for several NP-hard facility location problems. We prove that a simple local search heuristic yields polynomial-time constant-factor approximation bounds for the metric versions of the uncapacitated k-median problem and the uncapacitated facility location problem. (For the k-median problem, our algorithms require a constant-factor blowup in the parameter k.) This local search heuristic was first proposed several decades ago, and has been shown to exhibit good practical performance in empirical studies. We also extend the above results to obtain constant-factor approximation bounds for the metric versions of capacitated k-median and facility location problems.
SODA	Matroid Decomposition Methods for the Set Maxima Problem.	Vincenzo Liberatore	1998	Matroid Decomposition Methods for the Set Maxima Problem.
SODA	Error Correcting Codes, Perfect Hashing Circuits, and Deterministic Dynamic Dictionaries.	Peter Bro Miltersen	1998	Error Correcting Codes, Perfect Hashing Circuits, and Deterministic Dynamic Dictionaries.
SODA	Analysis of Random Processes via And-Or Tree Evaluation.	Michael Luby,Michael Mitzenmacher,Mohammad Amin Shokrollahi	1998	Analysis of Random Processes via And-Or Tree Evaluation.
SODA	Computing Univariate GCDs over Number Fields.	Michael B. Monagan,Roger Margot	1998	Computing Univariate GCDs over Number Fields.
SODA	Spatial Codes and the Hardness of String Folding Problems (Extended Abstract).	Ashwin Nayak,Alistair Sinclair,Uri Zwick	1998	Spatial Codes and the Hardness of String Folding Problems (Extended Abstract).
SODA	Fast Backtracking Principles Applied to Find New Cages.	Brendan D. McKay,Wendy J. Myrvold,Jacqueline Nadon	1998	Fast Backtracking Principles Applied to Find New Cages.
SODA	Approximate Polynomials Gcds, Padé Approximation, Polynomial Zeros and Bipartite Graphs.	Victor Y. Pan	1998	Approximate Polynomials Gcds, Padé Approximation, Polynomial Zeros and Bipartite Graphs.
SODA	Exploring Unknown Undirected Graphs.	Petrisor Panaite,Andrzej Pelc	1998	Exploring Unknown Undirected Graphs.
SODA	An Experimental Study of LP-Based Approximation Algorithms for Scheduling Problems.	Martin W. P. Savelsbergh,R. N. Uma,Joel Wein	1998	Recently there has been much progress on the design of approximation algorithms for a variety of scheduling problems in which the goal is to minimize the average weighted completion time of the jobs scheduled. Many of these approximation algorithms have been inspired by polyhedral formulations of the scheduling problems and their use in computing optimal solutions to small instances. In this paper we demonstrate that the progress in the design and analysis of approximation algorithms for these problems also yields techniques with improved computational efficacy. Specifically, we give a comprehensive experimental study of a number of these approximation algorithms for 1|rj|âwjCj, the problem of scheduling jobs with release dates on one machine so as to minimize the average weighted completion time of the jobs scheduled. We study both the quality of lower bounds given for this problem by different linear-programming relaxations and combinatorial relaxations, and the quality of upper bounds delivered by a number of approximation algorithms based on them. The best algorithms, on almost all instances, come within a few percent of the optimal average weighted completion time. Furthermore, we show that this can usually be achieved with O(n log n) computation. In addition we observe that on most kinds of synthetic data used in experimental studies a simple greedy heuristic, used in successful combinatorial branch-and-bound algorithms for the problem, outperforms (on average) all of the LP-based heuristics. We identify, however, other classes of problems on which the LP-based heuristics are superior and report on experiments that give a qualitative sense of the range of dominance of each. We consider the impact of local improvement on the solutions as well. We also consider the performance of the algorithms for the average weighted flow-time criterion, which, although equivalent to average weighted completion time at optimality, is provably much harder to approximate. Nonetheless, we demonstrate that for most instances we consider that the algorithms give very good results for this criterion as well. Finally, we extend the techniques to a rather different and more complex problem that arises from an actual manufacturing application: resource-constrained project scheduling. In this setting as well, the techniques yield algorithms with improved performance; we give the best-known solutions for a set of instances provided by BASF AG, Germany.
SODA	Analysis of First-Come-First-Serve Parallel Job Scheduling.	Uwe Schwiegelshohn,Ramin Yahyapour	1998	Analysis of First-Come-First-Serve Parallel Job Scheduling.
SODA	The Maximum Subforest Problem: Approximation and Exact Algorithms (Extended Abstract).	Ron Shamir,Dekel Tsur	1998	The Maximum Subforest Problem: Approximation and Exact Algorithms (Extended Abstract).
SODA	New Approximation Techniques for Some Ordering Problems.	Satish Rao,Andréa W. Richa	1998	New Approximation Techniques for Some Ordering Problems.
SODA	Collision Detection in Aspect and Scale Bounded Polyhedra.	Subhash Suri,Philip M. Hubbard,John F. Hughes	1998	Collision Detection in Aspect and Scale Bounded Polyhedra.
SODA	Algorithms for the Maxium Subarray Problem Based on Matrix Multiplication.	Hisao Tamaki,Takeshi Tokuyama	1998	Algorithms for the Maxium Subarray Problem Based on Matrix Multiplication.
SODA	Multi-Item Inventory Staggering Problems: Heuristic and Bounds.	Chung-Piaw Teo,Jihong Ou,Kok-Choon Tan	1998	Multi-Item Inventory Staggering Problems: Heuristic and Bounds.
SODA	Faster Deterministic Sorting and Priority Queues in Linear Space.	Mikkel Thorup	1998	Faster Deterministic Sorting and Priority Queues in Linear Space.
SODA	Reconstructing Randomly Sampled Multivariate Polynomials from Highly Noisy Data.	Hal Wasserman	1998	Reconstructing Randomly Sampled Multivariate Polynomials from Highly Noisy Data.
SODA	Ring Routing and Wavelength Translation.	Gordon T. Wilfong,Peter Winkler	1998	Ring Routing and Wavelength Translation.
SODA	A Polynomial Time Approximation Scheme for Minimum Routing Cost Spanning Trees.	Bang Ye Wu,Giuseppe Lancia,Vineet Bafna,Kun-Mao Chao,R. Ravi,Chuan Yi Tang	1998	Given an undirected graph with nonnegative costs on the edges, the routing cost of any of its spanning trees is the sum over all pairs of vertices of the cost of the path between the pair in the tree. Finding a spanning tree of minimum routing cost is NP-hard, even when the costs obey the triangle inequality. We show that the general case is in fact reducible to the metric case and present a polynomial-time approximation scheme valid for both versions of the problem. In particular, we show how to build a spanning tree of an n-vertex weighted graph with routing cost at most $(1+\epsilon)$ of the minimum in time $O(n^{O({\frac{1}{\epsilon}}% )})$. Besides the obvious connection to network design, trees with small routing cost also find application in the construction of good multiple sequence alignments in computational biology. The communication cost spanning tree problem is a generalization of the minimum routing cost tree problem where the routing costs of different pairs are weighted by different requirement amounts. We observe that a randomized O(log n log log n)-approximation for this problem follows directly from a recent result of Bartal, where n is the number of nodes in a metric graph. This also yields the same approximation for the generalized sum-of-pairs alignment problem in computational biology.
SODA	On-Line File Caching.	Neal E. Young	1998	Consider the following file caching problem: in response to a sequence of requests for files, where each file has a specified size and retrieval cost, maintain a cache of files of total size at most some specified k so as to minimize the total retrieval cost. Specifically, when a requested file is not in the cache, bring it into the cache, pay the retrieval cost, and choose files to remove from the cache so that the total size of files in the cache is at most k. This problem generalizes previous paging and caching problems by allowing objects of arbitrary size and cost, both important attributes when caching files for world-wide-web browsers, servers, and proxies. We give a simple deterministic on-line algorithm that generalizes many well-known paging and weighted-caching strategies, including least-recently-used, first-in-first-out, flush-when-full, and the balance algorithm. On any request sequence, the total cost incurred by the algorithm is at most k/(k-h+1) times the minimum possible using a cache of size h >= k. For any algorithm satisfying the latter bound, we show it is also the case that for most choices of k, the retrieval cost is either insignificant or the competitive ratio is constant. This helps explain why competitive ratios of many on-line paging algorithms have been typically observed to be constant in practice.
SODA	Bounding the Diffuse Adversary.	Neal E. Young	1998	Bounding the Diffuse Adversary.
SODA	Approximation Algorithms for Constraint Satisfaction Problems Involving at Most Three Variables per Constraint.	Uri Zwick	1998	Approximation Algorithms for Constraint Satisfaction Problems Involving at Most Three Variables per Constraint.
SODA	Proceedings of the Ninth Annual ACM-SIAM Symposium on Discrete Algorithms, 25-27 January 1998, San Francisco, California.	Howard J. Karloff	1998	Proceedings of the Ninth Annual ACM-SIAM Symposium on Discrete Algorithms, 25-27 January 1998, San Francisco, California.
STOC	The Shortest Vector Problem in is -hard for Randomized Reductions (Extended Abstract).	Miklós Ajtai	1998	The Shortest Vector Problem in is -hard for Randomized Reductions (Extended Abstract).
STOC	The Closure of Monadic NP (Extended Abstract).	Miklós Ajtai,Ronald Fagin,Larry J. Stockmeyer	1998	The Closure of Monadic NP (Extended Abstract).
STOC	Minimizing Stall Time in Single and Parallel Disk Systems.	Susanne Albers,Naveen Garg,Stefano Leonardi	1998	We study integrated prefetching and caching problems following the work of Cao et al. [1995] and Kimbrel and Karlin [1996]. Cao et al. and Kimbrel and Karlin gave approximation algorithms for minimizing the total elapsed time in single and parallel disk settings. The total elapsed time is the sum of the processor stall times and the length of the request sequence to be served.We show that an optimum prefetching/caching schedule for a single disk problem can be computed in polynomial time, thereby settling an open question by Kimbrel and Karlin. For the parallel disk problem, we give an approximation algorithm for minimizing stall time. The solution uses a few extra memory blocks in cache. Stall time is an important and harder to approximate measure for this problem. All of our algorithms are based on a new approach which involves formulating the prefetching/caching problems as linear programs.
STOC	A Characterization of Span Program Size and Improved Lower Bounds for Monotone Span Programs.	Anna Gál	1998	We give a characterization of span program size by a combinatorial-algebraic measure. The measure we consider is a generalization of a measure on covers which has been used to prove lower bounds on formula size and has also been studied with respect to communication complexity.In the monotone case our new methods yield nΩ(log n) lower bounds for the monotone span program complexity of explicit Boolean functions in n variables over arbitrary fields, improving the previous lower bounds on monotone span program size. Our characterization of span program size implies that any matrix with superpolynomial separation between its rank and cover number can be used to obtain superpolynomial lower bounds on monotone span program size. We also identify a property of bipartite graphs that is sufficient for constructing Boolean functions with large monotone span program complexity.
STOC	Quantum Circuits with Mixed States.	Dorit Aharonov,Alexei Kitaev,Noam Nisan	1998	Quantum Circuits with Mixed States.
STOC	Adaptive Packet Routing for Bursty Adversarial Traffic.	William Aiello,Eyal Kushilevitz,Rafail Ostrovsky,Adi Rosén	1998	Adaptive Packet Routing for Bursty Adversarial Traffic.
STOC	Stability Results for Networks with Input and Output Blocking.	Matthew Andrews,Lisa Zhang	1998	Stability Results for Networks with Input and Output Blocking.
STOC	The Approximability of NP-hard Problems.	Sanjeev Arora	1998	The Approximability of NP-hard Problems.
STOC	Approximation Schemes for Euclidean -Medians and Related Problems.	Sanjeev Arora,Prabhakar Raghavan,Satish Rao	1998	Approximation Schemes for Euclidean -Medians and Related Problems.
STOC	The Cost of the Missing Bit: Communication Complexity with Help.	László Babai,Thomas P. Hayes,Peter G. Kimmel	1998	The Cost of the Missing Bit: Communication Complexity with Help.
STOC	Multicasting in Heterogeneous Networks.	Amotz Bar-Noy,Sudipto Guha,Joseph Naor,Baruch Schieber	1998	Multicasting in Heterogeneous Networks.
STOC	On Approximating Arbitrary Metrices by Tree Metrics.	Yair Bartal	1998	On Approximating Arbitrary Metrices by Tree Metrics.
STOC	On the Complexity of Unsatisfiability Proofs for Random -CNF Formulas.	Paul Beame,Richard M. Karp,Toniann Pitassi,Michael E. Saks	1998	On the Complexity of Unsatisfiability Proofs for Random -CNF Formulas.
STOC	NP Might Not Be As Easy As Detecting Unique Solutions.	Richard Beigel,Harry Buhrman,Lance Fortnow	1998	We construct an oracle A such that P^A = Parityp^A and NP^A=EXP^A. This relativized world has several amazing properties: - The oracle A gives the first relativized world where one can solve satisfiability on formulae with at most one assignment yet P is not equal to NP. - The oracle A is the first where P^A = UP^A >< NP^A = coNP^A. - The construction gives a much simpler proof than Fenner, Fortnow and Kurtz of a relativized world where all NP-complete sets are polynomial-time isomorphic. It is the first such computable oracle. - Relative to $A$ we have a collapse of Parityexp^A is in ZPP^A in P^A/poly. We also create a different relativized world where there exists a set L in NP that is NP-complete under reductions that make one query to L but not under traditional many-one reductions. This contrasts with the result of Buhrman, Spaan and Torenvliet showing that these two completeness notions for NEXP coincide.
STOC	"One Help Bit Doesn't Help."	Richard Beigel,Tirza Hirst	1998	"One Help Bit Doesn't Help."
STOC	A Modular Approach to the Design and Analysis of Authentication and Key Exchange Protocols (Extended Abstract).	Mihir Bellare,Ran Canetti,Hugo Krawczyk	1998	A Modular Approach to the Design and Analysis of Authentication and Key Exchange Protocols (Extended Abstract).
STOC	Semi-Definite Relaxations for Minimum Bandwidth and other Vertex-Ordering Problems.	Avrim Blum,Goran Konjevod,R. Ravi,Santosh Vempala	1998	Semi-Definite Relaxations for Minimum Bandwidth and other Vertex-Ordering Problems.
STOC	The Power of a Pebble: Exploring and Mapping Directed Graphs.	Michael A. Bender,Antonio Fernández,Dana Ron,Amit Sahai,Salil P. Vadhan	1998	"Exploring and mapping an unknown environment is a fundamental problem that is studied in a variety of contexts. Many results have focused on finding efficient solutions to restricted versions of the problem. In this paper, we consider a model that makes very limited assumptions about the environment and solve the mapping problem in this general setting. We model the environment by an unknown directed graph G, and consider the problem of a robot exploring and mapping G. The edges emanating from each vertex are numbered from '1' to 'd', but we do not assume that the vertices of G are labeled. Since the robot has no way of distinguishing between vertices, it has no hope of succeeding unless it is given some means of distinguishing between vertices. For this reason we provide the robot with a ""pebble'--a device that it can place on a vertex and use to identify the vertex later. In this paper we show: (1) If the robot knows an upper bound on the number of vertices then it can learn the graph efficiently with only one pebble. (2) If the robot does not know an upper bound on the number of vertices n, then Θ(log log n) pebbles are both necessary and sufficient. In both cases our algorithms are deterministic."
STOC	Min-Wise Independent Permutations (Extended Abstract).	Andrei Z. Broder,Moses Charikar,Alan M. Frieze,Michael Mitzenmacher	1998	Min-Wise Independent Permutations (Extended Abstract).
STOC	A New Composition Theorem for Learning Algorithms.	Nader H. Bshouty	1998	A New Composition Theorem for Learning Algorithms.
STOC	Linear-Time Pointer-Machine Algorithms for Least Common Ancestors, MST Verification, and Dominators.	Adam L. Buchsbaum,Haim Kaplan,Anne Rogers,Jeffery Westbrook	1998	Linear-Time Pointer-Machine Algorithms for Least Common Ancestors, MST Verification, and Dominators.
STOC	Quantum vs. Classical Communication and Computation.	Harry Buhrman,Richard Cleve,Avi Wigderson	1998	Quantum vs. Classical Communication and Computation.
STOC	An Improved Approximation Algorithm for Multiway Cut.	Gruia Calinescu,Howard J. Karloff,Yuval Rabani	1998	An Improved Approximation Algorithm for Multiway Cut.
STOC	The Random Oracle Methodology, Revisited (Preliminary Version).	Ran Canetti,Oded Goldreich,Shai Halevi	1998	The Random Oracle Methodology, Revisited (Preliminary Version).
STOC	Perfectly One-Way Probabilistic Hash Functions (Preliminary Version).	Ran Canetti,Daniele Micciancio,Omer Reingold	1998	Perfectly One-Way Probabilistic Hash Functions (Preliminary Version).
STOC	Rounding via Trees: Deterministic Approximation Algorithms for Group Steiner Trees and -Median.	Moses Charikar,Chandra Chekuri,Ashish Goel,Sudipto Guha	1998	Rounding via Trees: Deterministic Approximation Algorithms for Group Steiner Trees and -Median.
STOC	Algorithms for Capacitated Vehicle Routing.	Moses Charikar,Samir Khuller,Balaji Raghavachari	1998	Given n identical objects (pegs), placed at arbitrary initial locations, we consider the problem of transporting them efficiently to n target locations (slots) with a vehicle that can carry at most k pegs at a time. This problem is referred to as k-delivery TSP, and it is a generalization of the traveling salesman problem. We give a 5-approximation algorithm for the problem of minimizing the total distance traveled by the vehicle.There are two kinds of transportations possible---one that could drop pegs at intermediate locations and pick them up later in the route for delivery (preemptive) and one that transports pegs to their targets directly (nonpreemptive). In the former case, by exploiting the freedom to drop, one may be able to find a shorter delivery route. We construct a nonpreemptive tour that is within a factor 5 of the optimal preemptive tour. In addition we show that the ratio of the distances traveled by an optimal nonpreemptive tour versus a preemptive tour is bounded by 4.
STOC	Planar Map Graphs.	Zhi-Zhong Chen,Michelangelo Grigni,Christos H. Papadimitriou	1998	Planar Map Graphs.
STOC	Randomized Protocols for Low Congestion Circuit Routing in Multistage Interconnection Networks.	Richard Cole,Bruce M. Maggs,Friedhelm Meyer auf der Heide,Michael Mitzenmacher,Andréa W. Richa,Klaus Schröder,Ramesh K. Sitaraman,Berthold Vöcking	1998	Randomized Protocols for Low Congestion Circuit Routing in Multistage Interconnection Networks.
STOC	On the Complexity of Protein Folding (Extended Abstract).	Pierluigi Crescenzi,Deborah Goldman,Christos H. Papadimitriou,Antonio Piccolboni,Mihalis Yannakakis	1998	On the Complexity of Protein Folding (Extended Abstract).
STOC	Non-Interactive and Non-Malleable Commitment.	Giovanni Di Crescenzo,Yuval Ishai,Rafail Ostrovsky	1998	Non-Interactive and Non-Malleable Commitment.
STOC	Adaptive versus Nonadaptive Attribute-Efficient Learning.	Peter Damaschke	1998	We study the complexity of learning arbitrary Boolean functions of n variables by membership queries, if at most r variables are relevant. Problems of this type have important applications in fault searching, e.g. logical circuit testing and generalized group testing. Previous literature concentrates on special classes of such Boolean functions and considers only adaptive strategies. First we give a straightforward adaptive algorithm using O(r2r log n) queries, but actually, most queries are asked nonadaptively. This leads to the problem of purely nonadaptive learning. We give a graph-theoretic characterization of nonadaptive learning families, called r-wise bipartite connected families. By the probabilistic method we show the existence of such families of size O(r2r log n + r22r). This implies that nonadaptive attribute-efficient learning is not essentially more expensive than adaptive learning. We also sketch an explicit pseudopolynomial construction, though with a slightly worse bound. It uses the common derandomization technique of small-biased k-independent sample spaces. For the special case r &equals; 2, we get roughly 2.275 log n adaptive queries, which is fairly close to the obvious lower bound of 2 log n. For the class of monotone functions, we prove that the optimal query number O(2r + r log n) can be already achieved in O(r) stages. On the other hand, &Omega;(2r log n) is a lower bound on nonadaptive queries.
STOC	TCP Dynamic Acknowledgment Delay: Theory and Practice (Extended Abstract).	Daniel R. Dooly,Sally A. Goldman,Stephen D. Scott	1998	TCP Dynamic Acknowledgment Delay: Theory and Practice (Extended Abstract).
STOC	Concurrent Zero-Knowledge.	Cynthia Dwork,Moni Naor,Amit Sahai	1998	Concurrent executions of a zero-knowledge protocol by a single prover (with one or more verifiers) may leak information and may not be zero-knowledge in toto. In this article, we study the problem of maintaining zero-knowledge.We introduce the notion of an (&alpha;, &beta;) timing constraint: for any two processors P1 and P2, if P1 measures &alpha; elapsed time on its local clock and P2 measures &beta; elapsed time on its local clock, and P2 starts after P1 does, then P2 will finish after P1 does. We show that if the adversary is constrained by an (&alpha;, &beta;) assumption then there exist four-round almost concurrent zero-knowledge interactive proofs and perfect concurrent zero-knowledge arguments for every language in NP. We also address the more specific problem of Deniable Authentication, for which we propose several particularly efficient solutions. Deniable Authentication is of independent interest, even in the sequential case; our concurrent solutions yield sequential solutions without recourse to timing, that is, in the standard model.
STOC	Spot-Checkers.	Funda Ergün,Sampath Kannan,Ravi Kumar,Ronitt Rubinfeld,Mahesh Viswanathan	1998	Spot-Checkers.
STOC	Approximating the Bandwidth via Volume Respecting Embeddings (Extended Abstract).	Uriel Feige	1998	Approximating the Bandwidth via Volume Respecting Embeddings (Extended Abstract).
STOC	Improved Bounds for Acyclic Job Shop Scheduling (Extended Abstract).	Uriel Feige,Christian Scheideler	1998	Improved Bounds for Acyclic Job Shop Scheduling (Extended Abstract).
STOC	Are Lower Bounds Easier over the Reals?	Hervé Fournier,Pascal Koiran	1998	Are Lower Bounds Easier over the Reals?
STOC	Robust Efficient Distributed RSA-Key Generation.	Yair Frankel,Philip D. MacKenzie,Moti Yung	1998	Robust Efficient Distributed RSA-Key Generation.
STOC	Information Theoretic Implications for Pairing Heaps.	Michael L. Fredman	1998	Information Theoretic Implications for Pairing Heaps.
STOC	-sat on Groups and Undecidability.	Michael H. Freedman	1998	-sat on Groups and Undecidability.
STOC	Protecting Data Privacy in Private Information Retrieval Schemes.	Yael Gertner,Yuval Ishai,Eyal Kushilevitz,Tal Malkin	1998	Protecting Data Privacy in Private Information Retrieval Schemes.
STOC	On the Limits of Non-Approximability of Lattice Problems.	Oded Goldreich,Shafi Goldwasser	1998	On the Limits of Non-Approximability of Lattice Problems.
STOC	A Sublinear Bipartiteness Tester for Bunded Degree Graphs.	Oded Goldreich,Dana Ron	1998	A Sublinear Bipartiteness Tester for Bunded Degree Graphs.
STOC	Honest-Verifier Statistical Zero-Knowledge Equals General Statistical Zero-Knowledge.	Oded Goldreich,Amit Sahai,Salil P. Vadhan	1998	Honest-Verifier Statistical Zero-Knowledge Equals General Statistical Zero-Knowledge.
STOC	Randomized Complexity Lower Bounds.	Dima Grigoriev	1998	Randomized Complexity Lower Bounds.
STOC	An Exponential Lower Bound for Depth 3 Arithmetic Circuits.	Dima Grigoriev,Marek Karpinski	1998	An Exponential Lower Bound for Depth 3 Arithmetic Circuits.
STOC	A Framework for Fast Quantum Mechanical Algorithms.	Lov K. Grover	1998	A Framework for Fast Quantum Mechanical Algorithms.
STOC	Poly-Logarithmic Deterministic Fully-Dynamic Algorithms for Connectivity, Minimum Spanning Tree, 2-Edge, and Biconnectivity.	Jacob Holm,Kristian de Lichtenberg,Mikkel Thorup	1998	Deterministic fully dynamic graph algorithms are presented for connectivity, minimum spanning tree, 2-edge connectivity, and biconnectivity. Assuming that we start with no edges in a graph with n vertices, the amortized operation costs are O(log2 n) for connectivity, O(log4 n) for minimum spanning forest, 2-edge connectivity, and O(log5 n) biconnectivity.
STOC	A Black Box Approach to the Algebraic Set Decomposition Problem.	Ming-Deh A. Huang,Ashwin J. Rao	1998	A Black Box Approach to the Algebraic Set Decomposition Problem.
STOC	Exact Sampling and Approximate Counting Techniques.	Mark Huber	1998	Exact Sampling and Approximate Counting Techniques.
STOC	Approximate Nearest Neighbors: Towards Removing the Curse of Dimensionality.	Piotr Indyk,Rajeev Motwani	1998	Approximate Nearest Neighbors: Towards Removing the Curse of Dimensionality.
STOC	Finding Maximum Flows in Undirected Graphs Seems Easier than Bipartite Matching.	David R. Karger,Matthew S. Levine	1998	Finding Maximum Flows in Undirected Graphs Seems Easier than Bipartite Matching.
STOC	On Broadcast Disk Paging.	Sanjeev Khanna,Vincenzo Liberatore	1998	"Broadcast disks are an emerging paradigm for massive data dissemination. In a broadcast disk, data is divided into n equal-sized pages, and pages are broadcast in a round-robin fashion by a server. Broadcast disks are effective because many clients can simultaneously retrieve any transmitted data. Paging is used by the clients to improve performance, much as in virtual memory systems. However, paging on broadcast disks differs from virtual memory paging in at least two fundamental aspects: A page fault in the broadcast disk model has a variable cost that depends on the requested page as well as the current state of the broadcast. Prefetching is both natural and a provably essential mechanism for achieving significantly better competitive ratios in broadcast disk paging. In this paper, we design a deterministic algorithm that uses prefetching to achieve an O(n log k) competitive ratio for the broadcast disk paging problem, where k denotes the size of the client's cache. We also show a matching lower bound of $\Omega(n\log k)$ that applies even when the adversary is not allowed to use prefetching. In contrast, we show that when prefetching is not allowed, no deterministic online algorithm can achieve a competitive ratio better than $\Omega(nk)$. Moreover, we show a lower bound of $\Omega(n \log k)$ on the competitive ratio achievable by any nonprefetching randomized algorithm against an oblivious adversary. These lower bounds are trivially matched from above by known results about deterministic and randomized marking algorithms for paging. An interpretation of our results is that in the broadcast disk paging, prefetching is a perfect substitute for randomization."
STOC	On Indexed Data Broadcast.	Sanjeev Khanna,Shiyu Zhou	1998	On Indexed Data Broadcast.
STOC	Decision Algorithms for Unsplittable Flow and the Half-Disjoint Paths Problem.	Jon M. Kleinberg	1998	Decision Algorithms for Unsplittable Flow and the Half-Disjoint Paths Problem.
STOC	Segmentation Problems.	Jon M. Kleinberg,Christos H. Papadimitriou,Prabhakar Raghavan	1998	We study a novel genre of optimization problems, which we call segmentation problems, motivated in part by certain aspects of clustering and data mining. For any classical optimization problem, the corresponding segmentation problem seeks to partition a set of cost vectors into several segments, so that the overall cost is optimized. We focus on two natural and interesting (but MAXSNP-complete) problems in this class, the hypercube segmentation problem and the catalog segmentation problem, and present approximation algorithms for them. We also present a general greedy scheme, which can be specialized to approximate any segmentation problem.
STOC	Weak Alternating Automata and Tree Automata Emptiness.	Orna Kupferman,Moshe Y. Vardi	1998	Weak Alternating Automata and Tree Automata Emptiness.
STOC	Efficient Search for Approximate Nearest Neighbor in High Dimensional Spaces.	Eyal Kushilevitz,Rafail Ostrovsky,Yuval Rabani	1998	We address the problem of designing data structures that allow efficient search for approximate nearest neighbors. More specifically, given a database consisting of a set of vectors in some high dimensional Euclidean space, we want to construct a space-efficient data structure that would allow us to search, given a query vector, for the closest or nearly closest vector in the database. We also address this problem when distances are measured by the L1 norm and in the Hamming cube. Significantly improving and extending recent results of Kleinberg, we construct data structures whose size is polynomial in the size of the database and search algorithms that run in time nearly linear or nearly quadratic in the dimension. (Depending on the case, the extra factors are polylogarithmic in the size of the database.)
STOC	Efficient Algorithms for Constructing Fault-Tolerant Geometric Spanners.	Christos Levcopoulos,Giri Narasimhan,Michiel H. M. Smid	1998	Efficient Algorithms for Constructing Fault-Tolerant Geometric Spanners.
STOC	Checking Polynomial Identities over any Field: Towards a Derandomization?	Daniel Lewin,Salil P. Vadhan	1998	Checking Polynomial Identities over any Field: Towards a Derandomization?
STOC	Trees and Euclidean Metrics.	Nathan Linial,Avner Magen,Michael E. Saks	1998	Trees and Euclidean Metrics.
STOC	A Deterministic Strongly Polynomial Algorithm for Matrix Scaling and Approximate Permanents.	Nathan Linial,Alex Samorodnitsky,Avi Wigderson	1998	A Deterministic Strongly Polynomial Algorithm for Matrix Scaling and Approximate Permanents.
STOC	Analysis of Low Density Codes and Improved Designs Using Irregular Graphs.	Michael Luby,Michael Mitzenmacher,Mohammad Amin Shokrollahi,Daniel A. Spielman	1998	Analysis of Low Density Codes and Improved Designs Using Irregular Graphs.
STOC	Further Algorithmic Aspects of the Local Lemma.	Michael Molloy,Bruce A. Reed	1998	Further Algorithmic Aspects of the Local Lemma.
STOC	Asymptotic Acceleration of Solving Multivariate Polynomial Systems of Equations.	Bernard Mourrain,Victor Y. Pan	1998	Asymptotic Acceleration of Solving Multivariate Polynomial Systems of Equations.
STOC	A Polynomial Approximation Algorithm for the Minimum Fill-In Problem.	Assaf Natanzon,Ron Shamir,Roded Sharan	1998	In the minimum fill-in problem, one wishes to find a set of edges of smallest size, whose addition to a given graph will make it chordal. The problem has important applications in numerical algebra and has been studied intensively since the 1970s. We give the first polynomial approximation algorithm for the problem. Our algorithm constructs a triangulation whose size is at most eight times the optimum size squared. The algorithm builds on the recent parameterized algorithm of Kaplan, Shamir, and Tarjan for the same problem.For bounded degree graphs we give a polynomial approximation algorithm with a polylogarithmic approximation ratio. We also improve the parameterized algorithm.
STOC	"Approximating Geometrical Graphs via ""Spanners"" and ""Banyans""."	Satish Rao,Warren D. Smith	1998	"Approximating Geometrical Graphs via ""Spanners"" and ""Banyans""."
STOC	Random Generation of Embedded Graphs and an Extension to Dobrushin Uniqueness (Extended Abstract).	Marcus Peinado,Thomas Lengauer	1998	Random Generation of Embedded Graphs and an Extension to Dobrushin Uniqueness (Extended Abstract).
STOC	Almost Optimal Dispersers.	Amnon Ta-Shma	1998	Almost Optimal Dispersers.
STOC	Decoding Algebraic-Geometric Codes Beyond the Error-Correction Bound.	Mohammad Amin Shokrollahi,Hal Wasserman	1998	Decoding Algebraic-Geometric Codes Beyond the Error-Correction Bound.
STOC	On Separating the Read-k-Times Branching Program Hierarchy.	Jayram S. Thathachar	1998	On Separating the Read-k-Times Branching Program Hierarchy.
STOC	Over Words, Two Variables Are as Powerful as One Quantifier Alternation.	Denis Thérien,Thomas Wilke	1998	Over Words, Two Variables Are as Powerful as One Quantifier Alternation.
STOC	Recycling Queries in PCPs and in Linearity Tests (Extended Abstract).	Luca Trevisan	1998	Recycling Queries in PCPs and in Linearity Tests (Extended Abstract).
STOC	Computing Local Dimension of a Semialgebraic Set.	Nicolai Vorobjov	1998	Computing Local Dimension of a Semialgebraic Set.
STOC	Finding Almost-Satisfying Assignments.	Uri Zwick	1998	Finding Almost-Satisfying Assignments.
STOC	Proceedings of the Thirtieth Annual ACM Symposium on the Theory of Computing, Dallas, Texas, USA, May 23-26, 1998	Jeffrey Scott Vitter	1998	Proceedings of the Thirtieth Annual ACM Symposium on the Theory of Computing, Dallas, Texas, USA, May 23-26, 1998
FOCS	ong-lived Adaptive Collect with Applications.	Yehuda Afek,Gideon Stupp,Dan Touitou	1999	ong-lived Adaptive Collect with Applications.
FOCS	Approximation Schemes for Minimizing Average Weighted Completion Time with Release Dates.	Foto N. Afrati,Evripidis Bampis,Chandra Chekuri,David R. Karger,Claire Kenyon,Sanjeev Khanna,Ioannis Milis,Maurice Queyranne,Martin Skutella,Clifford Stein,Maxim Sviridenko	1999	We consider the problem of scheduling n jobs with release dates on m machines so as to minimize their average weighted completion time. We present the first known polynomial time approximation schemes for several variants of this problem. Our results include PTASs for the case of identical parallel machines and a constant number of unrelated machines with and without preemption allowed. Our schemes are efficient: for all variants the running time for a \math approximation is of the form \math poly(n).
FOCS	Primality and Identity Testing via Chinese Remaindering.	Manindra Agrawal,Somenath Biswas	1999	We give a simple and new randomized primality testing algorithm by reducing primality testing for number n to testing if a specific univariate identity over Zn holds.We also give new randomized algorithms for testing if a multivariate polynomial, over a finite field or over rationals, is identically zero. The first of these algorithms also works over Zn for any n. The running time of the algorithms is polynomial in the size of arithmetic circuit representing the input polynomial and the error parameter. These algorithms use fewer random bits and work for a larger class of polynomials than all the previously known methods, for example, the Schwartz--Zippel test [Schwartz 1980; Zippel 1979], Chen--Kao and Lewin--Vadhan tests [Chen and Kao 1997; Lewin and Vadhan 1998].
FOCS	Efficient Testing of Large Graphs.	Noga Alon,Eldar Fischer,Michael Krivelevich,Mario Szegedy	1999	Efficient Testing of Large Graphs.
FOCS	Regular Languages Are Testable with a Constant Number of Queries.	Noga Alon,Michael Krivelevich,Ilan Newman,Mario Szegedy	1999	We continue the study of combinatorial property testing, initiated by Goldreich, Goldwasser, and Ron in [J. ACM, 45 (1998), pp. 653--750]. The subject of this paper is testing regular languages. Our main result is as follows. For a regular language $L\in \{0,1\}^*$ and an integer n there exists a randomized algorithm which always accepts a word w of length n if $w\in L$ and rejects it with high probability if $w$ has to be modified in at least $\epsilon n$ positions to create a word in L. The algorithm queries $\tilde{O}(1/\epsilon)$ bits of w. This query complexity is shown to be optimal up to a factor polylogarithmic in $1/\epsilon$. We also discuss the testability of more complex languages and show, in particular, that the query complexity required for testing context-free languages cannot be bounded by any function of $\epsilon$. The problem of testing regular languages can be viewed as a part of a very general approach, seeking to probe testability of properties defined by logical means.
FOCS	A Non-linear Time Lower Bound for Boolean Branching Programs.	Miklós Ajtai	1999	"We prove that for all positive integer k and for all sufficiently small \math if n is sufficiently large then there is no Boolean (or 2-way) branching program of size less than \math which for all inputs \math computes in time kn the parity of the number of elements of the set of all pairs x,y with the property \math. For the proof of this fact we show that if \mathn is a random n by n matrix over the field with 2 elements with the condition that ""\math, \math implies \math"" then with a high probability the rank of each \math by \math submatrix of A is at least \math, where \math is an absolute constant and n is sufficiently large with respect to \math."
FOCS	A Better Lower Bound for Quantum Algorithms Searching an Ordered List.	Andris Ambainis	1999	We show that any quantum algorithm searching an ordered list of n elements needs to examine at least log n/12-O(1) of them. Classically, log n queries are both necessary and sufficient. This shows that quantum algorithms can achieve only a constant speedup for this problem.
FOCS	Efficient Regular Data Structures and Algorithms for Location and Proximity Problems.	Arnon Amir,Alon Efrat,Piotr Indyk,Hanan Samet	1999	In this paper we investigate data-structures obtained by a recursive partitioning of the input domain into regions of equal size. One of the most well known examples of such a structure is the quadtree, used here as a basis for more complex data structures; we also provide multidimensional versions of the stratified tree by van Emde Boas [24].We show that under the assumption that the input points have limited precision (i.e. are drawn from the integer grid of size u) these data structures yield efficient solutions to many important problems. In particular, they allow us to achieve O(log log u) time per operation for dynamic approximate nearest neighbor (under insertions and deletions) and exact on-line closest pair (under insertions only) in any constant dimension. They allow O(log log u) point location in a given planar shape or in its expansion (dilation by a ball of a given radius).Finally, we provide a linear time (optimal) algorithm for computing the expansion of a shape represented by a quadtree. This result shows that the spatial order imposed by this regular data structure is sufficient to optimize the dilation by a ball operation.
FOCS	An Algorithmic Theory of Learning: Robust Concepts and Random Projection.	Rosa I. Arriaga,Santosh Vempala	1999	"We study the phenomenon of cognitive learning from an algorithmic standpoint. How does the brain effectively learn concepts from a small number of examples despite the fact that each example contains a huge amount of information? We provide a novel algorithmic analysis via a model of robust concept learning (closely related to ""margin classifiers""), and show that a relatively small number of examples are sufficient to learn rich concept classes. The new algorithms have several advantages--they are faster, conceptually simpler, and resistant to low levels of noise. For example, a robust half-space can be learned in linear time using only a constant number of training examples, regardless of the number of attributes. A general (algorithmic) consequence of the model, that ""more robust concepts are easier to learn"", is supported by a multitude of psychological studies."
FOCS	A Theoretical Framework for Memory-Adaptive Algorithms.	Rakesh D. Barve,Jeffrey Scott Vitter	1999	"External Memory algorithms play a key role in database management systems and large scale processing systems. External memory algorithms are typically tuned for efficient performance given a fixed, statically allocated amount of internal memory. However, with the advent of real-time database system and database systems based upon administratively defined goals, algorithms must increasingly be able to adapt in an online manner when the amount of internal memory allocated to them changes dynamically and unpredictably. In this paper, we present a theoretical and applicable framework for memory-adaptive algorithms (or simply MA algorithms).We define the competitive worst-case notion of what it means for an MA algorithm to be dynamically optimal and prove fundamental lower bounds on the performance of MA algorithms for problems such as sorting, standard matrix multiplication, and several related problems. Our main tool for proving dynamic optimality is the notion of resource consumption, which measures how efficiently an MA algorithm adapts itself to memory fluctuations.We present the first dynamically optimal algorithm for sorting (based upon mergesort), permuting, FFT, permutation networks, buffer trees, (standard) matrix multiplication, and LU decomposition. In each case, dynamic optimality is demonstrated via a potential function argument showing that the algorithm's resource consumption is within a constant factor of optimal."
FOCS	"Random CNF's are Hard for the Polynomial Calculus."	Eli Ben-Sasson,Russell Impagliazzo	1999	We show a general reduction that derives lower bounds on degrees of polynomial calculus proofs of tautologies over any field of characteristic other than 2 from lower bounds for resolution proofs of a related set of linear equations modulo 2. We apply this to derive linear lower bounds on the degrees of PC proofs of randomly generated tautologies.
FOCS	A 5/2 n-Lower Bound for the Rank of n×n Matrix Multiplication over Arbitrary Fields.	Markus Bläser	1999	A 5/2 n-Lower Bound for the Rank of n×n Matrix Multiplication over Arbitrary Fields.
FOCS	Finely-Competitive Paging.	Avrim Blum,Carl Burch,Adam Kalai	1999	"We construct an online algorithm for paging that achieves an O(r + log k) competitive ratio when compared to an offline strategy that is allowed the additional ability to ""rent"" pages at a cost of 1/r. In contrast, the competitive ratio of the Marking algorithm for this scenario is O(r* log k). Our algorithm can be thought of in the standard setting as having a ""fine-grained"" competitive ratio, achieving an O(1) ratio when the request sequence consists of a small number of working sets, gracefully decaying to O(log k) as this number increases.Our result is a generalization of the result in Bartal et al. [BBBT97] that one can achieve an O(r + log n) ratio for the unfair n-state uniform-space Metrical Task System problem. That result was a key component of the polylog(n) competitive randomized algorithm given in that paper for the general Metrical Task System problem. One motivation of this work is that it may be a first step toward achieving a polylog(k) randomized competitive ratio for the much more difficult k-server problem."
FOCS	A Study of Proof Search Algorithms for Resolution and Polynomial Calculus.	Maria Luisa Bonet,Nicola Galesi	1999	This paper is concerned with the complexity of proofs and of searching for proofs in two propositional proof systems: Resolution and Polynomial Calculus (PC). For the former system we show that the recently proposed algorithm of BenSasson and Wigderson (STOC 99) for searching for proofs cannot give better than weakly exponential performance. This is a consequence of showing optimality of their general relationship referred to as size-width tradeoff. We moreover obtain the optimality of the size-width tradeoff for the widely used restrictions of resolution: regular, Davis-Putnam, negative, positive and linear.As for the second system, we show that the direct translation to polynomials of a CNF formula having short resolution proofs, cannot be refuted in PC with degree less than \math. A consequence of this is that the simulation of resolution by PC of Clegg, Edmonds and Impagliazzo (STOC 92) cannot be improved to better than quasipolynomial in the case we start with small resolution proofs. We conjecture that the simulation of Clegg at al. is optimal.
FOCS	Torpid Mixing of Some Monte Carlo Markov Chain Algorithms in Statistical Physics.	Christian Borgs,Jennifer T. Chayes,Alan M. Frieze,Jeong Han Kim,Prasad Tetali,Eric Vigoda,Van H. Vu	1999	Torpid Mixing of Some Monte Carlo Markov Chain Algorithms in Statistical Physics.
FOCS	"On Universal and Fault-Tolerant Quantum Computing: A Novel Basis and a New Constructive Proof of Universality for Shor's Basis."	P. Oscar Boykin,Tal Mor,Matthew Pulver,Vwani P. Roychowdhury,Farrokh Vatan	1999	A novel universal and fault-tolerant basis (set of gates) for quantum computation is described. Such a set is necessary to perform quantum computation in a realistic noisy environment. The new basis consists of two single-qubit gates (Hadamard and \math), and one double-qubit gate (Controlled-NOT). Since the set consisting of Controlled-NOT and Hadamard gates is not universal, the new basis achieves universality by including only one additional elementary (in the sense that it does not include angles that are irrational multiples of \math) single-qubit gate, and hence, is potentially the simplest universal basis that one can construct. We also provide an alternative proof of universality for the only other known class of universal and fault-tolerant quantum basis.
FOCS	Bounds for Small-Error and Zero-Error Quantum Algorithms.	Harry Buhrman,Richard Cleve,Ronald de Wolf,Christof Zalka	1999	We present a number of results related to quantum algorithms with small error probability and quantum algorithms that are zero-error. First, we give a tight analysis of the tradeoffs between the number of queries of quantum search algorithms, their error probability, the size of the search space, and the number of solutions in this space. Using this, we deduce new lower and upper bounds for quantum versions of amplification problems. Next, we establish nearly optimal quantum-classical separations for the query complexity of monotone functions in the zero-error model (where our quantum zero-error model is defined so as to be robust when the quantum gates are noisy).Also, we present a communication complexity problem related to a total function for which there is a quantum-classical communication complexity gap in the zero-error model. Finally, we prove separations for monotone graph properties in the zero-error and other error models which imply that the evasiveness conjecture for such properties does not hold for quantum computers.
FOCS	Finding Double Euler Trails of Planar Graphs in Linear Time.	Zhi-Zhong Chen,Xin He,Chun-Hsi Huang	1999	This paper answers an open question in the design of complimentary metal-oxide semiconductor VLSI circuits. The question asks whether a polynomial-time algorithm can decide if a given planar graph has a plane embedding ${\cal E}$ such that ${\cal E}$ has an Euler trail P = e1 e2 ... em and its dual graph has an Euler trail $P^*=e^*_1 e^*_2 \ldots e^*_m$, where $e^*_i$ is the dual edge of ei for i=1,2,...,m. This paper answers this question in the affirmative by presenting a linear-time algorithm.
FOCS	Dynamic Planar Convex Hull Operations in Near-Logarithmic Amortized Time.	Timothy M. Chan	1999	We give a data structure that allows arbitrary insertions and deletions on a planar point set P and supports basic queries on the convex hull of P, such as membership and tangent-finding. Updates take O(log1+&egr;n) amori tzed time and queries take O (log n time each, where n is the maximum size of P and &egr; is any fixed positive constant. For some advanced queries such as bridge-finding, both our bounds increase to O(log3/2n). The only previous fully dynamic solution was by Overmars and van Leeuwen from 1981 and required O(log2n) time per update and O(log n) time per query.
FOCS	Improved Combinatorial Algorithms for the Facility Location and k-Median Problems.	Moses Charikar,Sudipto Guha	1999	We present improved combinatorial approximation algorithms for the uncapacitated facility location and k-median problems. Two central ideas in most of our results are cost scaling and greedy improvement. We present a simple greedy local search algorithm which achieves an approximation ratio of \math in \math time. This also yields a bicriteria approximation tradeoff of \math for facility cost versus service cost which is better than previously known tradeoffs and close to the best possible. Combining greedy improvement and cost scaling with a recent primal dual algorithm for facility location due to Jain and Vazirani, we get an approximation ratio of 1.853 in \math time. This is already very close to the approximation guarantee of the best known algorithm which is LP-based. Further, combined with the best known LP-based algorithm for facility location, we get a very slight improvement in the approximation factor for facility location, achieving 1.728. We present improved approximation algorithms for capacitated facility location and a variant.We also present a 4-approximation for the k-median problem, using similar ideas, building on the 6-approximation of Jain and Vazirani. The algorithm runs in \math time.
FOCS	Learning Mixtures of Gaussians.	Sanjoy Dasgupta	1999	We give the first provably correct algorithm for learning a mixture of Gaussians from data. The running time is only linear in the dimension of the data and polynomial in the number of Gaussians.
FOCS	Hardness of Approximating the Minimum Distance of a Linear Code.	Ilya Dumer,Daniele Micciancio,Madhu Sudan	1999	We show that the minimum distance of a linear code (or equivalently, the weight of the lightest code-word) is not approximable to within any constant factor in random polynomial time (RP), unless NP equals RP. Under the stronger assumption that NP is not contained in RQP (random quasi-polynomial time), we show that the minimum distance is not approximable to within the factor \math, for any \math, where n denotes the block length of the code.Our results hold for codes over every finite field, including the special case of binary codes. In the process we show that the nearest code-word problem is hard to solve even under the promise that the number of errors is (a constant factor) smaller than the distance of the code. This is a particularly meaningful version of the nearest code-word problem.Our results strengthen (though using stronger assumptions) a previous result of Vardy who showed that the minimum distance is NP-hard to compute exactly. Our results are obtained by adapting proofs of analogous results for integer lattices due to Ajtai and Micciancio. A critical component in the adaptation is our use of linear codes that perform better than random (linear) codes.
FOCS	Magic Functions.	Cynthia Dwork,Moni Naor,Omer Reingold,Larry J. Stockmeyer	1999	Magic Functions.
FOCS	On Counting Independent Sets in Sparse Graphs.	Martin E. Dyer,Alan M. Frieze,Mark Jerrum	1999	We prove two results concerning approximate counting of independent sets in graphs with constant maximum degree $\Delta$. The first implies that the Markov chain Monte Carlo technique is likely to fail if $\Delta \geq 6$. The second shows that no fully polynomial randomized approximation scheme can exist for $\Delta \geq 25$, unless $\mathrm{RP}=\mathrm{NP}$.
FOCS	Setting Parameters by Example.	David Eppstein	1999	"We introduce a class of ""inverse parametric optimization"" problems, in which one is given both a parametric optimization problem and a desired optimal solution; the task is to determine parameter values that lead to the given solution. We describe algorithms for solving such problems for minimum spanning trees, shortest paths, and other ""optimal subgraph"" problems and discuss applications in multicast routing, vehicle path planning, resource allocation, and board game programming."
FOCS	Approximate Nearest Neighbor Algorithms for Hausdorff Metrics via Embeddings.	Martin Farach-Colton,Piotr Indyk	1999	Hausdorff metrics are used in geometric settings for measuring the distance between sets of points. They have been used extensively in areas such as computer vision, pattern recognition and computational chemistry.While computing the distance between a single pair of sets under the Hausdorff metric has been well studied, no results were known for the Nearest Neighbor problem under Hausdorff metrics. Indeed, no results were known for the nearest neighbor problem for any metric without norm structure, of which the Hausdorff is one.We present the first nearest neighbor algorithm for the Hausdorff metric. We achieve our result by embedding Hausdorff metrics into l1 and using known nearest neighbor algorithms for this target metric. We give upper and lower bounds on the number of dimensions needed for such an l1 embedding. Our bounds require the introduction of new techniques based on superimposed codes and non-uniform sampling.
FOCS	Noncryptographic Selection Protocols.	Uriel Feige	1999	Selection tasks generalize some well studied problems, such as collective coin flipping and leader election. We present new selection protocols in the full information model, and new negative results. In particular, when there are \math good players, we show a protocol that chooses a good leader with probability \math, and show that every leader election protocol has success probability \math, for every \math. Previously known protocols for this problem have success probability that is exponentially small in \math, and no nontrivial upper bounds on the success probability were known.
FOCS	Approximating Fractional Multicommodity Flow Independent of the Number of Commodities.	Lisa Fleischer	1999	We describe fully polynomial time approximation schemes for various multicommodity flow problems in graphs with m edges and n vertices. We present the first approximation scheme for maximum multicommodity flow that is independent of the number of commodities k, and our algorithm improves upon the run time of previous algorithms by this factor of k, running in ${{\cal O}^*(\epsilon^{-2}m^2)}$ time. For maximum concurrent flow and minimum cost concurrent flow, we present algorithms that are faster than the current known algorithms when the graph is sparse or the number of commodities k is large, i.e., k > m/n. Our algorithms build on the framework proposed by Garg and Könemann [Proceedings of the 39th Annual IEEE Symposium on Foundations of Computer Science, IEEE, New York, 1998, pp. 300--309]. They are simple, deterministic, and for the versions without costs, they are strongly polynomial. The approximation guarantees are obtained by comparison with dual feasible solutions found by our algorithm.Our maximum multicommodity flow algorithm extends to an approximation scheme for the maximum weighted multicommodity flow, which is faster than those implied by previous algorithms by a factor of k/log W, where W is the maximum weight of a commodity.
FOCS	An Approximate L-Difference Algorithm for Massive Data Streams.	Joan Feigenbaum,Sampath Kannan,Martin Strauss,Mahesh Viswanathan	1999	"Massive data sets are increasingly important in a wide range of applications, including observational sciences, product marketing, and the monitoring and operations of large systems. In network operations, raw data typically arrive in streams, and decisions must be made by algorithms that make one pass over each stream, throw much of the raw data away, and produce ""synopses"" or ""sketches"" for further processing. Moreover, network-generated massive data sets are often distributed: Several different, physically separated network elements may receive or generate data streams that, together, comprise one logical data set; to be of use in operations, the streams must be analyzed locally and their synopses sent to a central operations facility. The enormous scale, distributed nature, and one-pass processing requirement on the data sets of interest must be addressed with new algorithmic techniques.We present one fundamental new technique here: a space-efficient, one-pass algorithm for approximating the L1-difference $\sum_i|a_i-b_i|$ between two functions, when the function values ai and bi are given as data streams, and their order is chosen by an adversary. Our main technical innovation, which may be of interest outside the realm of massive data stream algorithmics, is a method of constructing families $\{V_j(s)\}$ of limited-independence random variables that are range-summable, by which we mean that $\sum_{j=0}^{c-1} V_j(s)$ is computable in time polylog(c) for all seeds s. Our L1-difference algorithm can be viewed as a ""sketching"" algorithm, in the sense of [Broder et al., J. Comput. System Sci., 60 (2000), pp. 630--659], and our technique performs better than that of Broder et al. when used to approximate the symmetric difference of two sets with small symmetric difference."
FOCS	The Directed Steiner Network Problem is Tractable for a Constant Number of Terminals.	Jon Feldman,Matthias Ruhl	1999	We consider the Directed Steiner Network problem, also called the Point-to-Point Connection problem. Given a directed graph G and p pairs {(s1,t1),...,(sp,tp)} of nodes in the graph, one has to find the smallest subgraph H of G that contains paths from si to ti for all i. The problem is NP-hard for general p, since the Directed Steiner Tree problem is a special case. Until now, the complexity was unknown for constant p \geq 3. We prove that the problem is polynomially solvable if p is any constant number, even if nodes and edges in G are weighted and the goal is to minimize the total weight of the subgraph H. In addition, we give an efficient algorithm for the Strongly Connected Steiner Subgraph problem for any constant p, where given a directed graph and p nodes in the graph, one has to compute the smallest strongly connected subgraph containing the p nodes.
FOCS	Cache-Oblivious Algorithms.	Matteo Frigo,Charles E. Leiserson,Harald Prokop,Sridhar Ramachandran	1999	"This paper presents asymptotically optimal algorithms for rectangular matrix transpose, FFT, and sorting on computers with multiple levels of caching. Unlike previous optimal algorithms, these algorithms are cache oblivious: no variables dependent on hardware parameters, such as cache size and cache-line length, need to be tuned to achieve optimality. Nevertheless, these algorithms use an optimal amount of work and move data optimally among multiple levels of cache. For a cache with size Z and cache-line length L where \math the number of cache misses for an \math matrix transpose is \math. The number of cache misses for either an n-point FFT or the sorting of n numbers is \math. We also give an \math-work algorithm to multiply an \math matrix by an \math matrix that incurs \math cache faults.We introduce an `ideal-cache' model to analyze our algorithms. We prove that an optimal cache-oblivious algorithm designed for two levels of memory is also optimal for multiple levels and that the assumption of optimal replacement in the ideal-cache model can be simulated efficiently by LRU replacement. We also provide preliminary empirical results on the effectiveness of cache-oblivious algorithms in practice."
FOCS	Stochastic Load Balancing and Related Problems.	Ashish Goel,Piotr Indyk	1999	"We study the problems of makespan minimization (load balancing), knapsack, and bin packing when the jobs have stochastic processing requirements or sizes. If the jobs are all Poisson, we present a two approximation for the first problem using Graham's rule, and observe that polynomial time approximation schemes can be obtained for the last two problems. If the jobs are all exponential, we present polynomial time approximation schemes for all three problems. We also obtain quasi-polynomial time approximation schemes for the last two problems if the jobs are Bernoulli variables."
FOCS	Algorithmic Aspects of Protein Structure Similarity.	Deborah Goldman,Sorin Istrail,Christos H. Papadimitriou	1999	Algorithmic Aspects of Protein Structure Similarity.
FOCS	Cuts, Trees and l-Embeddings of Graphs.	Anupam Gupta,Ilan Newman,Yuri Rabinovich,Alistair Sinclair	1999	Cuts, Trees and l-Embeddings of Graphs.
FOCS	Taking a Walk in a Planar Arrangement.	Sariel Har-Peled	1999	We present a randomized algorithm for computing portions of an arrangement of n arcs in the plane, each pair of which intersect in at most t points. We use this algorithm to perform online walks inside such an arrangement (i.e., compute all the faces that a curve, given in an online manner, crosses) and to compute a level in an arrangement, both in an output-sensitive manner. The expected running time of the algorithm is $O(\lambda_{t+2}(m+n)\log n)$, where m is the number of intersections between the walk and the given arcs. No similarly efficient algorithm is known for the general case of arcs. For the case of lines and for certain restricted cases involving line segments, our algorithm improves the best known algorithm of [M. H. Overmars and J. van Leeuwen, J. Comput. System Sci., 23 (1981), pp. 166--204] by almost a logarithmic factor.
FOCS	Near-Optimal Conversion of Hardness into Pseudo-Randomness.	Russell Impagliazzo,Ronen Shaltiel,Avi Wigderson	1999	"Various efforts have been made in recent years to derandomize probabilistic algorithms using the complexity theoretic assumption that there exists a problem in E=dtime(2O(n)), that requires circuits of size s(n), (for some function s). These results are based on the NW-generator. For the strong lower bound \math, Impagliazzo and Wigderson get the optimal derandomization: P=BPP. However, for weaker lower bound functions s(n), these constructions fall far short of the natural conjecture for optimal derandomization, namely that bptime(t) \math dtime \math. The gap in these constructions is due to an inherent limitation on efficiency in NW-style pseudo-random generators.In this paper we are able to get derandomization in almost optimal time using any lower bound s(n). We do this by using the NW-generator in a new, more sophisticated way. We view any failure of the generator as a reduction from the given ``hard'' function to its restrictions on smaller input sizes. Thus, either the original construction works (almost) optimally, or one of the restricted functions is (almost) as hard as the original. Any such restriction can then be plugged into the NW-generator recursively. This process generates many ``candidate'' generators, and at least one is guaranteed to be ``good''. Then, to perform the approximation of the acceptance probability of the given circuit, we use ideas from Andreev Clementi and Rolim: we run a tournament between the ``candidate'' generators which yields an accurate estimate.Following Trevisan, we explore information theoretic analogs of our new construction. Trevisan used the NW-generator to construct efficient extractors. However, the inherent limitation of the NW-generator mentioned above makes the extra randomness required by that extractor suboptimal (for certain parameters). Applying our construction, we get an almost optimal disperser."
FOCS	A Sublinear Time Approximation Scheme for Clustering in Metric Spaces.	Piotr Indyk	1999	The metric 2-clustering problem is defined as follows: given a metric (X; d), partition X into two sets S1 and S2 in order to minimize the value of \math\math d(u,v) i {u,v}\math Si In this paper we show an approximation scheme for this problem.
FOCS	Primal-Dual Approximation Algorithms for Metric Facility Location and k-Median Problems.	Kamal Jain,Vijay V. Vazirani	1999	We present approximation algorithms for the metric uncapacitated facility location problem and the metric k-median problem achieving guarantees of 3 and 6 respectively. The distinguishing feature of our algorithms is their low running time: O(m log m) and O(m log m (L + log(n))) respectively, where n and m are the total number of vertices and edges in the underlying graph. The main algorithmic idea is a new extension of the primal-dual schema.
FOCS	"Lovász's Lemma for the Three-Dimensional K-Level of Concave Surfaces and its Applications."	Naoki Katoh,Takeshi Tokuyama	1999	"Lovász's Lemma for the Three-Dimensional K-Level of Concave Surfaces and its Applications."
FOCS	Limits on the Efficiency of One-Way Permutation-Based Hash Functions.	Jeong Han Kim,Daniel R. Simon,Prasad Tetali	1999	"Naor and Yung have shown that a one-bit-compressing universal one-way hash function (UOWHF) can be constructed based on a one-way permutation. This construction can be iterated to build a UOWHF which compresses by \math bits, at the cost of \math invocations of the one-way permutation. We show that this construction is not far from optimal, in the following sense: there exists an oracle relative to which there exists a one-way permutation with inversion probability \math (for any \math, but any construction of an \math-bit-compressing UOWHF requires \math invocations of the one-way permutation, on average. (For example, there exists in this relativized world a one-way permutation with inversion probability \math, but no UOWHF that invokes it fewer than \math times.) Thus any proof that a more efficient UOWHF can be derived from a one-way permutation is necessarily non-relativizing; in particular, no provable construction of a more efficient UOWHF can exist based solely on a ""black box"" one-way permutation. This result can be viewed as a partial justification for the practice of building efficient UOWHFs from stronger primitives (such as collision-intractable hash functions), rather than from weaker primitives such as one-way permutations."
FOCS	Fully Dynamic Algorithms for Maintaining All-Pairs Shortest Paths and Transitive Closure in Digraphs.	Valerie King	1999	This paper presents the first fully dynamic algorithms for maintaining all-pairs shortest paths in digraphs with positive integer weights less than b. For approximate shortest paths with an error factor of \math, for any positive constant \math, the amortized update time is O(n2 log2 n/log log n); for an error factor of \math the amortized update time is \math. For exact shortest paths the amortized update time is \math. Query time for exact and approximate shortest distances is O(1); exact and approximate paths can be generated in time proportional to their lengths.Also presented is a fully dynamic transitive closure algorithm with update time O(n2 log n) and query time O(1). The previously known fully dynamic transitive closure algorithm with fast query time has one-sided error and update time O(n2:28). The algorithms use simple data structures, and are deterministic.
FOCS	Fairness in Routing and Load Balancing.	Jon M. Kleinberg,Yuval Rabani,Éva Tardos	1999	Fairness in Routing and Load Balancing.
FOCS	Approximation Algorithms for Classification Problems with Pairwise Relationships: Metric Labeling and Markov Random Fields.	Jon M. Kleinberg,Éva Tardos	1999	"In a traditional classification problem, we wish to assign one of k labels (or classes) to each of n objects, in a way that is consistent with some observed data that we have about the problem. An active line of research in this area is concerned with classification when one has information about pairwise relationships among the objects to be classified; this issue is one of the principal motivations for the framework of Markov random fields, and it arises in areas such as image processing, biometry, and document analysis. In its most basic form, this style of analysis seeks a classification that optimizes a combinatorial function consisting of assignment costs - based on the individual choice of label we make for each object - and separation costs - based on the pair of choices we make for two ""related"" objects.We formulate a general classification problem of this type, the metric labeling problem; we show that it contains as special cases a number of standard classification frameworks, including several arising from the theory of Markov random fields. From the perspective of combinatorial optimization, our problem can be viewed as a substantial generalization of the multi-way cut problem, and equivalent to a type of uncapacitated quadratic assignment problem.We provide the first non-trivial polynomial-time approximation algorithms for a general family of classification problems of this type. Our main result is an O(log k log log k)-approximation algorithm for the metric labeling problem, with respect to an arbitrary metric on a set of k labels, and an arbitrary weighted graph of relationships on a set of objects. For the special case in which the labels are endowed with the uniform metric - all distances are the same - our methods provide a 2-approximation."
FOCS	Boosting and Hard-Core Sets.	Adam Klivans,Rocco A. Servedio	1999	"This paper connects two fundamental ideas from theoretical computer science: hard-core set construction, a type of hardness amplification from computational complexity, and boosting, a technique from computational learning theory. Using this connection we give fruitful applications of complexity-theoretic techniques to learning theory and vice versa. We show that the hard-core set construction of Impagliazzo [15], which establishes the existence of distributions under which boolean functions are highly inapproximable, may be viewed as a boosting algorithm. Using alternate boosting methods we give an improved bound for hard-core set construction which matches known lower bounds from boosting and thus is optimal within this class of techniques. We then show how to apply techniques from [15] to give a new version of Jackson's celebrated Harmonic Sieve algorithm for learning DNF formulae under the uniform distribution using membership queries. Our new version has a significant asymptotic improvement in running time. Critical to our arguments is a careful analysis of the distributions which are employed in both boosting and hard-core set constructions."
FOCS	Finding Maximal Repetitions in a Word in Linear Time.	Roman M. Kolpakov,Gregory Kucherov	1999	A repetition in a word w is a sub-word with the period of at most half of the sub-word length. We study maximal repetitions occurring in w, that is those for which any extended sub-word of w has a bigger period. The set of such repetitions represents in a compact way all repetitions in w.We first prove a combinatorial result asserting that the sum of exponents of all maximal repetitions of a word of length n is bounded by a linear function in n. This implies, in particular, that there is only a linear number of maximal repetitions in a word. This allows us to construct a linear-time algorithm for finding all maximal repetitions. Some consequences and applications of these results are discussed, as well as related works.
FOCS	Markovian Coupling vs. Conductance for the Jerrum-Sinclair Chain.	V. S. Anil Kumar,H. Ramesh	1999	We show that no Markovian Coupling argument can prove rapid mixing of the Jerrum-Sinclair Markov chain for sampling almost uniformly from the set of perfect and near perfect matchings of a given graph. In particular, we show that there exists a bipartite graph G such that any Markovian coupling argument on the Jerrum-Sinclair Markov chain for G must necessarily take time exponential in the number of vertices in G.This holds even when the coupling argument is Time-Variant, i.e., the transition probabilities used by the coupling process depend upon the history of the process. In contrast, the above Markov chain on G has been shown to mix in polynomial time using conductance arguments.
FOCS	Weak Adversaries for the k-Server Problem.	Elias Koutsoupias	1999	We study the k-server problem when the off-line algorithm has fewer than k servers. We give two upper bounds of the cost WFA(\math) of the Work Function Algorithm. The first upper bound is \math, where \math denotes the optimal cost to service \math by m servers. The second upper bound is \math for \math. Both bounds imply that the Work Function Algorithm is (2k-1)-competitive. Perhaps more important is our technique which seems promising for settling the k-server conjecture. The proofs are simple and intuitive and they do not involve potential functions. We also apply the technique to give a simple condition for the Work Function Algorithm to be k-competitive; this condition results in a new proof that the k-server conjecture holds for k=2.
FOCS	On the Complexity of SAT.	Richard J. Lipton,Anastasios Viglas	1999	In this work we show that non-deterministic time NTIME(n) is not contained in deterministic time \math and poly-logarithmic space, for any \math. This implies that (infinitely often) satisfiability cannot be solved in time \math and poly-logarithmic space. A similar result is presented for uniform circuits; a log-space uniform circuit of poly-logarithmic width computing satisfiability requires infinitely often almost quadratic size.
FOCS	Reducing Network Congestion and Blocking Probability Through Balanced Allocation.	Malwina J. Luczak,Eli Upfal	1999	We compare the performance of a variant of the standard {\it Dynamic Alternative Routing (DAR)} technique commonly used in telephone and ATM networks to a path selection algorithm that is based on the balanced allocations principle - the Balanced Dynamic Alternative Routing (BDAR) algorithm. While the standard technique checks alternative routes sequentially until available bandwidth is found, the BDAR algorithm compares and chooses the best among a small number of alternatives.We show that, at the expense of a minor increase in routing overhead, the BDAR gives a substantial improvement in network performance in terms of both network congestion and blocking probabilities.
FOCS	Verifiable Random Functions.	Silvio Micali,Michael O. Rabin,Salil P. Vadhan	1999	Verifiable Random Functions.
FOCS	Derandomizing Arthur-Merlin Games Using Hitting Sets.	Peter Bro Miltersen,N. V. Vinodchandran	1999	"We prove that AM (and hence Graph Nonisomorphism) is in NP if for some ε > 0, some language in NE ∩ coNE requires nondeterministic circuits of size 2εn. This improves results of Arvind and Köbler and of Klivans and van Melkebeek who proved the same conclusion, but under stronger hardness assumptions.The previous results on derandomizing AM were based on pseudorandom generators. In contrast, our approach is based on a strengthening of Andreev, Clementi and Rolim's hitting set approach to derandomization. As a spin-off, we show that this approach is strong enough to give an easy proof of the following implication: for some ε > 0, if there is a language in E which requires nondeterministic circuits of size 2εn, then P = BPP. This differs from Impagliazzo and Wigderson's theorem ""only"" by replacing deterministic circuits with nondeterministic ones."
FOCS	Random Walks on Truncated Cubes and Sampling 0-1 Knapsack Solutions.	Ben Morris,Alistair Sinclair	1999	"We solve an open problem concerning the mixing time of symmetric random walk on the n-dimensional cube truncated by a hyperplane, showing that it is polynomial in n. As a consequence, we obtain a fully polynomial randomized approximation scheme for counting the feasible solutions of a 0-1 knapsack problem. The results extend to the case of any fixed number of hyperplanes. The key ingredient in our analysis is a combinatorial construction we call a ""balanced almost uniform permutation,"" which is of independent interest."
FOCS	Online Scheduling to Minimize Average Stretch.	S. Muthukrishnan,Rajmohan Rajaraman,Anthony Shaheen,Johannes Gehrke	1999	We consider the classical problem of online job scheduling on uniprocessor and multiprocessor machines. For a given job, we measure the quality of service provided by an algorithm by the stretch of the job, which is defined as the ratio of the amount of time that the job spends in the system to the processing time of the job. For a given sequence of jobs, we measure the performance of an algorithm by the average stretch achieved by the algorithm over all the jobs in the sequence. The average stretch metric has been used to evaluate the performance of scheduling algorithms in many applications arising in databases, networks, and systems. The main contribution of this paper is to show that the shortest remaining processing time (SRPT) algorithm is O(1)-competitive with respect to average stretch for both uniprocessors and multiprocessors. For uniprocessors, we prove that SRPT is 2-competitive; we also establish an essentially matching lower bound on the competitive ratio of SRPT. For multiprocessors, we show that the competitive ratio of SRPT is at most $9 + 2\sqrt{6} \le 14$. Furthermore, we establish constant-factor lower bounds on the competitive ratio of any online algorithm for both uniprocessors and multiprocessors.
FOCS	Optimal Lower Bounds for Quantum Automata and Random Access Codes.	Ashwin Nayak	1999	"Consider the finite regular language \math. In [3] it was shown that while this language is accepted by a deterministic finite automaton of size O(n), any one-way quantum finite automaton (QFA) for it has size \math . This was based on the fact that the evolution of a QFA is required to be reversible. When arbitrary intermediate measurements are allowed, this intuition breaks down. Nonetheless, we show a \math lower bound for such QFA for Ln , thus also improving the previous bound.The improved bound is obtained from simple entropy arguments based on Holevo's theorem [8]. This method also allows us to obtain an asymptotically optimal (1 - H(p))n bound for the dense quantum codes (random access codes) introduced in [3]. We then turn to Holevo's theorem, and show that in typical situations, it may be replaced by a tighter and more transparent in-probability bound."
FOCS	A Near-Tight Lower Bound on the Time Complexity of Distributed MST Construction.	David Peleg,Vitaly Rubinovich	1999	This paper presents a lower bound of [(W)\tilde](D+On) on the time required for the distributed construction of a minimum-weight spanning tree (MST) in weighted n-vertex networks of diameter D = W(logn), in the bounded message model. This establishes the asymptotic near-optimality of existing time-efficient distributed algorithms for the problem, whose complexity is O(D + On log* n).
FOCS	Satisfiability of Word Equations with Constants is in PSPACE.	Wojciech Plandowski	1999	We prove that satisfiability problem for word equations is in PSPACE.
FOCS	Error Reduction for Extractors.	Ran Raz,Omer Reingold,Salil P. Vadhan	1999	We present a general method to reduce the error of any extractor. Our method works particularly well in the case that the original extractor extracts up to a constant fraction of the source min-entropy and achieves a polynomially small error. In that case, we are able to reduce the error to (almost) any \math, using only \math additional truly random bits (while keeping the other parameters of the original extractor more or less the same). In other cases (e.g. when the original extractor extracts all the min-entropy or achieves only a constant error) our method is not optimal but it is still quite efficient and leads to improved constructions of extractors.Using our method, we are able to improve almost all known extractors in the case where the error required is relatively small (e.g. less than polynomially small error). In particular, we apply our method to the new extractors of [Tre99,RRV99] to get improved constructions in almost all cases. Specifically, we obtain extractors that work for sources of any min-entropy on strings of length n which: (a) extract any \math fraction of the min-entropy using \math truly random bits (\math), (b) extract any constant fraction of the min-entropy using \math truly random bits, and (c) extract all the min-entropy using \math truly random bits.
FOCS	Non-Malleable Non-Interactive Zero Knowledge and Adaptive Chosen-Ciphertext Security.	Amit Sahai	1999	We introduce the notion of non-malleable non-interactive zero-knowledge (NIZK) proof systems. We show how to transform any ordinary NIZK proof system into one that has strong non-malleability properties. We then show that the elegant encryption scheme of Naor and Yung can be made secure against adaptive chosen-ciphertext attack by using a non-malleable NIZK proof instead of a standard NIZK proof.Our encryption scheme is simple to describe and works in the standard cryptographic model under general assumptions. The encryption scheme can be realized assuming the existence of trapdoor permutations.
FOCS	Non-Interactive CryptoComputing For NC.	Tomas Sander,Adam Young,Moti Yung	1999	"The area of ""computing with encrypted data"" has been studied by numerous authors in the past twenty years since it is fundamental to understanding properties of encryption and it has many practical applications. The related fundamental area of ""secure function evaluation"" has been studied since the mid 80's. In its basic two-party case, two parties (Alice and Bob) evaluate a known circuit over private inputs (or a private input and a private circuit). Much attention has been paid to the important issue of minimizing rounds of computation in this model. Namely, the number of communication rounds in which Alice and Bob need to engage in to evaluate a circuit on encrypted data securely. Advancements in these areas have been recognized as open problems and have remained open for a number of years. In this paper we give a one round, and thus round optimal, protocol for secure evaluation of circuits which is in polynomial-time for NC1 circuits. The protocol involves an input party sending encrypted input to a second party, a cryptocomputer, which evaluates the circuit (or a known circuit over its additional private input) non-interactively, securely and obliviously, and provides the output to the input party without learning it.This improves on previous (general) results that are specialized to the case of NC1 circuits and require a constant number of communication rounds. We further suggest applications to network and mobile computing. The scenario also coincides with computing with encrypted data when the input is transformed into an output while remaining encrypted throughout the computation.New techniques are required for our highly constrained non-interactive setting. Naturally, some of these techniques are related to special properties of encryption schemes (we in fact, need probabilistic encryption schemes which are random self-reducible). Homomorphic encryption schemes are closely related to and useful in secure circuit evaluation. They have been associated with computations with encrypted data (as well as with many other cryptographic applications). Surprisingly, the known homomorphic schemes have been limited to a small number of algebraic structures, e.g. all the schemes we are aware of are homomorphic over groups. We also give a new provably secure public key scheme that allows the computation of the logical AND operation using encrypted data. This scheme is homomorphic over a semigroup (instead of a group) and thus also expands the range of algebraic structures which can be encrypted ""homomorphically""."
FOCS	A Probabilistic Algorithm for k-SAT and Constraint Satisfaction Problems.	Uwe Schöning	1999	We present a simple probabilistic algorithm for solving k-SAT, and more generally, for solving constraint satisfaction problems (CSP). The algorithm follows a simple local-search paradigm: randomly guess an initial assignment and then, guided by those clauses (constraints) that are not satisfied, by successively choosing a random literal from such a clause and flipping the corresponding bit, try to find a satisfying assignment. If no satisfying assignment is found after O(n) steps, start over again. Our analysis shows that for any satisfiable k-CNF formula with n variables this process has to be repeated only t times, on the average, to find a satisfying assignment, where t is within a polynomial factor of (2(1-1/k))n. This is the fastest (and also the simplest) algorithm for 3-SAT known up to date. We consider also the more general case of a CSP with n variables, each variable taking at most d values, and constraints of order l, and analyze the complexity of the corresponding (generalized) algorithm. It turns out that any CSP can be solved with complexity about (d(1-1/l))n.
FOCS	All Pairs Shortest Paths in Undirected Graphs with Integer Weights.	Avi Shoshan,Uri Zwick	1999	We show that the All Pairs Shortest Paths (APSP) problem for undirected graphs with integer edge weights taken from the range \math can be solved using only a logarithmic number of distance products of matrices with elements in the range \math. As a result, we get an algorithm for the APSP problem in such graphs that runs in \math$ time, where n is the number of vertices in the input graph, M is the largest edge weight in the graph, and \math is the exponent of matrix multiplication. This improves, and also simplifies, an \math time algorithm of Galil and Margalit.
FOCS	Hardness of Approximating Sigma Minimization Problems.	Christopher Umans	1999	Hardness of Approximating Sigma Minimization Problems.
FOCS	Improved Bounds for Sampling Colorings.	Eric Vigoda	1999	We consider the problem of sampling uniformly from the set of proper k-colorings of a graph with maximum degree \math. Our main result is the design of a simple Markov chain that converges in O(nk logn) time to the desired distribution when \math.
FOCS	How Asymmetry Helps Load Balancing.	Berthold Vöcking	1999	"This paper deals with balls and bins processes related to randomized load balancing, dynamic resource allocation, and hashing. Suppose n balls have to be assigned to n bins, where each ball has to be placed without knowledge about the distribution of previously placed balls. The goal is to achieve an allocation that is as even as possible so that no bin gets much more balls than the average. A well known and good solution for this problem is to choose d possible locations for each ball at random, to look into each of these bins, and to place the ball into the least full among these bins. This class of algorithms has been investigated intensively in the past, but almost all previous analyses assume that the d locations for each ball are chosen uniformly and independently at random from the set of all bins.We investigate whether a non-uniform and possibly dependent choice of the d locations for a ball can improve the load balancing. Three types of selections are distinguished: 1) uniform and independent 2) non-uniform and independent 3) non-uniform and dependent. Our first result shows that choosing the locations in a non-uniform way (type 2) results in a better load balancing than choosing the locations uniformly (type 1). Surprisingly, this smooth load balancing is obtained by an algorithm called ""Always-Go-Left"" which creates an asymmetric assignment of the balls to the binsOur second result is a lower bound on the smallest possible maximum load that can be achieved by any allocation algorithm of type 1, 2, or 3. Our upper and lower bounds are tight up to a small additive constant, showing that the Always-Go-Left scheme achieves almost the optimal load balancing. Furthermore, we show that our upper bound can be generalized to infinite processes in which balls are inserted and deleted by an adversary."
FOCS	PSPACE Has Constant-Round Quantum Interactive Proof Systems.	John Watrous	1999	In this paper we introduce quantum interactive proof systems, which are interactive proof systems in which the prover and verifier may perform quantum computations and exchange quantum messages. It is proved that every language in PSPACE has a quantum interactive proof system that requires a total of only three messages to be sent between the prover and verifier and has exponentially small (one-sided) probability of error. It follows that quantum interactive proof systems are strictly more powerful than classical interactive proof systems in the constant-round case unless the polynomial time hierarchy collapses to the second level.
FOCS	On Quantum and Classical Space-bounded Processes with Algebraic Transition Amplitudes.	John Watrous	1999	We define a class of stochastic processes based on evolutions and measurements of quantum systems, and consider the complexity of predicting their long-term behavior. It is shown that a very general class of decision problems regarding these stochastic processes can be efficiently solved classically in the space-bounded case. The following corollaries are implied by our main result for any space-constructible, not sub-logarithmic space bound s.Any space O(s) uniform family of quantum circuit acting on s qubits and consisting of unitary gates and measurement gates defined in a typical way by matrices of algebraic numbers can be simulated by an unbounded error space O(s) ordinary (i.e., fair-coin flipping) probabilistic Turing machine, and hence by space O(s) uniform classical (deterministic) circuits of depth O(s2) and size 2O(s). The quantum circuits are not required to operate with bounded error and may have depth exponential in s.Any quantum Turing machine running in space s, having arbitrary algebraic transition amplitudes, allowing unrestricted measurements during its computation, and having no restrictions on running time can be simulated by a space O(s) ordinary probabilistic Turing machine in the unbounded error setting.We also obtain the following classical result: Any unbounded error probabilistic Turing machine running in space s that allows algebraic probabilities and algebraic cut-point can be simulated by a space O(s) ordinary probabilistic Turing machine with cut-point 1/2. Our technique for handling algebraic numbers in the above simulations may be of independent interest. It is shown that any real algebraic number can be accurately approximated by a ratio of GapL functions.
FOCS	Edge-Disjoint Routing in Plane Switch Graphs in Linear Time.	Karsten Weihe	1999	"By a switch graph we mean an undirected graph such that some vertices (the plugs) have degree one and all other vertices (the switches) have even degrees. We call a switch graph plane if it is planar and can be embedded such that all plugs are in the outer face. Given a set of pairs of plugs, the problem is to find as many edge-disjoint paths such that every path connects one of these pairs.The best asymptotic worst-case complexity known so far is quadratic in the number of vertices. In this paper, a linear, and thus asymptotically optimal, algorithm is introduced. This result may be viewed as a concluding ""keystone"" for a number of previous results on various special cases of the problem."
FOCS	"40th Annual Symposium on Foundations of Computer Science, FOCS '99, 17-18 October, 1999, New York, NY, USA"		1999	"40th Annual Symposium on Foundations of Computer Science, FOCS '99, 17-18 October, 1999, New York, NY, USA"
SODA	Beating the Logarithmic Lower Bound: Randomized Preemptive Disjoint Paths and Call Control Algorithms.	Ran Adler,Yossi Azar	1999	We consider the maximum disjoint paths problem and its generalization, the call control problem, in the on-line setting. In the maximum disjoint paths problem, we are given a sequence of connection requests for some communication network. Each request consists of a pair of nodes, that wish to communicate over a path in the network. The request has to be immediately connected or rejected, and the goal is to maximize the number of connected pairs, such that no two paths share an edge. In the call control problem, each request has an additional bandwidth specification, and the goal is to maximize the total bandwidth of the connected pairs (throughput), while satisfying the bandwidth constraints (assuming each edge has unit capacity). These classical problems are central in routing and admission control in high speed networks and in optical networks.We present the first known constant-competitive algorithms for both problems on the line. This settles an open problem of Garay et al. and of Leonardi. Moreover, to the best of our knowledge, all previous algorithms for any of these problems, are Ω(log n)-competitive, where n is the number of vertices in the network (and obviously noncompetitive for the continuous line). Our algorithms are randomized and preemptive. Our results should be contrasted with the Ω(log n) lower bounds for deterministic preemptive algorithms of Garay et al. and the Ω(log n) lower bounds for randomized non-preemptive algorithms of Lipton and Tomkins and Awerbuch et al. Interestingly, nonconstant lower bounds were proved by Canetti and Irani for randomized preemptive algorithms for related problems but not for these exact problems.
SODA	I/O-Efficient Dynamic Point Location in Monotone Planar Subdivisions.	Pankaj K. Agarwal,Lars Arge,Gerth Stølting Brodal,Jeffrey Scott Vitter	1999	I/O-Efficient Dynamic Point Location in Monotone Planar Subdivisions.
SODA	Playing Twenty Questions with a Procrastinator.	Andris Ambainis,Stephen A. Bloch,David L. Schweizer	1999	Playing Twenty Questions with a Procrastinator.
SODA	Motion Planning of a Ball Amid Segments in Three Dimensions.	Pankaj K. Agarwal,Micha Sharir	1999	Motion Planning of a Ball Amid Segments in Three Dimensions.
SODA	Inverse Inbreeding Coefficient Problems with an Application to Linkage Analysis of Recessive Diseases in Inbred Populations.	Richa Agarwala,Leslie G. Biesecker,Alejandro A. Schäffer	1999	Inverse Inbreeding Coefficient Problems with an Application to Linkage Analysis of Recessive Diseases in Inbred Populations.
SODA	Interleaved Prefetching.	Tracy Kimbrel	1999	Interleaved Prefetching.
SODA	A New Way to Use Semidefinite Programming with Applications to Linear Equations mod .	Gunnar Andersson,Lars Engebretsen,Johan Håstad	1999	A New Way to Use Semidefinite Programming with Applications to Linear Equations mod .
SODA	Page Replacement for General Caching Problems.	Susanne Albers,Sanjeev Arora,Sanjeev Khanna	1999	Page Replacement for General Caching Problems.
SODA	Exploring Unknown Environments with Obstacles.	Susanne Albers,Klaus Kursawe,Sven Schuierer	1999	Exploring Unknown Environments with Obstacles.
SODA	The Advantages of Forward Thinking in Generating Rooted and Free Trees.	Gang Li,Frank Ruskey	1999	The Advantages of Forward Thinking in Generating Rooted and Free Trees.
SODA	A Practical Clustering Algorithm for Static and Dynamic Information Organization.	Javed A. Aslam,Katya Pelekhov,Daniela Rus	1999	A Practical Clustering Algorithm for Static and Dynamic Information Organization.
SODA	Improved Bicriteria Existence Theorems for Scheduling.	Javed A. Aslam,April Rasala,Clifford Stein,Neal E. Young	1999	Improved Bicriteria Existence Theorems for Scheduling.
SODA	Group Signatures .	Giuseppe Ateniese,Gene Tsudik	1999	Group Signatures .
SODA	Cooperative Sharing and Asynchronous Consensus Using Single-Reader Single-Writer Registers.	Yonatan Aumann,Avivit Kapah-Levy	1999	Cooperative Sharing and Asynchronous Consensus Using Single-Reader Single-Writer Registers.
SODA	Computing Morse Functions on Triangulated Manifolds.	Ulrike Axen	1999	Computing Morse Functions on Triangulated Manifolds.
SODA	Algorithms for Total Weighted Completion Time Scheduling.	Ivan D. Baev,Waleed Meleis,Alexandre E. Eichenberger	1999	Algorithms for Total Weighted Completion Time Scheduling.
SODA	Parameterized diff.	Brenda S. Baker	1999	Parameterized diff.
SODA	Using Homogenous Weights for Approximating the Partial Cover Problem.	Reuven Bar-Yehuda	1999	Using Homogenous Weights for Approximating the Partial Cover Problem.
SODA	"A Lower Bound for Hellbronn's Triangle Problem in Dimensions."	Gill Barequet	1999	"In this paper we show a lower bound for the generalization of Heilbronn's triangle problem to d dimensions; namely, we show that there exists a set S of n points in the d-dimensional unit cube so that every d+1 points of S define a simplex of volume $\Omega (\frac{1}{n^d})$. We also show a constructive incremental positioning of n points in a unit 3-cube for which every tetrahedron defined by four of these points has volume $\Omega (\frac{1}{n^4})$."
SODA	Efficiently Approximating the Minimum-Volume Bounding Box of a Point Set in Three Dimensions.	Gill Barequet,Sariel Har-Peled	1999	Efficiently Approximating the Minimum-Volume Bounding Box of a Point Set in Three Dimensions.
SODA	Polygon-containment and Translational min-Hausdorff-Distance between segment Sets are 3SUM-hard.	Gill Barequet,Sariel Har-Peled	1999	Polygon-containment and Translational min-Hausdorff-Distance between segment Sets are 3SUM-hard.
SODA	Fast, Fair, and Frugal Bandwidth Allocation in ATM Networks.	Yair Bartal,Martin Farach-Colton,Shibu Yooseph,Lisa Zhang	1999	Fast, Fair, and Frugal Bandwidth Allocation in ATM Networks.
SODA	Kinetic Collision Detection Between Two Simple Polygons.	Julien Basch,Jeff Erickson,Leonidas J. Guibas,John Hershberger,Li Zhang	1999	We design a kinetic data structure for detecting collisions between two simple polygons in motion. In order to do so, we create a planar subdivision of the free space between the two polygons, called the external relative geodesic triangulation, which certifies their disjointness. We show how this subdivision can be maintained as a kinetic data structure when the polygons are moving, and analyze its performance in the kinetic setting.
SODA	Finding Maximum Independent Sets in Sparse and General Graphs.	Richard Beigel	1999	Finding Maximum Independent Sets in Sparse and General Graphs.
SODA	Locally Efficient On-Line Strategies for Routing Packets Along Fixed Paths.	Petra Berenbrink,Christian Scheideler	1999	Locally Efficient On-Line Strategies for Routing Packets Along Fixed Paths.
SODA	Optimal Multichannel Communication Under Failure.	Tanya Y. Berger-Wolf,Edward M. Reingold	1999	Optimal Multichannel Communication Under Failure.
SODA	A Wide-Range Efficient Algorithm for Minimal Triangulation.	Anne Berry	1999	A Wide-Range Efficient Algorithm for Minimal Triangulation.
SODA	Queries with Segments in Voronoi Diagrams.	Sergei Bespamyatnikh,Jack Snoeyink	1999	Queries with Segments in Voronoi Diagrams.
SODA	The Full Degree Spanning Tree Problem.	Randeep Bhatia,Samir Khuller,Robert Pless,Yoram J. Sussmann	1999	The Full Degree Spanning Tree Problem.
SODA	"Efficient Algorithms for Petersen's Matching Theorem."	Therese C. Biedl,Prosenjit Bose,Erik D. Demaine,Anna Lubiw	1999	"Efficient Algorithms for Petersen's Matching Theorem."
SODA	Locked and Unlocked Polygonal Chains in 3D.	"Therese C. Biedl,Erik D. Demaine,Martin L. Demaine,Sylvain Lazard,Anna Lubiw,Joseph O'Rourke,Mark H. Overmars,Steve Robbins,Ileana Streinu,Godfried T. Toussaint,Sue Whitesides"	1999	Locked and Unlocked Polygonal Chains in 3D.
SODA	A Formal Treatment of Remotely Keyed Encryption.	Matt Blaze,Joan Feigenbaum,Moni Naor	1999	A Formal Treatment of Remotely Keyed Encryption.
SODA	"Stop Minding Your p's and q's: A Simplified () Planar Embedding Algorithm."	John M. Boyer,Wendy J. Myrvold	1999	"Stop Minding Your p's and q's: A Simplified () Planar Embedding Algorithm."
SODA	Unscrambling Address Lines.	Andrei Z. Broder,Michael Mitzenmacher,Laurent Moll	1999	Unscrambling Address Lines.
SODA	Fast Algorithms for Constructing Optimal Trees from Quartets.	David Bryant,Mike A. Steel	1999	Fast Algorithms for Constructing Optimal Trees from Quartets.
SODA	Some Graphic Uses of an Even Number of Odd Nodes.	Kathie Cameron,Jack Edmonds	1999	Some Graphic Uses of an Even Number of Odd Nodes.
SODA	A Small Universal Graph for Bounded-degree Planar Graphs.	Michael R. Capalbo	1999	A Small Universal Graph for Bounded-degree Planar Graphs.
SODA	A Near-Linear Area Bound for Drawing Binary Trees.	Timothy M. Chan	1999	A Near-Linear Area Bound for Drawing Binary Trees.
SODA	Greedy Local Improvement and Weighted Set Packing Approximation.	Barun Chandra,Magnús M. Halldórsson	1999	Greedy Local Improvement and Weighted Set Packing Approximation.
SODA	Minimizing Wirelength in Zero and Bounded Skew Clock Trees.	Moses Charikar,Jon M. Kleinberg,Ravi Kumar,Sridhar Rajagopalan,Amit Sahai,Andrew Tomkins	1999	An important problem in VLSI design is distributing a clock signal to synchronous elements in a VLSI circuit so that the signal arrives at all elements simultaneously. The signal is distributed by means of a clock routing tree rooted at a global clock source. The difference in length between the longest and shortest root-leaf path is called the skew of the tree. The problem is to construct a clock tree with zero skew (to achieve synchronicity) and minimal sum of edge lengths (so that circuit area and clock tree capacitance are minimized).We give the first constant-factor approximation algorithms for this problem and its variants that arise in the VLSI context. For the zero skew problem in general metric spaces, we give an approximation algorithm with a performance guarantee of 2e. For the L1 version on the plane, we give an (8/ln 2)-approximation algorithm.
SODA	On Multi-Dimensional Packing Problems.	Chandra Chekuri,Sanjeev Khanna	1999	On Multi-Dimensional Packing Problems.
SODA	Minimizing Weighted Completion Time on a Single Machine.	Chandra Chekuri,Rajeev Motwani	1999	Minimizing Weighted Completion Time on a Single Machine.
SODA	Nonplanar Topological Inference and Political-Map Graphs.	Zhi-Zhong Chen,Xin He,Ming-Yang Kao	1999	Nonplanar Topological Inference and Political-Map Graphs.
SODA	Approximate Minimum Weight Steiner Triangulation in Three Dimensions.	Siu-Wing Cheng,Tamal K. Dey	1999	Approximate Minimum Weight Steiner Triangulation in Three Dimensions.
SODA	Two-Point Euclidean Shortest Path Queries in the Plane.	Yi-Jen Chiang,Joseph S. B. Mitchell	1999	Two-Point Euclidean Shortest Path Queries in the Plane.
SODA	On the Parallel Time Complexity of Undirected Connectivity and Minimum Spanning Trees.	Ka Wong Chong,Yijie Han,Tak Wah Lam	1999	On the Parallel Time Complexity of Undirected Connectivity and Minimum Spanning Trees.
SODA	Improved Approximation Algorithms for a Capacitated Facility Location Problem.	Fabián A. Chudak,David B. Shmoys	1999	Improved Approximation Algorithms for a Capacitated Facility Location Problem.
SODA	Fluid Limits, Bin Packing, and Stochastic Analysis of Algorithms.	Edward G. Coffman Jr.,Alexander L. Stolyar	1999	Fluid Limits, Bin Packing, and Stochastic Analysis of Algorithms.
SODA	Scheduling Calls for Multicasting in Tree-Networks.	Johanne Cohen,Pierre Fraigniaud,Margarida Mitjana	1999	Scheduling Calls for Multicasting in Tree-Networks.
SODA	LP-based Analysis of Greedy-dual-size.	Edith Cohen,Haim Kaplan	1999	LP-based Analysis of Greedy-dual-size.
SODA	Dynamic LCA Queries on Trees.	Richard Cole,Ramesh Hariharan	1999	"We show how to maintain a data structure on trees which allows for the following operations, all in worst-case constant time: insertion of leaves and internal nodes, deletion of leaves, deletion of internal nodes with only one child, determining the least common ancestor of any two nodes. We also generalize the Dietz--Sleator ""cup-filling"" scheduling methodology, which may be of independent interest."
SODA	Tree Pattern Matching and Subset Matching in Deterministic ( log )-time.	Richard Cole,Ramesh Hariharan,Piotr Indyk	1999	Tree Pattern Matching and Subset Matching in Deterministic ( log )-time.
SODA	LBFS Orderings and Cocomparability Graphs.	Derek G. Corneil,Stephan Olariu,Lorna Stewart	1999	LBFS Orderings and Cocomparability Graphs.
SODA	Compact Routing with Minimum Stretch.	Lenore Cowen	1999	Compact Routing with Minimum Stretch.
SODA	Compact Roundtrip Routing for Digraphs.	Lenore Cowen,Christopher G. Wagner	1999	Compact Roundtrip Routing for Digraphs.
SODA	Existence of Multiplicative Secret Sharing Schemes with Polynomial Share Expansion.	Giovanni Di Crescenzo,Yair Frankel	1999	Existence of Multiplicative Secret Sharing Schemes with Polynomial Share Expansion.
SODA	Recovering Evolutionary Trees Through Harmonic Greedy Triplets.	Miklós Csürös,Ming-Yang Kao	1999	Recovering Evolutionary Trees Through Harmonic Greedy Triplets.
SODA	Delayed Path Coupling and Generating Random Permutations via Distributed Stochastic Processes.	Artur Czumaj,Przemyslawa Kanarek,Miroslaw Kutylowski,Krzysztof Lorys	1999	Delayed Path Coupling and Generating Random Permutations via Distributed Stochastic Processes.
SODA	On Approximability of the Minimum-Cost -Connected Spanning Subgraph Problem.	Artur Czumaj,Andrzej Lingas	1999	On Approximability of the Minimum-Cost -Connected Spanning Subgraph Problem.
SODA	Parallel Virtual Memory.	Frank K. H. A. Dehne,Wolfgang Dittrich,David A. Hutchinson,Anil Maheshwari	1999	Parallel Virtual Memory.
SODA	Folding and One Straight Cut Suffice.	Erik D. Demaine,Martin L. Demaine,Anna Lubiw	1999	Folding and One Straight Cut Suffice.
SODA	A Simple Provable Algorithm for Curve Reconstruction.	Tamal K. Dey,Piyush Kumar	1999	A Simple Provable Algorithm for Curve Reconstruction.
SODA	The 2-Catalog Segmentation Problem.	Yevgeniy Dodis,Venkatesan Guruswami,Sanjeev Khanna	1999	The 2-Catalog Segmentation Problem.
SODA	Clustering in Large Graphs and Matrices.	Petros Drineas,Alan M. Frieze,Ravi Kannan,Santosh Vempala,V. Vinay	1999	Clustering in Large Graphs and Matrices.
SODA	Balanced Aspect Ratio Trees: Combining the Advantages of -d Trees and Octrees.	Christian A. Duncan,Michael T. Goodrich,Stephen G. Kobourov	1999	Balanced Aspect Ratio Trees: Combining the Advantages of -d Trees and Octrees.
SODA	Incremental and Decremental Maintenance of Planar Width.	David Eppstein	1999	Incremental and Decremental Maintenance of Planar Width.
SODA	Shortest Paths in an Arrangement with Line Orientations.	David Eppstein,David Hart	1999	Shortest Paths in an Arrangement with Line Orientations.
SODA	Randomized Online Scheduling on Two Uniform Machines.	Leah Epstein,John Noga,Steven S. Seiden,Jiri Sgall,Gerhard J. Woeginger	1999	Randomized Online Scheduling on Two Uniform Machines.
SODA	Separation-Sensitive Collision Detection for Convex Objects.	Jeff Erickson,Leonidas J. Guibas,Jorge Stolfi,Li Zhang	1999	Separation-Sensitive Collision Detection for Convex Objects.
SODA	Simplicity and Hardness of the Maximum Traveling Salesman Problem Under Geometric Distances.	Sándor P. Fekete	1999	Simplicity and Hardness of the Maximum Traveling Salesman Problem Under Geometric Distances.
SODA	Optimal Node-Degree Bounds for the Complexity of Nonplanarity Parameters.	Celina M. Herrera de Figueiredo,Luerbio Faria,Candido Ferreira Xavier de Mendonça Neto	1999	Optimal Node-Degree Bounds for the Complexity of Nonplanarity Parameters.
SODA	Checking Priority Queues.	Ulrich Finkler,Kurt Mehlhorn	1999	Checking Priority Queues.
SODA	Optimal Construction of Edge-Disjoint Paths in Random Regular Graphs.	Alan M. Frieze,Lei Zhao	1999	"Given a graph G = (V, E) and a set of &kappa; pairs of vertices in V, we are interested in finding, for each pair (ai, bi), a path connecting ai to bi such that the set of &kappa; paths so found is edge-disjoint. (For arbitrary graphs the problem is &Nscr;&Pscr;-complete, although it is in &Pscr; if &kappa; is fixed.)We present a polynomial time randomized algorithm for finding edge-disjoint paths in the random regular graph Gn,r, for sufficiently large r. (The graph is chosen first, then an adversary chooses the pairs of end-points.) We show that almost every Gn,r is such that all sets of &kappa; = &Omega;(n&#x002F;log n) pairs of vertices can be joined. This is within a constant factor of the optimum."
SODA	Randomized Splay Trees.	Martin Fürer	1999	Randomized Splay Trees.
SODA	How to Make a Square Grid Framework with Cables Rigid.	Harold N. Gabow,Tibor Jordán	1999	This paper solves the problem of making a bipartite digraph strongly connected by adding the smallest number of new edges that preserve bipartiteness. A result of Baglivo and Graver shows that this corresponds to making a two-dimensional square grid framework with cables rigid by adding the smallest number of new cables. We prove a min-max formula for the smallest number of new edges in the digraph problem and give a corresponding linear-time algorithm. We generalize these results to the problem of making an arbitrary digraph strongly connected by adding the smallest number of new edges, each of which joins vertices in distinct blocks of a given partition of the vertex set.
SODA	Efficient Approximation Algorithms for the Hamming Center Problem.	Leszek Gasieniec,Jesper Jansson,Andrzej Lingas	1999	Efficient Approximation Algorithms for the Hamming Center Problem.
SODA	Algorithms for Compile-Time Memory Optimization.	Jordan Gergov	1999	Algorithms for Compile-Time Memory Optimization.
SODA	Synopsis Data Structures for Massive Data Sets.	Phillip B. Gibbons,Yossi Matias	1999	Synopsis Data Structures for Massive Data Sets.
SODA	Stability of Networks and Protocols in the Adversarial Queueing Model for Packet Routing.	Ashish Goel	1999	The adversarial queueing theory model for packet routing was suggested by Borodin et al. We give a complete and simple characterization of all networks that are universally stable in this model. We show that a specific greedy protocol, SIS (Shortest In System), is stable against a large class of stochastic adversaries. New applications such as multicast packet scheduling and job scheduling with precedence constraints xsare suggested for the adversarial model.
SODA	Two-Dimensional Gantt Charts and a Scheduling Algorithm of Lawler.	Michel X. Goemans,David P. Williamson	1999	"In this note we give an alternate proof that a scheduling algorithm of Lawler [E. L. Lawler, Ann. Discrete Math., 2 (1978), pp. 75--90, E. L. Lawler and J. K. Lenstra, in Ordered Sets, I. Rival, ed., D. Reidel, 1982, pp. 655--675] finds the optimal solution for the scheduling problem $1 | prec | \sum_j w_j C_j$ when the precedence constraints are series-parallel. We do this by using a linear programming formulation of $1 | prec | \sum_j w_j C_j$ introduced by Queyranne and Wang. [ Math. Oper. Res., 16 (1991), pp. 1--20]. Queyranne and Wang proved that their formulation completely describes the scheduling polyhedron in the case of series-parallel constraints; a by-product of our proof of correctness of Lawler's algorithm is an alternate proof of this fact. In the course of our proof it is helpful to use what might be called two-dimensional (2D) Gantt charts. We think these may find independent use, and to illustrate this we show that some recent work in the area becomes transparent using 2D Gantt charts."
SODA	The Complexity of Gene Placement.	Leslie Ann Goldberg,Paul W. Goldberg,Mike Paterson,Pavel A. Pevzner,Süleyman Cenk Sahinalp,Elizabeth Sweedyk	1999	The Complexity of Gene Placement.
SODA	Cut Tree Algorithms.	Andrew V. Goldberg,Kostas Tsioutsiouliklis	1999	Cut Tree Algorithms.
SODA	Combinatorial Algorithms Test Sets [CATS]: The ACM/EATCS Platform for Experimental Research.	Andrew V. Goldberg,Bernard M. E. Moret	1999	Combinatorial Algorithms Test Sets [CATS]: The ACM/EATCS Platform for Experimental Research.
SODA	Patience is a Virtue: The Effect of Slack on Competitiveness for Admission Control.	Michael H. Goldwasser	1999	"We consider the online competitiveness for scheduling a single resource non-preemptively in order to maximize its utilization. Our work examines this model when parameterizing an instance by a new value which we term the patience. This parameter measures each job's willingness to endure a delay before starting, relative to this same job's processing time. Specifically, the slack of a job is defined as the gap between its release time and the last possible time at which it may be started while still meeting its deadline. We say that a problem instance has patience κ, if each job with length ||J|| has a slack of at least κ ċ ||J||.Without any restrictions placed on the job characteristics, previous lower bounds show that no algorithm, deterministic or randomized, can guarantee a constant bound on the competitiveness of a resulting schedule. Previous researchers have analyzed a problem instance by parameterizing based on the ratio between the longest job's processing time and the shortest job's processing time. Our main contribution is to provide a fine-grained analysis of the problem when simultaneously parameterized by patience and the range of job lengths. We are able to give tight or almost tight bounds on the deterministic competitiveness for all parameter combinations.If viewing the analysis of each parameter individually, our evidence suggests that parameterizing solely on patience provides a richer analysis than parameterizing solely on the ratio of the job lengths. For example, in the special case where all jobs have the same length, we generalize a previous bound of 2 for the deterministic competitiveness with arbitrary slacks, showing that the competitiveness for any κ ≥ 0 is exactly 1 + 1/(⌊κ⌋ + 1). Without any bound on the job lengths, a simple greedy algorithm is (2+ 1/κ)- competitive for any κ > 0. More generally we will find that for any fixed ratio of job lengths, the competitiveness of the problem tends towards 1 as the patience is increased. The converse is not true, as for any fixed κ > 0 we find that the competitiveness is bounded away from 1, no matter what further restrictions are placed on the ratio of job lengths."
SODA	Reconstructing Set Partitions.	Vladimir Grebinski,Gregory Kucherov	1999	Reconstructing Set Partitions.
SODA	Estimating Interpolation Error: A Combinatorial Approach.	Stephen Guattery,Gary L. Miller,Noel Walkington	1999	Estimating Interpolation Error: A Combinatorial Approach.
SODA	Fast Deterministic Construction of Static Dictionaries.	Torben Hagerup	1999	Fast Deterministic Construction of Static Dictionaries.
SODA	Online Coloring Known Graphs.	Magnús M. Halldórsson	1999	Online Coloring Known Graphs.
SODA	Parallel Integer Sorting is More Efficient than Parallel Comparison Sorting on Exclusive Write PRAMs.	Yijie Han,Xiaojun Shen	1999	We present a significant improvement for parallel integer sorting. On the EREW (exclusive read exclusive write) PRAM our algorithm sorts n integers in the range {0,1, . . . ,m-1 } in time O(log n) with $O(n \sqrt{\frac{\log n}{k}})$ operations using word length $k \log (m+n)$, where $1 \leq k \leq \log n$. In this paper we present the following four variants of our algorithm.\noindent (1) The first variant sorts integers in $\{ 0, 1, \ldots, m-1\}$ in time O(log n) and in linear space with O(n) operations using word length log m log n. (2) The second variant sorts integers in {0, 1, . . , n-1} in time O(log n) and in linear space with $O(n\sqrt{\log n})$ operations using word length log n. (3) The third variant sorts integers in {0, 1, . . . , m-1} in time O(log3/2 n) and in linear space with $O(n\sqrt{\log n})$ operations using word length log (m+n). (4) The fourth variant sorts integers in {0, 1, . . . ,m-1} in time O(log n) and space $O(nm^\epsilon )$ with $O(n\sqrt{\log n})$ operations using word length log (m+n).Our algorithms can then be generalized to the situation where the word length is k log (m+n), $1 \leq k \leq \log n$.
SODA	New Algorithms for Generating Conway Polynomials Over Finite Fields.	Lenwood S. Heath,Nicholas A. Loehr	1999	New Algorithms for Generating Conway Polynomials Over Finite Fields.
SODA	Dynamical System Representation of Open Address Hash Functions.	Gregory L. Heileman,Chaouki T. Abdallah,Bernard M. E. Moret,Bradley J. Smith	1999	Dynamical System Representation of Open Address Hash Functions.
SODA	Scheduling Multicasts on Unit-Capacity Trees and Meshes.	Monika Rauch Henzinger,Stefano Leonardi	1999	This paper studies the multicast routing and admission control problem on unit-capacity tree and mesh topologies in the throughput model. The problem is a generalization of the edge-disjoint paths problem and is NP-hard both on trees and meshes. We study both the offline and the online version of the problem: In the offline setting, we give the first constant-factor approximation algorithm for trees, and an O((log log n)2)-factor approximation algorithm for meshes. In the online setting, we give the first polylogarithmic competitive online algorithm for tree and mesh topologies. No polylogarithmiccompetitive algorithm is possible on general network topologies (Lower bounds for on-line graph problems with application to on-line circuits and optical routing, in: Proceedings of the 28th ACM Symposium on Theory of Computing, 1996, pp. 531-540) and there exists a polylogarithmic lower bound on the competitive ratio of any online algorithm on tree topologies (Making commitments in the face of uncertainity: how to pick a winner almost every time, in: Proceedings of the 28th Annual ACM Symposium on Theory of Computing, 1996, pp. 519-530). We prove the same lower bound for meshes.
SODA	A 1.598 Approximation Algorithm for the Steiner Problem in Graphs.	Stefan Hougardy,Hans Jürgen Prömel	1999	A 1.598 Approximation Algorithm for the Steiner Problem in Graphs.
SODA	Efficient Exact Sampling from the Ising Model Using Swendsen-Wang.	Mark Huber	1999	Efficient Exact Sampling from the Ising Model Using Swendsen-Wang.
SODA	Fully Dynamic Algorithms for Chordal Graphs.	Louis Ibarra	1999	Fully Dynamic Algorithms for Chordal Graphs.
SODA	A Small Approximately min-wise Independent Family of Hash Functions.	Piotr Indyk	1999	A Small Approximately min-wise Independent Family of Hash Functions.
SODA	Geometric Matching Under Noise: Combinatorial Bounds and Algorithms.	Piotr Indyk,Rajeev Motwani,Suresh Venkatasubramanian	1999	Geometric Matching Under Noise: Combinatorial Bounds and Algorithms.
SODA	The Phase Transition in Random Horn Satisfiability and Its Algorithmic Implications.	Gabriel Istrate	1999	Let c > 0 be a constant, and Φ be a random Horn formula with n variables and m = c . 2n clauses, chosen uniformly at random (with repetition) from the set of all nonempty Horn clauses in the given variables. By analyzing PUR, a natural implementation of positive unit resolution, we show that limn→∞ Pr(Φ is satisfiable) = 1 - F(e-c), where F(x) = (1 - x)(1 - x2)(1 - x4) (1 - x8) .... Our method also yields as a byproduct an average-case analysis of this algorithm.
SODA	An O(N) Oblivious Routing Algorithm for 2-D Meshes of Constant Queue-Size.	Kazuo Iwama,Eiji Miyano	1999	An O(N) Oblivious Routing Algorithm for 2-D Meshes of Constant Queue-Size.
SODA	Computing the Maximum Degree of Minors in Matrix Pencils via Combinatorial Relaxation.	Satoru Iwata	1999	Computing the Maximum Degree of Minors in Matrix Pencils via Combinatorial Relaxation.
SODA	A Primal-Dual Schema Based Approximation Algorithm for the Element Connectivity Problem.	Kamal Jain,Ion I. Mandoiu,Vijay V. Vazirani,David P. Williamson	1999	"The element connectivity problem falls in the category of survivable network design problems-it is intermediate to the versions that ask for edge-disjoint and vertex-disjoint paths. The edge version is by now well understood from the view-point of approximation algorithms [Williamson et al., Combinatorica 15 (1995) 435-454; Goemans et al., in: SODA '94, 223-232; Jain, Combinatorica 21 (2001) 39-60], but very little is known about the vertex version. In our problem, vertices are partitioned into two sets: terminals and nonterminals. Only edges and nonterminals can fail--we refer to them as elements--and only pairs of terminals have connectivity requirements, specifying the number of element-disjoint paths required. Our algorithm achieves an approximation guarantee of factor 2Hk, where k is the largest requirement and Hn = 1 + ½ +... + 1/n. Besides providing possible insights for solving the vertex-disjoint paths version, the element connectivity problem is of independent interest, since it models a realistic situation."
SODA	Linear-Time Approximation Schemes for Scheduling Malleable Parallel Tasks.	Klaus Jansen,Lorant Porkolab	1999	Linear-Time Approximation Schemes for Scheduling Malleable Parallel Tasks.
SODA	What are the Least Tractable Instances of max Tndependent Set?	David S. Johnson,Mario Szegedy	1999	What are the Least Tractable Instances of max Tndependent Set?
SODA	A Generalized Root Algorithm.	Anna M. Johnston	1999	A Generalized Root Algorithm.
SODA	Eliminating Migration in Multi-Processor Scheduling.	Bala Kalyanasundaram,Kirk Pruhs	1999	Eliminating Migration in Multi-Processor Scheduling.
SODA	Computing Nearest Neighbors for Moving Points and Applications to Clustering.	Tapas Kanungo,David M. Mount,Nathan S. Netanyahu,Christine D. Piatko,Ruth Silverman,Angela Y. Wu	1999	Computing Nearest Neighbors for Moving Points and Applications to Clustering.
SODA	Designing Proxies for Stock Market Indices is Computationally Hard.	Ming-Yang Kao,Stephen R. Tate	1999	Designing Proxies for Stock Market Indices is Computationally Hard.
SODA	On-line Complexity of Monotone Set Systems.	Haim Kaplan,Mario Szegedy	1999	On-line Complexity of Monotone Set Systems.
SODA	Just the Fax - Differentiating Voice and Fax Phone Lines Using Call Billing Data.	Haim Kaplan,Martin Strauss,Mario Szegedy	1999	Just the Fax - Differentiating Voice and Fax Phone Lines Using Call Billing Data.
SODA	Parametric Polymatroid Optimization and Its Geometric Applications.	Naoki Katoh,Hisao Tamaki,Takeshi Tokuyama	1999	Parametric Polymatroid Optimization and Its Geometric Applications.
SODA	Optimal On-line Algorithms for an Electronic Commerce Money Distribution System.	Hiroshi Kawazoe,Tetsuo Shibuya,Takeshi Tokuyama	1999	Optimal On-line Algorithms for an Electronic Commerce Money Distribution System.
SODA	Recovering Branches on the Tree of Life: An Approximation Algorithm.	Paul E. Kearney,Ming Li,John Tsang,Tao Jiang	1999	Recovering Branches on the Tree of Life: An Approximation Algorithm.
SODA	The Data Broadcast Problem with Non-Uniform Transmission Rimes.	Claire Kenyon,Nicolas Schabanel	1999	The Data Broadcast Problem with Non-Uniform Transmission Rimes.
SODA	A Uniform Framework for Approximating Weighted Connectivity Problems.	Samir Khuller,Balaji Raghavachari,An Zhu	1999	A Uniform Framework for Approximating Weighted Connectivity Problems.
SODA	Roundness Estimation via Random Sampling.	Ravi Kumar,D. Sivakumar	1999	Roundness Estimation via Random Sampling.
SODA	Wavelength Conversion in Optical Networks.	Jon M. Kleinberg,Amit Kumar	1999	In many models of optical routing, we are given a set of communication paths in a network, and we must assign a wavelength to each path so that paths sharing an edge receive different wavelengths. The goal is to assign as few wavelengths as possible, in order to make as efficient use as possible of the optical bandwidth. Wilfong and Winkler considered the problem of placing wavelength converters in such a network: if a node of the network contains a converter, any path that passes through this node may change its wavelength. Having converters at some of the nodes can reduce the number of wavelengths required for routing, down to the following natural {\em congestion bound}: even with converters, we will always need at least as many wavelengths as the maximum number of paths sharing a single edge. Thus Winkler and Wilfong defined a set $S$ of nodes in a network to be {\em sufficient} if, placing converters at the nodes in $S$, every set of paths can be routed with a number of wavelengths equal to its congestion bound. They showed that finding a sufficient set of minimum size is NP-complete. In this paper, we provide a polynomial-time algorithm to find a sufficient set for an arbitrary directed network whose size is within a factor of $2$ of minimum. For the special case of planar graphs with bi-directional edges, we obtain a polynomial-time approximation scheme. Our techniques establish a connection between the problem of finding a minimum sufficient set and an interesting simultaneous generalization of the Vertex Cover and Feedback Vertex Set problems in undirected graphs.
SODA	Cache Performance Analysis of Traversals and Random Accesses.	Richard E. Ladner,James D. Fix,Anthony LaMarca	1999	Cache Performance Analysis of Traversals and Random Accesses.
SODA	Online Resource Minimization.	Anton J. Kleywegt,Vijay S. Nori,Martin W. P. Savelsbergh,Craig A. Tovey	1999	Online Resource Minimization.
SODA	Trade-offs Between Speed and Processor in Hard-Deadline Scheduling.	Tak Wah Lam,Kar-Keung To	1999	Trade-offs Between Speed and Processor in Hard-Deadline Scheduling.
SODA	Distinguishing String Selection Problems.	J. Kevin Lanctot,Ming Li,Bin Ma,Shaojiu Wang,Louxin Zhang	1999	This paper presents a collection of string algorithms that are at the core of several biological problems such as discovering potential drug targets, creating diagnostic probes, universal primers or unbiased consensus sequences. All these problems reduce to the task of finding a pattern that, with some error, occurs in one set of strings (Closest Substring Problem) and does not occur in another set (Farthest String Problem). In this paper, we break down the problem into several subproblems and prove the following results. 1. The following are all NP-Hard: the Farthest String Problem, the Closest Substring Problem, and the Closest String Problem of finding a string that is close to each string in a set. 2. There is a PTAS for the Farthest String Problem based on a linear programming relaxation technique. 3. There is a polynomial-time (4/3 + ε)-approximation algorithm for the Closest String Problem for any small constant ε > 0. Using this algorithm, we also provide an efficient heuristic algorithm for the Closest Substring Problem. 4. The problem of finding a string that is at least Hamming distance d from as many strings in a set as possible, cannot be approximated within nε in polynomial time for some fixed constant ε unless NP = P, where n is the number of strings in the set. 5. There is a polynomial-time 2-approximation for finding a string that is both the Closest Substring to one set, and the Farthest String from another set.
SODA	New Algorithmic Aspects of the Local Lemma with Applications to Routing and Partitioning.	Frank Thomson Leighton,Satish Rao,Aravind Srinivasan	1999	New Algorithmic Aspects of the Local Lemma with Applications to Routing and Partitioning.
SODA	Placement Algorithms for Hierarchical Cooperative Caching.	Madhukar R. Korupolu,C. Greg Plaxton,Rajmohan Rajaraman	1999	Consider a hierarchical network in which each node periodically issues a request for an object drawn from a fixed set of unit-sized objects. Suppose further that the following conditions are satisfied: the frequency with which each node accesses each object is known; each node has a cache of known capacity; any cache can be accessed by any node; any request is satisfied by the closest node with a copy of the desired object. In such an environment, it is desirable to fill the available cach space with copies of objects in such a way that the average access cost is minimized. We provide both exact and approximate polynomial-time algorithms for this hierarchical placement problem. Our exact algorithm is based on a reduction to min-cost flow, and does not appear to be practical for large problem sizes. Thus we are motivated to search for a faster approximation algorithm. Our main result is a simple constant-factor approximation algorithm for the hierarchical placement problem that admits an efficient distributed implementation.
SODA	Indexing Schemes for Random Points.	Elias Koutsoupias,David Scot Taylor	1999	Indexing Schemes for Random Points.
SODA	Empirical Investigation of the Markov Reference Model.	Vincenzo Liberatore	1999	Empirical Investigation of the Markov Reference Model.
SODA	An Algorithm to Symbolically Describe Flows on Surfaces.	Luis-Miguel Lopez,Philippe Narbel	1999	An Algorithm to Symbolically Describe Flows on Surfaces.
SODA	A Deterministic Approximation Algorithm for a Minmax Integer Programming Problem.	Chi-Jen Lu	1999	A Deterministic Approximation Algorithm for a Minmax Integer Programming Problem.
SODA	Using Stopping Times to Bound Mixing Times.	Igor Pak	1999	Using Stopping Times to Bound Mixing Times.
SODA	Combinatorics Helps for Hexahedral Mesh Generation in CAD.	Matthias Müller-Hannemann	1999	Combinatorics Helps for Hexahedral Mesh Generation in CAD.
SODA	I/O-Complexity of Graph Algorithms.	Kamesh Munagala,Abhiram G. Ranade	1999	I/O-Complexity of Graph Algorithms.
SODA	An Analysis of the Burrows-Wheeler Transform.	Giovanni Manzini	1999	The Burrows-Wheeler Transform (also known as Block-Sorting) is at the base of compression algorithms which are the state of the art in lossless data compression. In this paper we analyze two algorithms which use this technique. The first one is the original algorithm described by Burrows and Wheeler, which, despite its simplicity, outperforms the gzip compressor. The second one uses an additional run-length encoding step to improve compression. We prove that the compression ratio of both algorithms can be bounded in terms of the k-th order empirical entropy of the input string for any k<0. We make no assumptions on the input and we obtain bounds which hold in the worst case, that is, for every possible input string. All previous results for Block-Sorting algorithms were concerned with the average compression ratio and have been established assuming that the input comes from a finite-order Markov source.
SODA	On the Optimality of Parsing in Dynamic Dictionary Based Data Compression.	Yossi Matias,Süleyman Cenk Sahinalp	1999	On the Optimality of Parsing in Dynamic Dictionary Based Data Compression.
SODA	Approximation Algorithms for Protein Folding Prediction.	Giancarlo Mauri,Giulio Pavesi,Antonio Piccolboni	1999	Approximation Algorithms for Protein Folding Prediction.
SODA	Compass Permits Leader Election.	Jacques Mazoyer,Codrin M. Nichitiu,Eric Rémila	1999	Compass Permits Leader Election.
SODA	All-to-All Optical Routing in Optimal Chordal Rings of Degree Four.	Lata Narayanan,Jaroslav Opatrny,Dominique Sotteau	1999	All-to-All Optical Routing in Optimal Chordal Rings of Degree Four.
SODA	Approximating Multiroot 3-Outconnected Subgraphs.	Zeev Nutov	1999	Approximating Multiroot 3-Outconnected Subgraphs.
SODA	Combinatorial Approximation Algorithms for Generalized Flow Problems.	Jeffrey D. Oldham	1999	Combinatorial Approximation Algorithms for Generalized Flow Problems.
SODA	Dual-Issue Scheduling with Spills for Binary Trees.	Waleed Meleis,Edward S. Davidson	1999	Dual-Issue Scheduling with Spills for Binary Trees.
SODA	Certified Computation of the Sign of a Matrix Determinant.	Victor Y. Pan,Yanqiang Yu	1999	Certified Computation of the Sign of a Matrix Determinant.
SODA	Rendering Equation Revisited: How to Avoid Explicit Visibility Computations.	Marco Pellegrini	1999	Rendering Equation Revisited: How to Avoid Explicit Visibility Computations.
SODA	An Efficient Algorithm for Generating Necklaces with Fixed Density.	Joe Sawada,Frank Ruskey	1999	An Efficient Algorithm for Generating Necklaces with Fixed Density.
SODA	Approximability of Scheduling with Fixed Jobs.	Mark Scharbrodt,Angelika Steger,Horst Weisser	1999	Approximability of Scheduling with Fixed Jobs.
SODA	Greedy Algorithms for Optimized DNA Sequencing.	Allon G. Percus,David C. Torney	1999	Greedy Algorithms for Optimized DNA Sequencing.
SODA	Colouring Graphs with Prescribed Induced Cycle Lengths.	Ingo Schiermeyer,Bert Randerath	1999	Colouring Graphs with Prescribed Induced Cycle Lengths.
SODA	An Oracle-Polynomial Time Augmentation Algorithm for Integer Programming.	Andreas S. Schulz,Robert Weismantel	1999	An Oracle-Polynomial Time Augmentation Algorithm for Integer Programming.
SODA	Preemptive Scheduling with Job-Dependent Setup Times.	Petra Schuurman,Gerhard J. Woeginger	1999	Preemptive Scheduling with Job-Dependent Setup Times.
SODA	Optimal Scheduling of Multiclass Parallel Machines.	Jay Sethuraman,Mark S. Squillante	1999	Optimal Scheduling of Multiclass Parallel Machines.
SODA	An Efficient Algorithm for Computing the th letter of 4a.	Jeffrey Shallit,David Swart	1999	An Efficient Algorithm for Computing the th letter of 4a.
SODA	Approximation Algorithms for the Asymmetric Postman Problem.	Balaji Raghavachari,Jeyakesavan Veerasamy	1999	Approximation Algorithms for the Asymmetric Postman Problem.
SODA	On the Bidirected Cut Relaxation for the Metric Steiner Tree Problem.	Sridhar Rajagopalan,Vijay V. Vazirani	1999	On the Bidirected Cut Relaxation for the Metric Steiner Tree Problem.
SODA	Emulations Between QSM, BSP, and LogP: A Framework for General-Purpose Parallel Algorithm Design.	Vijaya Ramachandran,Brian Grayson,Michael Dahlin	1999	"We present work-preserving emulations with small slowdown between LogP and two other parallel models: BSP and QSM. In conjunction with earlier work-preserving emulations between QSM and BSP, these results establish a close correspondence between these three general-purpose parallel models. Our results also correct and improve on results reported earlier on emulations between BSP and LogP. In particular we shed new light on the relative power of stalling and non-stalling LogP models.The QSM is a shared-memory model with only two parameters--p, the number of processors, and g, a bandwidth parameter. The simplicity of the QSM parameters makes QSM a convenient model for parallel algorithm design, and simple work-preserving emulations of QSM on BSP and QSM on LogP show that algorithms designed for the QSM will also map quite well to these other models. The simplicity and generality of QSM present a strong case for the use of QSM as the model of choice for parallel algorithm design.We present QSM algorithms for three basic problems--prefix sums, sample sort and list ranking. We show that these algorithms are optimal in terms of both the total work performed and the number of 'phases' for input sizes of practical interest. For prefix sums, we present a matching lower bound that shows our algorithm to be optimal over the complete range of these parameters. We then examine the predicted and simulated performance of these algorithms. These results suggest that QSM analysis will predict algorithm performance quite accurately for problem sizes that arise in practice."
SODA	Median Bounds and Their Application.	Alan Siegel	1999	Median Bounds and Their Application.
SODA	Sampling Spin Configurations of an Ising System.	Dana Randall,David Wilson	1999	Sampling Spin Configurations of an Ising System.
SODA	Rectangular Tiling in Multi-dimensional Arrays.	Adam Smith,Subhash Suri	1999	Rectangular Tiling in Multi-dimensional Arrays.
SODA	A Generalization of Janson Inequalities and its Application to Finding Shortest Paths.	C. R. Subramanian	1999	A Generalization of Janson Inequalities and its Application to Finding Shortest Paths.
SODA	Packet Filtering in High Speed Networks.	Subhash Suri,George Varghese	1999	Packet Filtering in High Speed Networks.
SODA	A Slique Size Bounding Technique with Application to Non-Linear Codes.	Mario Szegedy	1999	A Slique Size Bounding Technique with Application to Non-Linear Codes.
SODA	Lower Bounds for SRPT-Subsequence Algorithms for Nonpreemptive Scheduling.	Eric Torng,Patchrawat Uthaisombut	1999	Lower Bounds for SRPT-Subsequence Algorithms for Nonpreemptive Scheduling.
SODA	Approximation Algorithms for Bipartite and Non-Bipartite Matching in the Plane.	Kasturi R. Varadarajan,Pankaj K. Agarwal	1999	Approximation Algorithms for Bipartite and Non-Bipartite Matching in the Plane.
SODA	A Convex Relaxation for the Asymmetric TSP.	Santosh Vempala,Mihalis Yannakakis	1999	A Convex Relaxation for the Asymmetric TSP.
SODA	Computational Complexity of Compaction to Cycles.	Narayan Vikas	1999	Computational Complexity of Compaction to Cycles.
SODA	Exact Solutions to Large-scale Plane Steiner Tree Problems.	David M. Warme,Pawel Winter,Martin Zachariasen	1999	Exact Solutions to Large-scale Plane Steiner Tree Problems.
SODA	A New Property and a Faster Algorithm for Baseball Elimination.	Kevin D. Wayne	1999	"In the baseball elimination problem, there is a league consisting of n teams. At some point during the season, team i has wi wins and gij games left to play against team j. A team is eliminated if it cannot possibly finish the season in first place or tied for first place. The goal is to determine exactly which teams are eliminated. The problem is not as easy as many sports writers would have you believe, in part because the answer depends not only on the number of games won and left to play but also on the schedule of remaining games. In the 1960's, Schwartz showed how to determine whether one particular team is eliminated using a maximum flow computation.This paper indicates that the problem is not as difficult as many mathematicians would have you believe. For each team i, let gi denote the number of games remaining. We prove that there exists a value W* such that team i is eliminated if and only if wi + gi W*. Using this surprising fact, we can determine all eliminated teams in time proportional to a single maximum flow computation in a graph with n nodes; this improves upon the previous best known complexity bound by a factor of n."
SODA	Faster Approximation Algorithms for Generalized Flow.	Kevin D. Wayne,Lisa Fleischer	1999	Faster Approximation Algorithms for Generalized Flow.
SODA	When Does a Dynamic Programming Formulation Guarantee the Existence of an FPTAS?	Gerhard J. Woeginger	1999	When Does a Dynamic Programming Formulation Guarantee the Existence of an FPTAS?
SODA	Experimental Performance of Shared RSA Modulus Generation.	Rebecca N. Wright,Sara Spalding	1999	Experimental Performance of Shared RSA Modulus Generation.
SODA	Fast and Effective Stripification of Polygonal Surface Models.	Xinyu Xiang,Martin Held,Joseph S. B. Mitchell	1999	Fast and Effective Stripification of Polygonal Surface Models.
SODA	Analysis of a Bounding Box Heuristic for Object Intersection.	Yunhong Zhou,Subhash Suri	1999	Analysis of a Bounding Box Heuristic for Object Intersection.
SODA	Proceedings of the Tenth Annual ACM-SIAM Symposium on Discrete Algorithms, 17-19 January 1999, Baltimore, Maryland.	Robert Endre Tarjan,Tandy Warnow	1999	Proceedings of the Tenth Annual ACM-SIAM Symposium on Discrete Algorithms, 17-19 January 1999, Baltimore, Maryland.
STOC	Determinism versus Non-Determinism for Linear Time RAMs (Extended Abstract).	Miklós Ajtai	1999	Determinism versus Non-Determinism for Linear Time RAMs (Extended Abstract).
STOC	Worst-Case and Amortised Optimality in Union-Find (Extended Abstract).	Stephen Alstrup,Amir M. Ben-Amram,Theis Rauhe	1999	Worst-Case and Amortised Optimality in Union-Find (Extended Abstract).
STOC	Undecidability on Quantum Finite Automata.	Masami Amano,Kazuo Iwama	1999	Undecidability on Quantum Finite Automata.
STOC	Dense Quantum Coding and a Lower Bound for 1-Way Quantum Automata.	Andris Ambainis,Ashwin Nayak,Amnon Ta-Shma,Umesh V. Vazirani	1999	Dense Quantum Coding and a Lower Bound for 1-Way Quantum Automata.
STOC	Packet Routing with Arbitrary End-to-End Delay Requirements.	Matthew Andrews,Lisa Zhang	1999	Packet Routing with Arbitrary End-to-End Delay Requirements.
STOC	Approximation Schemes for Minimum Latency Problems.	Sanjeev Arora,George Karakostas	1999	The minimum latency problem, also known as the traveling repairman problem, is a variant of the traveling salesman problem in which the starting node of the tour is given and the goal is to minimize the sum of the arrival times at the other nodes. We present a quasi-polynomial time approximation scheme (QPTAS) for this problem when the instance is a weighted tree, when the nodes lie in $\mathbb{R}^d$ for some fixed d, and for planar graphs. We also present a polynomial time constant factor approximation algorithm for the general metric case. The currently best polynomial time approximation algorithm for general metrics, due to Goemans and Kleinberg, computes a 3.59-approximation.
STOC	Minimizing the Flow Time Without Migration.	Baruch Awerbuch,Yossi Azar,Stefano Leonardi,Oded Regev	1999	We consider the classical problem of scheduling jobs in a multiprocessor setting in order to minimize the flow time (total time in the system). The performance of the algorithm, both in offline and online settings, can be significantly improved if we allow preemption, i.e., interrupt a job and later continue its execution, perhaps migrating it to a different machine. Preemption is inherent to make a scheduling algorithm efficient. While in the case of a single processor most operating systems can easily handle preemptions, migrating a job to a different machine results in a huge overhead. Thus, it is not commonly used in most multiprocessor operating systems. The natural question is whether migration is an inherent component for an efficient scheduling algorithm in either the online or offline setting.Leonardi and Raz [Proceedings of the Twenty-Ninth Annual ACM Symposium on Theory of Computing, El Paso, TX, 1997, pp. 110--119] showed that the well-known algorithm, shortest remaining processing time (SRPT), performs within a logarithmic factor of the optimal offline algorithm. Note that SRPT must use both preemption and migration to schedule the jobs. It is not known if better approximation factors can be reached and thus SRPT, although it is an online algorithm, becomes the best known algorithm in the offline setting. In fact, in the online setting, Leonardi and Raz showed that no algorithm can achieve a better bound.Without migration, no (offline or online) approximations are known. This paper introduces a new algorithm that does not use migration, works online, and is just as effective (in terms of approximation ratio) as the best known offline algorithm that uses migration.
STOC	Approximating the Throughput of Multiple Machines Under Real-Time Scheduling.	Amotz Bar-Noy,Sudipto Guha,Joseph Naor,Baruch Schieber	1999	Approximating the Throughput of Multiple Machines Under Real-Time Scheduling.
STOC	Optimal Bounds for the Predecessor Problem.	Paul Beame,Faith E. Fich	1999	Optimal Bounds for the Predecessor Problem.
STOC	One-Way Functions Are Essential for Single-Server Private Information Retrieval.	Amos Beimel,Yuval Ishai,Eyal Kushilevitz,Tal Malkin	1999	One-Way Functions Are Essential for Single-Server Private Information Retrieval.
STOC	Backing Up in Singly Linked Lists.	Amir M. Ben-Amram,Holger Petersen	1999	We show how to reduce the time overhead for implementing two-way movement on a singly linked list to O(n&epsi;) per operation without modifying the list and without making use of storage other than a finite number of pointers into the list. We also prove a matching lower bound.These results add precision to the intuitive feeling that doubly linked lists are more efficient than singly linked lists, and quantify the efficiency gap in a read-only situation. We further analyze the number of points of access into the list (pointers) necessary for obtaining a desired value of &epsi;. We obtain tight tradeoffs which also separate the amortized and worst-case settings.Our upper bound implies that read-only programs with singly-linked input can do string matching much faster than previously expected.
STOC	Short Proofs are Narrow - Resolution Made Simple.	Eli Ben-Sasson,Avi Wigderson	1999	The width of a Resolution proof is defined to be the maximal number of literals in any clause of the proof. In this paper we relate proof width to proof size, in both general Resolution, and its tree-like variant. Specifically, the main observation of this paper is a relation between these two fundamental resources
STOC	On the Complexity of Computing Short Linearly Independent Vectors and Short Bases in a Lattice.	Johannes Blömer,Jean-Pierre Seifert	1999	On the Complexity of Computing Short Linearly Independent Vectors and Short Bases in a Lattice.
STOC	Lower Bounds for High Dimensional Nearest Neighbor Search and Related Problems.	Allan Borodin,Rafail Ostrovsky,Yuval Rabani	1999	Lower Bounds for High Dimensional Nearest Neighbor Search and Related Problems.
STOC	Subquadratic Approximation Algorithms for Clustering Problems in High Dimensional Spaces.	Allan Borodin,Rafail Ostrovsky,Yuval Rabani	1999	One of the central problems in information retrieval, data mining, computational biology, statistical analysis, computer vision, geographic analysis, pattern recognition, distributed protocols is the question of classification of data according to some clustering rule. Often the data is noisy and even approximate classification is of extreme importance. The difficulty of such classification stems from the fact that usually the data has many incomparable attributes, and often results in the question of clustering problems in high dimensional spaces. Since they require measuring distance between every pair of data points, standard algorithms for computing the exact clustering solutions use quadratic or &ldquo;nearly quadratic&rdquo; running time&semi; i.e., O(dn2&minus;&alpha;(d)) time where n is the number of data points, d is the dimension of the space and &alpha;(d) approaches 0 as d grows. In this paper, we show (for three fairly natural clustering rules) that computing an approximate solution can be done much more efficiently. More specifically, for agglomerative clustering (used, for example, in the Alta Vista&trade; search engine), for the clustering defined by sparse partitions, and for a clustering based on minimum spanning trees we derive randomized (1 + &epsi;) approximation algorithms with running times &Otilde;(d2 n2&minus;&gamma;) where &gamma; > 0 depends only on the approximation parameter &epsi; and is independent of the dimension d.
STOC	Linear Gaps Between Degrees for the Polynomial Calculus Modulo Distinct Primes.	Samuel R. Buss,Dima Grigoriev,Russell Impagliazzo,Toniann Pitassi	1999	Linear Gaps Between Degrees for the Polynomial Calculus Modulo Distinct Primes.
STOC	Hardness and Hierarchy Theorems for Probabilistic Quasi-Polynomial Time.	Jin-yi Cai,Ajay Nerurkar,D. Sivakumar	1999	Hardness and Hierarchy Theorems for Probabilistic Quasi-Polynomial Time.
STOC	Secure Computation with Honest-Looking Parties: What If Nobody Is Truly Honest? (Extended Abstract).	Ran Canetti,Rafail Ostrovsky	1999	Secure Computation with Honest-Looking Parties: What If Nobody Is Truly Honest? (Extended Abstract).
STOC	Small Universal Graphs.	Michael R. Capalbo,S. Rao Kosaraju	1999	Small Universal Graphs.
STOC	A Lower Bound on the Complexity of Approximate Nearest-Neighbor Searching on the Hamming Cube.	Amit Chakrabarti,Bernard Chazelle,Benjamin Gum,Alexey Lvov	1999	A Lower Bound on the Complexity of Approximate Nearest-Neighbor Searching on the Hamming Cube.
STOC	A Constant-Factor Approximation Algorithm for the -Median Problem (Extended Abstract).	Moses Charikar,Sudipto Guha,Éva Tardos,David B. Shmoys	1999	A Constant-Factor Approximation Algorithm for the -Median Problem (Extended Abstract).
STOC	On targeting Markov segments.	Moses Charikar,Ravi Kumar,Prabhakar Raghavan,Sridhar Rajagopalan,Andrew Tomkins	1999	On targeting Markov segments.
STOC	Optimal Buy-and-Hold Strategies for Financial Markets with Bounded Daily Returns.	Gen-Huey Chen,Ming-Yang Kao,Yuh-Dauh Lyuu,Hsing-Kuo Wong	1999	In the context of investment analysis, we formulate an abstract online computing problem called a planning game and develop general tools for solving such a game. We then use the tools to investigate a practical buy-and-hold trading problem faced by long-term investors in stocks. We obtain the unique optimal static online algorithm for the problem and determine its exact competitive ratio. We also compare this algorithm with the popular dollar averaging strategy using actual market data.
STOC	Lifting Markov Chains to Speed up Mixing.	Fang Chen,László Lovász,Igor Pak	1999	Lifting Markov Chains to Speed up Mixing.
STOC	A Polynomial Time Approximation Scheme for General Multiprocessor Job Scheduling (Extended Abstract).	Jianer Chen,Antonio Miranda	1999	A Polynomial Time Approximation Scheme for General Multiprocessor Job Scheduling (Extended Abstract).
STOC	Exploiting Regularities in Web Traffic Patterns for Cache Replacement.	Edith Cohen,Haim Kaplan	1999	Exploiting Regularities in Web Traffic Patterns for Cache Replacement.
STOC	Connection Caching.	Edith Cohen,Haim Kaplan,Uri Zwick	1999	Connection Caching.
STOC	Security-Preserving Hardness-Amplification for Any Regular One-Way Function.	Giovanni Di Crescenzo,Russell Impagliazzo	1999	Security-Preserving Hardness-Amplification for Any Regular One-Way Function.
STOC	Bit Complexity of Breaking and Achieving Symmetry in Chains and Rings (Extended Abstract).	Yefim Dinitz,Shlomo Moran,Sergio Rajsbaum	1999	Bit Complexity of Breaking and Achieving Symmetry in Chains and Rings (Extended Abstract).
STOC	PCP Characterizations of NP: Towards a Polynomially-Small Error-Probability.	Irit Dinur,Eldar Fischer,Guy Kindler,Ran Raz,Shmuel Safra	1999	PCP Characterizations of NP: Towards a Polynomially-Small Error-Probability.
STOC	Design Networks with Bounded Pairwise Distance.	Yevgeniy Dodis,Sanjeev Khanna	1999	Design Networks with Bounded Pairwise Distance.
STOC	Scheduling in the Dark.	Jeff Edmonds	1999	Scheduling in the Dark.
STOC	Fast Approximate PCPs.	Funda Ergün,Ravi Kumar,Ronitt Rubinfeld	1999	Fast Approximate PCPs.
STOC	Complexity of Graph Partition Problems.	Tomás Feder,Pavol Hell,Sulamita Klein,Rajeev Motwani	1999	Complexity of Graph Partition Problems.
STOC	Nonmonotonic Phenomena in Packet Routing.	Uriel Feige	1999	Nonmonotonic Phenomena in Packet Routing.
STOC	Multi-Method Dispatching: A Geometric Approach With Applications to String Matching Problems.	Paolo Ferragina,S. Muthukrishnan,Mark de Berg	1999	Multi-Method Dispatching: A Geometric Approach With Applications to String Matching Problems.
STOC	Unique Maximum Matching Algorithms.	Harold N. Gabow,Haim Kaplan,Robert Endre Tarjan	1999	Unique Maximum Matching Algorithms.
STOC	A Theorem on Sensitivity and Applications in Private Computation.	Anna Gál,Adi Rosén	1999	In this paper we prove a theorem that gives an (almost) tight upper bound on the sensitivity of a multiple-output Boolean function in terms of the sensitivity of its coordinates and the size of the range of the function. We apply this theorem to get improved lower bounds on the time (number of rounds) to compute Boolean functions by private protocols. These bounds are given in terms of the sensitivity of the function being computed and the amount of randomness used by the private protocol. These lower bounds are tight (up to constant factors) for the case of the xor function and together with the results in [E. Kushilevitz and A. Rosén, SIAM J. Discrete Math., 11 (1998), pp. 61--80.] establish a tight (up to constant factors) tradeoff between randomness and time in private computation.
STOC	Stability of Adaptive and Non-Adaptive Packet Routing Policies in Adversarial Queueing Networks.	David Gamarnik	1999	Stability of Adaptive and Non-Adaptive Packet Routing Policies in Adversarial Queueing Networks.
STOC	Scheduling Data Transfers in a Network and the Set Scheduling Problem.	Ashish Goel,Monika Rauch Henzinger,Serge A. Plotkin,Éva Tardos	1999	In this paper we consider the online ftp problem. The goal is to service a sequence of file transfer requests given bandwidth constraints of the underlying communication network. The main result of the paper is a technique that leads to algorithms that optimize several natural metrics, such as max-stretch, total flow time, max flow time, and total completion time. In particular, we show how to achieve optimum total flow time and optimum max-stretch if we increase the capacity of the underlying network by a logarithmic factor. We show that the resource augmentation is necessary by proving polynomial lower bounds on the max-stretch and total flow time for the case where online and offline algorithms are using same-capacity edges. Moreover, we also give polylogarithmic lower bounds on the resource augmentation factor necessary in order to keep the total flow time and max-stretch within a constant factor of optimum.
STOC	Chinese Remaindering with Errors.	Oded Goldreich,Dana Ron,Madhu Sudan	1999	Chinese Remaindering with Errors.
STOC	Efficient Recovery from Power Outage (Extended Abstract).	Sudipto Guha,Anna Moss,Joseph Naor,Baruch Schieber	1999	Efficient Recovery from Power Outage (Extended Abstract).
STOC	Embedding Tree Metrics Into Low Dimensional Euclidean Spaces.	Anupam Gupta	1999	Embedding Tree Metrics Into Low Dimensional Euclidean Spaces.
STOC	Near-Optimal Hardness Results and Approximation Algorithms for Edge-Disjoint Paths and Related Problems.	Venkatesan Guruswami,Sanjeev Khanna,Rajmohan Rajaraman,F. Bruce Shepherd,Mihalis Yannakakis	1999	We study the approximability of edge-disjoint paths and related problems. In the edge-disjoint paths (EDP) problem, we are given a network G with source-sink pairs (si, ti), 1 ≤i≤k, and the goal is to find a largest subset of source-sink pairs that can be simultaneously connected in an edge-disjoint manner. We show that in directed networks, for any ε>0, EDP is NP-hard to approximate within m1/2-ε. We also design simple approximation algorithms that achieve essentially matching approximation guarantees for some generalizations of EDP. Another related class of routing problems that we study concerns EDP with the additional constraint that the routing paths be of bounded length. We show that, for any ε > 0, bounded length EDP is hard to approximate within m1/2-ε even in undirected networks, and give an O(√m)-approximation algorithm for it. For directed networks, we show that even the single source-sink pair case (i.e. find the maximum number of paths of bounded length between a given source-sink pair) is hard to approximate within m1/2-ε, for any ε > 0.
STOC	Quantum Fourier Sampling Simplified.	Lisa Hales,Sean Hallgren	1999	Quantum Fourier Sampling Simplified.
STOC	Sublinear Time Algorithms for Metric Space Problems.	Piotr Indyk	1999	Sublinear Time Algorithms for Metric Space Problems.
STOC	Inerpolation of Symmetric Functions and a New Type of Combinatorial Design.	Piotr Indyk	1999	Inerpolation of Symmetric Functions and a New Type of Combinatorial Design.
STOC	Improved Upper Bounds on Information-Theoretic Private Information Retrieval (Extended Abstract).	Yuval Ishai,Eyal Kushilevitz	1999	Improved Upper Bounds on Information-Theoretic Private Information Retrieval (Extended Abstract).
STOC	Improved Approximation Schemes for Scheduling Unrelated Parallel Machines.	Klaus Jansen,Lorant Porkolab	1999	We consider the problem of schedulingn independent jobs onm unrelated parallel machines where each job has to be processed by exactly one machine, processing jobj on machinei requiresp ijtime units, and the objective is to minimize the makespan, i.e., the maximum job completion time. Focusing on the case whenm is fixed, we present for both preemptive and nonpreemptive variants of the problem fully polynomial approximation schemes whose running times depend only linearly onn. We also study an extension of the problem where processing jobj on machinei incurs a cost ofc ij , and thus there are two optimization criteria: makespan and cost. We show that, for any fixedm, there is a fully polynomial approximation scheme that, given valuesT andC, computes for any fixed e &gt; 0 a schedule in0( n) time with makespan at most (1 + e) T and cost at most (1 + e) C, if there exists a schedule of makespanT and costC.
STOC	Makespan Minimization in Job Shops: A Polynomial Time Approximation Scheme.	Klaus Jansen,Roberto Solis-Oba,Maxim Sviridenko	1999	Makespan Minimization in Job Shops: A Polynomial Time Approximation Scheme.
STOC	Efficient Computation of Geodesic Shortest Paths.	Sanjiv Kapoor	1999	Efficient Computation of Geodesic Shortest Paths.
STOC	Rounding Algorithms for a Geometric Embedding of Minimum Multiway Cut.	David R. Karger,Philip N. Klein,Clifford Stein,Mikkel Thorup,Neal E. Young	1999	Given an undirected graph with edge costs and a subset ofk=3 nodes calledterminals, a multiway, ork-way, cut is a subset of the edges whose removal disconnects each terminal from the others. The multiway cut problem is to find a minimum-cost multiway cut. This problem is Max-SNP hard. Recently, Calinescu et al. (Calinescu, G., H. Karloff, Y. Rabani. 2000. An improved approximation algorithm for Multiway Cut.J. Comput. System Sci.60(3) 564--574) gave a novel geometric relaxation of the problem and a rounding scheme that produced a (3/2-1/ k)-approximation algorithm.In this paper, we study their geometric relaxation. In particular, we study the worst-case ratio between the value of the relaxation and the value of the minimum multicut (the so-called integrality gap of the relaxation). Fork=3, we show the integrality gap is 12/11, giving tight upper and lower bounds. That is, we exhibit a family of graphs with integrality gaps arbitrarily close to 12/11 and give an algorithm that finds a cut of value 12/11 times the relaxation value. Our lower bound shows that this is the best possible performance guarantee for any algorithm based purely on the value of the relaxation. Our upper bound meets the lower bound and improves the factor of 7/6 shown by Calinescu et al.For allk, we show that there exists a rounding scheme with performance ratio equal to the integrality gap, and we give explicit constructions of polynomial-time rounding schemes that lead to improved upper bounds. Fork=4 and 5, our best upper bounds are based on computer-constructed rounding schemes (with computer proofs of correctness). For generalk we give an algorithm with performance ratio 1.3438-e k .Our results were discovered with the help of computational experiments that we also describe here.
STOC	A Fully Dynamic Algorithm for Maintaining the Transitive Closure.	Valerie King,Garry Sagert	1999	"This paper presents an efficient fully dynamic graph algorithm for maintaining the transitive closure of a directed graph. The algorithm updates the adjacency matrix of the transitive closure with each update to the graph; hence, each reachability query of the form ""Is there a directed path from i to j?"" can be answered in O(1) time. The algorithm is randomized and has a one-sided error; it is correct when answering yes, but has O(1/nc) probability of error when answering no, for any constant c. In acyclic graphs, worst case update time is O(n2). In general graphs, the update time is O(n2.26). The space complexity of the algorithm is O(n2)."
STOC	Approximate Testing with Relative Error.	Marcos A. Kiwi,Frédéric Magniez,Miklos Santha	1999	Approximate Testing with Relative Error.
STOC	Graph Nonisomorphism has Subexponential Size Proofs Unless the Polynomial-Time Hierarchy Collapses.	Adam Klivans,Dieter van Melkebeek	1999	Traditional hardness versus randomness results focus on time-efficient randomized decision procedures. We generalize these trade-offs to a much wider class of randomized processes. We work out various applications, most notably to derandomizing Arthur-Merlin games. We show that every language with a bounded round Arthur-Merlin game has subexponential size membership proofs for infinitely many input lengths unless exponential time coincides with the third level of the polynomial-time hierarchy (and hence the polynomial-time hierarchy collapses). Since the graph nonisomorphism problem has a bounded round Arthur-Merlin game, this provides the first strong evidence that graph nonisomorphism has subexponential size proofs. We also establish hardness versus randomness trade-offs for space bounded computation.
STOC	The Complexity of the Matrix Eigenproblem.	Victor Y. Pan,Zhao Q. Chen	1999	The Complexity of the Matrix Eigenproblem.
STOC	Covering Rectilinear Polygons with Axis-Parallel Rectangles.	V. S. Anil Kumar,H. Ramesh	1999	We give an $O(\sqrt{\log n})$ factor approximation algorithm for covering a rectilinear polygon with holes using axis-parallel rectangles. This is the first polynomial time approximation algorithm for this problem with an $o(\log n)$ approximation factor.
STOC	Finding Similar Regions in Many Strings.	Ming Li,Bin Ma,Lusheng Wang	1999	Algorithms for finding similar, or highly conserved, regions in a group of sequences are at the core of many molecular biology problems. Assume that we are given n DNA sequences s1, ...., sn. The Consensus Patterns problem, which has been widely studied in bioinformatics research, in its simplest form, asks for a region of length L in each si, and a median string s of length L so that the total Hamming distance from s to these regions is minimized. We show that the problem is NP-hard and give a polynomial time approximation scheme (PTAS) for it. We then present an efficient approximation algorithm for the consensus pattern problem under the original relative entropy measure. As an interesting application of our analysis, we further obtain a PTAS for a restricted (but still NP-hard) version of the important consensus alignment problem allowing at most constant number of gaps, each of arbitrary length, in each sequence.
STOC	Faster Mixing via Average Conductance.	László Lovász,Ravi Kannan	1999	Faster Mixing via Average Conductance.
STOC	Hypergraph Isomorphism and Structural Equivalence of Boolean Functions.	Eugene M. Luks	1999	Hypergraph Isomorphism and Structural Equivalence of Boolean Functions.
STOC	Compact Grid Layouts of Multi-Level Networks.	S. Muthukrishnan,Mike Paterson,Süleyman Cenk Sahinalp,Torsten Suel	1999	Compact Grid Layouts of Multi-Level Networks.
STOC	Oblivious Transfer and Polynomial Evaluation.	Moni Naor,Benny Pinkas	1999	Oblivious Transfer and Polynomial Evaluation.
STOC	The Quantum Query Complexity of Approximating the Median and Related Statistics.	Ashwin Nayak,Felix Wu	1999	The Quantum Query Complexity of Approximating the Median and Related Statistics.
STOC	Algorithmic Mechanism Design (Extended Abstract).	Noam Nisan,Amir Ronen	1999	Algorithmic Mechanism Design (Extended Abstract).
STOC	A Displacement Approach to Efficient Decoding of Algebraic-Geometric Codes.	Vadim Olshevsky,Mohammad Amin Shokrollahi	1999	A Displacement Approach to Efficient Decoding of Algebraic-Geometric Codes.
STOC	Static and Dynamic Evaluation of QoS Properties.	Gopal Pandurangan,Eli Upfal	1999	Static and Dynamic Evaluation of QoS Properties.
STOC	Satisfiability of Word Equations with Constants is in NEXPTIME.	Wojciech Plandowski	1999	Satisfiability of Word Equations with Constants is in NEXPTIME.
STOC	The Communication Complexity of Pointer Chasing: Applications of Entropy and Sampling.	Stephen Ponzio,Jaikumar Radhakrishnan,Srinivasan Venkatesh	1999	We study the k-round two-party communication complexity of pointer chasing problem for fixed k. Damm, Jukna and Sgall showed an upper bound of O(n \log ^{(k-1)} n) for this problem. We prove a matching lower bound; this improves the lower bound of \Omega(n) shown by Nisan and Wigderson. This yields a corresponding improvement in the hierarchy results for bounded-depth monotone circuits.We consider the bit version of this problem, and show upper and lower bounds. This implies that there is an abrupt jump in complexity, from linear to superlinear, when the number of rounds is reduced below k/2. We also consider the s-paths version originally studied by Klauck and obtain upper and lower bounds.The lower bounds are based on arguments using entropy. One of the main contributions of this work is a transfer lemma for distributions with high entropy; this should be of independent interest.
STOC	On the Complexity of Diophantine Geometry in Low Dimensions (Extended Abstract).	J. Maurice Rojas	1999	On the Complexity of Diophantine Geometry in Low Dimensions (Extended Abstract).
STOC	Exponential Separation of Quantum and Classical Communication Complexity.	Ran Raz	1999	Exponential Separation of Quantum and Classical Communication Complexity.
STOC	On Recycling the Randomness of States in Space Bounded Computation.	Ran Raz,Omer Reingold	1999	On Recycling the Randomness of States in Space Bounded Computation.
STOC	"Extracting all the Randomness and Reducing the Error in Trevisan's Extractors."	Ran Raz,Omer Reingold,Salil P. Vadhan	1999	"We give explicit constructions of extractors which work for a source of any min-entropy on strings of length n. These extractors can extract any constant fraction of the min-entropy using O(log2 n) additional random bits, and can extract all the min-entropy using O(log3 n) additional random bits. Both of these constructions use fewer truly random bits than any previous construction which works for all min-entropies and extracts a constant fraction of the min-entropy. We then improve our second construction and show that we can reduce the entropy loss to 2log(1/ε)+O(1) bits, while still using O(log3n) truly random bits (where entropy loss is defined as [(source min-entropy)+(# truly random bits used)-(# output bits)], and ε is the statistical difference from uniform achieved). This entropy loss is optimal up to a constant additive term. Our extractors are obtained by observing that a weaker notion of ""combinatorial design"" suffices for the Nisan-Wigderson pseudorandom generator, which underlies the recent extractor of Trevisan. We give near-optimal constructions of such ""weak designs"" which achieve much better parameters than possible with the notion of designs used by Nisan-Wigderson and Trevisan. We also show how to improve our constructions (and Trevisan's construction) when the required statistical difference ε from the uniform distribution is relatively small. This improvement is obtained by using multilinear error-correcting codes over finite fields, rather than the arbitrary error-correcting codes used by Trevisan."
STOC	Lower Bounds for Leader Election and Collective Coin-Flipping in the Perfect Information Model.	Alexander Russell,Michael E. Saks,David Zuckerman	1999	Collective coin-flipping is the problem of producing common random bits in a distributed computing environment with adversarial faults. We consider the perfect information model: all communication is by broadcast and corrupt players are computationally unbounded. Protocols in this model may involve many asynchronous rounds. We assume that honest players communicate only uniformly random bits. We demonstrate that any n-player coin-flipping protocol that is resilient against corrupt coalitions of linear size must use either at least [1/2 - o(1)]log* n communication rounds or at least [log(2k-1) n]1-o(1) communication bits in the kth round, where log(j) denotes the logarithm iterated j times. In particular, protocols using one bit per round require [1/2 - o(1)]log* n rounds. These bounds also apply to the leader election problem. The primary component of this result is a new bound on the influence of random sets of variables on Boolean functions. Finally, in the one-round case, using other methods we prove a new bound on the influence of sets of variables of size $\beta n$ for $\beta > 1/3$.
STOC	A PTAS for Minimizing the Weighted Sum of Job Completion Times on Parallel Machines.	Martin Skutella,Gerhard J. Woeginger	1999	A PTAS for Minimizing the Weighted Sum of Job Completion Times on Parallel Machines.
STOC	Graph Ramsey Theory and the Polynomial Hierarchy.	Marcus Schaefer	1999	In the Ramsey theory of graphs F arrows (G,H) means that for every way of coloring the edges of F red and blue F will contain either a red G or a blue H. The problem ARROWING of deciding whether F arrows (G,H) lies in coNP^NP and it was shown to be coNP-hard by Burr in 1990. We prove that ARROWING is actually coNP^NP-complete, simultaneously settling a conjecture of Burr and providing a rare natural example of a problem complete for a higher level of the polynomial hierarchy. We also show that STRONG ARROWING, the version for induced subgraphs, is complete for coNP^NP under Turing-reductions.
STOC	Random Sampling of Large Planar Maps and Convex Polyhedra.	Gilles Schaeffer	1999	Random Sampling of Large Planar Maps and Convex Polyhedra.
STOC	From Static to Dynamic Routing: Efficient Transformations of Store-and-Forward Protocols.	Christian Scheideler,Berthold Vöcking	1999	We investigate how static store-and-forward routing algorithms can be transformed into efficient dynamic algorithms, that is, how algorithms that have been designed for the case that all packets are injected at the same time can be adapted to more realistic scenarios in which packets are continuously injected into the network. Besides describing specific transformations for well-known static routing algorithms, we present a black box transformation scheme applicable to every static, oblivious routing algorithm. We analyze the performance of our protocols under a stochastic and an adversarial model of packet injections.One result of our specific transformations is the first dynamic routing algorithm for leveled networks that is stable for arbitrary admissible injection rates and that works with packet buffers of size depending solely on the injection rate and the node degree, but not on the size of the network. Furthermore, we prove strong delay bounds for the packets. Our results imply, for example, that a throughput of 99% can be achieved on an n-input butterfly network with buffers of constant size while each packet is delivered in time O(log n), with high probability.Our black box transformation ensures that if the static algorithm is pure (i.e., no extra packets apart from the original packets are routed), its dynamic variant is stable up to a maximum possible injection rate. Furthermore, in the stochastic model, the routing time of a packet depends on local parameters such as the length of its routing path, rather than on the maximum possible path length, even if the static algorithm chosen for the transformation does not provide this locality feature and is not pure. In the adversarial model, the delay bound of the packets is closely related to the time bound given for the static algorithm.
STOC	Pseudorandom Generators Without the XOR Lemma (Extended Abstract).	Madhu Sudan,Luca Trevisan,Salil P. Vadhan	1999	Pseudorandom Generators Without the XOR Lemma (Extended Abstract).
STOC	"Majorizing Estimators and the Approximation of 	P-Complete Problems."	Leonard J. Schulman,Vijay V. Vazirani	1999
STOC	Molecular Scale Heat Engines and Scalable Quantum Computation.	Leonard J. Schulman,Umesh V. Vazirani	1999	Molecular Scale Heat Engines and Scalable Quantum Computation.
STOC	Computational Sample Complexity and Attribute-Efficient Learning.	Rocco A. Servedio	1999	Computational Sample Complexity and Attribute-Efficient Learning.
STOC	Construction of Extractors Using Pseudo-Random Generators (Extended Abstract).	Luca Trevisan	1999	Construction of Extractors Using Pseudo-Random Generators (Extended Abstract).
STOC	Robust Logics.	Leslie G. Valiant	1999	Robust Logics.
STOC	All Pairs Lightest Shortest Paths.	Uri Zwick	1999	All Pairs Lightest Shortest Paths.
STOC	Outward Rotations: A Tool for Rounding Solutions of Semidefinite Programming Relaxations, with Applications to MAX CUT and Other Problems.	Uri Zwick	1999	Outward Rotations: A Tool for Rounding Solutions of Semidefinite Programming Relaxations, with Applications to MAX CUT and Other Problems.
STOC	A Polynomial Combinatorial Algorithm for Generalized Minimum Cost Flow.	Kevin D. Wayne	1999	We propose the first combinatorial solution to the generalized minimum cost flow problem (flow with losses and gains). Despite a rich history dating back to Kantorovich and Dantzig, until now, the only known way to solve the problem in polynomial-time was via general-purpose linear programming techniques. Polynomial combinatorial algorithms were previously known only for the version of our problem without costs. We design the first such algorithms for the version with costs. Our algorithms also find provably good solutions faster than optimal ones, providing the first strongly polynomial approximation schemes for the problem.Our techniques extend to optimize linear programs with two variables per inequality. Polynomial combinatorial algorithms were previously developed for testing the feasibility of such linear programs. We propose the first such methods for the optimization version.
STOC	Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, May 1-4, 1999, Atlanta, Georgia, USA	Jeffrey Scott Vitter,Lawrence L. Larmore,Frank Thomson Leighton	1999	Proceedings of the Thirty-First Annual ACM Symposium on Theory of Computing, May 1-4, 1999, Atlanta, Georgia, USA
FOCS	Optimal myopic algorithms for random 3-SAT.	Dimitris Achlioptas,Gregory B. Sorkin	2000	Let F/sub 3/(n,m) be a random 3-SAT formula formed by selecting uniformly, independently and with replacement, m clauses among all 8(/sup n/C/sub 3/) possible 3-clauses over n variables. It has been conjectured that there exists a constant r/sub 3/ such that, for any /spl epsiv/
FOCS	Pseudorandom Generators in Propositional Proof Complexity.	Michael Alekhnovich,Eli Ben-Sasson,Alexander A. Razborov,Avi Wigderson	2000	"We call a pseudorandom generator $G_n:\{0,1\}^n\to \{0,1\}^m$ hard for a propositional proof system P if P cannot efficiently prove the (properly encoded) statement $G_n(x_1,\ldots,x_n)\neq b$ for any string $b\in\{0,1\}^m$. We consider a variety of ""combinatorial"" pseudorandom generators inspired by the Nisan--Wigderson generator on the one hand, and by the construction of Tseitin tautologies on the other. We prove that under certain circumstances these generators are hard for such proof systems as resolution, polynomial calculus, and polynomial calculus with resolution (PCR)."
FOCS	Universality and Tolerance.	Noga Alon,Michael R. Capalbo,Yoshiharu Kohayakawa,Vojtech Rödl,Andrzej Rucinski,Endre Szemerédi	2000	For any positive integers r and n, let H(r,n) denote the family of graphs on n vertices with maximum degree r, and let H(r,n,n) denote the family of bipartite graphs H on 2n vertices with n vertices in each vertex class, and with maximum degree r. On one hand, we note that any H(r,n)-universal graph must have /spl Omega/(n/sup 2-2/r/) edges. On the other hand, for any n/spl ges/n/sub 0/(r), we explicitly construct H(r,n)-universal graphs G and /spl Lambda/ on n and 2n vertices, and with O(n/sup 2-/spl Omega//(1/r log r)) and O(n/sup 2-1/r/ log/sup 1/r/ n) edges, respectively, such that we can efficiently find a copy of any H /spl epsiv/ H (r,n) in G deterministically. We also achieve sparse universal graphs using random constructions. Finally, we show that the bipartite random graph G=G(n,n,p), with p=cn/sup -1/2r/ log/sup 1/2r/ n is fault-tolerant; for a large enough constant c, even after deleting any /spl alpha/-fraction of the edges of G, the resulting graph is still H(r,/spl alpha/(/spl alpha/)n,/spl alpha/(/spl alpha/)n)-universal for some /spl alpha/: [0,1)/spl rarr/(0,1].
FOCS	Testing of Clustering.	Noga Alon,Seannie Dar,Michal Parnas,Dana Ron	2000	"A set X of points in $\Re^d$ is (k,b)-clusterable if X can be partitioned into k subsets (clusters) so that the diameter (alternatively, the radius) of each cluster is at most b. We present algorithms that, by sampling from a set X, distinguish between the case that X is (k,b)-clusterable and the case that X is $\epsilon$-far from being (k,b')-clusterable for any given $0<\epsilon\leq 1$ and for $b' \geq b$. By $\epsilon$-far from being (k,b')-clusterable we mean that more than $\epsilon\cdot|X|$ points should be removed from X so that it becomes (k,b')-clusterable. We give algorithms for a variety of cost measures that use a sample of size independent of |X| and polynomial in k and $1/\epsilon$.Our algorithms can also be used to find approximately good clusterings. Namely, these are clusterings of all but an $\epsilon$-fraction of the points in X that have optimal (or close to optimal) cost. The benefit of our algorithms is that they construct an implicit representation of such clusterings in time independent of |X|. That is, without actually having to partition all points in X, the implicit representation can be used to answer queries concerning the cluster to which any given point belongs."
FOCS	New Data Structures for Orthogonal Range Searching.	Stephen Alstrup,Gerth Stølting Brodal,Theis Rauhe	2000	We present new general techniques for static orthogonal range searching problems in two and higher dimensions. For the general range reporting problem in R/sup 3/, we achieve query time O(log n+k) using space O(n log/sup 1+/spl epsiv// n), where n denotes the number of stored points and k the number of points to be reported. For the range reporting problem on an n/spl times/n grid, we achieve query time O(log log n+k) using space O(n log/sup /spl epsiv// n). For the two-dimensional semi-group range sum problem we achieve query time O(log n) using space O(n log n).
FOCS	Private Quantum Channels.	Andris Ambainis,Michele Mosca,Alain Tapp,Ronald de Wolf	2000	We investigate how a classical private key can be used by two players, connected by an insecure one-way quantum channel, to perform private communication of quantum information. In particular, we show that in order to transmit n qubits privately, 2n bits of shared private key are necessary and sufficient. This result may be viewed as the quantum analogue of the classical one-time pad encryption scheme.
FOCS	Nearly Optimal Expected-Case Planar Point Location.	Sunil Arya,Theocharis Malamatos,David M. Mount	2000	We consider the planar point location problem from the perspective of expected search time. We are given a planar polygonal subdivision S and for each polygon of the subdivision the probability that a query point lies within this polygon. The goal is to compute a search structure to determine which cell of the subdivision contains a given query point, so as to minimize the expected search time. This is a generalization of the classical problem of computing an optimal binary search tree for one-dimensional keys. In the one-dimensional case it has long been known that the entropy H of the distribution is the dominant term in the lower bound on the expected-case search time, and further there exist search trees achieving expected search times of at most H+2. Prior to this work, there has been no known structure for planar point location with an expected search time better than 2H, and this result required strong assumptions on the nature of the query point distribution. Here we present a data structure whose expected search time is nearly equal to the entropy lower bound, namely H+o(H). The result holds for any polygonal subdivision in which the number of sides of each of the polygonal cells is bounded, and there are no assumptions on the query distribution within each cell. We extend these results to subdivisions with convex cells, assuming a uniform query distribution within each cell.
FOCS	Using Upper Confidence Bounds for Online Learning.	Peter Auer	2000	We show how a standard tool from statistics, namely confidence bounds, can be used to elegantly deal with situations which exhibit an exploitation/exploration trade-off. Our technique for designing and analyzing algorithms for such situations is very general and can be applied when an algorithm has to make exploitation-versus-exploration decisions based on uncertain information provided by a random process. We consider two models with such an exploitation/exploration trade-off. For the adversarial bandit problem our new algorithm suffers only O/spl tilde/(T/sup 1/2/) regret over T trials which improves significantly over the previously best O/spl tilde/(T/sup 2/3/) regret. We also extend our results for the adversarial bandit problem to shifting bandits. The second model we consider is associative reinforcement learning with linear value functions. For this model our technique improves the regret from O/spl tilde/(T/sup 3/4/) to O/spl tilde/(T/sup 1/2/).
FOCS	Testing that distributions are close.	Tugkan Batu,Lance Fortnow,Ronitt Rubinfeld,Warren D. Smith,Patrick White	2000	Given two distributions over an n element set, we wish to check whether these distributions are statistically close by only sampling. We give a sublinear algorithm which uses O(n/sup 2/3//spl epsiv//sup -4/ log n) independent samples from each distribution, runs in time linear in the sample size, makes no assumptions about the structure of the distributions, and distinguishes the cases when the distance between the distributions is small (less than max(/spl epsiv//sup 2//32/sup 3//spl radic/n,/spl epsiv//4/spl radic/n=)) or large (more than /spl epsiv/) in L/sub 1/-distance. We also give an /spl Omega/(n/sup 2/3//spl epsiv//sup -2/3/) lower bound. Our algorithm has applications to the problem of checking whether a given Markov process is rapidly mixing. We develop sublinear algorithms for this problem as well.
FOCS	Super-linear time-space tradeoff lower bounds for randomized computation.	Paul Beame,Michael E. Saks,Xiaodong Sun,Erik Vee	2000	We prove the first time-space lower bound tradeoffs for randomized computation of decision problems. The bounds hold even in the case that the computation is allowed to have arbitrary probability of error on a small fraction of inputs. Our techniques are an extension of those used by M. Ajtai (1999) in his time-space tradeoffs for deterministic RAM algorithms computing element distinctness and for deterministic Boolean branching programs computing an explicit function based on quadratic forms over GF(2). Our results also give a quantitative improvement over those given by Ajtai. Ajtai shows, for certain specific functions, that any branching program using space S=o(n) requires time T that is superlinear. The functional form of the superlinear bound is not given in his paper, but optimizing the parameters in his arguments gives T= /spl Omega/(n log log n/log log log n) for S=0(n/sup 1-/spl epsiv//). For the same functions considered by Ajtai, we prove a time-space tradeoff of the form T=/spl Omega/(n/spl radic/(log(n/S)/log log(n/S))). In particular for space 0(n/sup 1-/spl epsiv//), this improves the lower bound on time to /spl Omega/(n/spl radic/(log n/log log n)).
FOCS	Cache-Oblivious B-Trees.	Michael A. Bender,Erik D. Demaine,Martin Farach-Colton	2000	"This paper presents two dynamic search trees attaining near-optimal performance on any hierarchical memory. The data structures are independent of the parameters of the memory hierarchy, e.g., the number of memory levels, the block-transfer size at each level, and the relative speeds of memory levels. The performance is analyzed in terms of the number of memory transfers between two memory levels with an arbitrary block-transfer size of B; this analysis can then be applied to every adjacent pair of levels in a multilevel memory hierarchy. Both search trees match the optimal search bound of $\Theta(1+\log_{B+1}N)$ memory transfers. This bound is also achieved by the classic B-tree data structure on a two-level memory hierarchy with a known block-transfer size B. The first search tree supports insertions and deletions in $\Theta(1+\log_{B+1}N)$ amortized memory transfers, which matches the B-tree's worst-case bounds. The second search tree supports scanning S consecutive elements optimally in $\Theta(1+S/B)$ memory transfers and supports insertions and deletions in $\Theta(1+\log_{B+1}N + \frac{\log^2N}{B})$ amortized memory transfers, matching the performance of the B-tree for $B = \Omega(\log N \log\log N)$."
FOCS	On Levels in Arrangements of Curves.	Timothy M. Chan	2000	Analyzing the worst-case complexity of the k-level in a planar arrangement of n curves is a fundamental problem in combinatorial geometry. We give the first subquadratic upper bound (roughly O(nk/sup 1-2/3/*)) for curves that are graphs of polynomial functions of an arbitrary fixed degree s. Previously, nontrivial results were known only for the case s=1 and s=2. We also improve the earlier bound for pseudo-parabolas (curves that pairwise intersect at most twice) to O(nk/sup 7/9/log/sup 2/3/ k). The proofs are simple and rely on a theorem of Tamaki and Tokuyama on cutting pseudo-parabolas into pseudo-segments, as well as a new observation for cutting pseudo-segments into pieces that can be extended to pseudo-lines. We mention applications to parametric and kinetic minimum spanning trees.
FOCS	Fast Broadcasting and Gossiping in Radio Networks.	Marek Chrobak,Leszek Gasieniec,Wojciech Rytter	2000	We establish an O(nlog2n) upper bound on the time for deterministic distributed broadcasting in multi-hop radio networks with unknown topology. This nearly matches the known lower bound of Ω(n log n). The fastest previously known algorithm for this problem works in time O(n3/2). Using our broadcasting algorithm, we develop an O(n3/2log2n) algorithm for gossiping in the same network model.
FOCS	Combinatorial feature selection problems.	Moses Charikar,Venkatesan Guruswami,Ravi Kumar,Sridhar Rajagopalan,Amit Sahai	2000	Motivated by frequently recurring themes in information retrieval and related disciplines, we define a genre of problems called combinatorial feature selection problems. Given a set S of multidimensional objects, the goal is to select a subset K of relevant dimensions (or features) such that some desired property /spl Pi/ holds for the set S restricted to K. Depending on /spl Pi/, the goal could be to either maximize or minimize the size of the subset K. Several well-studied feature selection problems can be cast in this form. We study the problems in this class derived from several natural and interesting properties /spl Pi/, including variants of the classical p-center problem as well as problems akin to determining the VC-dimension of a set system. Our main contribution is a theoretical framework for studying combinatorial feature selection, providing (in most cases essentially tight) approximation algorithms and hardness results for several instances of these problems.
FOCS	Fast parallel circuits for the quantum Fourier transform.	Richard Cleve,John Watrous	2000	"We give new bounds on the circuit complexity of the quantum Fourier transform (QFT). We give an upper bound of O(log n+log log(1//spl epsiv/)) on the circuit depth for computing an approximation of the QFT with respect to the modulus 2/sup n/ with error bounded by /spl epsiv/. Thus, even for exponentially small error, our circuits have depth O(log n). The best previous depth bound was O(n), even for approximations with constant error. Moreover, our circuits have size O(n log(n//spl epsiv/)). As an application of this depth bound, we show that P. Shor's (1997) factoring algorithm may be based on quantum circuits with depth only O(log n) and polynomial size, in combination with classical polynomial-time pre- and postprocessing. Next, we prove an /spl Omega/(log n) lower bound on the depth complexity of approximations of the QFT with constant error. This implies that the above upper bound is asymptotically tight (for a reasonable range of values of /spl epsiv/). We also give an upper bound of O(n(log n)/sup 2/ log log n) on the circuit size of the exact QFT modulo 2/sup n/, for which the best previous bound was O(n/sup 2/). Finally, based on our circuits for the QFT with power-of-2 moduli, we show that the QFT with respect to an arbitrary modulus m can be approximated with accuracy /spl epsiv/ with circuits of depth O((log log m)(log log 1//spl epsiv/)) and size polynomial in log m+log(1//spl epsiv/)."
FOCS	Straighting Polygonal Arcs and Convexifying Polygonal Cycles.	Robert Connelly,Erik D. Demaine,Günter Rote	2000	"Consider a planar linkage, consisting of disjoint polygonal arcs and cycles of rigid bars joined at incident endpoints (polygonal chains), with the property that no cycle surrounds another arc or cycle. We prove that the linkage can be continuously moved so that the arcs become straight, the cycles become convex, and no bars cross while preserving the bar lengths. Furthermore, our motion is piecewise-differentiable, does not decrease the distance between any pair of vertices, and preserves any symmetry present in the initial configuration. In particular this result settles the well-studied carpenter's rule conjecture."
FOCS	Fully Dynamic Transitive Closure: Breaking Through the O(n) Barrier.	Camil Demetrescu,Giuseppe F. Italiano	2000	Fully Dynamic Transitive Closure: Breaking Through the O(n) Barrier.
FOCS	Zaps and Their Applications.	Cynthia Dwork,Moni Naor	2000	A zap is a 2-round, public coin witness-indistinguishable protocol in which the first round, consisting of a message from the verifier to the prover, can be fixed &ldquo;once and for all&rdquo; and applied to any instance. We present a zap for every language in NP, based on the existence of noninteractive zero-knowledge proofs in the shared random string model. The zap is in the standard model and hence requires no common guaranteed random string. We present several applications for zaps, including 3-round concurrent zero-knowledge and 2-round concurrent deniable authentication, in the timing model of Dwork, Naor, and Sahai [J. ACM, 51 (2004), pp. 851-898], using moderately hard functions. We also characterize the existence of zaps in terms of a primitive called verifiable pseudorandom bit generators.
FOCS	Computing the Determinant and Smith Form of an Integer Matrix.	Wayne Eberly,Mark Giesbrecht,Gilles Villard	2000	Computing the Determinant and Smith Form of an Integer Matrix.
FOCS	Topological Persistence and Simplification.	Herbert Edelsbrunner,David Letscher,Afra Zomorodian	2000	We formalize a notion of topological simplification within the framework of a filtration, which is the history of a growing complex. We classify a topological change that happens during growth as either a feature or noise, depending on its life-time or persistence within the filtration. We give fast algorithms for completing persistence and experimental evidence for their speed and utility.
FOCS	A polylogarithmic approximation of the minimum bisection.	Uriel Feige,Robert Krauthgamer	2000	A bisection of a graph with $n$ vertices is a partition of its vertices into two sets, each of size $n/2$. The bisection cost is the number of edges connecting the two sets. The problem of finding a bisection of minimum cost is prototypical to graph partitioning problems, which arise in numerous contexts. This problem is NP-hard. We present an algorithm that finds a bisection whose cost is within a factor of $O(\log^{1.5} n)$ from the minimum. For graphs excluding any fixed graph as a minor (e.g., planar graphs) we obtain an improved approximation ratio of $O(\log n)$. The previously known approximation ratio for bisection was roughly $\sqrt{n}$.
FOCS	Opportunistic Data Structures with Applications.	Paolo Ferragina,Giovanni Manzini	2000	There is an upsurging interest in designing succinct data structures for basic searching problems (see [Munro99] and references therein). The motivation has to be found in the exponential increase of electronic data nowadays available which is even surpassing the significant increase in memory and disk storage capacities of current computers. Space reduction is an attractive issue because it is also intimately related to performance improvements as noted by several authors (e.g. Knuth [knuth3], Bentley [bentley]). In designing these implicit data structures the goal is to reduce as much as possible the auxiliary information kept together with the input data without introducing a significant slowdown in the final query performance. Yet input data are represented in their entirety thus taking no advantage of possible repetitiveness into them. The importance of those issues is well known to programmers who typically use various tricks to squeeze data as much as possible and still achieve good query performance. Their approaches, thought, boil down to heuristics whose effectiveness is witnessed only by experimentation. In this paper, we address the issue of compressing and indexing data by studying it in a theoretical framework. We devise a novel data structure for indexing and searching whose space occupancy is a function of the entropy of the underlying data set. The novelty resides in the careful combination of a compression algorithm, proposed by Burrows-Wheeler [bw], with the structural properties of a well known indexing tool, the Suffix Array [MM93]. We call the data structure opportunistic since its space occupancy is decreased when the input is compressible at no significant slowdown in the query performance and without any assumption on a particular fixed distribution. More precisely, its space occupancy is optimal in a information-content sense because a text $T[1,u]$ is stored using $O(k(T)) + o(1)$ bits per input symbol, where $k(T)$ is the $k$th order entropy of $T$ (the bound holds for any fixed $k$). Given an arbitrary string $P[1,p]$, the opportunistic data structure allows to search for the $occ$ occurrences of $P$ in $T$ requiring $O(p + occ \log^\epsilon u)$ time complexity (for any fixed $\epsilon <0$). If data are non compressible, then we achieve the best space bound currently known [GV00]; otherwise our solution improves the succinct suffix array in [GV00] and the classical suffix tree and suffix array data structures either in space or in query time complexity or both. It was a belief [Witten:1999:MGC] that some space overhead should be paid to use full-text indices (i.e. suffix trees or suffix arrays) with respect to the word-based indices (i.e. inverted lists). The results in this paper show that no space overhead is needed at all, and as an application we improve space and query time complexity of the well-known Glimpse tool [glimpse]. We finally investigate the modifiability of our opportunistic data structure by studying
FOCS	The Randomness Recycler: A New Technique for Perfect Sampling.	James Allen Fill,Mark Huber	2000	For many probability distributions of interest, it is quite difficult to obtain samples efficiently. Often, Markov chains are employed to obtain approximately random samples from these distributions. The primary drawback to traditional Markov chain methods is that the mixing time of the chain is usually unknown, which makes it impossible to determine how close the output samples are to having the target distribution. The authors present a novel protocol, the randomness recycler (RR), that overcomes this difficulty. Unlike classical Markov chain approaches, an RR-based algorithm creates samples drawn exactly from the desired distribution. Other perfect sampling methods such as coupling from the past, use existing Markov chains, but RR does not use the traditional Markov chain at all. While by no means universally useful, RR does apply to a wide variety of problems. In restricted instances of certain problems, it gives the first expected linear time algorithms for generating samples. The authors apply RR to self-organizing lists, the Ising model, random independent sets, random colorings, and the random cluster model.
FOCS	Using Expander Graphs to Find Vertex Connectivity.	Harold N. Gabow	2000	The (vertex) connectivity &kappa; of a graph is the smallest number of vertices whose deletion separates the graph or makes it trivial. We present the fastest known algorithm for finding &kappa;. For a digraph with n vertices, m edges and connectivity &kappa; the time bound is O((n &plus; min&lcub;&kappa;&frac52;, &kappa;n&frac34;&rcub;)m). This improves the previous best bound of O((n &plus; min&lcub;&kappa;3, &kappa;n&rcub)m). For an undirected graph both of these bounds hold with m replaced by &kappa;n. Expander graphs are useful for solving the following subproblem that arises in connectivity computation: A known set R of vertices contains two large but unknown subsets that are separated by some unknown set S of &kappa; vertices; we must find two vertices of R that are separated by S.
FOCS	Concurrent Oblivious Transfer.	Juan A. Garay,Philip D. MacKenzie	2000	We consider the problem of designing an efficient oblivious transfer (OT) protocol that is provably secure in a concurrent setting, i.e., where many OT sessions may be running concurrently with their messages interleaved arbitrarily. Known OT protocols use zero-knowledge proofs, and no concurrent zero-knowledge proofs are known that use less than a poly-logarithmic number of rounds (at least without requiring a pre-processing phase, a public random string, an auxiliary string, timing constraints, or pre-distributed public keys). We introduce a model for proving security of concurrent OT protocols, and present a protocol that is proven secure in this model based on the decisional Diffie-Hellman problem. The protocol is efficient, requiring only a slightly non-constant number of rounds. Index Terms: protocols; cryptography; timing; concurrent oblivious transfer; protocol; concurrent setting; zero-knowledge proofs; poly-logarithmic number; public random string; auxiliary string; timing constraints; decisional Diffie-Hellman problem
FOCS	Lower Bounds on the Efficiency of Generic Cryptographic Constructions.	Rosario Gennaro,Luca Trevisan	2000	We present lower bounds on the efficiency of constructions for Pseudo-Random Generators (PRGs) and Universal One-Way Hash Functions (UOWHFs) based on black-box access to one-way permutations. Our lower bounds are tight as they match the efficiency of known constructions. A PRG (resp. UOWHF) construction based on black-box access is a machine that is given oracle access to a permutation. Whenever the permutation is hard to invert, the construction is hard to break. In this paper we give lower bounds on the number of invocations to the oracle by the construction. If S is the assumed security of the oracle permutation /spl pi/ (i.e. no adversary of size S can invert /spl pi/ on a fraction larger than 1/S of its inputs) then a PRG (resp. UOWHF) construction that stretches (resp. compresses) its input by k bits must query /spl pi/ in q=/spl Omega/(k/log S) points. This matches known constructions. Our results are given in an extension of the Impagliazzo-Rudich model. That is, we prove that a proof of the existence of PRG (resp. UOWHF) black-box constructions that beat our lower bound would imply a proof of the unconditional existence of such construction (which would also imply P/spl ne/NP).
FOCS	The Relationship between Public Key Encryption and Oblivious Transfer.	Yael Gertner,Sampath Kannan,Tal Malkin,Omer Reingold,Mahesh Viswanathan	2000	In this paper we study the relationships among some of the most fundamental primitives and protocols in cryptography: public-key encryption (i.e. trapdoor predicates), oblivious transfer (which is equivalent to general secure multi-party computation), key agreement and trapdoor permutations. Our main results show that public-key encryption and oblivious transfer are incomparable under black-box reductions. These separations are tightly matched by our positive results where a restricted (strong) version of one primitive does imply the other primitive. We also show separations between oblivious transfer and key agreement. Finally, we conclude that neither oblivious transfer nor trapdoor predicates imply trapdoor permutations. Our techniques for showing negative results follow the oracle separations of R. Impagliazzo and S. Rudich (1989).
FOCS	Existential Second-Order Logic over Graphs: Charting the Tractability Frontier.	Georg Gottlob,Phokion G. Kolaitis,Thomas Schwentick	2000	"Fagin's theorem, the first important result of descriptive complexity, asserts that a property of graphs is in NP if and only if it is definable by an existential second-order formula. In this article, we study the complexity of evaluating existential second-order formulas that belong to prefix classses of existential second-order logic, where a prefix class is the collection of all existential second-order formulas in prenex normal form such that the second-order and the first-order quantifiers obey a certain quantifier pattern. We completely characterize the computational complexity of prefix classes of existential second-order logic in three different contexts: (1) over directed graphs, (2) over undirected graphs with self-loops and (3) over undirected graphs without self-loops. Our main result is that in each of these three contexts a dichotomy holds, that is to say, each prefix class of existential second-order logic either contains sentences that can express NP-complete problems, or each of its sentences expresses a polynomial-time solvable problem. Although the boundary of the dichotomy coincides for the first two cases, it changes, as one moves to undirected graphs without self-loops. The key difference is that a certain prefix class, based on the well-known Ackermann class of first-order logic, contains sentences that can express NP-complete problems over graphs of the first two types, but becomes tractable over undirected graphs without self-loops. Moreover, establishing the dichotomy over undirected graphs without self-loops turns out to be a technically challenging problem that requires the use of sophisticated machinery from graph theory and combinatorics, including results about graphs of bounded tree-width and Ramsey's theorem."
FOCS	Nested Graph Dissection and Approximation Algorithms.	Sudipto Guha	2000	This paper considers approximation algorithms for graph completion problems using the nested dissection paradigm. Given a super-additive function of interest (the smallest planar or chordal extension for example) and a test that relates it to an upper bound of the smallest separator, we provide a framework how to dissect the graph recursively such that no subgraph has more than half the value of its parent, (or is indistinguishable via separator tests) in polynomial time. Interestingly we cannot bound such a function till we have constructed the entire nested dissection. We achieve a partition of the graph with respect to a constant number of such unknown estimator functions simultaneously. Using the framework the paper presents improvements in approximating the chordal completion size (by a factor of log n), operation count (by a factor of log/sup 2/ n and the polynomial term depending on degree) and elimination height. We show that there exists a nested dissection ordering that simultaneously minimizes the elimination height, chordal completion, operation count to within O(log n) factors of the best possible (which may be obtained by three independent orderings) improving the previous existence theorem by factors of log n and d/sup 1/3/ log/sup 3/ n for the latter two. We also show that graphs with small crossing number or fill-in have better approximations of the elimination height, completion and operation count. As a consequence we can approximate the pathwidth, cutwidth, vertex ranking problems better for such graphs. The paper also improves, in some cases, the approximation results of minimum drawing size (number of vertices plus the crossing number) of a planar embedding of a graph, and its layout area on a grid.
FOCS	Hierarchical Placement and Network Design Problems.	Sudipto Guha,Adam Meyerson,Kamesh Munagala	2000	In this paper, we give the first constant-approximations for a number of layered network design problems. We begin by modeling hierarchical caching, where caches are placed in layers and each layer satisfies a fixed percentage of the demand (bounded miss rates). We present a constant approximation to the minimum total cost of placing the caches and routing demand through the layers. We extend this model to cover more general layered caching scenarios, giving the first constant approximation to the well studied multi-level facility location problem. We consider a facility location variant, the Load Balanced Facility Location problem in which every demand is served by a unique facility and each open facility must serve at least a certain amount of demand. By combining Load Balanced Facility Location with our results on hierarchical caching, we give the first constant approximation for the Access Network Design problem.
FOCS	Clustering Data Streams.	"Sudipto Guha,Nina Mishra,Rajeev Motwani,Liadan O'Callaghan"	2000	We study clustering under the data stream model of computation where: given a sequence of points, the objective is to maintain a consistently good clustering of the sequence observed so far, using a small amount of memory and time. The data stream model is relevant to new classes of applications involving massive data sets, such as Web click stream analysis and multimedia data analysis. We give constant-factor approximation algorithms for the k-median problem in the data stream model of computation in a single pass. We also show negative results implying that our algorithms cannot be improved in a certain sense.
FOCS	Hardness of Approximate Hypergraph Coloring.	Venkatesan Guruswami,Johan Håstad,Madhu Sudan	2000	"We introduce the notion of covering complexity of a verifier for probabilistically checkable proofs (PCPs). Such a verifier is given an input, a claimed theorem, and an oracle, representing a purported proof of the theorem. The verifier is also given a random string and decides whether to accept the proof or not, based on the given random string. We define the covering complexity of such a verifier, on a given input, to be the minimum number of proofs needed to ""satisfy"" the verifier on every random string; i.e., on every random string, at least one of the given proofs must be accepted by the verifier. The covering complexity of PCP verifiers offers a promising route to getting stronger inapproximability results for some minimization problems and, in particular, (hyper)graph coloring problems. We present a PCP verifier for NP statements that queries only four bits and yet has a covering complexity of one for true statements and a superconstant covering complexity for statements not in the language. Moreover, the acceptance predicate of this verifier is a simple not-all-equal check on the four bits it reads. This enables us to prove that, for any constant c, it is NP-hard to color a 2-colorable 4-uniform hypergraph using just c colors and also yields a superconstant inapproximability result under a stronger hardness assumption."
FOCS	"""Soft-decision"" Decoding of Chinese Remainder Codes."	Venkatesan Guruswami,Amit Sahai,Madhu Sudan	2000	Given n relatively prime integers p/sub 1/>...>p/sub n/ and an integer k>n, the Chinese Remainder Code, CRT/sub p1,...,pnik/, has as its message space M={0,...,/spl Pi//sub i=1//sup k/,pi-1}, and encodes a message m /spl isin/M as the vector >m/sub 1/,...,m/sub n/w/sub 1/,...,w/sub n/
FOCS	An Improved Quantum Fourier Transform Algorithm and Applications.	Lisa Hales,Sean Hallgren	2000	We give an algorithm for approximating the quantum Fourier transform over an arbitrary Z/sub p/ which requires only O(n log n) steps where n=log p to achieve an approximation to within an arbitrary inverse polynomial in n. This improves the method of A.Y. Kitaev (1995) which requires time quadratic in n. This algorithm also leads to a general and efficient Fourier sampling technique which improves upon the quantum Fourier sampling lemma of L. Hales and S. Hallgren (1997). As an application of this technique, we give a quantum algorithm which finds the period of an arbitrary periodic function, i.e. a function which may be many-to-one within each period. We show that this algorithm is efficient (polylogarithmic in the period of the function) for a large class of periodic functions. Moreover, using standard quantum lower-bound techniques, we show that this characterization is right. That is, this is the maximal class of periodic functions with an efficient quantum period-finding algorithm.
FOCS	On the Existence of Booster Types.	Maurice Herlihy,Eric Ruppert	2000	"A data type's consensus number measures its power in asynchronous concurrent models of computation. We characterize the circumstances under which types of high consensus number can be constructed from types with lower consensus numbers, a process called boosting. In settings where boosting is impossible, we can reason about the synchronization power of objects in isolation. We give a new and simple topological condition, called /spl kappa/-solo-connectivity sufficient to ensure that one-shot types cannot be boosted to consensus number /spl kappa/. The booster type need not be one-shot; it can be arbitrary. We also show that, for /spl kappa/"
FOCS	Stable Distributions, Pseudorandom Generators, Embeddings and Data Stream Computation.	Piotr Indyk	2000	In this article, we show several results obtained by combining the use of stable distributions with pseudorandom generators for bounded space. In particular:---We show that, for any p &isin; (0, 2], one can maintain (using only O(log n/&epsi;2) words of storage) a sketch C(q) of a point q &isin; lnp under dynamic updates of its coordinates. The sketch has the property that, given C(q) and C(s), one can estimate &Verbar;q &minus; s&Verbar;p up to a factor of (1 &plus; &epsi;) with large probability. This solves the main open problem of Feigenbaum et al. [1999].---We show that the aforementioned sketching approach directly translates into an approximate algorithm that, for a fixed linear mapping A, and given x &isin; &real;n and y &isin; &real;m, estimates &Verbar;Ax &minus; y&Verbar;p in O(n &plus; m) time, for any p &isin; (0, 2]. This generalizes an earlier algorithm of Wasserman and Blum [1997] which worked for the case p &equals; 2.---We obtain another sketch function C&prime; which probabilistically embeds ln1 into a normed space lm1. The embedding guarantees that, if we set m &equals; log(1/&delta;)O(1/&epsi;), then for any pair of points q, s &isin; ln1, the distance between q and s does not increase by more than (1 &plus; &epsi;) with constant probability, and it does not decrease by more than (1 &minus; &epsi;) with probability 1 &minus; &delta;. This is the only known dimensionality reduction theorem for the l1 norm. In fact, stronger theorems of this type (i.e., that guarantee very low probability of expansion as well as of contraction) cannot exist [Brinkman and Charikar 2003].---We give an explicit embedding of ln2 into lnO(log n)1 with distortion (1 &plus; 1/n&Theta;(1)).
FOCS	Randomizing Polynomials: A New Representation with Applications to Round-Efficient Secure Computation.	Yuval Ishai,Eyal Kushilevitz	2000	"Motivated by questions about secure multi-party computation, we introduce and study a new natural representation of functions by polynomials, which we term randomizing polynomials. ""Standard"" low-degree polynomials over a finite field are easy to compute with a small number of communication rounds in virtually any setting for secure computation. However, most Boolean functions cannot be evaluated by a polynomial whose degree is smaller than their input size. We get around this barrier by relaxing the requirement of evaluating f into a weaker requirement of randomizing f: mapping the inputs of f along with independent random inputs into a vector of outputs, whose distribution depends only on the value of f. We show that degree-3 polynomials are sufficient to randomize any function f, relating the efficiency of such a randomization to the branching program size of f. On the other hand, by characterizing the exact class of Boolean functions which can be randomized by degree-2 polynomials, we show that 3 is the minimal randomization degree of most functions. As an application, randomizing polynomials provide a powerful, general, and conceptually simple tool for the design of round-efficient secure protocols. Specifically, the secure evaluation of any function can be reduced to a secure evaluation of degree-3 polynomials. One corollary of this reduction is that two (respectively, three) communication rounds are sufficient for k parties to compute any Boolean function f of their inputs, with perfect information-theoretic [k-1/3]-privacy (resp., [k-1/2]-privacy), and communication complexity which is at most quadratic in the branching program size of f (with a small probability of one-sided error)."
FOCS	The Cover Time, the Blanket Time, and the Matthews Bound.	Jeff Kahn,Jeong Han Kim,László Lovász,Van H. Vu	2000	We prove upper and lower bounds and give an approximation algorithm for the cover time of the random walk on a graph. We introduce a parameter M motivated by the well-known Matthews bounds (P. Matthews, 1988) on the cover time, C, and prove that M/2>C= O(M(lnlnn)/sup 2/). We give a deterministic-polynomial time algorithm to approximate M within a factor of 2; this then approximates C within a factor of O((lnlnn)/sup 2/), improving the previous bound O(lnn) due to Matthews. The blanket time B was introduced by P. Winkler and D. Zuckerman (1996): it is the expectation of the first time when all vertices are visited within a constant factor of the number of times suggested by the stationary distribution. Obviously C/spl les/B. Winkler and Zuckerman conjectured B=O(C) and proved B=O(Clnn). Our bounds above are also valid for the blanket time, and so it follows that B=O(C(lnlnn)/sup 2/).
FOCS	Efficient Algorithms for Universal Portfolios.	Adam Kalai,Santosh Vempala	2000	"A constant rebalanced portfolio is an investment strategy that keeps the same distribution of wealth among a set of stocks from day to day. There has been much work on Cover's Universal algorithm, which is competitive with the best constant rebalanced portfolio determined in hindsight (Cover, 1991, Helmbold et al, 1998, Blum and Kalai, 1999, Foster and Vohra, 1999, Vovk, 1998, Cover and Ordentlich, 1996a, Cover, 1996c). While this algorithm has good performance guarantees, all known implementations are exponential in the number of stocks, restricting the number of stocks used in experiments (Helmbold et al, 1998, Cover and Ordentlich, 1996a, Ordentlich and Cover, 1996b, Cover, 1996c, Blum and Kalai, 1999). We present an efficient implementation of the Universal algorithm that is based on non-uniform random walks that are rapidly mixing (Applegate and Kannan, 1991, Lovasz and Simonovits, 1992, Frieze and Kannan, 1999). This same implementation also works for non-financial applications of the Universal algorithm, such as data compression (Cover, 1996c) and language modeling (Chen et al, 1999)."
FOCS	Building Steiner Trees with Incomplete Global Knowledge.	David R. Karger,Maria Minkoff	2000	A networking problem of present-day interest is that of distributing a single data item to multiple clients while minimizing network usage. Steiner tree algorithms are a natural solution method, but only when the set of clients requesting the data is known. We study what can be done without this global knowledge, when a given vertex knows only the probability that any other client wishes to be connected, and must simply specify a fixed path to the data to be used in case it is requested. Our problem is an example of a class of network design problems with concave cost functions (which arise when the design problem exhibits economies of scale). In order to solve our problem, we introduce a new version of the facility location problem: one in which every open facility is required to have some minimum amount of demand assigned to it. We present a simple bicriterion approximation for this problem, one which is loose in both assignment cost and minimum demand, but within a constant factor of the optimum for both. This suffices for our application. We leave open the question of finding an algorithm that produces a truly feasible approximate solution.
FOCS	Optimization Problems in Congestion Control.	Richard M. Karp,Elias Koutsoupias,Christos H. Papadimitriou,Scott Shenker	2000	"One of the crucial elements in the Internet's success is its ability to adequately control congestion. The paper defines and solves several optimization problems related to Internet congestion control, as a step toward understanding the virtues of the TCP congestion control algorithm currently used and comparing it with alternative algorithms. We focus on regulating the rate of a single unicast flow when the bandwidth available to it is unknown and may change over time. We determine near-optimal policies when the available bandwidth is unchanging, and near-optimal competitive policies when the available bandwidth is changing in a restricted manner under the control of an adversary."
FOCS	Randomized Rumor Spreading.	Richard M. Karp,Christian Schindelhauer,Scott Shenker,Berthold Vöcking	2000	Investigates the class of epidemic algorithms that are commonly used for the lazy transmission of updates to distributed copies of a database. These algorithms use a simple randomized communication mechanism to ensure robustness. Suppose n players communicate in parallel rounds in each of which every player calls a randomly selected communication partner. In every round, players can generate rumors (updates) that are to be distributed among all players. Whenever communication is established between two players, each one must decide which of the rumors to transmit. The major problem is that players might not know which rumors their partners have already received. For example, a standard algorithm forwarding each rumor form the calling to the called players for /spl Theta/(ln n) rounds needs to transmit the rumor /spl Theta/(n ln n) times in order to ensure that every player finally receives the rumor with high probability. We investigate whether such a large communication overhead is inherent to epidemic algorithms. On the positive side, we show that the communication overhead can be reduced significantly. We give an algorithm using only O(n ln ln n) transmissions and O(ln n) rounds. In addition, we prove the robustness of this algorithm. On the negative side, we show that any address-oblivious algorithm needs to send /spl Omega/(n ln ln n) messages for each rumor, regardless of the number of rounds. Furthermore, we give a general lower bound showing that time and communication optimality cannot be achieved simultaneously using random phone calls, i.e. every algorithm that distributes a rumor in O(ln n) rounds needs /spl omega/(n) transmissions.
FOCS	Linear Waste of Best Fit Bin Packing on Skewed Distributions.	Claire Kenyon,Michael Mitzenmacher	2000	We prove that Best Fit bin packing has linear waste on the discrete distribution U{j, k} (where items are drawn uniformly from the set {1/k,2/k ..... j/k}) for sufficiently large k when j = αk and 0.66 ≥ α > 2/3. Our results extend to continuous skewed distributions, where items are drawn uniformly on [0, a], for 0.66 ≥ a > 2/3. This implies that the expected asymptotic performance ratio of Best Fit is strictly greater than 1 for these distributions.
FOCS	Detecting a Network Failure.	Jon M. Kleinberg	2000	"Measuring the properties of a large, unstructured network can be difficult: one may not have full knowledge of the network topology, and detailed global measurements may be infeasible. A valuable approach to such problems is to take measurements from selected locations within the network and then aggregate them to infer large-scale properties. One sees this notion applied in settings that range from Internet topology discovery tools to remote software agents that estimate the download times of popular Web pages. Some of the most basic questions about this type of approach, however, are largely unresolved at an analytical level. How reliable are the results? How much does the choice of measurement locations affect the aggregate information one infers about the network? We describe algorithms that yield provable guarantees for a particular problem of this type: detecting a network failure. Suppose we want to detect events of the following form: an adversary destroys up to k nodes or edges, after which two subsets of the nodes, each at least an /spl epsi/ fraction of the network, are disconnected from one another. We call such an event an (/spl epsi/,k) partition. One method for detecting such events would be to place ""agents"" at a set D of nodes, and record a fault whenever two of them become separated from each other. To be a good detection set, D should become disconnected whenever there is an (/spl epsi/,k)-partition; in this way, it ""witnesses"" all such events. We show that every graph has a detection set of size polynomial in k and /spl epsi//sup -1/, and independent of the size of the graph itself. Moreover, random sampling provides an effective way to construct such a set. Our analysis establishes a connection between graph separators and the notion of VC-dimension, using techniques based on matchings and disjoint paths."
FOCS	Fairness Measures for Resource Allocation.	Amit Kumar,Jon M. Kleinberg	2000	In many optimization problems, one seeks to allocate a limited set of resources to a set of individuals with demands. Thus, such allocations can naturally be viewed as vectors, with one coordinate representing each individual. Motivated by work in network routing and bandwidth assignment, we consider the problem of producing solutions that simultaneously approximate all feasible allocations in a coordinate-wise sense. This is a very strong type of &ldquo;global&rdquo; approximation guarantee, and we explore its consequences in a wide range of discrete optimization problems, including facility location, scheduling, and bandwidth assignment in networks. A fundamental issue&mdash;one not encountered in the traditional design of approximation algorithms&mdash;is that good approximations in this global sense need not exist for every problem instance; there is no a priori reason why there should be an allocation that simultaneously approximates all others. As a result, the existential questions concerning such good allocations lead to a new perspective on a number of fundamental problems in resource allocation, and on the structure of their feasible solutions.
FOCS	Random graph models for the web graph.	Ravi Kumar,Prabhakar Raghavan,Sridhar Rajagopalan,D. Sivakumar,Andrew Tomkins,Eli Upfal	2000	Random graph models for the web graph.
FOCS	The Common Fragment of CTL and LTL.	Monika Maidl	2000	It is well-known that CTL (computation tree logic) and LTL (linear time logic) have incomparable expressive power. In this paper, we give an inductive definition of those ACTL (Action-based CTL) formulas that can be expressed in LTL. In addition, we obtain a procedure to decide whether an ACTL formula lies in LTL, and show that this problem is PSPACE-complete. By omitting path quantifiers, we get an inductive definition of the LTL formulas that are expressible in ACTL. We can show that the fragment defined by our logic represents exactly those LTL formulas the negation of which can be represented by a 1-weak Bu/spl uml/chi automaton and that, for this fragment, the representing automaton can be chosen to be of size linear in the size of the formula.
FOCS	Sampling Adsorbing Staircase Walks Using a New Markov Chain Decomposition Method.	Russell A. Martin,Dana Randall	2000	Staircase walks are lattice paths from (0,0) to (2n,0) which take diagonal steps and which never fall below the x-axis. A path hitting the x-axis /spl kappa/ times is assigned a weight of /spl lambda//sup /spl kappa//, where /spl lambda/1. We give the first proof that this Markov chain is also mixing in the more interesting case of /spl lambda/
FOCS	The Online Median Problem.	Ramgopal R. Mettu,C. Greg Plaxton	2000	We introduce a natural variant of the (metric uncapacitated) k-median problem that we call the online median problem. Whereas the k-median problem involves optimizing the simultaneous placement of k facilities, the online median problem imposes the following additional constraints: the facilities are placed one at a time; a facility, once placed, cannot be moved; the total number of facilities to be placed, k, is not known in advance. The objective of an online median algorithm is to minimize competitive ratio, that is, the worst-case ratio of the cost of an online placement to that of an optimal offline placement. Our main result is a linear-time constant-competitive algorithm for the online median problem. In addition, we present a related, though substantially simpler, linear-time constant-factor approximation algorithm for the (metric uncapacitated) facility location problem. The latter algorithm is similar in spirit to the recent primal-dual-based facility location algorithm of Jain and Vazirani, but our approach is more elementary and yields an improved running time.
FOCS	Cost-Distance: Two Metric Network Design.	Adam Meyerson,Kamesh Munagala,Serge A. Plotkin	2000	We present the Cost-Distance problem: finding a Steiner tree which optimizes the sum of edge costs along one metric and the sum of source-sink distances along an unrelated second metric. We give the first known $O(\log k)$ randomized approximation scheme for Cost-Distance, where $k$ is the number of sources. We reduce several common network design problems to Cost-Distance, obtaining (in some cases) the first known logarithmic approximation for them. These problems include single-sink buy-at-bulk with variable pipe types between different sets of nodes, facility location with buy-at-bulk-type costs on edges (integrated logistics), constructing single-source multicast trees with good cost and delay properties, priority Steiner trees, and multilevel facility location. Our algorithm is also easier to implement and significantly faster than previously known algorithms for buy-at-bulk design problems.
FOCS	Polynomial Time Approximation Schemes for Geometric k-Clustering.	Rafail Ostrovsky,Yuval Rabani	2000	"We deal with the problem of clustering data points. Given n points in a larger set (for example, R/sup d/) endowed with a distance function (for example, L/sup 2/ distance), we would like to partition the data set into k disjoint clusters, each with a ""cluster center"", so as to minimize the sum over all data points of the distance between the point and the center of the cluster containing the point. The problem is provably NP-hard in some high dimensional geometric settings, even for k=2. We give polynomial time approximation schemes for this problem in several settings, including the binary cube (0, 1)/sup d/ with Hamming distance, and R/sup d/ either with L/sup 1/ distance, or with L/sup 2/ distance, or with the square of L/sup 2/ distance. In all these settings, the best previous results were constant factor approximation guarantees. We note that our problem is similar in flavor to the k-median problem (and the related facility location problem), which has been considered in graph-theoretic and fixed dimensional geometric settings, where it becomes hard when k is part of the input. In contrast, we study the problem when k is fixed, but the dimension is part of the input. Our algorithms are based on a dimension reduction construction for the Hamming cube, which may be of independent interest."
FOCS	On the boundary complexity of the union of fat triangles.	János Pach,Gábor Tardos	2000	A triangle is said to be {\it $\delta$-fat\/} if its smallest angle is at least $\delta>0$. A connected component of the complement of the union of a family of triangles is called a {\it hole}. It is shown that any family of n $\delta$-fat triangles in the plane determines at most $O\left(\frac{n}{\delta}\log\frac{2}{\delta}\right)$ holes. This improves on some earlier bounds of Efrat, Rote, Sharir, and Matousek, et al. Solving a problem of Agarwal and Bern, we also give a general upper bound for the number of holes determined by n triangles in the plane with given angles. As a corollary, we obtain improved upper bounds for the boundary complexity of the union of fat polygons in the plane, which, in turn, leads to better upper bounds for the running times of some known algorithms for motion planning, for finding a separator line for a set of segments, etc.
FOCS	The product replacement algorithm is polynomial.	Igor Pak	2000	The product replacement algorithm is a heuristic designed to generate random group elements. The idea is to run a random walk on generating /spl kappa/-tuples of the group, and then output a random component. The algorithm was designed by C.R. Leedham-Green, and further investigated by F. Cellar et al. (1995). It was found to have an outstanding performance, much better than the previously known algorithms (P. Diaconis and L. Saloff-Coste, 1996). The algorithm is now included in two major group algebra packages: GAP (M. Scheonert et al., 1995) and MAGMA (W. Bosma et al., 1997). In spite of the many serious attempts and partial results, the analysis of the algorithm remains difficult at best. For small values of /spl kappa/, even graph connectivity becomes a serious obstacle. The most general results are due to Diaconis and Saloff-Coste, who used a state of the art analytic technique to obtain polynomial bounds in special cases, and (sub)-exponential bounds in the general case. The main result of the paper is a polynomial upper bound for the cost of the algorithm, provided /spl kappa/ is large enough.
FOCS	On the Approximability of Trade-offs and Optimal Access of Web Sources.	Christos H. Papadimitriou,Mihalis Yannakakis	2000	We study problems in multiobjective optimization, in which solutions to a combinatorial optimization problem are evaluated with respect to several cost criteria, and we are interested in the trade-off between these objectives (the so-called Pareto curve). We point out that, under very general conditions, there is a polynomially succinct curve that /spl epsiv/-approximates the Pareto curve, for any /spl epsiv/
FOCS	Testing of Functions that have small width Branching Programs.	Ilan Newman	2000	Combinatorial property testing, initiated formally by (Goldreich et al., 1996) and inspired by (Rubinfeld and Sudan, 1996), deals with the following relaxation of decision problems: given a fixed property and an input x, one wants to decide whether x has the property or is being far from having the property. The main result here is that if G={g:{0,1}/sup n//spl rarr/{0,1}} is a family of Boolean functions that have read-once branching programs of width w, then for every n and /spl epsiv/
FOCS	Entropy Waves, the Zig-Zag Graph Product, and New Constant-Degree Expanders and Extractors.	Omer Reingold,Salil P. Vadhan,Avi Wigderson	2000	"The main contribution is a new type of graph product, which we call the zig-zag product. Taking a product of a large graph with a small graph, the resulting graph inherits (roughly) its size from the large one, its degree from the small one, and its expansion properties from both. Iteration yields simple explicit constructions of constant-degree expanders of every size, starting from one constant-size expander. Crucial to our intuition (and simple analysis) of the properties of this graph product is the view of expanders as functions which act as ""entropy wave"" propagators-they transform probability distributions in which entropy is concentrated in one area to distributions where that concentration is dissipated. In these terms, the graph product affords the constructive interference of two such waves. A variant of this product can be applied to extractors, giving the first explicit extractors whose seed length depends (poly)logarithmically on only the entropy deficiency of the source (rather than its length) and that extract almost all the entropy of high min-entropy sources. These high min-entropy extractors have several interesting applications, including the first constant-degree explicit expanders which beat the ""eigenvalue bound""."
FOCS	The Quantum Complexity of Set Membership.	Jaikumar Radhakrishnan,Pranab Sen,Srinivasan Venkatesh	2000	"Studies the quantum complexity of the static set membership problem: given a subset S (|S|/spl les/n) of a universe of size m(/spl Gt/n), store it as a table, T:(0,1)/sup r//spl rarr/(0,1), of bits so that queries of the form 'is x in S?' can be answered. The goal is to use a small table and yet answer queries using a few bit probes. This problem was considered by H. Buhrman et al. (2000), who showed lower and upper bounds for this problem in the classical deterministic and randomised models. In this paper, we formulate this problem in the ""quantum bit-probe model"". We assume that access to the table T is provided by means of a black-box (oracle) unitary transform O/sub T/ that takes the basis state (y,b) to the basis state |y,b/spl oplus/T(y)"
FOCS	How Bad is Selfish Routing?	Tim Roughgarden,Éva Tardos	2000	"We consider the problem of routing traffic to optimize the performance of a congested network. We are given a network, a rate of traffic between each pair of nodes, and a latency function for each edge specifying the time needed to traverse the edge given its congestion; the objective is to route traffic such that the sum of all travel times-the total latency-is minimized. In many settings, including the Internet and other large-scale communication networks, it may be expensive or impossible to regulate network traffic so as to implement an optimal assignment of routes. In the absence of regulation by some central authority, we assume that each network user routes its traffic on the minimum-latency path available to it, given the network congestion caused by the other users. In general such a ""selfishly motivated"" assignment of traffic to paths will not minimize the total latency; hence, this lack of regulation carries the cost of decreased network performance. We quantify the degradation in network performance due to unregulated traffic. We prove that if the latency of each edge is a linear function of its congestion, then the total latency of the routes chosen by selfish network users is at most 4/3 times the minimum possible total latency (subject to the condition that all traffic must be routed). We also consider the more general setting in which edge latency functions are assumed only to be continuous and non-decreasing in the edge congestion."
FOCS	Extracting Randomness via Repeated Condensing.	Omer Reingold,Ronen Shaltiel,Avi Wigderson	2000	"Extractors (as defined by Nisan and Zuckerman) are procedures that use a small number of truly random bits (called the seed) to extract many (almost) truly random bits from arbitrary distributions as long as distributions have sufficient (min)-entropy. A natural weakening of an extractor is a condenser, whose output distribution has a higher entropy rate than the input distribution (without losing much of the initial entropy). An extractor can be viewed as an ultimate condenser because it outputs a distribution with the maximal entropy rate.In this paper we construct explicit condensers with short seed length. The condenser constructions combine (variants of or more efficient versions of) ideas from several works, including the block extraction scheme of [N. Nisan and D. Zuckerman, J. Comput. System Sci., 52 (1996), pp. 43-52], the observation made in [A. Srinivasan and D. Zuckerman, SIAM J. Comput., 28 (1999), pp. 1433-1459; N. Nisan and A. Ta-Shma, J. Comput. System Sci., 58 (1999), pp. 148-173] that a failure of the block extraction scheme is also useful, the recursive ""win-win"" case analysis of [R. Impagliazzo, R. Shaltiel, and A. Wigderson, Near-optimal conversion of hardness into pseudo-randomness, in Proceedings of the 40th Annual IEEE Symposium on Foundations of Computer Science, IEEE, Los Alamitos, CA, 1999, pp. 181-190; R. Impagliazzo, R. Shaltiel, and A. Wigderson, Extractors and pseudo-random generators with optimal seed length, in Proceedings of the 32nd Annual ACM Symposium on Theory of Computing, ACM, New York, 2000, pp. 1-10], and the error correction of random sources used in [L. Trevisan, J. ACM, 48 (2001), pp. 860-879]. As a by-product (via repeated iterating of condensers), we obtain new extractor constructions. The new extractors give significant qualitative improvements over previous ones for sources of arbitrary min-entropy; they are nearly optimal simultaneously in the two main parameters of seed length and output length. Specifically, our extractors can make any one of these two parameters optimal (up to a constant factor) only at a polylogarithmic loss in the other. Previous constructions require polynomial loss in both cases for general sources.We also give a simple reduction converting ""standard"" extractors (which are good for an average seed) into ""strong"" ones (which are good for most seeds), with essentially the same parameters. With this reduction, all the above improvements apply to strong extractors as well."
FOCS	Approximating the single source unsplittable min-cost flow problem.	Martin Skutella	2000	In the single source unsplittable min-cost flow problem, commodities must be routed simultaneously from a common source vertex to certain destination vertices in a given graph with edge capacities and costs; the demand of each commodity must be routed along a single path and the total cost must not exceed a given budget. This problem has been introduced by J.M. Kleinberg (1996) and generalizes several NP-complete problems from various areas in combinatorial optimization such as packing, partitioning, scheduling load balancing, and virtual-circuit routing. S.G. Kolliopoulos and C. Stein (2000) and Y.N. Dinitz et al. (1999) developed algorithms improving the first approximation results of Kleinberg for the problem to minimize the violation of edge capacities and for other variants. However, none of the developed techniques is capable of providing solutions without also violating the cost constraint. We give the first approximation results with hard cost constraints. Moreover all our results dominate the best known bicriteria approximations. Finally, we provide results on the hardness of approximation for several variants of the problem.
FOCS	A Combinatorial Approach to Planar Non-colliding Robot Arm Motion Planning.	Ileana Streinu	2000	"We propose a combinatorial approach to plan noncolliding motions for a polygonal bar-and-joint framework. Our approach yields very efficient deterministic algorithms for a category of robot arm motion planning problems with many degrees of freedom, where the known general roadmap techniques would give exponential complexity. It is based on a novel class of one-degree-of-freedom mechanisms induced by pseudo triangulations of planar point sets, for which we provide several equivalent characterization and exhibit rich combinatorial and rigidity theoretic properties. The main application is an efficient algorithm for the Carpenter's rule problem: convexify a simple bar-and-joint planar polygonal linkage using only non self-intersecting planar motions. A step in the convexification motion consists in moving a pseudo-triangulation-based mechanism along its unique trajectory in configuration space until two adjacent edges align. At that point, a local alteration restores the pseudo triangulation. The motion continues for O(n/sup 2/) steps until all the points are in convex position."
FOCS	Approximability and in-approximability results for no-wait shop scheduling.	Maxim Sviridenko,Gerhard J. Woeginger	2000	We investigate the approximability of no-wait shop scheduling problems under the makespan criterion. In a flow shop, all jobs pass through the machines in the same ordering. In the more general job shop, the routes of the jobs are job-dependent. We present a polynomial time approximation scheme (PTAS) for the no-wait flow shop problem on any fixed number of machines. Unless P=NP, this result cannot be extended to the job shop problem on a fixed number of machines: We show that the no-wait job shop problem is APX-hard on (i) two machines with at most five operations per job, and on (ii) three machines with at most three operations per job.
FOCS	On the Hardness of Graph Isomorphism.	Jacobo Torán	2000	We show that the graph isomorphism problem is hard under DLOGTIME uniform AC{$^0$} many-one reductions for the complexity classes NL, PL (probabilistic logarithmic space) for every logarithmic space modular class {Mod}$_k$L and for the class DET of problems NC{$^1$} reducible to the determinant. These are the strongest known hardness results for the graph isomorphism problem and imply a randomized logarithmic space reduction from the perfect matching problem to graph isomorphism. We also investigate hardness results for the graph automorphism problem.
FOCS	Extracting Randomness from Samplable Distributions.	Luca Trevisan,Salil P. Vadhan	2000	The standard notion of a randomness extractor is a procedure which converts any weak source of randomness into an almost uniform distribution. The conversion necessarily uses a small amount of pure randomness, which can be eliminated by complete enumeration in some, but not all, applications. We consider the problem of deterministically converting a weak source of randomness into an almost uniform distribution. Previously, deterministic extraction procedures were known only for sources satisfying strong independence requirements. We look at sources which are samplable, i.e. can be generated by an efficient sampling algorithm. We seek an efficient deterministic procedure that, given a sample from any samplable distribution of sufficiently large min-entropy, gives an almost uniformly distributed output. We explore the conditions under which such deterministic extractors exist. We observe that no deterministic extractor exists if the sampler is allowed to use more computational resources than the extractor. On the other hand, if the extractor is allowed (polynomially) more resources than the sampler, we show that deterministic extraction becomes possible. This is true unconditionally in the nonuniform setting (i.e., when the extractor can be computed by a small circuit), and (necessarily) relies on complexity assumptions in the uniform setting.
FOCS	On Clusterings - Good, Bad and Spectral.	Ravi Kannan,Santosh Vempala,Adrian Vetta	2000	"We motivate and develop a natural bicriteria measure for assessing the quality of a clustering that avoids the drawbacks of existing measures. A simple recursive heuristic is shown to have poly-logarithmic worst-case guarantees under the new measure. The main result of the article is the analysis of a popular spectral algorithm. One variant of spectral clustering turns out to have effective worst-case guarantees; another finds a ""good"" clustering, if one exists."
FOCS	Succinct quantum proofs for properties of finite groups.	John Watrous	2000	The article considers a quantum computational variant of nondeterminism based on the notion of a quantum proof, which is a quantum state that plays a role similar to a certificate in an NP-type proof. Specifically, we consider quantum proofs for properties of black-box groups, which are finite groups whose elements are encoded as strings of a given length and whose group operations are performed by a group oracle. We prove that for an arbitrary group oracle, there exist succinct (polynomial-length) quantum proofs for the Group Non-Membership problem that can be checked with small error in polynomial time on a quantum computer. Classically, this is impossible; it is proved that there exists a group oracle, relative to which this problem does not have succinct proofs that can be checked classically with bounded error in polynomial time (i.e., the problem is not in MA relative to the group oracle constructed). By considering a certain subproblem of the Group Non-Membership problem, we obtain a simple proof that there exists an oracle relative to which BQP is not contained in MA. Finally, we show that quantum proofs for non-membership and classical proofs for various other group properties can be combined to yield succinct quantum proofs for other group properties not having succinct proofs in the classical setting, such as verifying that a number divides the order of a group and verifying that a group is not a simple group.
FOCS	41st Annual Symposium on Foundations of Computer Science, FOCS 2000, 12-14 November 2000, Redondo Beach, California, USA		2000	41st Annual Symposium on Foundations of Computer Science, FOCS 2000, 12-14 November 2000, Redondo Beach, California, USA
SODA	Pattern matching in dynamic texts.	Stephen Alstrup,Gerth Stølting Brodal,Theis Rauhe	2000	Pattern matching in dynamic texts.
SODA	Exact and approximation algorithms for minimum-width cylindrical shells.	Pankaj K. Agarwal,Boris Aronov,Micha Sharir	2000	Exact and approximation algorithms for minimum-width cylindrical shells.
SODA	Word encoding tree connectivity works.	Stephen Alstrup,Jens P. Secher,Mikkel Thorup	2000	Word encoding tree connectivity works.
SODA	Approximation algorithms for layered manufacturing.	Pankaj K. Agarwal,Pavan K. Desikan	2000	Approximation algorithms for layered manufacturing.
SODA	TSP-based curve reconstruction in polynomial time.	Ernst Althaus,Kurt Mehlhorn	2000	TSP-based curve reconstruction in polynomial time.
SODA	Computing the arrangement of curve segments: divide-and-conquer algorithms via sampling.	Nancy M. Amato,Michael T. Goodrich,Edgar A. Ramos	2000	Computing the arrangement of curve segments: divide-and-conquer algorithms via sampling.
SODA	Approximation algorithms for projective clustering.	Pankaj K. Agarwal,Cecilia Magdalena Procopiuc	2000	We consider the following two instances of the projective clustering problem: Given a set S of n points in Rd and an integer k > 0, cover S by k slabs (respectively d-cylinders) so that the maximum width of a slab (respectively the maximum diameter of a d-cylinder) is minimized. Let w* be the smallest value so that S can be covered by k slabs (respectively d-cylinders), each of width (respectively diameter) at most w*. This paper contains three main results: (i) For d = 2, we present a randomized algorithm that computes O(k log k) strips of width at most w* that cover S. Its expected running time is O(nk2log4n) if k2 log k ≤ n; for larger values of k, the expected running time is O(n2/3k8/3log14/3n). (ii) For d = 3, a cover of S by O(k log k) slabs of width at most w* can be computed in expected time O(n3/2k9/4polygon(n)).(iii) We compute a cover of S ⊂ Rd by O(dk log k) d-cylinders of diameter at most 8w* in expected time O(dnk3 log4 n). We also present a few extensions of this result.
SODA	Real scaled matching.	Amihood Amir,Ayelet Butman,Moshe Lewenstein	2000	Real scaled matching.
SODA	Accurate approximations for Asian options.	Donald Aingworth,Rajeev Motwani,Jeffrey D. Oldham	2000	Accurate approximations for Asian options.
SODA	Faster algorithms for string matching with mismatches.	Amihood Amir,Moshe Lewenstein,Ely Porat	2000	The string matching with mismatches problem is that of finding the number of mismatches between a pattern P of length m and every length m substring of the text T. Currently, the fastest algorithms for this problem are the following. The Galil-Giancarlo algorithm finds all locations where the pattern has at most k errors (where k is part of the input) in time O(nk). The Abrahamson algorithm finds the number of mismatches at every location in time O(n√ m log m). We present an algorithm that is faster than both. Our algorithm finds all locations where the pattern has at most k errors in time O(n√k log k). We also show an algorithm that solves the above problem in time O((n + (nk3)/m) log k).
SODA	Inplace run-length 2d compressed search.	Amihood Amir,Gad M. Landau,Dina Sokol	2000	The recent explosion in the amount of stored data has necessitated the storage and transmission of data in compressed form. The need to quickly access this data has given rise to a new paradigm in searching, that of compressed matching (Proc. Data Compression Conf, Snow Bird, UT, 1992, pp. 279-288; Proc. 8th Annu. Symp. on Combinatorial Pattern Matching (CPM 97), Lecture Notes in Computer Science, Vol. 1264, Springer, Berlin, 1997, pp. 40-51; Proc. 7th Annu. Symp. on Combinatorial Pattern Matching (CPM 96), Lecture Notes in Computer Science, Vol. 1075, Springer, Berlin, 1996, pp. 39-49). The goal of the compressed pattern matching problem is to find a pattern in a text without decompressing the text.The criterion of extra space is very relevant to compressed searching. An algorithm is called inplace if the amount of extra space used is proportional to the input size of the pattern. In this paper we present a 2d compressed matching algorithm that is inplace. Let compressed(T) and compressed(P) denote the compressed text and pattern, respectively. The algorithm presented in this paper runs in time O(|compressed(T)| + |P|log σ) where σ is min(|P|,|Σ), and Σ is the alphabet, for all patterns that have no trivial rows (rows consisting of a single repeating symbol). The amount of space used is O(|compressed(P)|). The compression used is the 2d run-length compression, used in FAX transmission.
SODA	Coloring powers of planar graphs.	Geir Agnarsson,Magnús M. Halldórsson	2000	We give nontrivial bounds for the inductiveness or degeneracy of power graphs Gk of a planar graph G. This implies bounds for the chromatic number as well, since the inductiveness naturally relates to a greedy algorithm for vertex-coloring the given graph. The inductiveness moreover yields bounds for the choosability of the graph. We show that the inductiveness of a square of a planar graph G is at most $\lceil 9\Delta /5 \rceil$, for the maximum degree $\Delta$ sufficiently large, and that it is sharp. In general, we show for a fixed integer $k\geq1$ the inductiveness, the chromatic number, and the choosability of Gk to be $O(\Delta^{\lfloor k/2 \rfloor})$, which is tight.
SODA	Instability of FIFO in session-oriented networks.	Matthew Andrews	2000	We show that the First-In-First-Out (FIFO) scheduling discipline can be unstable in the (σ,ρ) regulated session model for packet-switched networks. In this model packets are injected into the network in fixed sessions. The total size of the session-i packets injected during the time interval [x, y) is at most σi + ρi(y - x) for some burst parameter σi and rate ρi. The sum of the rates of sessions passing through a server is at most the server speed.Previous work on FIFO stability either allowed for dynamically changing session paths or else assumed that session-i packets are injected at a constant rate. Our result shows that FIFO can be unstable for static paths as long as the injections into a session can be temporarily suspended.
SODA	The effects of temporary sessions on network performance.	Matthew Andrews,Lisa Zhang	2000	We consider a packet network, in which packets are injected in sessions along fixed paths. Packet movement is restricted by link bandwidth. In case of contention, a contention resolution protocol determines which packets proceed. In the permanent session model, a fixed set of connections is present in the network at all times. In the temporary session model, connections come and go over time. In this paper we compare network performance in these two models in terms of stability and end-to-end delay.We provide the first separation of the two models in terms of stability. In particular, we show that generalized processor sharing (GPS) can be unstable with temporary sessions, whereas GPS is known to be stable and have polynomial delay bounds with permanent sessions.We also observe that the relative performance of protocols can differ in the two models. For example, in the temporary session model the protocol farthest-to-go (FTG) is known to be stable and therefore outperforms GPS. However, in the permanent session model we show that FTG can suffer exponential delays and is therefore outperformed by GPS.Although polynomial delay bounds are easy to obtain for permanent sessions, this is not the case when sessions can be temporary. We show that a common framework for bounding delays can only lead to superpolynomial bounds in the temporary session model. We also construct superpolynomial lower bounds on delay for a large class of deterministic, distributed protocols that includes the longest-in-system protocol.
SODA	Cutting planes and the traveling salesman problem (abstract only).	David Applegate,Robert E. Bixby,Vasek Chvátal,William J. Cook	2000	Cutting planes and the traveling salesman problem (abstract only).
SODA	Approximating the maximum quadratic assignment problem.	Esther M. Arkin,Refael Hassin	2000	Approximating the maximum quadratic assignment problem.
SODA	A 2+epsilon approximation algorithm for the -MST problem.	Sanjeev Arora,George Karakostas	2000	A 2+epsilon approximation algorithm for the -MST problem.
SODA	The interlace polynomial: a new graph polynomial.	Richard Arratia,Béla Bollobás,Gregory B. Sorkin	2000	The interlace polynomial: a new graph polynomial.
SODA	Expected-case complexity of approximate nearest neighbor searching.	Sunil Arya,Ho-Yam Addy Fu	2000	Most research in algorithms for geometric query problems has focused on their worst-case performance. However, when information on the query distribution is available, the alternative paradigm of designing and analyzing algorithms from the perspective of expected-case performance appears more attractive. We study the approximate nearest neighbor problem from this perspective.As a first step in this direction, we assume that the query points are sampled uniformly from a hypercube that encloses all the data points; however, we make no assumption on the distribution of the data points. We show that with a simple partition tree, called the sliding-midpoint tree, it is possible to achieve linear space and logarithmic query time in the expected case; in contrast, the data structures known to achieve linear space and logarithmic query time in the worst case are complex, and algorithms on them run more slowly in practice. Moreover, we prove that the sliding-midpoint tree achieves optimal expected query time in a certain class of algorithms.
SODA	Improved approximation algorithms for MAX SAT.	Takao Asano,David P. Williamson	2000	"MAX SAT (the maximum satisfiability problem) is stated as follows: given a set of clauses with weights, find a truth assignment that maximizes the sum of the weights of the satisfied clauses. In this paper, we consider approximation algorithms for MAX SAT proposed by Goemans and Williamson and present a sharpened analysis of their performance guarantees. We also show that these algorithms, combined with recent approximation algorithms for MAX 2SAT, MAX 3SAT, and MAX SAT due to Feige and Goemans, Karloff and Zwick, and Zwick, respectively, lead to an improved approximation algorithm for MAX SAT. By using the MAX 2SAT and 3SAT algorithms, we obtain a performance guarantee of 0.7846, and by using Zwick's algorithm, we obtain a performance guarantee of 0.8331, which improves upon the performance guarantee of 0.7977 based on Zwick's conjecture. The best previous result for MAX SAT without assuming Zwick's conjecture is a 0.770-approximation algorithm of Asano. Our best algorithm requires a new family of 3/4-approximation algorithms that generalize a previous algorithm of Goemans and Williamson."
SODA	"Strong bias of group generators: an obstacle to the ``product replacement algorithm''."	László Babai,Igor Pak	2000	"Let G be a finite group. Efficient generation of nearly uniformly distributed random elements in G, starting from a given set of generators of G, is a central problem in computational group theory. In this paper we demonstrate a weakness in the popular ""product replacement algorithm,"" widely used for this purpose. The main results are the following. Let Nk(G) be the set of generating k-tuples of elements of G. Consider the distribution of the first components of the k-tuples in Nk(G) induced by the uniform distribution over Nk(G). We show that there exist infinite sequences of gtoups G such that this distribution is very far from uniform in two different senses: (1) its variation distance from uniform is > 1 - ε and (2) there exists a short word (of length (loglog |G|)O(k)) which separates the two distributions with probability 1 - ε. The class of groups we analyze is direct powers of alternating groups. The methods used include statistical analysis of permutation groups, the theory of random walks, the AKS sorting network, and a randomized simulation of monotone Boolean operations by group operations, inspired by Barrington's work on bounded-width branching programs. The problem is motivated by the product replacement algorithm which was introduced in [Comm. Algebra 23 (1995) 4931-4948] and is widely used. Our results show that for certain groups the probability distribution obtained by the product replacement algorithm has a bias which can be detected by a short straight line program."
SODA	Minimizing maximum response time in scheduling broadcasts.	Yair Bartal,S. Muthukrishnan	2000	Minimizing maximum response time in scheduling broadcasts.
SODA	Scheduling to minimize average stretch without migration.	Luca Becchetti,Stefano Leonardi,S. Muthukrishnan	2000	Scheduling to minimize average stretch without migration.
SODA	Finding minimal triangulations of convex 3-polytopes is NP-hard.	Alexander Below,Jesús A. De Loera,Jürgen Richter-Gebert	2000	Finding minimal triangulations of convex 3-polytopes is NP-hard.
SODA	Efficient dynamic traitor tracing.	Omer Berkman,Michal Parnas,Jiri Sgall	2000	The notion of traitor tracing was introduced by Chor, Fiat, and Naor [Tracing Traitors, Lecture Notes in Comput. Sci. 839, 1994, pp. 257--270] in order to combat piracy scenarios. Recently, Fiat and Tassa [ Tracing Traitors, Lecture Notes in Comput. Sci. 1666, 1999, pp. 354--371] proposed a dynamic traitor tracing scenario, in which the algorithm adapts dynamically according to the responses of the pirate. Let n be the number of users and p the number of traitors.Our main result is an algorithm which locates p traitors, even if p is unknown, using a watermarking alphabet of size p+1 and an optimal number of $\Theta(p^2 + p\log n)$ rounds. This improves the exponential number of rounds achieved by Fiat and Tassa in this case. We also present two algorithms that use a larger alphabet: for an alphabet of size p+c+1, $c\geq1$, an algorithm that uses O(p2/c+ p log n) rounds; for an alphabet of size pc+1, an algorithm that uses O(p logcn) rounds.Our final result is a lower bound of $\Omega(p^2/c+p\log_{c+1}n)$ rounds for any algorithm that uses an alphabet of size p+c, assuming that p is not known in advance.
SODA	A practical algorithm for recovering the best supported edges of an evolutionary tree (extended abstract).	Vincent Berry,David Bryant,Tao Jiang,Paul E. Kearney,Ming Li,Todd Wareham,Haoyong Zhang	2000	A practical algorithm for recovering the best supported edges of an evolutionary tree (extended abstract).
SODA	epsilon-Approximate linear programs: new bounds and computation.	Daniel Bienstock	2000	epsilon-Approximate linear programs: new bounds and computation.
SODA	Applying extra-resource analysis to load balancing.	Mark Brehob,Eric Torng,Patchrawat Uthaisombut	2000	Applying extra-resource analysis to load balancing.
SODA	Min-Wise versus linear independence (extended abstract).	Andrei Z. Broder,Uriel Feige	2000	Min-Wise versus linear independence (extended abstract).
SODA	Improved classification via connectivity information.	Andrei Z. Broder,Robert Krauthgamer,Michael Mitzenmacher	2000	Improved classification via connectivity information.
SODA	Selective mapping: a discrete optimization approach to selecting a population subset for use in a high-density genetic mapping project.	Daniel G. Brown,Todd J. Vision,Steven D. Tanksley	2000	Selective mapping: a discrete optimization approach to selecting a population subset for use in a high-density genetic mapping project.
SODA	Computing the quartet distance between evolutionary trees.	David Bryant,John Tsang,Paul E. Kearney,Ming Li	2000	Computing the quartet distance between evolutionary trees.
SODA	Engineering the compression of massive tables: an experimental approach.	Adam L. Buchsbaum,Donald F. Caldwell,Kenneth Ward Church,Glenn S. Fowler,S. Muthukrishnan	2000	Engineering the compression of massive tables: an experimental approach.
SODA	On external memory graph traversal.	Adam L. Buchsbaum,Michael H. Goldwasser,Suresh Venkatasubramanian,Jeffery Westbrook	2000	On external memory graph traversal.
SODA	Maintaining hierarchical graph views.	Adam L. Buchsbaum,Jeffery Westbrook	2000	Maintaining hierarchical graph views.
SODA	Randomized greedy hot-potato routing.	Costas Busch,Maurice Herlihy,Roger Wattenhofer	2000	Randomized greedy hot-potato routing.
SODA	Fast practical solution of sorting by reversals.	Alberto Caprara,Giuseppe Lancia,See-Kiong Ng	2000	Fast practical solution of sorting by reversals.
SODA	On the red-blue set cover problem.	Robert D. Carr,Srinivas Doddi,Goran Konjevod,Madhav V. Marathe	2000	On the red-blue set cover problem.
SODA	Strengthening integrality gaps for capacitated network design and covering problems.	Robert D. Carr,Lisa Fleischer,Vitus J. Leung,Cynthia A. Phillips	2000	Strengthening integrality gaps for capacitated network design and covering problems.
SODA	Computing contour trees in all dimensions.	Hamish Carr,Jack Snoeyink,Ulrike Axen	2000	We show that contour trees can be computed in all dimensions by a simple algorithm that merges two trees. Our algorithm extends, simplifies, and improves work of Tarasov and Vyalyi and of van Kreveld et al.
SODA	Towards a 4/3 approximation for the asymmetric traveling salesman problem.	Robert D. Carr,Santosh Vempala,Jacques Mandler	2000	Towards a 4/3 approximation for the asymmetric traveling salesman problem.
SODA	Escaping a grid by edge-disjoint paths.	Wun-Tat Chan,Francis Y. L. Chin,Hing-Fung Ting	2000	Escaping a grid by edge-disjoint paths.
SODA	A PTAS for the multiple knapsack problem.	Chandra Chekuri,Sanjeev Khanna	2000	A PTAS for the multiple knapsack problem.
SODA	Optimizing the sum of linear fractional functions and applications.	Danny Z. Chen,Ovidiu Daescu,Yang Dai,Naoki Katoh,Xiaodong Wu,Jinhui Xu	2000	Optimizing the sum of linear fractional functions and applications.
SODA	A dynamic programming approach to de novo peptide sequencing via tandem mass spectrometry.	Ting Chen,Ming-Yang Kao,Matthew Tepel,John Rush,George M. Church	2000	A dynamic programming approach to de novo peptide sequencing via tandem mass spectrometry.
SODA	Deterministic broadcasting in unknown radio networks.	Bogdan S. Chlebus,Leszek Gasieniec,Alan Gibbons,Andrzej Pelc,Wojciech Rytter	2000	Deterministic broadcasting in unknown radio networks.
SODA	Recognizing dart-free perfect graphs.	Vasek Chvátal,Jean Fonlupt,L. Sun,Abdelhamid Zemirline	2000	A graph G is called a Berge graph if neither G nor its complement contains a chordless cycle whose length is odd and at least five; what we call a dart is the graph with vertices u,v,w,x,y and edges uv,vw,uy,vy,wy,xy; a graph is called dart-free if it has no induced subgraph isomorphic to the dart. We present a polynomial-time algorithm to recognize dart-free Berge graphs; this algorithm uses as a subroutine the polynomial-time algorithm for recognizing claw-free Berge graphs designed previously by Chvátal and Sbihi [J. Combin. Theory Ser. B, 44 (1988), pp. 154--176].
SODA	On the temporal HZY compression scheme.	Z. Cohen,Yossi Matias,S. Muthukrishnan,Süleyman Cenk Sahinalp,Jacob Ziv	2000	On the temporal HZY compression scheme.
SODA	Communication complexity of document exchange.	Graham Cormode,Mike Paterson,Süleyman Cenk Sahinalp,Uzi Vishkin	2000	"We have two users, A and B, who hold documents x and y respectively. Neither of the users has any information about the other''s document. They exchange messages so that B computes x; it may be required that A compute y as well. Our goal is to design communication protocols with the main objective of minimizing the total number of bits they exchange; other objectives are minimizing the number of rounds and the complexity of internal computations. An important notion which determines the efficiency of the protocols is how one measures the distance between x and y. We consider several metrics for measuring this distance, namely the Hamming metric, the Levenshtein metric (edit distance), and a new LZ metric, which is introduced in this paper. We show how to estimate the distance between x and y using a single message of logarithmic size. For each metric, we present the first communication-efficient protocols, which often match the corresponding lower bounds. A consequence of these are error-correcting codes for these error models which correct up to d errors in n characters using O(d log n) bits. Our most interesting methods use a new histogram transformation that we introduce to convert edit distance to L1 distance."
SODA	Sharing one secret vs. sharing many secrets: tight bounds on the average improvement ratio.	Giovanni Di Crescenzo	2000	Sharing one secret vs. sharing many secrets: tight bounds on the average improvement ratio.
SODA	Algorithms for optimizing production DNA sequencing.	Éva Czabarka,Goran Konjevod,Madhav V. Marathe,Allon G. Percus,David C. Torney	2000	Algorithms for optimizing production DNA sequencing.
SODA	Coloring non-uniform hypergraphs: a new algorithmic approach to the general Lovász local lemma.	Artur Czumaj,Christian Scheideler	2000	Coloring non-uniform hypergraphs: a new algorithmic approach to the general Lovász local lemma.
SODA	A (2 + epsilon)-approximation scheme for minimum domination on circle graphs.	Mirela Damian-Iordache,Sriram V. Pemmaraju	2000	A (2 + epsilon)-approximation scheme for minimum domination on circle graphs.
SODA	Commuting with delay prone buses.	Mayur Datar,Abhiram G. Ranade	2000	Commuting with delay prone buses.
SODA	Adaptive set intersections, unions, and differences.	Erik D. Demaine,Alejandro López-Ortiz,J. Ian Munro	2000	Adaptive set intersections, unions, and differences.
SODA	Evaluating the cylindricity of a nominally cylindrical point set.	Olivier Devillers,Franco P. Preparata	2000	Evaluating the cylindricity of a nominally cylindrical point set.
SODA	Typical random 3-SAT formulae and the satisfiability threshold.	Olivier Dubois,Yacine Boufkhad,Jacques Mandler	2000	Typical random 3-SAT formulae and the satisfiability threshold.
SODA	The complexity of counting graph homomorphisms (extended abstract).	Martin E. Dyer,Catherine S. Greenhill	2000	The complexity of counting graph homomorphisms (extended abstract).
SODA	An extension of path coupling and its application to the Glauber dynamics for graph colourings (extended abstract).	Martin E. Dyer,Leslie Ann Goldberg,Catherine S. Greenhill,Mark Jerrum,Michael Mitzenmacher	2000	An extension of path coupling and its application to the Glauber dynamics for graph colourings (extended abstract).
SODA	Sweeping simple polygons with a chain of guards.	Alon Efrat,Leonidas J. Guibas,Sariel Har-Peled,David C. Lin,Joseph S. B. Mitchell,T. M. Murali	2000	Sweeping simple polygons with a chain of guards.
SODA	On incremental rendering of silhouette maps of polyhedral scene.	Alon Efrat,Leonidas J. Guibas,Olaf A. Hall-Holt,Li Zhang	2000	On incremental rendering of silhouette maps of polyhedral scene.
SODA	Orthogonal graph drawing with constraints.	Markus Eiglsperger,Ulrich Fößmeier,Michael Kaufmann	2000	Orthogonal graph drawing with constraints.
SODA	Finite-resolution hidden surface removal.	Jeff Erickson	2000	Finite-resolution hidden surface removal.
SODA	Movement minimization in conveyor flow shop processing.	Wolfgang Espelage,Egon Wanke	2000	Movement minimization in conveyor flow shop processing.
SODA	Restructuring ordered binary trees.	William S. Evans,David G. Kirkpatrick	2000	We consider the problem of restructuring an ordered binary tree T, preserving the in-order sequence of its nodes, so as to reduce its height to some target value h. Such a restructuring necessarily involves the downward displacement of some of the nodes of T. Our results, focusing both on the maximum displacement over all nodes and on the maximum displacement over leaves only, provide (i) an explicit tradeoff between the worst-case displacement and the height restriction (including a family of trees that exhibit the worst-case displacements) and (ii) efficient algorithms to achieve height-restricted restructuring while minimizing the maximum node displacement.
SODA	Testing and spot-checking of data streams (extended abstract).	Joan Feigenbaum,Sampath Kannan,Martin Strauss,Mahesh Viswanathan	2000	Testing and spot-checking of data streams (extended abstract).
SODA	Hamiltonicity and colorings of arrangement graphs.	Stefan Felsner,Ferran Hurtado,Marc Noy,Ileana Streinu	2000	We study connectivity, Hamilton path and Hamilton cycle decomposition, 4-edge and 3-vertex coloring for geometric graphs arising from pseudoline (affine or projective) and pseudocircle (spherical) arrangements. While arrangements as geometric objects are well studied in discrete and computational geometry, their graph theoretical properties seem to have received little attention so far. In this paper we show that they provide well-structured examples of families of planar and projective-planar graphs with very interesting properties. Most prominently, spherical arrangements admit decompositions into two Hamilton cycles; this is a new addition to the relatively few families of 4-regular graphs that are known to have Hamiltonian decompositions. Other classes of arrangements have interesting properties as well: 4-connectivity, 3-vertex coloring or Hamilton paths and cycles. We show a number of negative results as well: there are projective arrangements which cannot be 3-vertex colored. A number of conjectures and open questions accompany our results.
SODA	Edge-disjoint paths in expander graphs.	Alan M. Frieze	2000	Given a graph G=(V,E)and a set of $\kappa$ pairs of vertices in V, we are interested in finding, for each pair (ai, bi), a path connecting ai to bi such that the set of $\kappa$ paths so found is edge-disjoint. For arbitrary graphs the problem is ${\cal NP}$-complete, although it is in ${\cal P}$ if $\kappa$ is fixed. We present a polynomial time randomized algorithm for finding edge-disjoint paths in an r-regular expander graph G. We show that if G has sufficiently strong expansion properties and r is sufficiently large, then all sets of $\kappa=\Omega(n/\log n)$ pairs of vertices can be joined. This is within a constant factor of best possible.
SODA	On deciding stability of scheduling policies in queueing systems.	David Gamarnik	2000	On deciding stability of scheduling policies in queueing systems.
SODA	Balancing Steiner trees and shortest path trees online.	Ashish Goel,Kamesh Munagala	2000	Balancing Steiner trees and shortest path trees online.
SODA	Cooperative facility location games.	Michel X. Goemans,Martin Skutella	2000	"The location of facilities in order to provide service for customers is a well-studied problem in the operations research literature. In the basic model, there is a predefined cost for opening a facility and also for connecting a customer to a facility, the goal being to minimize the total cost. Often, both in the case of public facilities (such as libraries, municipal swimming pools, fire stations,....) and private facilities (such as distribution centers, switching stations, ....), we may want to find a 'fair' allocation of the total cost to the customers-this is known as the cost allocation problem. A central question in cooperative game theory is whether the total cost can be allocated to the customers such that no coalition of customers has any incentive to build their own facility or to ask a competitor to service them. We establish strong connections between fair cost allocations and linear programming relaxations for several variants of the facility location problem. In particular, we show that a fair cost allocation exists if and only if there is no integrality gap for a corresponding linear programming relaxation; this was only known for the simplest unconstrained variant of the facility location problem. Moreover, we introduce a subtle variant of randomized rounding and derive new proofs for the existence of fair cost allocations for several classes of instances. We also show that it is in general NP-complete to decide whether a fair cost allocation exists and whether a given allocation is fair."
SODA	Algorithmic strategies in combinatorial chemistry.	Deborah Goldman,Sorin Istrail,Giuseppe Lancia,Antonio Piccolboni,Brian Walenz	2000	Algorithmic strategies in combinatorial chemistry.
SODA	Approximation algorithms for data placement on parallel disks.	Leana Golubchik,Sanjeev Khanna,Samir Khuller,Ramakrishna Thurimella,An Zhu	2000	We study an optimization problem that arises in the context of data placement in a multimedia storage system. We are given a collection of M multimedia objects (data objects) that need to be assigned to a storage system consisting of N disks d1,d2&hellip;,dN. We are also given sets U1,U2,&hellip;,UM such that Ui is the set of clients seeking the ith data object. Each disk dj is characterized by two parameters, namely, its storage capacity Cj which indicates the maximum number of data objects that may be assigned to it, and a load capacity Lj which indicates the maximum number of clients that it can serve. The goal is to find a placement of data objects to disks and an assignment of clients to disks so as to maximize the total number of clients served, subject to the capacity constraints of the storage system. We study this data placement problem for two natural classes of storage systems, namely, homogeneous and uniform ratio. We show that an algorithm developed by Shachnai and Tamir [2000a] for data placement achieves the best possible absolute bound regarding the number of clients that can always be satisfied. We also show how to implement the algorithm so that it has a running time of O((N + M) log(N + M)). In addition, we design a polynomial-time approximation scheme, solving an open problem posed in the same paper.
SODA	Competitive tree-structured dictionaries.	Michael T. Goodrich	2000	Competitive tree-structured dictionaries.
SODA	Generating adversaries for request-answer games.	Todd Gormley,Nick Reingold,Eric Torng,Jeffery Westbrook	2000	Generating adversaries for request-answer games.
SODA	Improved bandwidth approximation for trees.	Anupam Gupta	2000	Improved bandwidth approximation for trees.
SODA	Improved approximation algorithms for the vertex cover problem in graphs and hypergraphs.	Eran Halperin	2000	We obtain improved algorithms for finding small vertex covers in bounded degree graphs and hypergraphs. We use semidefinite programming to relax the problems and introduce new} rounding techniques for these relaxations. On graphs with maximum degree at most $\Delta$, the algorithm achieves a performance ratio of $2-(1-o(1))\frac{2 \ln \ln \Delta}{\ln \Delta}$ for large $\Delta$, which improves the previously known ratio of $2-\frac{\log \Delta + O(1)}{\Delta}$ obtained by Halld{órsson and Radhakrishnan. Using similar techniques, we also present improved approximations for the vertex cover problem in hypergraphs. For k-uniform hypergraphs with n vertices, we achieve a ratio of $k-(1-o(1))\frac{k\ln \ln n}{\ln n}$ for large n, and for k-uniform hypergraphs with maximum degree at most $\Delta$ the algorithm achieves a ratio of $k-(1-o(1))\frac{k(k-1)\ln \ln \Delta}{\ln \Delta}$ for large $\Delta$. These results considerably improve the previous best ratio of $k(1-c/\Delta^\frac{1}{k-1})$ for bounded degree k-uniform hypergraphs, and $k(1-c/n^\frac{k-1}{k})$ for general k-uniform hypergraphs, both obtained by Krivelevich. Using similar techniques, we also obtain an approximation algorithm for the weighted independent set problem, matching a recent result of Halldorsson.
SODA	Weakly chordal graph algorithms via handles.	Ryan Hayward,Jeremy Spinrad,R. Sritharan	2000	Weakly chordal graph algorithms via handles.
SODA	Caching in networks (extended abstract).	Friedhelm Meyer auf der Heide,Berthold Vöcking,Matthias Westermann	2000	Caching in networks (extended abstract).
SODA	A faster method for sampling independent sets.	Mark Huber	2000	A faster method for sampling independent sets.
SODA	Dimensionality reduction techniques for proximity problems.	Piotr Indyk	2000	Dimensionality reduction techniques for proximity problems.
SODA	Approximate congruence in nearly linear time.	Piotr Indyk,Suresh Venkatasubramanian	2000	"The problem of geometric point set matching has been studied extensively in the domain of computational geometry, and has many applications in areas such as computer vision, computational chemistry, and pattern recognition. One of the commonly used metrics is the bottleneck distance, which for two point sets P and Q is the minimum over all one-to-one mappings f : P → Q of maxp∈Pd(p,f(p)), where d is the Euclidean distance. Much effort has gone into developing efficient algorithms for minimising the bottleneck distance between two point sets under groups of transformations. However, the algorithms that have thus far been developed suffer from running times that are large polynomials in the size of the input, even for approximate formulations of the problem.In this paper we define a point set similarity measure that includes both the bottleneck distance and the Hausdorff distance as special cases. This measure relaxes the condition that the mapping must be one-to-one, but guarantees that only a few points are mapped to any point. Using a novel application of Hall's Theorem to reduce the geometric matching problem to a combinatorial matching problem, we present near-linear time approximation schemes for minimising this distance between two point sets in the plane under isometries; we note here that the best known algorithms for congruence under the bottleneck measure run in time Õ(n2.5).We also obtain a combinatorial bound on the metric entropy of certain families of geometric objects. This result yields improved algorithms for approximate congruence, and may be of independent interest."
SODA	On permutations with limited independence.	Toshiya Itoh,Yoshinori Takei,Jun Tarui	2000	On permutations with limited independence.
SODA	The prize collecting Steiner tree problem: theory and practice.	David S. Johnson,Maria Minkoff,Steven Phillips	2000	The prize collecting Steiner tree problem: theory and practice.
SODA	Directed network design with orientation constraints.	Sanjeev Khanna,Joseph Naor,F. Bruce Shepherd	2000	Directed network design with orientation constraints.
SODA	Watermarking maps: hiding information in structured data.	Sanjeev Khanna,Francis Zane	2000	Watermarking maps: hiding information in structured data.
SODA	On local search and placement of meters in networks.	Samir Khuller,Randeep Bhatia,Robert Pless	2000	This work is motivated by the problem of placing pressure-meters in fluid networks. The problem is formally defined in graph-theoretic terms as follows. Given a graph, find a cotree (complement of a tree) incident upon the minimum number of vertices. We show that this problem is NP-hard and MAX SNP-hard. We design an algorithm with an approximation factor of $2 + \epsilon$ for this problem for any fixed $\epsilon >0$. This approximation bound comes from the analysis of a local search heuristic, a common practical optimization technique that does not often allow formal worst-case analysis. The algorithm is made very efficient by finding restrictive definitions of the local neighborhoods to be searched. We also exhibit a polynomial time approximation scheme for this problem when the input is restricted to planar graphs.
SODA	"Finding the closest lattice vector when it's unusually close."	Philip N. Klein	2000	"Finding the closest lattice vector when it's unusually close."
SODA	Construction of visual secret sharing schemes with almost optimal contrast.	Christian Kuhlmann,Hans-Ulrich Simon	2000	Construction of visual secret sharing schemes with almost optimal contrast.
SODA	A tree-edit-distance algorithm for comparing simple, closed shapes.	Philip N. Klein,Srikanta Tirthapura,Daniel Sharvit,Benjamin B. Kimia	2000	A tree-edit-distance algorithm for comparing simple, closed shapes.
SODA	Height in a digital search tree and the longest phrase of the Lempel-Ziv scheme.	Charles Knessl,Wojciech Szpankowski	2000	Height in a digital search tree and the longest phrase of the Lempel-Ziv scheme.
SODA	Estimating DNA sequence entropy.	J. Kevin Lanctot,Ming Li,En-Hui Yang	2000	Estimating DNA sequence entropy.
SODA	On the shared substring alignment problem.	Gad M. Landau,Michal Ziv-Ukelson	2000	On the shared substring alignment problem.
SODA	An optimal algorithm for hyperplane depth in the plane.	Stefan Langerman,William L. Steiger	2000	An optimal algorithm for hyperplane depth in the plane.
SODA	An approximation algorithm for the covering Steiner problem.	Goran Konjevod,R. Ravi	2000	An approximation algorithm for the covering Steiner problem.
SODA	"On Heilbronn's problem in higher dimension."	Hanno Lefmann	2000	"On Heilbronn's problem in higher dimension."
SODA	Fast randomized algorithms for computing minimum {3, 4, 5, 6}-way cuts.	Matthew S. Levine	2000	Fast randomized algorithms for computing minimum {3, 4, 5, 6}-way cuts.
SODA	On the complexity of bicoloring clique hypergraphs of graphs (extended abstract).	Jan Kratochvíl,Zsolt Tuza	2000	On the complexity of bicoloring clique hypergraphs of graphs (extended abstract).
SODA	Improved bounds on the sample complexity of learning.	Yi Li,Philip M. Long,Aravind Srinivasan	2000	Improved bounds on the sample complexity of learning.
SODA	Forcing relations for AND/OR precedence constraints.	Rolf H. Möhring,Martin Skutella,Frederik Stork	2000	Forcing relations for AND/OR precedence constraints.
SODA	Nearly optimal computations with structured matrices.	Victor Y. Pan	2000	Nearly optimal computations with structured matrices.
SODA	A point-placement strategy for conforming Delaunay tetrahedralization.	Michael Murphy,David M. Mount,Carl W. Gable	2000	A point-placement strategy for conforming Delaunay tetrahedralization.
SODA	Efficient bundle sorting.	Yossi Matias,Eran Segal,Jeffrey Scott Vitter	2000	"Many data sets to be sorted consist of a limited number of distinct keys. Sorting such data sets can be thought of as bundling together identical keys and having the bundles placed in order; we therefore denote this as bundle sorting. We describe an efficient algorithm for bundle sorting in external memory, which requires at most c(N/B) logM/Bk disk accesses, where N is the number of keys, M is the size of internal memory, k is the number of distinct keys, B is the transfer block size, and 2 < c < 4. For moderately sized k, this bound circumvents the Theta((N/B) logM/B (N/B)) I/O lower bound known for general sorting. We show that our algorithm is optimal by proving a matching lower bound for bundle sorting. The improved running time of bundle sorting over general sorting can be significant in practice, as demonstrated by experimentation. An important feature of the new algorithm is that it is executed ""in-place,"" requiring no additional disk space."
SODA	The whole genome assembly of Drosophila.	Gene Myers	2000	The whole genome assembly of Drosophila.
SODA	Minimum ratio canceling is oracle polynomial for linear programming, but not strongly polynomial, even for networks.	S. Thomas McCormick,Akiyoshi Shioura	2000	Minimum ratio canceling is oracle polynomial for linear programming, but not strongly polynomial, even for networks.
SODA	Faster deterministic dictionaries.	Rasmus Pagh	2000	Faster deterministic dictionaries.
SODA	Improved Steiner tree approximation in graphs.	Gabriel Robins,Alexander Zelikovsky	2000	Improved Steiner tree approximation in graphs.
SODA	A fast algorithm to generate unlabeled necklaces.	Frank Ruskey,Joe Sawada	2000	A fast algorithm to generate unlabeled necklaces.
SODA	Pattern discovery on character sets and real-valued data: linear bound on irredundant motifs and an efficient polynomial time algorithm.	Laxmi Parida,Isidore Rigoutsos,Aris Floratos,Daniel E. Platt,Yuan Gao	2000	Pattern discovery on character sets and real-valued data: linear bound on irredundant motifs and an efficient polynomial time algorithm.
SODA	Fast concurrent access to parallel disks.	Peter Sanders,Sebastian Egner,Jan H. M. Korst	2000	Fast concurrent access to parallel disks.
SODA	Off-line admission control for general scheduling problems.	Cynthia A. Phillips,R. N. Uma,Joel Wein	2000	Off-line admission control for general scheduling problems.
SODA	A new bound for the Carathéodory rank of the bases of a matroid.	José Coelho de Pina,José Soares	2000	A new bound for the Carathéodory rank of the bases of a matroid.
SODA	Scheduling a pipelined operator graph.	Petra Schuurman,Gerhard J. Woeginger	2000	Scheduling a pipelined operator graph.
SODA	Towards a theory of cache-efficient algorithms.	Sandeep Sen,Siddhartha Chatterjee	2000	Towards a theory of cache-efficient algorithms.
SODA	A lower bound for DLL algorithms for -SAT (preliminary version).	Pavel Pudlák,Russell Impagliazzo	2000	A lower bound for DLL algorithms for -SAT (preliminary version).
SODA	New and improved algorithms for minsum shop scheduling.	Maurice Queyranne,Maxim Sviridenko	2000	New and improved algorithms for minsum shop scheduling.
SODA	The rectilinear Steiner arborescence problem is NP-complete.	Weiping Shi,Chen Su	2000	Given a set of points in the first quadrant, a rectilinear Steiner arborescence (RSA) is a directed tree rooted at the origin, containing all points, and composed solely of horizontal and vertical edges oriented from left to right, or from bottom to top. The complexity of finding an RSA with the minimum total edge length for general planar point sets has been a well-known open problem in algorithm design and VLSI routing. In this paper, we prove the problem is NP-complete in the strong sense.
SODA	Random three-dimensional tilings of Aztec octahedra and tetrahedra: an extension of domino tilings.	Dana Randall,Gary D. Yngve	2000	Random three-dimensional tilings of Aztec octahedra and tetrahedra: an extension of domino tilings.
SODA	Strictly non-blocking WDM cross-connects.	April Rasala,Gordon T. Wilfong	2000	Strictly non-blocking WDM cross-connects.
SODA	An algebraic method to compute a shortest path of local flips between two tilings.	Eric Rémila	2000	An algebraic method to compute a shortest path of local flips between two tilings.
SODA	Digraph minors and algorithms (abstract only).	Robin Thomas	2000	Digraph minors and algorithms (abstract only).
SODA	Even strongly universal hashing is pretty fast.	Mikkel Thorup	2000	Even strongly universal hashing is pretty fast.
SODA	An approximation algorithm for finding a long path in Hamiltonian graphs.	Sundar Vishwanathan	2000	An approximation algorithm for finding a long path in Hamiltonian graphs.
SODA	Locally lifting the curse of dimensionality for nearest neighbor search (extended abstract).	Peter N. Yianilos	2000	Locally lifting the curse of dimensionality for nearest neighbor search (extended abstract).
SODA	-medians, facility location, and the Chernoff-Wald bound.	Neal E. Young	2000	-medians, facility location, and the Chernoff-Wald bound.
SODA	Algorithms for minimum volume enclosing simplex in R.	Yunhong Zhou,Subhash Suri	2000	Algorithms for minimum volume enclosing simplex in R.
SODA	Proceedings of the Eleventh Annual ACM-SIAM Symposium on Discrete Algorithms, January 9-11, 2000, San Francisco, CA, USA.	David B. Shmoys	2000	Proceedings of the Eleventh Annual ACM-SIAM Symposium on Discrete Algorithms, January 9-11, 2000, San Francisco, CA, USA.
STOC	Setting 2 variables at a time yields a new lower bound for random 3-SAT (extended abstract).	Dimitris Achlioptas	2000	Setting 2 variables at a time yields a new lower bound for random 3-SAT (extended abstract).
STOC	Space complexity in propositional calculus.	Michael Alekhnovich,Eli Ben-Sasson,Alexander A. Razborov,Avi Wigderson	2000	We study space complexity in the framework of propositional proofs. We consider a natural model analogous to Turing machines with a read-only input tape and such popular propositional proof systems as resolution, polynomial calculus, and Frege systems. We propose two different space measures, corresponding to the maximal number of bits, and clauses/monomials that need to be kept in the memory simultaneously. We prove a number of lower and upper bounds in these models, as well as some structural results concerning the clause space for resolution and Frege systems.
STOC	Compression using efficient multicasting.	Micah Adler,Frank Thomson Leighton	2000	Compression using efficient multicasting.
STOC	Approximation algorithms for geometric shortest path problems.	Lyudmil Aleksandrov,Anil Maheshwari,Jörg-Rüdiger Sack	2000	Approximation algorithms for geometric shortest path problems.
STOC	Quantum bit escrow.	Dorit Aharonov,Amnon Ta-Shma,Umesh V. Vazirani,Andrew Chi-Chih Yao	2000	Quantum bit escrow.
STOC	Quantum lower bounds by quantum arguments.	Andris Ambainis	2000	We propose a new method for proving lower bounds on quantum query algorithms. Instead of a classical adversary that runs the algorithm with on input and then modifies the input, we use a quantum adversary that runs the algorithm with a superposition of inputs. If the algorithm works correctly, its state becomes entangled with the superposition over inputs. We bound the number of queries needed to achieve a sufficient entanglement and this implies a lower bound on the number of queries for the computation. Using this method, we prove two new Ω(√N) lower bounds on computing AND of ORs and inverting a permutation and also provide more uniform proofs for several known lower bounds which have been previously proven via a variety of different techniques.
STOC	A random graph model for massive graphs.	William Aiello,Fan R. K. Chung,Linyuan Lu	2000	A random graph model for massive graphs.
STOC	Computing with highly mixed states (extended abstract).	Andris Ambainis,Leonard J. Schulman,Umesh V. Vazirani	2000	Computing with highly mixed states (extended abstract).
STOC	Tight(er) worst-case bounds on dynamic searching and priority queues.	Arne Andersson,Mikkel Thorup	2000	Tight(er) worst-case bounds on dynamic searching and priority queues.
STOC	A unified approach to approximating resource allocation and scheduling.	Amotz Bar-Noy,Reuven Bar-Yehuda,Ari Freund,Joseph Naor,Baruch Schieber	2000	We present a general framework for solving resource allocation and scheduling problems. Given a resource of fixed size, we present algorithms that approximate the maximum throughput or the minimum loss by a constant factor. Our approximation factors apply to many problems, among which are: (i) real-time scheduling of jobs on parallel machines, (ii) bandwidth allocation for sessions between two endpoints, (iii) general caching, (iv) dynamic storage allocation, and (v) bandwidth allocation on optical line and ring topologies. For some of these problems we provide the first constant factor approximation algorithm. Our algorithms are simple and efficient and are based on the local-ratio technique. We note that they can equivalently be interpreted within the primal-dual schema.
STOC	Tighter bounds for nearest neighbor search and related problems in the cell probe model.	Omer Barkol,Yuval Rabani	2000	Tighter bounds for nearest neighbor search and related problems in the cell probe model.
STOC	Noise-tolerant learning, the parity problem, and the statistical query model.	Avrim Blum,Adam Kalai,Hal Wasserman	2000	We describe a slightly subexponential time algorithm for learning parity functions in the presence of random classification noise, a problem closely related to several cryptographic and coding problems. Our algorithm runs in polynomial time for the case of parity functions that depend on only the first O(log n log log n) bits of input, which provides the first known instance of an efficient noise-tolerant algorithm for a concept class that is not learnable in the Statistical Query model of Kearns [1998]. Thus, we demonstrate that the set of problems learnable in the statistical query model is a strict subset of those problems learnable in the presence of noise in the PAC model.In coding-theory terms, what we give is a poly(n)-time algorithm for decoding linear k &times; n codes in the presence of random noise for the case of k = c log n log log n for some c > 0. (The case of k = O(log n) is trivial since one can just individually check each of the 2k possible messages and choose the one that yields the closest codeword.)A natural extension of the statistical query model is to allow queries about statistical properties that involve t-tuples of examples, as opposed to just single examples. The second result of this article is to show that any class of functions learnable (strongly or weakly) with t-wise queries for t = O(log n) is also weakly learnable with standard unary queries. Hence, this natural extension to the statistical query model does not increase the set of weakly learnable functions.
STOC	Balanced allocations: the heavily loaded case.	Petra Berenbrink,Artur Czumaj,Angelika Steger,Berthold Vöcking	2000	"We investigate balls-into-bins processes allocating $m$ balls into $n$ bins based on the multiple-choice paradigm. In the classical single-choice variant each ball is placed into a bin selected uniformly at random. In a multiple-choice process each ball can be placed into one out of $d \ge 2$ randomly selected bins. It is known that in many scenarios having more than one choice for each ball can improve the load balance significantly. Formal analyses of this phenomenon prior to this work considered mostly the lightly loaded case, that is, when $m \approx n$. In this paper we present the first tight analysis in the heavily loaded case, that is, when $m \gg n$ rather than $m \approx n$.The best previously known results for the multiple-choice processes in the heavily loaded case were obtained using majorization by the single-choice process. This yields an upper bound of the maximum load of bins of $m/n + {\mbox{$\cal O$}}(\sqrt{m \ln n \,/\, n})$ with high probability. We show, however, that the multiple-choice processes are fundamentally different from the single-choice variant in that they have ""short memory."" The great consequence of this property is that the deviation of the multiple-choice processes from the optimal allocation (that is, the allocation in which each bin has either $\lfloor m/n \rfloor$ or $\lceil m/n \rceil$ balls) does not increase with the number of balls as in the case of the single-choice process. In particular, we investigate the allocation obtained by two different multiple-choice allocation schemes, the greedy scheme due to Azar et al. and the always-go-left scheme due to Vöcking. We show that these schemes result in a maximum load of only $m/n + {\mbox{$\cal O$}}(\ln \ln n)$ with high probability. All our detailed bounds on the maximum load are tight up to an additive constant.Furthermore, we investigate the two multiple-choice algorithms in a comparative study. We present a majorization result showing that the always-go-left scheme obtains a better load balancing than the greedy scheme for any choice of $n$, $m$, and $d$."
STOC	Finding smooth integers in short intervals using CRT decoding.	Dan Boneh	2000	"We present a new algorithm for CRT list decoding. An instance of the, CRT list decoding problem consists of integers B, 〈p1, ..., pn〉 and 〈r1, ..., rn〉, where p1 < p2 < ... < pn is a sequence of relatively prime integers. The CRT list decoding problem is to find all positive integers x < B such that x = ri mod pi for all but e values of i ∈ {1, ..., n}. Suppose B = Πi=1r pi for some integer k. Goldreich, Ron, and Sudan (in ""Proc. of STOC'99"", pp. 225-234, 1999) recently gave several applications for this problem and presented the first efficient algorithm that works whenever e (approximately) satisfies e < n - √2kn log pn/log p1. Our new algorithm achieves the stronger bound e < n - √kn log pn/log p1 (approximately). The improvement is significant when k is relatively close to n, e.g. k > n/3. The bounds we obtain are similar to the bounds obtained by Guruswami and Sudan for Reed-Solomon list decoding. Hence, our algorithm reduces the gap between CRT list decoding and list decoding of Reed-Solomon codes. In addition, we give a new application for CRT list decoding: finding smooth integers in short intervals. Problems of this type come up in several algorithms for factoring large integers. We define and solve a generalized CRT list decoding problem and discuss how it might be used within the quadratic sieve factoring method."
STOC	Improvements in throughout maximization for real-time scheduling.	Piotr Berman,Bhaskar DasGupta	2000	Improvements in throughout maximization for real-time scheduling.
STOC	A proof of the security of quantum key distribution (extended abstract).	Eli Biham,Michel Boyer,P. Oscar Boykin,Tal Mor,Vwani P. Roychowdhury	2000	A proof of the security of quantum key distribution (extended abstract).
STOC	Are bitvectors optimal?	Harry Buhrman,Peter Bro Miltersen,Jaikumar Radhakrishnan,Srinivasan Venkatesh	2000	"We study the it static membership problem: Given a set S of at most n keys drawn from a universe U of size m, store it so that queries of the form ""Is u in S?"" can be answered by making few accesses to the memory. We study schemes for this problem that use space close to the information theoretic lower bound of $\Omega(n\log(\frac{m}{n}))$ bits and yet answer queries by reading a small number of bits of the memory.We show that, for $\epsilon > 0$, there is a scheme that stores $O(\frac{n}{\epsilon^2}\log m)$ bits and answers membership queries using a randomized algorithm that reads just one bit of memory and errs with probability at most $\epsilon$. We consider schemes that make no error for queries in S but are allowed to err with probability at most $\epsilon$ for queries not in S. We show that there exist such schemes that store $O((\frac{n}{\epsilon})^2 \log m)$ bits and answer queries using just one bitprobe. If multiple probes are allowed, then the number of bits stored can be reduced to $O(n^{1+\delta}\log m)$ for any $\delta > 0$. The schemes mentioned above are based on probabilistic constructions of set systems with small intersections.We show lower bounds that come close to our upper bounds (for a large range of n and $\epsilon$): Schemes that answer queries with just one bitprobe and error probability $\epsilon$ must use $\Omega(\frac{n}{\epsilon\log(1/\epsilon)} \log m)$ bits of storage; if the error is restricted to queries not in S, then the scheme must use $\Omega(\frac{n^2}{\epsilon^2 \log (n/\epsilon)}\log m)$ bits of storage. We also consider deterministic schemes for the static membership problem and show tradeoffs between space and the number of probes."
STOC	Hard-Potato routing.	Costas Busch,Maurice Herlihy,Roger Wattenhofer	2000	Hard-Potato routing.
STOC	Resettable zero-knowledge (extended abstract).	Ran Canetti,Oded Goldreich,Shafi Goldwasser,Silvio Micali	2000	Resettable zero-knowledge (extended abstract).
STOC	Randomized metarounding (extended abstract).	Robert D. Carr,Santosh Vempala	2000	Randomized metarounding (extended abstract).
STOC	Query strategies for priced information (extended abstract).	Moses Charikar,Ronald Fagin,Venkatesan Guruswami,Jon M. Kleinberg,Prabhakar Raghavan,Amit Sahai	2000	Query strategies for priced information (extended abstract).
STOC	Shortest path queries in planar graphs.	Danny Z. Chen,Jinhui Xu	2000	Shortest path queries in planar graphs.
STOC	Faster suffix tree construction with missing suffix links.	Richard Cole,Ramesh Hariharan	2000	"We consider suffix tree construction for situations with missing suffix links. Two examples of such situations are suffix trees for parameterized strings and suffix trees for two-dimensional arrays. These trees also have the property that the node degrees may be large. We add a new back-propagation component to McCreight's algorithm and also give a high probability hashing scheme for large degrees. We show that these two features enable construction of suffix trees for general situations with missing suffix links in O(n) time, with high probability. This gives the first randomized linear time algorithm for constructing suffix trees for parameterized strings."
STOC	On the complexity of verifiable secret sharing and multiparty computation.	Ronald Cramer,Ivan Damgård,Stefan Dziembowski	2000	On the complexity of verifiable secret sharing and multiparty computation.
STOC	"On zero-knowledge proofs (extended abstract): ``from membership to decision''."	Giovanni Di Crescenzo,Kouichi Sakurai,Moti Yung	2000	"On zero-knowledge proofs (extended abstract): ``from membership to decision''."
STOC	On the sum-of-squares algorithm for bin packing.	János Csirik,David S. Johnson,Claire Kenyon,James B. Orlin,Peter W. Shor,Richard R. Weber	2000	In this article we present a theoretical analysis of the online Sum-of-Squares algorithm (SS) for bin packing along with several new variants. SS is applicable to any instance of bin packing in which the bin capacity B and item sizes s(a) are integral (or can be scaled to be so), and runs in time O(nB). It performs remarkably well from an average case point of view: For any discrete distribution in which the optimal expected waste is sublinear, SS also has sublinear expected waste. For any discrete distribution where the optimal expected waste is bounded, SS has expected waste at most O(log n). We also discuss several interesting variants on SS, including a randomized O(nB log B)-time online algorithm SS&ast; whose expected behavior is essentially optimal for all discrete distributions. Algorithm SS&ast; depends on a new linear-programming-based pseudopolynomial-time algorithm for solving the NP-hard problem of determining, given a discrete distribution F, just what is the growth rate for the optimal expected waste.
STOC	A new algorithm approach to the general Lovász local lemma with applications to scheduling and satisfiability problems (extended abstract).	Artur Czumaj,Christian Scheideler	2000	A new algorithm approach to the general Lovász local lemma with applications to scheduling and satisfiability problems (extended abstract).
STOC	Self-testing of universal and fault-tolerant sets of quantum gates.	Wim van Dam,Frédéric Magniez,Michele Mosca,Miklos Santha	2000	We consider the design of self-testers for quantum gates. A self-tester for the gates $\boldsymbol{F}_1,\ldots, \boldsymbol{F}_m$ is a procedure that, given any gates $\boldsymbol{G}_1, \ldots, \boldsymbol{G}_m$, decides with high probability if each $\boldsymbol{G}_i$ is close to $\boldsymbol{F}_i$. This decision has to rely only on measuring in the computational basis the effect of iterating the gates on the classical states. It turns out that, instead of individual gates, we can design only procedures for families of gates. To achieve our goal we borrow some elegant ideas of the theory of program testing: We characterize the gate families by specific properties, develop a theory of robustness for them, and show that they lead to self-testers. In particular we prove that the universal and fault-tolerant set of gates consisting of a Hadamard gate, a $\mathrm{c\text{-}NOT}$ gate, and a phase rotation gate of angle $\pi/4$ is self-testable.
STOC	Smoothing and cleaning up slivers.	Herbert Edelsbrunner,Xiang-Yang Li,Gary L. Miller,Andreas Stathopoulos,Dafna Talmor,Shang-Hua Teng,Alper Üngör,Noel Walkington	2000	Smoothing and cleaning up slivers.
STOC	Improved approximations of crossings in graph drawings.	Guy Even,Sudipto Guha,Baruch Schieber	2000	Improved approximations of crossings in graph drawings.
STOC	"Random walks with ``back buttons'' (extended abstract)."	Ronald Fagin,Anna R. Karlin,Jon M. Kleinberg,Prabhakar Raghavan,Sridhar Rajagopalan,Ronitt Rubinfeld,Madhu Sudan,Andrew Tomkins	2000	"Random walks with ``back buttons'' (extended abstract)."
STOC	Computing the median with uncertainty.	Tomás Feder,Rajeev Motwani,Rina Panigrahy,Chris Olston,Jennifer Widom	2000	We consider a new model for computing with uncertainty. It is desired to compute a function f(X1,. . .,Xn), where X1, . . ., Xn are unknown but guaranteed to lie in specified intervals I1, . . ., In. It is possible to query the precise value of any Xj at a cost cj. The goal is to pin down the value of f to within a precision $\delta$ at a minimum possible cost. We focus on the selection function f which returns the value of the kth smallest argument. We present optimal offline and online algorithms for this problem.
STOC	Finding long paths and cycles in sparse Hamiltonian graphs.	Tomás Feder,Rajeev Motwani,Carlos S. Subi	2000	Finding long paths and cycles in sparse Hamiltonian graphs.
STOC	Approximating the domatic number.	Uriel Feige,Magnús M. Halldórsson,Guy Kortsarz	2000	Approximating the domatic number.
STOC	Approximating the minimum bisection size (extended abstract).	Uriel Feige,Robert Krauthgamer,Kobbi Nissim	2000	Approximating the minimum bisection size (extended abstract).
STOC	Sharing the cost of muliticast transmissions (preliminary version).	Joan Feigenbaum,Christos H. Papadimitriou,Scott Shenker	2000	Sharing the cost of muliticast transmissions (preliminary version).
STOC	Better algorithms for unfair metrical task systems and applications.	Amos Fiat,Manor Mendel	2000	Unfair metrical task systems are a generalization of online metrical task systems. In this paper we introduce new techniques to combine algorithms for unfair metrical task systems and apply these techniques to obtain improved randomized online algorithms for metrical task systems on arbitrary metric spaces.
STOC	From partial consistency to global broadcast.	Matthias Fitzi,Ueli M. Maurer	2000	From partial consistency to global broadcast.
STOC	Improved algorithms for submodular function minimization and submodular flow.	Lisa Fleischer,Satoru Iwata	2000	Improved algorithms for submodular function minimization and submodular flow.
STOC	Exact computations of the inertia symmetric integer matrices.	Steven Fortune	2000	Exact computations of the inertia symmetric integer matrices.
STOC	Approximating permanents of complex matrices.	Martin Fürer	2000	Approximating permanents of complex matrices.
STOC	Combining fairness with throughput: online routing with multiple objectives.	Ashish Goel,Adam Meyerson,Serge A. Plotkin	2000	Combining fairness with throughput: online routing with multiple objectives.
STOC	More theory revision with queries (extended abstract).	Judy Goldsmith,Robert H. Sloan	2000	More theory revision with queries (extended abstract).
STOC	Isomorphism testing for embeddable graphs through definability.	Martin Grohe	2000	Isomorphism testing for embeddable graphs through definability.
STOC	Compressed suffix arrays and suffix trees with applications to text indexing and string matching (extended abstract).	Roberto Grossi,Jeffrey Scott Vitter	2000	Compressed suffix arrays and suffix trees with applications to text indexing and string matching (extended abstract).
STOC	Rapid sampling though quantum computing.	Lov K. Grover	2000	Rapid sampling though quantum computing.
STOC	A constant factor approximation algorithm for a class of classification problems.	Anupam Gupta,Éva Tardos	2000	A constant factor approximation algorithm for a class of classification problems.
STOC	List decoding algorithms for certain concatenated codes.	Venkatesan Guruswami,Madhu Sudan	2000	List decoding algorithms for certain concatenated codes.
STOC	A deterministic polynomial-time algorithm for approximating mixed discriminant and mixed volume.	Leonid Gurvits,Alex Samorodnitsky	2000	A deterministic polynomial-time algorithm for approximating mixed discriminant and mixed volume.
STOC	Satisfiability of equations in free groups is in PSPACE.	Claudio Gutiérrez	2000	Satisfiability of equations in free groups is in PSPACE.
STOC	Normal subgroup reconstruction and quantum computation using group representations.	Sean Hallgren,Alexander Russell,Amnon Ta-Shma	2000	Normal subgroup reconstruction and quantum computation using group representations.
STOC	Higher lower bounds on monotone size.	Danny Harnik,Ran Raz	2000	Higher lower bounds on monotone size.
STOC	Extractors and pseudo-random generators with optimal seed length.	Russell Impagliazzo,Ronen Shaltiel,Avi Wigderson	2000	Extractors and pseudo-random generators with optimal seed length.
STOC	Statistical mechanics, three-dimensionality and NP-completeness: I. Universality of intracatability for the partition function of the Ising model across non-planar surfaces (extended abstract).	Sorin Istrail	2000	Statistical mechanics, three-dimensionality and NP-completeness: I. Universality of intracatability for the partition function of the Ising model across non-planar surfaces (extended abstract).
STOC	A combinatorial, strongly polynomial-time algorithm for minimizing submodular functions.	Satoru Iwata,Lisa Fleischer,Satoru Fujishige	2000	A combinatorial, strongly polynomial-time algorithm for minimizing submodular functions.
STOC	Circuit minimization problem.	Valentine Kabanets,Jin-yi Cai	2000	Circuit minimization problem.
STOC	The risk profile problem for stock portfolio optimization (extended abstract).	Ming-Yang Kao,Andreas Nolte,Stephen R. Tate	2000	The risk profile problem for stock portfolio optimization (extended abstract).
STOC	On the efficiency of local decoding procedures for error-correcting codes.	Jonathan Katz,Luca Trevisan	2000	On the efficiency of local decoding procedures for error-correcting codes.
STOC	Complete characterization of security notions for probabilistic private-key encryption.	Jonathan Katz,Moti Yung	2000	Complete characterization of security notions for probabilistic private-key encryption.
STOC	Connectivity and inference problems for temporal networks.	David Kempe,Jon M. Kleinberg,Amit Kumar	2000	"Many network problems are based on fundamental relationships involving time. Consider, for example, the problems of modeling the flow of information through a distributed network, studying the spread of a disease through a population, or analyzing the reachability properties of an airline timetable. In such settings, a natural model is that of a graph in which each edge is annotated with a time label specifying the time at which its endpoints ""communicated."" We will call such a graph a temporal network. To model the notion that information in such a network ""flows"" only on paths whose labels respect the ordering of time, we call a path time-respecting if the time labels on its edges are non-decreasing. The central motivation for our work is the following question: how do the basic combinatorial and algorithmic properties of graphs change when we impose this additional temporal condition? The notion of a path is intrinsic to many of the most fundamental algorithmic problems on graphs; spanning trees, connectivity, flows, and cuts are some examples. When we focus on time-respecting paths in place of arbitrary paths, many of these problems acquire a character that is different from the traditional setting, but very rich in its own right. We provide results on two types of problems for temporal networks. First, we consider connectivity problems, in which we seek disjoint time-respecting paths between pairs of nodes. The natural analogue of Menger's Theorem for node-disjoint paths fails in general for time-respecting paths; we give a non-trivial characterization of those graphs for which the theorem does hold in terms of an excluded subdivision theorem, and provide a polynomial-time algorithm for connectivity on this class of graphs. (The problem on general graphs is NP-complete.) We then define and study the class of inference problems, in which we seek to reconstruct a partially specified time labeling of a network in a manner consistent with an observed history of information flow."
STOC	Polynomial-time approximation scheme for data broadcast.	Claire Kenyon,Nicolas Schabanel,Neal E. Young	2000	Polynomial-time approximation scheme for data broadcast.
STOC	More general completeness theorems for secure two-party computation.	Joe Kilian	2000	More general completeness theorems for secure two-party computation.
STOC	Parallelization, amplification, and exponential time simulation of quantum interactive proof systems.	Alexei Kitaev,John Watrous	2000	Parallelization, amplification, and exponential time simulation of quantum interactive proof systems.
STOC	On quantum and probabilistic communication: Las Vegas and one-way protocols.	Hartmut Klauck	2000	On quantum and probabilistic communication: Las Vegas and one-way protocols.
STOC	The small-world phenomenon: an algorithm perspective.	Jon M. Kleinberg	2000	"Long a matter of folklore, the ``small-world phenomenon'''' --the principle that we are all linked by short chains of acquaintances --was inaugurated as an area of experimental study in the social sciences through the pioneering work of Stanley Milgram in the 1960''s. This work was among the first to make the phenomenon quantitative, allowing people to speak of the ``six degrees of separation'''' between any two people in the United States. Since then, a number of network models have been proposed as frameworks in which to study the problem analytically. One of the most refined of these models was formulated in recent work of Watts and Strogatz; their framework provided compelling evidence that the small-world phenomenon is pervasive in a range of networks arising in nature and technology, and a fundamental ingredient in the evolution of the World Wide Web. But existing models are insufficient to explain the striking algorithmic component of Milgram''s original findings: that individuals using local information are collectively very effective at actually constructing short paths between two points in a social network. Although recently proposed network models are rich in short paths, we prove that no decentralized algorithm, operating with local information only, can construct short paths in these networks with non-negligible probability. We then define an infinite family of network models that naturally generalizes the Watts-Strogatz model, and show that for one of these models, there is a decentralized algorithm capable of finding short paths with high probability. More generally, we provide a strong characterization of this family of network models, showing that there is in fact a unique model within the family for which decentralized algorithms are effective."
STOC	A matter of degree: improved approximation algorithms for degree-bounded minimum spanning trees.	Jochen Könemann,R. Ravi	2000	In this paper, we present a new bicriteria approximation algorithm for the degree-bounded minimum spanning tree problem. In this problem, we are given an undirected graph, a nonnegative cost function on the edges, and a positive integer B*, and the goal is to find a minimum-cost spanning tree T with maximum degree at most B*. In an n-node graph, our algorithm finds a spanning tree with maximum degree O(B*+logn) and cost O(optB*), where optB* is the minimum cost of any spanning tree whose maximum degree is at most B*. Our algorithm uses ideas from Lagrangean duality. We show how a set of optimum Lagrangean multipliers yields bounds on both the degree and the cost of the computed solution.
STOC	Near optimal multiple alignment within a band in polynomial time.	Ming Li,Bin Ma,Lusheng Wang	2000	Near optimal multiple alignment within a band in polynomial time.
STOC	A new proof of the weak pigeonhole principle.	Alexis Maciel,Toniann Pitassi,Alan R. Woods	2000	The exact complexity of the weak pigeonhole principle is an old and fundamental problem in proof complexity. Using a diagonalization argument, J. B. Paris et al. (J. Symbolic Logic 53 (1988), 1235-1244) showed how to prove the weak pigeonhole principle with bounded-depth, quasipolynomialsize proofs. Their argument was further refined by J. Krajícek (J. Symbolic Logic 59 (1994), 73-86). In this paper, we present a new proof: we show that the weak pigeonhole principle has quasipolynomial-size LK proofs where every formula consists of a single AND/OR of polylog fan-in. Our proof is conceptually simpler than previous arguments, and is optimal with respect to depth.
STOC	A new NC-algorithm for finding a perfect matching in bipartite planar and small genus graphs (extended abstract).	Meena Mahajan,Kasturi R. Varadarajan	2000	A new NC-algorithm for finding a perfect matching in bipartite planar and small genus graphs (extended abstract).
STOC	On the decidability of accessibility problems (extended abstract).	Rajeev Motwani,Rina Panigrahy,Vijay A. Saraswat,Suresh Venkatasubramanian	2000	On the decidability of accessibility problems (extended abstract).
STOC	Approximate nearest neighbors and sequence comparison with block operations.	S. Muthukrishnan,Süleyman Cenk Sahinalp	2000	Approximate nearest neighbors and sequence comparison with block operations.
STOC	Pseudo-random functions and factoring (extended abstract).	Moni Naor,Omer Reingold,Alon Rosen	2000	Pseudo-random functions and factoring (extended abstract).
STOC	Matrix-vector product for confluent Cauchy-like matrices with application to confluent rational interpolation.	Vadim Olshevsky,Mohammad Amin Shokrollahi	2000	Matrix-vector product for confluent Cauchy-like matrices with application to confluent rational interpolation.
STOC	epsilon-optimization schemes and L-bit precision: alternative perspectives in combinatorial optimization (extended abstract).	James B. Orlin,Andreas S. Schulz,Sudipta Sengupta	2000	epsilon-optimization schemes and L-bit precision: alternative perspectives in combinatorial optimization (extended abstract).
STOC	On the approximability of the traveling salesman problem (extended abstract).	Christos H. Papadimitriou,Santosh Vempala	2000	On the approximability of the traveling salesman problem (extended abstract).
STOC	Strictly non-blocking WDM cross-connects for heterogeneous networks.	April Rasala,Gordon T. Wilfong	2000	Strictly non-blocking WDM cross-connects for heterogeneous networks.
STOC	The program-size complexity of self-assembled squares (extended abstract).	Paul W. K. Rothemund,Erik Winfree	2000	The program-size complexity of self-assembled squares (extended abstract).
STOC	How tall is a tree?	Bruce A. Reed	2000	How tall is a tree?
STOC	A PCP characterization of NP with optimal amortized query complexity.	Alex Samorodnitsky,Luca Trevisan	2000	A PCP characterization of NP with optimal amortized query complexity.
STOC	The value of strong inapproximability results for clique.	Aravind Srinivasan	2000	The value of strong inapproximability results for clique.
STOC	Clustering for edge-cost minimization (extended abstract).	Leonard J. Schulman	2000	Clustering for edge-cost minimization (extended abstract).
STOC	A guessing game and randomized online algorithms.	Steven S. Seiden	2000	A guessing game and randomized online algorithms.
STOC	Near-optimal fully-dynamic graph connectivity.	Mikkel Thorup	2000	Near-optimal fully-dynamic graph connectivity.
STOC	"On transformation of interactive proofs that preserve the prover's complexity."	Salil P. Vadhan	2000	"On transformation of interactive proofs that preserve the prover's complexity."
STOC	On dual minimum cost flow algorithms (extended abstract).	Jens Vygen	2000	On dual minimum cost flow algorithms (extended abstract).
STOC	Proceedings of the Thirty-Second Annual ACM Symposium on Theory of Computing, May 21-23, 2000, Portland, OR, USA	F. Frances Yao,Eugene M. Luks	2000	Proceedings of the Thirty-Second Annual ACM Symposium on Theory of Computing, May 21-23, 2000, Portland, OR, USA
FOCS	On the Average-Case Hardness of CVP.	Jin-yi Cai	2001	We prove a connection of the worst-case complexity to the average-case complexity based on the Closest Vector Problem (CVP) for lattices. Assume that there is an efficient algorithm which can solve approximately a random instance of CVP, with a non-trivial success probability, for lattices under a certain natural distribution, we show that one can approximately solve several lattice problems (including a version of CVP) efficiently for every lattice with high probability.
FOCS	Web Search via Hub Synthesis.	Dimitris Achlioptas,Amos Fiat,Anna R. Karlin,Frank McSherry	2001	Web Search via Hub Synthesis.
FOCS	Lower Bounds for Polynomial Calculus: Non-Binomial Case.	Michael Alekhnovich,Alexander A. Razborov	2001	"We generalize recent linear lower bounds for Polynomial Calculus based on binomial ideals. We produce a general hardness criterion (that we call immunity) which is satisfied by a random function and prove linear lower bounds on the degree of PC refutations for a wide class of tautologies based on immune functions. As some applications of our techniques, we introducemodp Tseitin tautologies in the Boolean case (e.g. in the presence of axioms x_i^2= x_i), prove that they are hard for PC over fields with characteristic different from p, and generalize them to Flow tautologies which are based on the MAJORITY function and are proved to be hard over any field. We also show the \Omega (n) lower bound for random k-CNF's over fields of characteristic 2."
FOCS	Resolution is Not Automatizable Unless W[P] is Tractable.	Michael Alekhnovich,Alexander A. Razborov	2001	We show that neither resolution nor tree-like resolution is automatizable unless the class W[P] from the hierarchy of parameterized problems is fixed-parameter tractable by randomized algorithms with one-sided error.
FOCS	On the Complexity of Many Faces in Arrangements of Circles.	Pankaj K. Agarwal,Boris Aronov,Micha Sharir	2001	We obtain improved bounds on the complexity of m distinct faces in an arrangement of n circles and in an arrangement of n unit circles. The bounds are worst-case tight for unit circles, and, for general circles, they nearly coincide with the best known bounds for the number of incidences between m points and n circles.
FOCS	Testing Subgraphs in Large Graphs.	Noga Alon	2001	Let H be a fixed graph with h vertices, let G be a graph on n vertices and suppose that at least \varepsilonn2 edges have to be deleted from it to make it H-free. It is known that in this case G contains at least f(\varepsilon, H)nh copies of H. We show that the largest possible function f(\varepsilon, H) is polynomial in \varepsilon if and only if H is bipartite. This implies that there is a one-sided error property tester for checking H-freeness, whose query complexity is polynomial in 1 = \varepsilon, if and only if H is bipartite.
FOCS	Random Evolution in Massive Graphs.	William Aiello,Fan R. K. Chung,Linyuan Lu	2001	"Many massive graphs (such as WWW graphs and Call graphs) share certain universal characteristics which can be described by the so-called the ""power law"". In this paper, we first briefly survey the history and previous work on power law graphs. Then we give four evolution models for generating power law graphs by adding one node/edge at a time. We show that for any given edge density and desired distributions for in-degrees and out-degrees (not necessarily the same, but adhered to certain general conditions), the resulting graph almost surely satisfy the power law and the in/out-degree conditions. We show that our most general directed and undirected models include nearly all known models as special cases. In addition, we consider another crucial aspect of massive graphs that is called ""scale-free"" in the sense that the frequency of sampling (w.r.t. the growth rate) is independent of the parameter of the resulting power law graphs. We show that our evolution models generate scale-free power law graphs."
FOCS	Semi-Direct Product in Groups and Zig-Zag Product in Graphs: Connections and Applications.	Noga Alon,Alexander Lubotzky,Avi Wigderson	2001	Semi-Direct Product in Groups and Zig-Zag Product in Graphs: Connections and Applications.
FOCS	Source Routing and Scheduling in Packet Networks.	Matthew Andrews,Antonio Fernández,Ashish Goel,Lisa Zhang	2001	"We study routing and scheduling in packet-switched networks. We assume an adversary that controls the injection time, source, and destination for each packet injected. A set of paths for these packets is admissible if no link in the network is overloaded. We present the first on-line routing algorithm that finds a set of admissible paths whenever this is feasible. Our algorithm calculates a path for each packet as soon as it is injected at its source using a simple shortest path computation. The length of a link reflects its current congestion. We also show how our algorithm can be implemented under today's Internet routing paradigms.When the paths are known (either given by the adversary or computed as above), our goal is to schedule the packets along the given paths so that the packets experience small end-to-end delays. The best previous delay bounds for deterministic and distributed scheduling protocols were exponential in the path length. In this article, we present the first deterministic and distributed scheduling protocol that guarantees a polynomial end-to-end delay for every packet.Finally, we discuss the effects of combining routing with scheduling. We first show that some unstable scheduling protocols remain unstable no matter how the paths are chosen. However, the freedom to choose paths can make a difference. For example, we show that a ring with parallel links is stable for all greedy scheduling protocols if paths are chosen intelligently, whereas this is not the case if the adversary specifies the paths."
FOCS	Truthful Mechanisms for One-Parameter Agents.	Aaron Archer,Éva Tardos	2001	Truthful Mechanisms for One-Parameter Agents.
FOCS	Simple Routing Strategies for Adversarial Systems.	Baruch Awerbuch,Petra Berenbrink,André Brinkmann,Christian Scheideler	2001	Simple Routing Strategies for Adversarial Systems.
FOCS	How to Go Beyond the Black-Box Simulation Barrier.	Boaz Barak	2001	How to Go Beyond the Black-Box Simulation Barrier.
FOCS	Resettably-Sound Zero-Knowledge and its Applications.	Boaz Barak,Oded Goldreich,Shafi Goldwasser,Yehuda Lindell	2001	Resettably-Sound Zero-Knowledge and its Applications.
FOCS	A Ramsy-type Theorem for Metric Spaces and its Applications for Metrical Task Systems and Related Problems.	Yair Bartal,Béla Bollobás,Manor Mendel	2001	A Ramsy-type Theorem for Metric Spaces and its Applications for Metrical Task Systems and Related Problems.
FOCS	Testing Random Variables for Independence and Identity.	Tugkan Batu,Lance Fortnow,Eldar Fischer,Ravi Kumar,Ronitt Rubinfeld,Patrick White	2001	Given access to independent samples of a distribution A over [n] × [m], we show how to test whether the distributions formed by projecting A to each coordinate are independent, i.e., whether A is \varepsilon-close in the L1 norm to the product distribution A1 × A2 for some distributions A1 over [n] and A2 over [m]. The sample complexity of our test is \widetilde0(n^{{2 \mathord{\left/ {\vphantom {2 3}} \right. \kern-\nulldelimiterspace} 3}} m^{{1 \mathord{\left/ {\vphantom {1 3}} \right. \kern-\nulldelimiterspace} 3}} poly(\varepsilon ^{ - 1} )), assuming without loss of generality that m \leqslant n. We also give a matching lower bound, up to poly(\log n,\varepsilon ^{ - 1} ) factors.Furthermore, given access to samples of a distribution X over [n], we show how to test if X is \varepsilon-close in L1 norm to an explicitly specified distribution Y . Our test uses \widetilde0(n^{{1 \mathord{\left/ {\vphantom {1 2}} \right. \kern-\nulldelimiterspace} 2}} poly(\varepsilon ^{ - 1} )) samples, which nearly matches the known tight bounds for the case when Y is uniform.
FOCS	The Natural Work-Stealing Algorithm is Stable.	Petra Berenbrink,Tom Friedetzky,Leslie Ann Goldberg	2001	In this paper we analyze a very simple dynamic work-stealing algorithm. In the work-generation model, there are n (work) generators. A generator-allocation function is simply a function from the n generators to the n processors. We consider a fixed, but arbitrary, distribution $\cal D$ over generator-allocation functions. During each time step of our process, a generator-allocation function h is chosen from $\cal D$, and the generators are allocated to the processors according to h. Each generator may then generate a unit-time task, which it inserts into the queue of its host processor. It generates such a task independently with probability $\lambda$. After the new tasks are generated, each processor removes one task from its queue and services it. For many choices of $\cal D$, the work-generation model allows the load to become arbitrarily imbalanced, even when $\lambdah which allocates all of the generators to just one processor. For this choice of $\cal D$, the chosen processor receives around $\lambda n$ units of work at each step and services one. The natural work-stealing algorithm that we analyze is widely used in practical applications and works as follows. During each time step, each empty processor (with no work to do) sends a request to a randomly selected other processor. Any nonempty processor having received at least one such request in turn decides (again randomly) in favor of one of the requests. The number of tasks which are transferred from the nonempty processor to the empty one is determined by the so-called work-stealing function f. In particular, if a processor that accepts a request has $\ell$ tasks stored in its queue, then $f(\ell)$ tasks are transferred to the currently empty one. A popular work-stealing function is $f(\ell)=\lfloor \ell/2\rfloor$, which transfers (roughly) half of the tasks. We analyze the long-term behavior of the system as a function of $\lambda$ and f. We show that the system is stable for any constant generation rate $\lambda<1$ and for a wide class of functions f. Most intuitively sensible functions are included in this class (for example, every monotonically nondecreasing function f which satisfies $0 \leq f(\ell)\leq \ell/2$ and $f(\ell)=\omega(1)$ as a function of $\ell$ is included). Furthermore, we give upper bounds on the average system load (as a function of f and n). Our proof techniques combine Lyapunov function arguments with domination arguments, which are needed to cope with dependency.
FOCS	Arc-Disjoint Paths in Expander Digraphs.	Tom Bohman,Alan M. Frieze	2001	Given a digraph D=(V,A) and a set of $\kappa$ pairs of vertices in V, we are interested in finding, for each pair (xi, yi), a directed path connecting xi to yi such that the set of $\kappa$ paths so found is arc-disjoint. For arbitrary graphs the problem is ${\cal NP}$-complete, even for $\kappa=2$. We present a polynomial time randomized algorithm for finding arc-disjoint paths in an r-regular expander digraph D. We show that if D has sufficiently strong expansion properties and the degree r is sufficiently large, then all sets of $\kappa=\Omega(n/\log n)$ pairs of vertices can be joined. This is within a constant factor of best possible.
FOCS	The Complexity of Factors of Multivariate Polynomials.	Peter Bürgisser	2001	The existence of string functions, which are not polynomial time computable, but whose graph is checkable in polynomial time, is a basic assumption in cryptography. We prove that in the framework of algebraic complexity, there are no such families of polynomial functions of polynomially bounded degree over fields of characteristic zero. The proof relies on a polynomial upper bound on the approximative complexity of a factor g of a polynomial f in terms of the (approximative) complexity of f and the degree of the factor g. This extends a result by Kaltofen. The concept of approximative complexity allows us to cope with the case that a factor has an exponential multiplicity, by using a perturbation argument. Our result extends to randomized (two-sided error) decision complexity.
FOCS	S subseteq ZPP.	Jin-yi Cai	2001	S subseteq ZPP.
FOCS	Universally Composable Security: A New Paradigm for Cryptographic Protocols.	Ran Canetti	2001	We propose a new paradigm for defining security of cryptographic protocols, called universally composable security. The salient property of universally composable definitions of security is that they guarantee security even when a secure protocol is composed with an arbitrary set of protocols, or more generally when the protocol is used as a component of an arbitrary system. This is an essential property for maintaining security of cryptographic protocols in complex and unpredictable environments such as the Internet. In particular, universally composable definitions guarantee security even when an unbounded number of protocol instances are executed concurrently in an adversarially controlled manner, they guarantee non-malleability with respect to arbitrary protocols, and more.We show how to formulate universally composable definitions of security for practically any cryptographic task. Furthermore, we demonstrate that practically any such definition can be realized using known techniques, as long as only a minority of the participants are corrupted. We then proceed to formulate universally composable definitions of a wide array of cryptographic tasks, including authenticated and secure communication, key-exchange, public-key encryption, signature, commitment, oblivious transfer, zero knowledge and more. We also make initial steps towards studying the realizability of the proposed definitions in various settings.
FOCS	Approximating Directed Multicuts.	Joseph Cheriyan,Howard J. Karloff,Yuval Rabani	2001	"The seminal paper of Leighton and Rao (1988) and subsequent papers presented approximate min-max theorems relating multicommodity flow values and cut capacities in undirected networks, developed the divide-and-conquer method for designing approximation algorithms, and generated novel tools for utilizing linear programming relaxations. Yet, despite persistent research efforts, these achievements could not be extended to directed networks, excluding a few cases that are &#x201c;&#x201c;symmetric&#x201d; and therefore similar to undirected networks. This paper is an attempt to remedy the situation. We consider the problem of finding a minimum multicut in a directed multicommodity flow network, and give the first nontrivial upper bounds on the max flow-to-min multicut ratio. Our results are algorithmic, demonstrating nontrivial approximation guarantees."
FOCS	Informational Complexity and the Direct Sum Problem for Simultaneous Message Complexity.	Amit Chakrabarti,Yaoyun Shi,Anthony Wirth,Andrew Chi-Chih Yao	2001	Informational Complexity and the Direct Sum Problem for Simultaneous Message Complexity.
FOCS	Approximation Algorithms for the Job Interval Selection Problem and Related Scheduling Problems.	Julia Chuzhoy,Rafail Ostrovsky,Yuval Rabani	2001	In this paper we consider the job interval selection problem (JISP), a simple scheduling model with a rich history and numerous applications. Special cases of this problem include the so-called real-time scheduling problem (also known as the throughput maximization problem) in single- and multiple-machine environments. In these special cases we have to maximize the number of jobs scheduled between their release date and deadline (preemption is not allowed). Even the single-machine case is NP-hard. The unrelated machines case, as well as other special cases of JISP, are MAX SNP-hard. A simple greedy algorithm gives a two-approximation for JISP. Despite many efforts, this was the best approximation guarantee known, even for throughput maximization on a single machine. In this paper, we break this barrier and show an approximation guarantee of less than 1.582 for arbitrary instances of JISP. For some special cases, we show better results.
FOCS	The Confluence of Ground Term Rewrite Systems is Decidable in Polynomial Time.	Hubert Comon,Guillem Godoy,Robert Nieuwenhuis	2001	The Confluence of Ground Term Rewrite Systems is Decidable in Polynomial Time.
FOCS	How Powerful is Adiabatic Quantum Computation?.	Wim van Dam,Michele Mosca,Umesh V. Vazirani	2001	How Powerful is Adiabatic Quantum Computation?.
FOCS	"""Planar"" Tautologies Hard for Resolution."	Stefan S. Dantchev,Søren Riis	2001	"""Planar"" Tautologies Hard for Resolution."
FOCS	Fully Dynamic All Pairs Shortest Paths with Real Edge Weights.	Camil Demetrescu,Giuseppe F. Italiano	2001	We present the first fully dynamic algorithm for maintaining all pairs shortest paths in directed graphs with real-valued edge weights. Given a dynamic directed graph G such that each edge can assume at most S different real values, we show how to support updates in O(n2.5√Slog3n) amortized time and queries in optimal worst-case time. This algorithm is deterministic: no previous fully dynamic algorithm was known before for this problem. In the special case where edge weights can only be increased, we give a randomized algorithm with one-sided error that supports updates faster in O(S ċ n log3 n) amortized time. We also show how to obtain query/update trade-offs for this problem, by introducing two new families of randomized algorithms. Algorithms in the first family achieve an update bound of Õ(S ċ k ċ n2)1 and a query bound of Õ(n/k), and improve over the previous best known update bounds for k in the range (n/S)1/3≤k<(n/S)1/2. Algorithms in the second family achieve an update bound of Õ(S ċ k ċ n2) and a query bound of Õ(n2/k2), and are competitive with the previous best known update bounds (first family included) for k in the range (n/S)1/6 ≤ k < (n/S)1/3.
FOCS	Fast Monte-Carlo Algorithms for Approximate Matrix Multiplication.	Petros Drineas,Ravi Kannan	2001	"Given an m × n matrix A and an n × p matrix B, we present 2 simple and intuitive algorithms to compute an approximation P to the product A ¿ B, with provable bounds for the norm of the ""error matrix"" P - A ¿ B. Both algorithms run in 0(mp+mn+np) time. In both algorithms, we randomly pick s = 0(1) columns of A to form an m × s matrix S and the corresponding rows of B to form an s × p matrix R. After scaling the columns of S and the rows of R, we multiply them together to obtain our approximation P. The choice of the probability distribution we use for picking the columns of A and the scaling are the crucial features which enable us to fairly elementary proofs of the error bounds. Our first algorithm can be implemented without storing the matrices A and B in Random Access Memory, provided we can make two passes through the matrices (stored in external memory). The second algorithm has a smaller bound on the 2-norm of the error matrix, but requires storage of A and B in RAM. We also present a fast algorithm that ""describes"" P as a sum of rank one matrices if B = AT."
FOCS	Randomly Colouring Graphs with Lower Bounds on Girth and Maximum Degree.	Martin E. Dyer,Alan M. Frieze	2001	Randomly Colouring Graphs with Lower Bounds on Girth and Maximum Degree.
FOCS	Planar Graphs, Negative Weight Edges, Shortest Paths, Near Linear Time.	Jittat Fakcharoenphol,Satish Rao	2001	Planar Graphs, Negative Weight Edges, Shortest Paths, Near Linear Time.
FOCS	An Iterative Rounding 2-Approximation Algorithm for the Element Connectivity Problem.	Lisa Fleischer,Kamal Jain,David P. Williamson	2001	An Iterative Rounding 2-Approximation Algorithm for the Element Connectivity Problem.
FOCS	Three Theorems Regarding Testing Graph Properties.	Oded Goldreich,Luca Trevisan	2001	Property testing is a relaxation of decision problems in which it is required to distinguish YES-instances (i.e., objects having a predetermined property) from instances that are far from any YES-instance. We presents three theorems regarding testing graph properties in the adjacency matrix representation. More specifically, these theorems relate to the project of characterizing graph properties according to the complexity of testing them (in the adjacency matrix representation).The first theorem is that there exist monotone graph properties in NP for which testing is very hard (i.e., requires to examine a constant fraction of the entries in the matrix). The second theorem is that every graph property that can be tested making a number of queries that is independent of the size of the graph, can be so tested by uniformly selecting a set of vertices and accepting iff the induced subgraph has some fixed graph property (which is not necessarily the same as the one being tested). The third theorem refers to the framework of graph partition problems, and is a characterization of the subclass of properties that can be tested using a one-sided error tester making a number of queries that is independent of the size of the graph.
FOCS	On the Impossibility of Basing Trapdoor Functions on Trapdoor Predicates.	Yael Gertner,Tal Malkin,Omer Reingold	2001	We prove that, somewhat surprisingly, there is no blackbox reduction of (poly-to-one) trapdoor functions to trapdoor predicates (equivalently, to public-key encryption schemes). Our proof follows the methodology that was introduced by Impagliazzo and Rudich [19], although we use a new, weaker model of separation.
FOCS	Sorting and Selection with Structured Costs.	Anupam Gupta,Amit Kumar	2001	"The study of the effect of priced information on basic algorithmic problems was initiated by the paper of Charikar et al. [5]. In this paper, we continue the study of sorting and selection in the priced comparison model, i.e., when each comparison has an associated cost, and answer some of the open problems suggested by [5]. If the comparison costs are allowed to be arbitrary, we show that one can not get good approximation ratios. A different way to assign costs is based on the idea that one can distill out an intrinsic value for each item being compared such that the cost of comparing two elements is some ""well-behaved"" or ""structured"" function of their values. We feel that most practical applications will have some structured cost property.In this paper, we study the problems of sorting and selection (which includes finding the maximum and the median) in the structured cost model. We get a variety of approximation results for these problems, depending on the restrictions we put on the structured costs. We show that it is possible to get much improved results with the structured cost model than the case when we do not have any assumptions on comparison costs."
FOCS	Traveling with a Pez Dispenser (Or, Routing Issues in MPLS).	Anupam Gupta,Amit Kumar,Rajeev Rastogi	2001	"A new packet routing model proposed by the Internet Engineering Task Force is MultiProtocol Label Switching, or MPLS [B. Davie and Y. Rekhter, MPLS: Technology and Applications, Morgan Kaufmann (Elsevier), New York, 2000]. Instead of each router's parsing the packet network layer header and doing its lookups based on that analysis (as in much of conventional packet routing), MPLS ensures that the analysis of the header is performed just once. The packet is then assigned a stack of labels, where the labels are usually much smaller than the packet headers themselves. When a router receives a packet, it examines the label at the top of the label stack and makes the decision of where the packet is forwarded based solely on that label. It can pop the top label off the stack if it so desires, and can also push some new labels onto the stack, before forwarding the packet. This scheme has several advantages over conventional routing protocols, the two primary ones being (a) reduced amount of header analysis at intermediate routers, which allows for faster switching times, and (b) better traffic engineering capabilities and hence easier handling of quality of service issues. However, essentially nothing is known at a theoretical level about the performance one can achieve with this protocol, or about the intrinsic trade-offs in its use of resources.This paper initiates a theoretical study of MPLS protocols, and routing algorithms and lower bounds are given for a variety of situations. We first study the routing problem on the line, a case which is already nontrivial, and give routing protocols whose trade-offs are close to optimality. We then extend our results for paths to trees, and thence onto more general graphs. These routing algorithms on general graphs are obtained by finding a tree cover of a graph, i.e., a small family of subtrees of the graph such that, for each pair of vertices, one of the trees in the family contains an (almost-)shortest path between them. Our results show tree covers of logarithmic size for planar graphs and graphs with bounded separators, which may be of independent interest."
FOCS	Expander-Based Constructions of Efficiently Decodable Codes.	Venkatesan Guruswami,Piotr Indyk	2001	"We present several novel constructions of codes which share the common thread of using expander (or expander-like) graphs as a component. The expanders enable the design of efficient decoding algorithms that correct a large number of errors through various forms of ""voting"" procedures. We consider both the notions of unique and list decoding, and in all cases obtain asymptotically good codes which are decodable up to a ""maximum"" possible radius and either (a) achieve a similar rate as the previously best known codes but come with significantly faster algorithms, or (b) achieve a rate better than any prior construction with similar error-correction properties. Among our main results are:Codes of rate \Omega (\varepsilon ^2 ) over constant-sized alphabet that can be list decoded in quadratic time from (1 - \varepsilon) errors. This matches the performance of the best algebraic-geometric (AG) codes, but with much faster encoding and decoding algorithms.Codes of rate \Omega(\varepsilon) over constant-sized alphabet that can be uniquely decoded from (1/2 - \varepsilon errors in near-linear time (once again this matches AG-codes with much faster algorithms). This construction is similar to that of [1], and our decoding algorithm can be viewed as a positive resolution of their main open question.Linear-time encodable and decodable binary codes of positive rate1 (in fact, rate \Omega(\varepsilon4)) that can correct up to (1/4 - \varepsilon) fraction errors. Note that this is the best error-correction one can hope for using unique decoding of binary codes. This significantly improves the fraction of errors corrected by the earlier linear-time codes of Spielman [19] and the linear-time decodable codes of [18, 22]."
FOCS	Clustering Motion.	Sariel Har-Peled	2001	"Given a set of moving points in &#x211d;d, we show how to cluster them in advance, using a small number of clusters, so that at any time this static clustering is competitive with the optimal k-center clustering at that time. The advantage of this approach is that it avoids updating the clustering as time passes. We also show how to maintain this static clustering efficiently under insertions and deletions.To implement this static clustering efficiently, we describe a simple technique for speeding up clustering algorithms and apply it to achieve faster clustering algorithms for several problems. In particular, we present a linear time algorithm for computing a 2-approximation to the k-center clustering of a set of n points in &#x211d;d. This slightly improves the algorithm of Feder and Greene, that runs in &#x0398;(n log k) time (which is optimal in the algebraic decision tree model)."
FOCS	A Replacement for Voronoi Diagrams of Near Linear Size.	Sariel Har-Peled	2001	For a set P of n points in \mathbb{R}^d , we define a new type of space decomposition. The new diagram provides an \varepsilon-approximation to the distance function associated with the Voronoi diagram of P, while being of near linear size, for d \geqslant 2. This contrasts with the standard Voronoi diagram that has \Omega (n^{\left\lceil {{d \mathord{\left/ {\vphantom {d 2}} \right. \kern-\nulldelimiterspace} 2}} \right\rceil } ) complexity in the worst case.
FOCS	Approximate Shape Fitting via Linearization.	Sariel Har-Peled,Kasturi R. Varadarajan	2001	Approximate Shape Fitting via Linearization.
FOCS	Vickrey Prices and Shortest Paths: What is an Edge Worth?.	John Hershberger,Subhash Suri	2001	"We solve a shortest path problem that is motivated by recent interest in pricing networks or other computational resources. Informally, how much is an edge in a network worth to a user who wants to send data between two nodes along a shortest path? If the network is a decentralized entity, such as the Internet, in which multiple self-interested agents own different parts of the network, then auction-based pricing seems appropriate. A celebrated result fromauction theory shows that the use of Vickrey pricing motivates the owners of the network resources to bid truthfully. In Vickrey's scheme, each agent is compensated in proportion to the marginal utility he brings to the auction. In the context of shortest path routing, an edge's utility is the value by which it lowers the length of the shortest path ¿ the differencebetween the shortest path lengths with and without the edge. Our problem is to compute these marginal values for all the edges of the network efficiently. The na¨ýve method requires solving the single-source shortest path problem up to n times, for an n-node network. We show that the Vickrey prices for all the edges can be computed in the same asymptotic time complexity as one single-source shortest path problem. This solves an open problem posed by Nisan and Ronen [12]."
FOCS	Query Efficient PCPs with Perfect Completeness.	Johan Håstad,Subhash Khot	2001	For every integer k \geqslant 1, we present a PCP characterization of NP where the verifier uses logarithmic randomness, queries 4k + k2 bits in the proof, accepts a correct proof with probability 1 (i.e. it is has perfect completeness) and accepts any supposed proof of a false statement with probability at most 2^{ - k^2+ 1}. In particular, the verifier achieves optimal amortized query complexity of 1+ \delta for arbitrarily small constant ¦\delta > 0. Such a characterization was already proved by Samorodnitsky and Trevisan [15], but their verifier loses perfect completeness and their proof makes an essential use of this feature.By using an adaptive verifier we can decrease the number of query bits to 2k + k2, the same number obtained in [15]. Finally we extend some of the results to larger domains.
FOCS	Counting Axioms Do Not Polynomially Simulate Counting Gates.	Russell Impagliazzo,Nathan Segerlind	2001	Counting Axioms Do Not Polynomially Simulate Counting Gates.
FOCS	Algorithmic Applications of Low-Distortion Geometric Embeddings.	Piotr Indyk	2001	The study of geometric representations of combinatorial structures (notably graphs) is a very wide area encompassing many disciplines. In this survey, however, we focus exclusively on geometric representations of metrics which achieve low distortion, as defined in the introduction. For a survey of many other ways of embedding combinatorial structures into geometric spaces, see [LV99].
FOCS	Glauber Dynamics on Trees and Hyperbolic Graphs.	Claire Kenyon,Elchanan Mossel,Yuval Peres	2001	Glauber Dynamics on Trees and Hyperbolic Graphs.
FOCS	Improved Inaproximability Results for MaxClique, Chromatic Number and Approximate Graph Coloring.	Subhash Khot	2001	"In this paper, we present improved inapproximability results for three problems : the problem of finding the maximum clique size in a graph, the problem of finding the chromaticnumber of a graph, and the problem of coloring a graph with a small chromatic number with a small number of colors.Håstad's celebrated result [13] shows that the maximum clique size in a graph with n vertices is inapproximable in polynomial time within a factor n1- \varepsilon for arbitrarily small constant \varepsilon > 0 unless NP=ZPP. In this paper, we aim at getting the best sub-constant value of \varepsilon in Håstad's result. We prove that clique size is inapproximable within a factor \frac{n}{{2(\log n)^{1 - \gamma } }} (corresponding to \varepsilon= \frac{1}{{(\log n)^\gamma}} for some constant \gamma> 0 unless NP \subseteq ZPTIME(2^{(\log n)^{0(1)} } ). This improves the previous best inapproximability factor of \frac{n}{{2^{0({{\log n} \mathord{\left/ {\vphantom {{\log n} {\sqrt {\log \log n} }}} \right. \kern-\nulldelimiterspace} {\sqrt {\log \log n} }}} }} (corresponding to \varepsilon= 0(\frac{1} {{\sqrt {\log \log n} }}) due to Engebretsen and Holmerin [7].A similar result is obtained for the problem of approximating chromatic number of a graph. Feige and Kilian [10] prove that chromatic number is hard to approximate within factor n1- \varepsilon for any constant \varepsilon > 0 unless NP=ZPP. We use some of their techniques to give a much simpler proof of the same result and also improve the hardness factor to \frac{n}{{2(\log n)^{1 - \gamma } }} for some constant \gamma > 0. The above two results are obtained by constructing a new Hadamard code based PCP inner verifier.We also present a new hardness result for approximate graph coloring. We show that for all sufficiently large constants k, it is NP-hard to color a k-colorable graph with K\frac{1}{{25}}(\log k) colors. This improves a result of Fürer [11] that for arbitrarily small constant \varepsilon > 0, for sufficiently large constants k, it is hard to color a k-colorable graph with k3/2-\varepsilon colors."
FOCS	Lower Bounds for Quantum Communication Complexity.	Hartmut Klauck	2001	We prove lower bounds on the bounded error quantum communication complexity. Our methods are based on the Fourier transform of the considered functions. First we generalize a method for proving classical communication complexity lower bounds developed by Raz [Comput. Complexity, 5 (1995), pp. 205-221] to the quantum case. Applying this method, we give an exponential separation between bounded error quantum communication complexity and nondeterministic quantum communication complexity. We develop several other lower bound methods based on the Fourier transform, notably showing that $\sqrt{\bar{s}(f)/\log n}$, for the average sensitivity $\bar{s}(f)$ of a function $f$, yields a lower bound on the bounded error quantum communication complexity of $f((x \wedge y)\oplus z)$, where $x$ is a Boolean word held by Alice and $y,z$ are Boolean words held by Bob. We then prove the first large lower bounds on the bounded error quantum communication complexity of functions, for which a polynomial quantum speedup is possible. For all the functions we investigate, the only previously applied general lower bound method based on discrepancy yields bounds that are $O(\log n)$.
FOCS	Tight Approximation Results for General Covering Integer Programs.	Stavros G. Kolliopoulos,Neal E. Young	2001	In this paper we study approximation algorithms for solving a general covering integer program. An n-vector x of nonnegative integers is sought, which minimizes cT ¿ x; subject to Ax \geqslant b,x \leqslant d: The entries of A; b; c are nonnegative. Let m be the number of rows of A: Covering problems have been heavily studied in combinatorial optimization. We focus on the effect of the multiplicity constraints, x \leqslant d; on approximability. Two longstanding open questions remain for this general formulation with upper bounds on the variables.(i) The integrality gap of the standard LP relaxation is arbitrarily large. Existing approximation algorithms that achieve the well-known O(logm)-approximation with respect to the LP value do so at the expense of violating the upper bounds on the variables by the same O(logm) multiplicative factor. What is the smallest possible violation of the upper bounds that still achieves cost within O(logm) of the standard LP optimum?(ii) The best known approximation ratio for the problem has been 0(\log (\max _j \sum\nolimits_i {A_{ij} })) since 1982. This bound can be as bad as polynomial in the input size. Is an O(logm)-approximation, like the one known for the special case of Set Cover, possible?We settle these two open questions. To answer the first question we give an algorithm based on the relatively simple new idea of randomly rounding variables to smaller-than integerunits. To settle the second question we give a reduction from approximating the problem while respecting multiplicity constraints to approximating the problem with a bounded violation of the multiplicity constraints.
FOCS	Almost Tight Upper Bounds for Vertical Decompositions in Four Dimensions.	Vladlen Koltun	2001	We show that the complexity of the vertical decomposition of an arrangement of n fixed-degree algebraic surfaces or surface patches in four dimensions is O(n4+&epsiv;), for any &epsiv; > 0. This improves the best previously known upper bound for this problem by a near-linear factor, and settles a major problem in the theory of arrangements of surfaces, open since 1989. The new bound can be extended to higher dimensions, yielding the bound O(n2d&minus;4+&epsiv;), for any &epsiv; > 0, on the complexity of vertical decompositions in dimensions d &ge; 4. We also describe the immediate algorithmic applications of these results, which include improved algorithms for point location, range searching, ray shooting, robot motion planning, and some geometric optimization problems.
FOCS	Online Facility Location.	Adam Meyerson	2001	We consider the online variant of facility location, in which demand points arrive one at a time and we must maintain a set of facilities to service these points. We provide a randomized online O(1)-competitive algorithm in the case where points arrive in random order. If points areordered adversarially, we show that no algorithm can be constant-competitive, and provide an O(log n)-competitive algorithm. Our algorithms are randomized and the analysis depends heavily on the concept of expected waiting time. We also combine our techniques with those of Charikar and Guha to provide a linear-time constant approximation for the offline facility location problem.
FOCS	Linear-time Recognition of Circular-arc Graphs.	Ross M. McConnell	2001	A graph G is a circular-arc graph if it is the intersection graph of a set of arcs on a circle. That is, there is one arc for each vertex of G, and two vertices are adjacent in G if the corresponding arcs intersect. We give a linear time bound for recognizing this class of graphs. When G is a member of the class, the algorithm gives a certificate in the form of a set of arcs that realize it.
FOCS	Spectral Partitioning of Random Graphs.	Frank McSherry	2001	Problems such as bisection, graph coloring, and clique are generally believed hard in the worst case. However, they can be solved if the input data is drawn randomly from a distribution over graphs containing acceptable solutions.In this paper we show that a simple spectral algorithm can solve all three problems above in the average case, as well as a more general problem of partitioning graphs based on edge density. In nearly all cases our approach meets or exceeds previous parameters, while introducing substantial generality. We apply spectral techniques, using foremost the observation that in all of these problems, the expected adjacency matrix is a low rank matrix wherein the structure of the solution is evident.
FOCS	Designing Networks Incrementally.	Adam Meyerson,Kamesh Munagala,Serge A. Plotkin	2001	Designing Networks Incrementally.
FOCS	Facility Location with Nonuniform Hard Capacities.	Martin Pál,Éva Tardos,Tom Wexler	2001	In this paper we give the first constant factor approximation algorithm for the Facility Location Problem with nonuniform, hard capacities. Facility location problems have received a great deal of attention in recent years. Approximation algorithms have been developed for many variants. Most of these algorithms are based on linear programming, but the LP techniques developed thus far have been unsuccessful in dealing with hard capacities.A local-search based approximation algorithm [11, 6] is known for the special case of hard but uniform capacities. We present a local-search heuristic that yields an approximation guarantee of 9 + \varepsilon for the case of nonuniform hard capacities. To obtain this result we introduce new operations that are natural in this context. Our proof is based on network flow techniques.
FOCS	Building Low-Diameter P2P Networks.	Gopal Pandurangan,Prabhakar Raghavan,Eli Upfal	2001	Building Low-Diameter P2P Networks.
FOCS	"Game Theory and Mathematical Economics: A Theoretical Computer Scientist's Introduction."	Christos H. Papadimitriou	2001	There has been recently increasing interaction between Game Theory and, more generally, Economic Theory, with Theoretical Computer Science, mainly in the context of the Internet. This paper is an invitation to this important fronteer.
FOCS	Designing Networks for Selfish Users is Hard.	Tim Roughgarden	2001	"e consider a directed network in which every edge possesses a latency function specifying the time needed to traverse the edge given its congestion. Selfish, noncooperativeagents constitute the network traffic and wish to travel from a source s to a sink t as quickly as possible. Since the route chosen by one network user affects the congestion (and hence the latency) experienced by others, we model the problem as a noncooperative game. Assuming each agent controls only a negligible portion of the overall traffic, Nash equilibria in this noncooperative game correspond to s-t flows in which all flow paths have equal latency.A natural measure for the performance of a network used by selfish agents is the common latency experienced by each user in a Nash equilibrium. It is a counterintuitive but well-knownfact that removing edges from a network may improve its performance; the most famous example of this phenomenon is the so-called Braess's Paradox. This fact motivates the following network design problem: given such a network, which edges should be removed to obtain the best possible flow at Nash equilibrium? Equivalently, given a large network of candidate edges to be built, which subnetwork will exhibit the best performance when used selfishly?We give optimal inapproximability results and approximation algorithms for several network design problems of this type. For example, we prove that for networks with n nodes and continuous, nondecreasing latency functions, there is no approximation algorithm for this problem with approximation ratio less than n/2 (unless P = NP). We also prove this hardness result to be best possible by exhibiting an n/2-approximation algorithm. For networks in which the latency of each edge is a linear function of the congestion, we prove that there is no (\frac{4}{3} - \varepsilon)-approximation algorithm for the problem (for any \varepsilon > 0, unless P = NP); the existence of a \frac{4}{3}-approximation algorithm follows easily from existing work, proving this hardness result sharp.Moreover, we prove that an optimal approximation algorithm for these problems is what we call the trivial algorithm: given a network of candidate edges, build the entire network. Roughly, this result implies that the presence of harmful extra edges in a network (a phenomenon that can lead to extremely poor performance in large networks with general latency functions) is impossible to detect efficiently."
FOCS	Simple Extractors for All Min-Entropies and a New Pseudo-Random Generator.	Ronen Shaltiel,Christopher Umans	2001	Simple Extractors for All Min-Entropies and a New Pseudo-Random Generator.
FOCS	Lower Bounds for Matrix Product.	Amir Shpilka	2001	We prove lower bounds on the number of product gates in bilinear and quadratic circuits that compute the product of two n &times; n matrices over finite fields. In particular we obtain the following results: We show that the number of product gates in any bilinear (or quadratic) circuit that computes the product of two n &times; n matrices over ${\rm GF}(2)$ is at least 3n2 - o(n2). We show that the number of product gates in any bilinear circuit that computes the product of two n &times; n matrices over ${\rm GF}(q)$ is at least $(2.5 + \frac{1.5}{q^3 -1})n^2 -o(n^2)$. These results improve the former results of [N. H. Bshouty, SIAM J. Comput., 18 (1989), pp. 759--765; M. Bläser, Proceedings of the 40th Annual IEEE Symposium on Foundations of Computer Science, IEEE Computer Society, Los Alamitos, CA, 1999, pp. 45--50], who proved lower bounds of 2.5 n2 - o(n2).
FOCS	Distributions on Level-Sets with Applications to Approximation Algorithms.	Aravind Srinivasan	2001	We consider a family of distributions on fixed-weight vectors in (0; 1)t these distributions enjoy certain negative correlation properties and also satisfy pre-specified conditions on their marginal distributions. We show the existence of such families, and present a linear-time algorithm to sample from them. This yields improved approximation algorithms for the following problems: (a) low-congestion multi-path routing; (b) maximum coverage versions of set cover; (c) partial vertex cover problems for bounded-degree graphs; and (d) the Group Steiner Tree problem. For (a) and (b), the improvement is in the approximation ratio; for (c), we show how to speedup existing approximation algorithms while preserving the best-known approximation ratio; we also improve the approximation ratio for certain families of instances of unbounded degree. For (d), we derive an approximation algorithm whose approximation guarantee is at least as good as what is known; our algorithm is shown to have a better approximation guarantee for the worst known input families for existing algorithms.
FOCS	Deterministic Computation of the Frobenius Form.	Arne Storjohann	2001	A deterministic algorithm for computing the Frobenius canonical-form of a matrix over a field is described. A similarity transformation-matrix is recovered in the same time. The algorithm is nearly optimal, requiring about the same number of field operations as required for matrix multipication. Previously-known reductions to matrix multiplication are probabilistic.
FOCS	Coding Theory: Tutorial and Survey.	Madhu Sudan	2001	Coding theory has played a central role in the theoretical computer science. Computer scientists have long exploited notions, constructions, theorems and techniques of coding theory. More recently, theoretical computer science has also been contributing to the theory of error-correcting codes ¿ in particular in making progress on some fundamental algorithmic connections. Here we survey some of the central goals of coding theory and the progress made via algebraic methods. We stress that this is a very partial view of coding theory and a lot of promising combinatorial and probabilistic approaches are not covered by this survey. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player
FOCS	Unique Sink Orientations of Cubes.	Tibor Szabó,Emo Welzl	2001	Unique Sink Orientations of Cubes.
FOCS	Extractors from Reed-Muller Codes.	Amnon Ta-Shma,David Zuckerman,Shmuel Safra	2001	Finding explicit extractors is an important derandomization goal that has received a lot of attention in the past decade. Previous research has focused on two approaches, one related to hashing and the other to pseudorandom generators. A third view, regarding extractors as good error correcting codes, was noticed before. Yet, researchers had failed to build extractors directly from a good code without using other tools from pseudorandomness. We succeed in constructing an extractor directly from a Reed-Muller code. To do this, we develop a novel proof technique.Furthermore, our construction is the first to achieve degree close to linear. In contrast, the best previous constructions brought the log of the degree within a constant of optimal, which gives polynomial degree. This improvement is important for certain applications. For example, it was used [E. Mossel, C. Umans, On the complexity of approximating the VC dimension, J. Comput. System Sci. 65 (2002) 660-671] to show that approximating VC dimension to within a factor of N1-δ is AM-hard for any positive δ.
FOCS	Compact Oracles for Reachability and Approximate Distances in Planar Digraphs.	Mikkel Thorup	2001	It is shown that a planar digraph can be preprocessed in near-linear time, producing a near-linear space oracle that can answer reachability queries in constant time. The oracle can be distributed as an O(log n) space label for each vertex and then we can determine if one vertex can reach another considering their two labels only.The approach generalizes to give a near-linear space approximate distances oracle for a weighted planar digraph. With weights drawn from &lcub;0, &hellip;, N&rcub;, it approximates distances within a factor (1 + &epsiv;) in O(log log (nN) + 1/&epsiv;) time. Our scheme can be extended to find and route along correspondingly short dipaths.
FOCS	Sequential and Parallel Algorithms for Mixed Packing and Covering.	Neal E. Young	2001	We describe sequential and parallel algorithms that approximately solve linear programs with no negative coefficients (a.k.a. mixed packing and covering problems).For explicitly given problems, our fastest sequential algorithm returns a solution satisfying all constraints within a 1 \pm \varepsilon factor in 0(md\log (m)/\varepsilon ^2 ) time, where m is the number of constraints and d is the maximum number of constraints any variable appears in.Our parallel algorithm runs in time polylogarithmic in the input size times \varepsilon ^4 and uses a total number of operations comparable to the sequential algorithm.The main contribution is that the algorithms solve mixed packing and covering problems (in contrast to pure packing or pure covering problems, which have only \leq or only \geq inequalities, but not both) and run in time independent of the so-called width of the problem.
FOCS	42nd Annual Symposium on Foundations of Computer Science, FOCS 2001, 14-17 October 2001, Las Vegas, Nevada, USA		2001	42nd Annual Symposium on Foundations of Computer Science, FOCS 2001, 14-17 October 2001, Las Vegas, Nevada, USA
SODA	Compact labeling schemes for ancestor queries.	Serge Abiteboul,Haim Kaplan,Tova Milo	2001	We consider the following problem. Give a rooted tree T, label the nodes of T in the most compact way such that given the labels of two nodes one can determine in constant time, by looking only at the labels, if one node is an ancestor of the other. The best known labeling scheme is rather straightforward and uses labels of size at most 2 log n, where n is the number of vertices In the tree. Our main result in this paper is a labeling scheme with maximum label size close to 3/2 log n. Our motivation for studying this problem is enhancing the performance of Web search engines. In the context of this application each indexed document is a tree and the labels of all trees are maintained in main memory. Therefore even small improvements in the maximum label size are important. There are no lower bounds known for this problem except for an obvious lower bound of log n that follows from the fact that different vertices must have different labels. The question whether one can find even shorter labels remains an intriguing open question.
SODA	Improved fast integer sorting in linear space.	Yijie Han	2001	We present improved fast deterministic algorithm for integer sorting in linear space. Our algorithm sorts n integers in linear space in &Ogr;(n log log n log log log n) time. This improves the &Ogr;(n(log log n)3/2) time bound given in [6]. When the n integers in {0,1,&hellip;, m - 1} to be sorted satisfying log m &gne;(log n)2+&isin;, 0 < &isin; < 1, the time complexity for sorting can be further reduced to &Ogr;(n log log n). These results are obtained by applying signature sorting on our previous result[6].
SODA	The phase transition in 1-in-k SAT and NAE 3-SAT.	Dimitris Achlioptas,Arthur D. Chtcherba,Gabriel Istrate,Cristopher Moore	2001	The phase transition in 1-in-k SAT and NAE 3-SAT.
SODA	Constructing worst case instances for semidefinite programming based approximation algorithms.	Noga Alon,Benny Sudakov,Uri Zwick	2001	Semidefinite programming based approximation algorithms, such as the Goemans and Williamson approximation algorithm for the MAX CUT problem, are usually shown to have certain performance guarantees using local ratio techniques. Are the bounds obtained in this way tight? This problem was considered before by Karloff and by Alon and Sudakov. Here we further extend their results and show, for the first time, that the local analyses of the Goemans and Williamson MAX CUT algorithm, as well as its extension by Zwick, are tight for every possible relative size of the maximum cut. We also obtain similar results for several related problems. Our approach is quite general and could possibly be applied to some additional problems and algorithms.
SODA	A cell probe lower bound for dynamic nearest-neighbor searching.	Stephen Alstrup,Thore Husfeldt,Theis Rauhe	2001	A cell probe lower bound for dynamic nearest-neighbor searching.
SODA	An efficient algorithm for the configuration problem of dominance graphs.	Ernst Althaus,Denys Duchier,Alexander Koller,Kurt Mehlhorn,Joachim Niehren,Sven Thiel	2001	Dominance constraints are logical tree descriptions originating from automata theory that have multiple applications in computational linguistics. The satisfiability problem of dominance constraints is NP-complete. In most applications, however, only normal dominance constraints are used. The satisfiability problem of normal dominance constraints can be reduced in linear time to the configuration problem of dominance graphs, as shown recently. In this paper, we give a polynomial time algorithm testing configurability of dominance graphs (and thus satisfiability of normal dominance constraints). Previous to our work no polynomial time algorithms were known.
SODA	Maintaining approximate extent measures of moving points.	Pankaj K. Agarwal,Sariel Har-Peled	2001	We present approximation algorithms for maintaining various descriptors of the extent of moving points in Rd. We first describe a data structure for maintaining the smallest orthogonal rectangle containing the point set. We then use this data structure to maintain the approximate diameter, smallest enclosing disk, width, and smallest area or perimeter bounding rectangle of a set of moving points in R2 so that the number of events is only a constant. This contrasts with &OHgr;(n2) events that data structures for the maintenance of those exact properties have to handle.
SODA	Overlap matching.	Amihood Amir,Richard Cole,Ramesh Hariharan,Moshe Lewenstein,Ely Porat	2001	We propose a new paradigm for string matching, namely structural matching. In structural matching, the text and pattern contents are not important. Rather, some areas in the text and patterns are singled out, say intervals. A &ldquo;match&rdquo; is a text location where a specified relation between the text and pattern areas is satisfied. In particular we define the structural matching problem of Overlap (Parity) Matching. We seek the text locations where all overlaps of the given pattern and text intervals have even length. We show that this problem can be solved in time &Ogr;(n log m), where the text length is n and the pattern length is m. As an application of overlap matching, we show how to reduce the String Matching with Swaps problem to the overlap matching problem. The String Matching with Swaps problem is the problem of string matching in the presence of local swaps. The best known deterministic upper bound for this problem was &Ogr;(nm1/3 log m log &sgr;) for a general alphabet &sum;, where &sgr; = min(m, &brvbar;&sum;&brvbar;). Our reduction provides a solution to the pattern matching with swaps problem in time &Ogr;(n log m log &sgr;).
SODA	"Approximate subset matching with Don't Cares."	Amihood Amir,Ely Porat,Moshe Lewenstein	2001	"Approximate subset matching with Don't Cares."
SODA	Random lifts of graphs.	Alon Amit,Nathan Linial,Jirí Matousek,Eyal Rozenman	2001	We describe here a simple probabilistic model for graphs that are lifts of a fixed base graph G, i.e., those graphs from which there is a covering man onto G. Our aim is to investigate the properties of typical graphs in this class. In particular, we show that almost every lift of G is &dgr;(G)-connected where &dgr;(G) is the minimal degree of G. We calculate the typical edge expansion of lifts of the bouquet Bd and
SODA	The inverse nearest neighbor problem with astrophysical applications.	Richard J. Anderson,Brian Tjaden	2001	This paper discusses algorithmic improvements to mature astrophysics applications as part of an on-going collaboration with Astrophysicists. We present an efficient algorithm for a variation of the Inverse Nearest Neighbor problem which is a basic computation in an astrophysical N-body simulation. We obtain empirical results demonstrating the improvements, which our algorithm offers to large-scale astrophysical simulations.
SODA	Dynamic string searching.	Arne Andersson,Mikkel Thorup	2001	Optimal bounds are presented for dynamic string searching. If the longest common prefix between a query key x and a currently stored string y is &ell; words, then finding the stored string lexicographically nearest to x takes optimal &THgr;(&radic;log n/log log n + &ell;) time. Similarly, we can insert and delete strings from the stored set within this time bound. The space requirements is linear and the time bounds are worst-case.
SODA	Optimal covering tours with turn costs.	Esther M. Arkin,Michael A. Bender,Erik D. Demaine,Sándor P. Fekete,Joseph S. B. Mitchell,Saurabh Sethia	2001	"We give the first algorithmic study of a class of ""covering tour"" problems related to the geometric traveling salesman problem: Find a polygonal tour for a cutter so that it sweeps out a specified region (""pocket"") in order to minimize a cost that depends mainly on the number of turns. These problems arise naturally in manufacturing applications of computational geometry to automatic tool path generation and automatic inspection systems, as well as arc routing (""postman"") problems with turn penalties. We prove the NP-completeness of minimum-turn milling and give efficient approximation algorithms for several natural versions of the problem, including a polynomial-time approximation scheme based on a novel adaptation of the $m$-guillotine method."
SODA	Entropy-preserving cuttings and space-efficient planar point location.	Sunil Arya,Theocharis Malamatos,David M. Mount	2001	Point location is the problem of preprocessing a planar polygonal subdivision S into a data structure in order to determine efficiently the cell of the subdivision that contains a given query point. Given the probabilities pz that the query point lies within each cell z &isin; S, a natural question is how to design such a structure so as to minimize the expected-case query time. The entropy H of the probability distribution is the dominant term in the lower bound on the expected-case search time. Clearly the number of edges n of the subdivision is a lower bound on the space required. There is no known approach that simultaneously achieves the goals of H + &Ogr;(H) query time and &Ogr;(n) space. In this paper we introduce entropy-preserving cuttings and show how to use them to achieve query time H + &Ogr;(H), using only &Ogr;(n log* n) space.
SODA	A simple entropy-based algorithm for planar point location.	Sunil Arya,Theocharis Malamatos,David M. Mount	2001	Given a planar polygonal subdivision S, point location involves preprocessing this subdivision into a data structure so that given any query point q, the cell of the subdivision containing q can be determined efficiently. Suppose that for each cell z in the subdivision, the probability pz that a query point lies within this cell is also given. The goal is to design the data structure to minimize the average search time. This problem has been considered before, but existing data structures are all quite complicated. It has long been known that the entropy H of the probability distribution is the dominant term in the lower bound on the average-case search time. In this article, we show that a very simple modification of a well-known randomized incremental algorithm can be applied to produce a data structure of expected linear size that can answer point-location queries in O(H) average time. We also present empirical evidence for the practical efficiency of this approach.
SODA	Towards understanding the predictability of stock markets from the perspective of computational complexity.	James Aspnes,David F. Fischer,Michael J. Fischer,Ming-Yang Kao,Alok Kumar	2001	This paper initiates a study into the century-old issue of market predictability from the perspective of computational complexity. We develop a simple agent-based model for a stock market where the agents are traders equipped with simple trading strategies, and their trades together determine the stock prices. Computer simulations show that a basic case of this model is already capable of generating price graphs which are visually similar to the recent price movements of high tech stocks. In the general model, we prove that if there are a large number of traders but they employ a relatively small number of strategies, then there is a polynomial-time algorithm for predicting future price movements with high accuracy. On the other hand, if the number of strategies is large, market prediction becomes complete in two new computational complexity classes CPP and BCPP, where PNP[&Ogr;(log n)] e BCPP e CPP = PP. These computational completeness results open up a novel possibility that the price graph of a actual stock could be sufficiently deterministic for various prediction goals but appear random to all polynomial-time prediction algorithms.
SODA	Approximation algorithms for data placement in arbitrary networks.	Ivan D. Baev,Rajmohan Rajaraman	2001	We study approximation algorithms for placing replicated data in arbitrary networks. Consider a network of nodes with individual storage capacities and a metric communication cost function, in which each node periodically issues a request for an object drawn from a collection of uniform-length objects. We consider the problem of placing copies of the objects among the nodes such that the average access cost is minimized. Our main result is a polynomial-time constant-factor approximation algorithm for this placement problem. Our algorithm is based on a careful rounding of a linear programming relaxation of the problem. We also show that the data placement problem is MAXSNP-hard. We extend our approximation result to a generalization of the data placement problem that models additional costs such as the cost of realizing the placement. We also show that when object lengths are non-uniform, a constant-factor approximation is achievable if the capacity at each node in the approximate solution is allowed to exceed that in the optimal solution by the length of the largest object.
SODA	Competitive on-line stream merging algorithms for media-on-demand.	Amotz Bar-Noy,Richard E. Ladner	2001	We consider the problem of minimizing the bandwidth needed by media-on-demand servers that use stream merging. We consider the on-line case where client requests are not known ahead of time. To facilitate stream merging, clients have the ability to receive data from two streams simultaneously and can buffer up to half of a full stream. We present a new family of on-line stream merging algorithms called dynamic tree algorithms. The bandwidth requirements of the best of these, the dynamic Fibonacci tree algorithms, are within a factor of the minimum between logφ(n) + O(1) and logφ(1/(2D)) + O(1) from the off-line optimal, where n is the number of requests, D is the guaranteed maximum start-up delay measured as a fraction of the time for a full stream, and φ = (1 + √5)/2. The new on-line algorithms use a dynamic Fibonacci tree to control how new arrivals should merge with existing streams. Empirical studies show that the dynamic Fibonacci tree algorithms perform much better than indicated by the analysis.
SODA	On the discrete Bak-Sneppen model of self-organized criticality.	Jérémy Barbay,Claire Kenyon	2001	We propose a discrete variant of the Bak-Sneppen model for self-organized criticality. In this process, a configuration is an n-bit word, and at each step one chooses a random bit of minimum value (usually a zero) and replaces it and its two neighbors by independent Bernoulli variables with parameter p. We prove bounds on the average number of ones in the stationary distribution and present experimental results.
SODA	Finding least common ancestors in directed acyclic graphs.	Michael A. Bender,Giridhar Pemmasani,Steven Skiena,Pavel Sumazin	2001	Finding least common ancestors in directed acyclic graphs.
SODA	Improved approximation algorithms for rectangle tiling and packing.	Piotr Berman,Bhaskar DasGupta,S. Muthukrishnan,Suneeta Ramaswami	2001	We provide improved approximation algorithms for several rectangle tiling and packing problems (RTILE, DRTILE and d-RPACK) studied in the literature. Our algorithms are highly efficient since their running times are near-linear in the space input size rather than in the domain size. In addition, we improve the best known approximation ratios, in some cases quite significantly.
SODA	Computing the depth of a flat.	Marshall W. Bern	2001	We compute the regression depth of a k-flat in a set of n points in Rd, in time &Ogr;(nd-2 + n log n) for 1 &lne; k &lne; d - 2. This contrasts with a bound of &Ogr;(nd-1 + n log n) when k = 0 or k = d - 1.
SODA	Linear reductions of maximum matching.	Therese C. Biedl	2001	Linear reductions of maximum matching.
SODA	Stability preserving transformations: packet routing networks with edge capacities and speeds.	Allan Borodin,Rafail Ostrovsky,Yuval Rabani	2001	In the context of an adversarial input model, we consider the effect on stability results when edges in packet routing networks can have capacities and speeds/slowdowns. In traditional packet routing networks, every edge is considered to have the same unit capacity and unit speed. We consider both static modifications (i.e. where the capacity or speed of an edge is fixed) and dynamic modifications where either the capacity or the speed of an edge can be dynamically changing over time. Amongst our results, we show that the universal stability of LIS is not preserved when either the capacity or the speed is changing dynamically whereas many other common scheduling protocols do maintain their universal stability. In terms of universal stability of networks, stability is preserved for dynamically changing capacities and speeds. The situation for static modifications, is not as clear but we are able to show that (in contrast to the dynamic case) that any &ldquo;well defined&rdquo; universally stable scheduling rule maintains its universality under static capacities, and common scheduling rules also maintain their universal stability under static speeds.
SODA	IMproved results for route planning in stochastic transportation.	Justin A. Boyan,Michael Mitzenmacher	2001	In the bus network problem, the goal is to generate a plan for getting from point X to point Y within a city using buses in the smallest expected time. Because bus arrival times are not determined by a fixed schedule but instead may be random, the problem requires more than standard shortest path techniques. In recent work, Datar and Ranade provide algorithms in the case where bus arrivals are assumed to be independent and exponentially distributed. We offer solutions to two important generalizations of the problem, answering open questions posed by Datar and Ranade. First, we provide a polynomial time algorithm for a much wider class of arrival distributions, namely those with increasing failure rate. This class includes not only exponential distributions but also uniform, normal, and gamma distributions. Second, in the case where bus arrival times are independent and geometric discrete random variables, we provide an algorithm for transportation networks of buses and trains, where trains run according to a fixed schedule.
SODA	On-line restricted caching.	Mark Brehob,Richard J. Enbody,Eric Torng,Stephen Wagner	2001	We study the on-line caching problem in a restricted cache where each memory item can be placed in only a restricted subset of cache locations. Examples of restricted caches in practice include victim caches, assist caches, and skew caches. To the best of our knowledge, all previous on-line caching studies have considered on-line caching in identical or fully-associative caches where every memory item can be placed in any cache location. In this paper, we focus on companion caches, a simple restricted cache that includes victim caches and assist caches as special cases. Our results show that restricted caches are significantly more complex than identical caches. For example, we show that the commonly studied Least Recently Used (LRU) algorithm is not competitive unless cache reorganization is allowed while the performance of the First In First Out (FIFO) algorithm is competitive but not optimal. We then present two near optimal algorithms for this problem as well as some lower bound arguments.
SODA	Worst case constant time priority queue.	Andrej Brodnik,Svante Carlsson,Johan Karlsson,J. Ian Munro	2001	We present a new data structure of size 3M + &Ogr;(M) bits for solving the &ldquo;discrete priority queue&rdquo; problem. When this data structure is used in combination with a new memory topology it provides an O(1) worst case time solution. In doing so we demonstrate how an unconventional, but practically implementable, memory architecture can be employed to sidestep a lower bound (of lg lg M) and achieve constant time performance.
SODA	A probabilistic analysis of a greedy algorithm arising from computational biology.	Daniel G. Brown	2001	A probabilistic analysis of a greedy algorithm arising from computational biology.
SODA	Approximation algorithms for the 0-extension problem.	Gruia Calinescu,Howard J. Karloff,Yuval Rabani	2001	"In the 0-extension problem, we are given a weighted graph with some nodes marked as terminals and a semi-metric on the set of terminals. Our goal is to assign the rest of the nodes to terminals so as to minimize the sum, over all edges, of the product of the edge's weight and the distance between the terminals to which its endpoints are assigned. This problem generalizes the multiway cut problem of Dahlhaus, Johnson, Papadimitriou, Seymour, and Yannakakis and is closely related to the metric labeling problem introduced by Kleinberg and Tardos. We present approximation algorithms for O-EXTENSION. In arbitrary graphs, we present an &Ogr;(log k)-approximation algorithm, k being the number of terminals. We also give &Ogr;(1)-approximation guarantees for weighted planar graphs. Our results are based on a natural metric relaxation of the problem, previously considered by Karzanov. It is similar in flavor to the linear programming relaxation of Garg, Vazirani, and Yannakakis for the multicut problem and similar to relaxations for other graph partitioning problems. We prove that the integrality ratio of the metric relaxation is at least c&radic;lgk for a positive c for infinitely many k. Our results improve some of the results of Kleinberg and Tardos and they further our understanding on how to use metric relaxations."
SODA	Hill-climbing finds random planted bisections.	Ted Carson,Russell Impagliazzo	2001	We analyze the behavior of hill-climbing algorithms for the minimum bisection problem on instances drawn from the &ldquo;planted bisection&rdquo; random graph model, Gn,p,q, previously studied in [3, 4, 10, 11, 14, 9, 7]. This is one of the few problem distributions for which various popular heuristic methods, such as simulated annealing, have been proven to succeed. However, it has been open whether these sophisticated methods were necessary, or whether simpler heuristics would also work. Juels [14] made the first progress towards an answer by showing that simple hill-climbing does suffice for very wide separations between p and q. Here we give a more complete answer. A simple, polynomial-time, hill-climbing algorithm for this problem is given and shown to succeed in finding the planted bisection with high probability if p - q = &OHgr; (n-&frac12;ln3n). For dense graphs, this matches the condition for optimality of the planted bisection to within a polylogarithmic factor. Furthermore, we show that a generic randomized hill-climbing algorithm succeeds in finding the planted bisection in polynomial time if p - q = &OHgr; (n-&frac14; ln3 n), for any &isin; > 0. This algorithm, studied also by [14], is a degenerate case of both Metropolis and go-with-the-winners, and the range here properly includes those analyzed in [11, 9, 14]. So this result implies, extends, and unifies those from [11, 9, 14]. Thus, to get a provable distinction between simulated annealing and hill-climbing for natural problems will require considerable progress both on new positive results for SA and new negative results for hill-climbing methods.
SODA	Algorithms for facility location problems with outliers.	Moses Charikar,Samir Khuller,David M. Mount,Giri Narasimhan	2001	Facility location problems are traditionally investigated with the assumption that all the clients are to be provided service. A significant shortcoming of this formulation is that a few very distant clients, called outliers, can exert a disproportionately strong influence over the final solution. In this paper we explore a generalization of various facility location problems (K-center, K-median, uncapacitated facility location etc) to the case when only a specified fraction of the customers are to be served. What makes the problems harder is that we have to also select the subset that should get service. We provide generalizations of various approximation algorithms to deal with this added constraint.
SODA	Generating well-shaped Delaunay meshed in 3D.	Xiang-Yang Li,Shang-Hua Teng	2001	A triangular mesh in 3D is a decomposition of a given geometric domain into tetrahedra. The mesh is well-shaped if the aspect ratio of every of its tetrahedra is bounded from above by a constant. It is Delaunay if the interior of the circum-sphere of each of its tetrahedra does not contain any other mesh vertices. Generating a well-shaped Delaunay mesh for any 3D domain has been a long term outstanding problem. In this paper, we present an efficient 3D Delaunay meshing algorithm that mathematically guarantees the well-shape quality of the mesh, if the domain does not have acute angles. The main ingredient of our algorithm is a novel refinement technique which systematically forbids the formation of shivers, a family of bad elements that none of the previous known algorithms can cleanly remove, especially near the domain boundary &mdash; needless to say, that our algorithm ensure that there is no sliver near the boundary of the domain.
SODA	A deterministic algorithm for the cost-distance problem.	Chandra Chekuri,Sanjeev Khanna,Joseph Naor	2001	A deterministic algorithm for the cost-distance problem.
SODA	Approximation algorithms for the metric labeling problem via a new linear programming formulation.	Chandra Chekuri,Sanjeev Khanna,Joseph Naor,Leonid Zosin	2001	We consider approximation algorithms for the metric labeling problem. This problem was introduced in a recent paper by Kleinberg and Tardos [20], and captures many classification problems that arise in computer vision and related fields. They gave an &Ogr;(log k log log k) approximation for the general case where k is the number of labels and a 2-approximation for the uniform metric case. More recently, Gupta and Tardos [15] gave a 4-approximation for the truncated linear metric, a natural non-uniform metric motivated by practical applications to image restoration and visual correspondence. In this paper we introduce a natural integer programming formulation and show that the integrality gap of its linear relaxation either matches or improves the ratios known for several cases of the metric labeling problem studied until now, providing a unified approach to solving them. In particular, we show that the integrality gap of our LP is bounded by &Ogr;(log k log log k) for general metric and 2 for the uniform metric thus matching the ratios in [20]. We also develop an algorithm based on our LP that achieves a ratio of 2 + &radic;2 &sime; 3.414 for the truncated linear metric improving the ratio given in [15]. Our algorithm uses the fact that the integrality gap of our LP is 1 on a linear metric. We believe that our formulation has the potential to provide improved approximation algorithms for the general case and other useful special cases. Finally, our formulation admits general non-metric distance functions. This leads to a non-trivial approximation guarantee for a non-metric case that arises in practice [21], namely the truncated quadratic distance function. We note here that there are non-metric distance functions for which no bounded approximation ratio is achievable.
SODA	Polygonal path approximation with angle constraints.	Danny Z. Chen,Ovidiu Daescu,John Hershberger,Peter M. Kogge,Jack Snoeyink	2001	We present efficient geometric algorithms for several problems of approximating an n-vertex polygonal path with angle constraints in the d-D space for any fixed d &gne; 2, improving significantly the corresponding graph- theoretic solutions based on known techniques (e.g., by (nearly) a factor of n for d = 2, 3). As a key step in our solutions, we formulate and solve an interesting problem called off-line ball exclusion search (OLBES), that may be of interest on its own.
SODA	K-pair delay constrained minimum cost routing in undirected networks.	Guangting Chen,Guoliang Xue	2001	We study a problem related to QoS routing in an undirected network where each edge has a delay and a cost. Given a k-pair routing request {(si, ti, di)&brvbar;i = l,&hellip;,k} where si is ith source node, ti is ith destination node, and di, is the ith delay tolerance, we want to compute a minimum cost network which contains an si-ti path whose delay is at most di for every i. We present an FPTAS for this problem when k is a constant.
SODA	Dynamic skin triangulation.	Ho-Lun Cheng,Tamal K. Dey,Herbert Edelsbrunner,John Sullivan	2001	This paper describes an algorithm for maintaining an approximating triangulation of a deforming surface in R3. The triangulation adapts dynamically to changing shape, curvature, and topology of the surface.
SODA	Orderly spanning trees with applications to graph encoding and graph drawing.	Yi-Ting Chiang,Ching-Chi Lin,Hsueh-I Lu	2001	The canonical ordering for triconnected planar graphs is a powerful method for designing graph algorithms. This paper introduces the orderly pair of connected planar graphs, which extends the concept of canonical ordering to planar graphs not required to be triconnected. Let G be a connected planar graph. We give a linear-time algorithm that obtains an orderly pair (H,T) of G, where H is a planar embedding of G, and T is an orderly spanning tree of H. As applications, we show that the technique of orderly spanning trees yields (i) the best known encoding of G with query support, and (ii) the first area-optimal 2-visibility drawing of G.
SODA	Approximation for minimum triangulation of convex polyhedra.	Francis Y. L. Chin,Stanley P. Y. Fung,Cao An Wang	2001	The minimum triangulation of a convex polyhedron is a triangulation that contains the minimum number of tetrahedra over all its possible triangulations. Since finding the minimum triangulation of convex polyhedra was recently shown to be NP-hard, it becomes significant to find algorithms that give good approximation. In this paper, we give a new triangulation algorithm with an improved approximation ratio 2 - &OHgr;(1/&radic;n). We also show that this is best possible for algorithms that only consider the combinatorial structure of the polyhedra.
SODA	Which formulae shrink under random restrictions?	Hana Chockler,Uri Zwick	2001	We show that the shrinkage exponent, under random restrictions, of formulae over a finite complete basis B of Boolean functions is strictly greater than 1 if and only if all the functions in B are monotone increasing or monotone decreasing in each one of their variables. As a consequence, we get non-linear lower bounds on the formula complexity of the parity function over any basis composed only of monotone increasing or decreasing functions.
SODA	Guessing secrets.	Fan R. K. Chung,Ronald L. Graham,Frank Thomson Leighton	2001	Guessing secrets.
SODA	Selective families, superimposed codes, and broadcasting on unknown radio networks.	Andrea E. F. Clementi,Angelo Monti,Riccardo Silvestri	2001	Selective families, a weaker variant of superimposed codes [KS64, F92, 197, CR96], have been recently used to design Deterministic Distributed Broadcast (DDB) protocols for unknown radio networks (a radio network is said to be unknown when the nodes know nothing about the network but their own label) [CGGPR00, CGOR00]. We first provide a general almost tight lower bound on the size of selective families. Then, by reverting the selective families - DDB protocols connection, we exploit our lower bound to construct a family of &ldquo;hard&rdquo; radio networks (i.e. directed graphs). These networks yield an &OHgr;(n log D) lower bound on the completion time of DDB protocols that is superlinear (in the size n of the network) even for very small maximum eccentricity D of the network, while all the previous lower bounds (e.g. &OHgr;(D log n) [CGGPR00]) are superlinear only when D is almost linear. On the other hand, the previous upper bounds are all superlinear in n independently of the eccentricity D and the maximum in-degree d of the network. We introduce a broadcast technique that exploits selective families in a new way. Then, by combining selective families of almost optimal size with our new broadcast technique, we obtain an &Ogr;(Dd log3 n) upper bound that we prove to be almost optimal when d = &Ogr;(n/D). This exponentially improves over the best known upper bound [CGR00) when D, d = &Ogr;(polylogn). Furthermore, by comparing our deterministic upper bound with the best known randomized one [BGI87] we obtain a new, rather surprising insight into the real gap between deterministic and randomized protocols. It turns out that this gap is exponential (as discovered in [BGI87]), but only when the network has large maximum in-degree (i.e. d = &OHgr;(na), for some constant a > O). We then look at the multibroadcast problem on unknown radio networks. A similar connection to that between selective families and (single) broadcast also holds between superimposed codes and multibroadcast. We in fact combine a variant of our (single) broadcast technique with superimposed codes of almost optimal size available in literature [EFF85, HS87, I97, CHI99]. This yields a multibroadcast protocol having completion time &Ogr;(Dd2 log3 n). Finally, in order to determine the limits of our multibroadcast technique, we generalize (and improve) the best known lower bound [CR96] on the size of superimposed codes.
SODA	Approximation algorithms for extensible bin packing.	Edward G. Coffman Jr.,George S. Lueker	2001	In a variation of bin packing called extensible bin packing, the number of bins is specified as part of the input, and bins may be extended to hold more than the usual unit capacity. The cost of a bin is 1 if it is not extended, and the size if it is extended. The goal is to pack a set of items of given sizes into the specified number of bins so as to minimize the total cost. Adapting ideas Grötschel et al. (1981), Grötschel et al. (1988), Karmarkar and Karp (1982), Murgolo (1987), we give a fully polynomial time asymptotic approximation scheme (FPTAAS) for extensible bin packing. We close with comments on the complexity of obtaining stronger results.
SODA	A faster implementation of the Goemans-Williamson clustering algorithm.	Richard Cole,Ramesh Hariharan,Moshe Lewenstein,Ely Porat	2001	We give an implementation of the Goemans-Williamson clustering procedure which is at the core of several approximation algorithms including those for Generalized Steiner Trees, Prize Collecting Travelling Salesman, 2-Edge Connected Subgraph etc. On a graph with n nodes and m edge, our implementation gives &Ogr; (k(n + m) log2 n) time approximation algorithms for all these problems at the expense of a slight additive degradation of 1/nk in the approximation factor, for any constant k.
SODA	Better approximation algorithms for bin covering.	János Csirik,David S. Johnson,Claire Kenyon	2001	Bin covering takes as input a list of items with sizes in (0, 1) and places them into bins of unit demand so as to maximize the number of bins whose demand is satisfied. This is in a sense a dual problem to the classical one-dimensional bin packing problem, but has for many years lagged behind the latter in terms of the quality of the best approximation algorithms. We design algorithms for this problem that close the gap, both in terms of worst- and average-case results. We present (1) the first asymptotic approximation scheme for the offline version, (2) algorithms that have bounded worst-case behavior for instances with discrete item sizes and expected behavior that is asymptotically optimal for all discrete &ldquo;perfect-packing distributions&rdquo; (ones for which optimal packings have sublinear expected waste), and (3) a learning algorithm that has asymptotically optimal expected behavior for all discrete distributions. The algorithms of (2) and (3) are based on the recently-developed online Sum-of-Squares algorithm for bin packing. We also present experimental analysis comparing the algorithms of (2) and suggesting that one of them, the Sum-of-Squares-with-Threshold algorithm, performs quite well even for discrete distributions that do not have the perfect-packing property.
SODA	Soft kinetic data structures.	Artur Czumaj,Christian Sohler	2001	We introduce the framework of soft kinetic data structures (SKDS). A soft kinetic data structure is an approximate data structure that can be used to answer queries on a set of moving objects with unpredictable motion. We analyze the quality of a soft kinetic data structure by giving a competitive analysis with respect to the dynamics of the system. We illustrate our approach by presenting soft kinetic data structures for maintaining classical data structures: sorted arrays, balanced search trees, heaps, and range trees. We also describe soft kinetic data structures for maintaining the Euclidean minimum spanning trees.
SODA	Computing optimal alpha-fat and alpha-small decompositions.	Mirela Damian-Iordache,Sriram V. Pemmaraju	2001	Computing optimal alpha-fat and alpha-small decompositions.
SODA	A linear lower bound on index size for text retrieval.	Erik D. Demaine,Alejandro López-Ortiz	2001	"Most information-retrieval systems preprocess the data to produce an auxiliary index structure. Empirically, it has been observed that there is a tradeoff between query response time and the size of the index. When indexing a large corpus, such as the web, the size of the index is an important consideration. In this case it would be ideal to produce an index that is substantially smaller than the text. In this work we prove a linear worst-case lower bound on the size of any index that reports the location (if any) of a substring in the text in time proportional to the length of the pattern. In other words, an index supporting linear-time substring searches requires about as much space as the original text. Here ""time"" is measured in the number of bit probes to the text; an arbitrary amount of computation may be done on an arbitrary amount of the index. Our lower bound applies to inverted word indices as well."
SODA	On universally easy classes for NP-complete problems.	Erik D. Demaine,Alejandro López-Ortiz,J. Ian Munro	2001	We explore the natural question of whether all NP-complete problems have a common restriction under which they are polynomially solvable. More precisely, we study what languages are universally easy in that their intersection with any NP-complete problem is in P. In particular, we give a polynomial-time algorithm to determine whether a regular language is universally easy. While our approach is language-theoretic, the results bear directly on finding polynomial-time solutions to very broad and useful classes of problems.
SODA	Universal configurations in light-flipping games.	Yevgeniy Dodis,Peter Winkler	2001	Universal configurations in light-flipping games.
SODA	Lattice approximation and linear discrepency of totally unimodular matrices.	Benjamin Doerr	2001	"This paper shows that the lattice approximation problem for totally unimodular matrices A &isin; Rm&times;n can be solved efficiently and optimally via a linear programming approach. The complexity of our algorithm is &Ogr;(log m) times the complexity of finding an extremal point of a polytope in Rn described by 2(m + n) linear constraints. We also consider the worst-case approximability. This quantity is usually called linear discrepancy lindisc(A). For any totally unimodular m &times; n matrix A we show lindisc(A) &le; min{1 - 1/n+1, 1 - 1/m}. This bound is sharp. It proves Spencer's conjecture lindisc(A) &le; (1 - 1/n+1) herdisc(A) for totally unimodular matrices. This seems to be the first time that linear programming is successfully used for a discrepancy problem."
SODA	On validating planar worlds.	Vida Dujmovic,Sue Whitesides	2001	We present an optimal linear time algorithm for solving a map validation problem: a robot equipped with one portable marker must determine the correctness of a given map of its graph-like world, modelled as a possibly non-planar embedding of a planar graph.
SODA	Approximation algorithms for TSP with neighborhoods in the plane.	Adrian Dumitrescu,Joseph S. B. Mitchell	2001	In the Euclidean TSP with neighborhoods (TSPN), we are given a collection of n regions (neighborhoods) and we seek a shortest tour that visits each region. As a generalization of the classical Euclidean TSP, TSPN is also NP-hard. In this paper, we present new approximation results for the TSPN, including (1) a constant-factor approximation algorithm for the case of arbitrary connected neighborhoods having comparable diameters; and (2) a PTAS for the important special case of disjoint unit disk neighborhoods (or nearly disjoint, nearly-unit disks). Our methods also yield improved approximation ratios for various special classes of neighborhoods, which have previously been studied. Further, we give a linear-time O(1)-approximation algorithm for the case of neighborhoods that are (infinite) straight lines.
SODA	Optimal constrained graph exploration.	Christian A. Duncan,Stephen G. Kobourov,V. S. Anil Kumar	2001	We address the problem of exploring an unknown graph G = (V, E) from a given start node s with either a tethered robot or a robot with a fuel tank of limited capacity, the former being a tighter constraint. In both variations of the problem, the robot can only move along the edges of the graph, i.e, it cannot jump between non-adjacent vertices. In the tethered robot case, if the tether (rope) has length l, then the robot must remain within distance l from the start node s. In the second variation, a fuel tank of limited capacity forces the robot to return to s after traversing C edges. The efficiency of algorithms for both variations of the problem is measured by the number of edges traversed during the exploration. We present an algorithm for a tethered robot which explores the graph in &Ogr;(&brvbar;E&brvbar;) edge traversals. The problem of exploration using a robot with a limited fuel tank capacity can be solved with a simple reduction from the tethered robot case and also yields a &Ogr;(&brvbar;E&brvbar;) algorithm. This improves on the previous best known bound of &Ogr;(&brvbar;E&brvbar; + &brvbar;V&brvbar;log 2&brvbar;V&brvbar;) in [4]. Since the lower bound for the graph exploration problems is &brvbar;E&brvbar;, our algorithm is optimal, thus answering the open problem of Awerbuch, Betke, Rivest, and Singh [3].
SODA	Morphing between polylines.	Alon Efrat,Sariel Har-Peled,Leonidas J. Guibas,T. M. Murali	2001	Given two non-intersecting simple polylines in the plane, we study the problem of continuously transforming or morphing one polyline into the other. Our morphing strategies have the desirable property that every intermediate polyline is also simple. We also guarantee that no portion of the polylines to be morphed is stretched or compressed by more than a user-defined parameter during the entire morphing. Our algorithms are based on the morphing width, a new metric we have developed for measuring the similarity between two polylines. We develop an algorithm that computes the morphing width of the two polylines and constructs a corresponding morphing strategy in &Ogr;(n2 log2 n) time using &Ogr;(n2) space, where n is the total number of vertices in the polylines. We describe another algorithm that computes a factor-2 approximation of the morphing width and a corresponding morphing scheme in &Ogr;(n log n) time.
SODA	Pattern matching for sets of segments.	Alon Efrat,Piotr Indyk,Suresh Venkatasubramanian	2001	In this paper we present algorithms for a number of problems in geometric pattern matching where the input consist of a collections of segments in the plain. Our work consists of two main parts. In the first, we address problems and measures that relate to collections of orthogonal line segments in the plane. Such collections arise naturally from problems in mapping buildings and robot exploration. We propose a new measure of segment similarity called a coverage measure, and present efficient algorithms for maximising this measure between sets of axis-parallel segments under translations. Our algorithms run in time &Ogr;(n3polylogn) in the general case, and run in time &Ogr;(n3polylogn) for the case when all segments are horizontal. In addition, we show that when restricted to translations that are only vertical, the Hausdorff distance between two sets of horizontal segments can be computed in time roughly &Ogr;(n3/2polylog n). These algorithms are significant improvements over the general algorithm of Chew et al. that takes time &Ogr;(n4 log2 n). In the second part of this paper we address the problem of matching polygonal chains. We study the well known Fr&eacute;chet distance, and present the first algorithm for computing the Fr&eacute;chet distance under general translations. Our methods also yield algorithms for computing a generalization of the Fr&eacute;chet distance, and we present a simple approximation algorithm for the Fr&eacute;chet distance and its generalization that runs in time &Ogr;(n2polylogn).
SODA	Parallel processor scheduling with delay constraints.	Daniel W. Engels,Jon Feldman,David R. Karger,Matthias Ruhl	2001	We consider the problem of scheduling unit-length jobs on identical parallel machines such that the makespan of the resulting schedule is minimized. Precedence constraints impose a partial order on the jobs, and both communication and precedence delays impose relative timing constraints on dependent jobs. The combination of these two types of timing constraints naturally models the instruction scheduling problem that occurs during software compilation for state-of-the-art VLIW (Very Long Instruction Word) processors and multiprocessor parallel machines. We present the first known polynomial-time algorithm for the case where the precedence constraint graph is a forest of in-trees (or a forest of out-trees), the number of machines m is fixed, and the delays (which are a function of both the job pair and the machines on which they run) are bounded by a constant D. Our algorithm relies on a new structural theorem for scheduling jobs with arbitrary precedence constraints. Given an instance with many independent dags, the theorem shows how to convert, in linear time, a schedule S for only the largest dags into a complete schedule that is either optimal or has the same makespan as S.
SODA	Improved algorithms for 3-coloring, 3-edge-coloring, and constraint satisfaction.	David Eppstein	2001	We consider worst case time bounds for NP-complete problems including 3-SAT, 3-coloring, 3-edge-coloring, and 3-list-coloring. Our algorithms are based on a constraint satisfaction (CSP) formulation of these problems; 3-SAT is equivalent to (2, 3)-CSP while the other problems above are special cases of (3, 2)-CSP. We give a fast algorithm for (3, 2)-CSP and use it to improve the time bounds for solving the other problems listed above. Our techniques involve a mixture of Davis-Putnam-style backtracking with more sophisticated matching and network flow based ideas.
SODA	Internet packet filter management and rectangle geometry.	David Eppstein,S. Muthukrishnan	2001	We consider rule sets for internet packet routing and filtering, where each rule consists of a range of source addresses, a range of destination addresses, a priority, and an action. A given packet should be handled by the action from the maximum priority rule that matches its source and destination. We describe new data structures for quickly finding the rule matching an incoming packet, in near-linear space, and a new algorithm for determining whether a rule set contains any conflicts, in time &Ogr;(n3/2).
SODA	Fast approximation of centrality.	David Eppstein,Joseph Wang	2001	Social studies researchers use graphs to model group activities in social networks. An important property in this context is the centrality of a vertex: the inverse of the average distance to each other vertex. We describe a randomized approximation algorithm for centrality in weighted graphs. For graphs exhibiting the small world phenomenon, our method estimates the centrality of all vertices with high probability within a (1 + &isin;) factor in near-linear time.
SODA	Polynomial-time approximation schemes for geometric graphs.	Thomas Erlebach,Klaus Jansen,Eike Seidel	2001	A disk graph is the intersection graph of a set of disks with arbitrary diameters in the plane. For the case that the disk representation is given, we present polynomial-time approximation schemes (PTASs) for the maximum weight independent set problem (selecting disjoint disks of maximum total weight) and for the minimum weight vertex cover problem in disk graphs. These are the first known PTASs for NP-hard optimization problems on disk graphs. They are based on a novel recursive subdivision of the plane that allows applying a shifting strategy on different levels simultaneously, so that a dynamic programming approach becomes feasible. The PTASs for disk graphs represent a common generalization of previous results for planar graphs and unit disk graphs. They can be extended to intersection graphs of other &ldquo;disk-like&rdquo; geometric objects (such as squares or regular polygons), also in higher dimensions.
SODA	An experimental study of an opportunistic index.	Paolo Ferragina,Giovanni Manzini	2001	The size of electronic data is currently growing at a faster rate than computer memory and disk storage capacities. For this reason compression appears always as an attractive choice, if not mandatory. However space overhead is not the only resource to be optimized when managing large data collections; in fact data turn out to be useful only when properly indexed to support search operations that efficiently extract the user-requested information. Approaches to combine compression and indexing techniques are nowadays receiving more and more attention. A first step towards the design of a compressed full-text index achieving guaranteed performance in the worst case has been recently done in [10]. This index combines the compression algorithm proposed by Burrows and Wheeler [5] with the suffix array data structure [16]. The index is opportunistic in that it takes advantage of the compressibility of the input data by decreasing the space occupancy at no significant asymptotic slowdown in the query performance. In this paper we present an implementation of this index and perform an extensive set of experiments on various text collections. The experiments show that our index is compact (its space occupancy is close to the one achieved by the best known compressors), it is fast in counting the number of pattern occurrences, and the cost of their retrieval is reasonable when they are few (i.e., in case of a selective query). In addition, our experiments show that the FM-index is flexible in that it is possible to trade space occupancy for search time by choosing the amount of auxiliary information stored into it.
SODA	Making data structures confluently persistent.	Amos Fiat,Haim Kaplan	2001	We address a longstanding open problem of [J.R. Driscoll, N. Sarnak, D. Sleator, R. Tarjan, J. Comput. System Sci. 38 (1989) 86-124, J. Driscoll, D. Sleator, R. Tarjan, J. ACM, 41 (5) (1994) 943-959], and present a general transformation that transforms any pointer based data structure to be confluently persistent. Such transformations for fully persistent data structures are given in [J.R. Driscoll, N. Sarnak, D. Sleator, R. Tarjan, J. Comput. System Sci. 38 (1989) 86-124], greatly improving the performance compared to the naive scheme of simply copying the inputs. Unlike fully persistent data structures, where both the naive scheme and the fully persistent scheme of [J.R. Driscoll, N. Sarnak, D. Sleator, R. Tarjan, J. Comput. System Sci. 38 (1989) 86-124] are feasible, we show that the naive scheme for confluently persistent data structures is itself infeasible (requires exponential space and time). Thus, prior to this paper there was no feasible method for making any data structure confluently persistent at all. Our methods give an exponential reduction in space and time compared to the naive method, placing confluently persistent data structures in the realm of possibility.
SODA	Testing graphs for colorable properties.	Eldar Fischer	2001	Let P be a property of graphs. An &egr;-test for P is a randomized algorithm which, given the ability to make queries whether a desired pair of vertices of an input graph G with n vertices are adjacent or not, distinguishes, with high probability, between the case of G satisfying P and the case that it has to be modified by adding and removing more than &egr;( <stack>2n</stack>) edges to make it satisfy P. The property P is called testable if for every &egr; there exists an &egr;-test for P whose total number of queries is independent of the size of the input graph. Goldreich, Goldwasser, and Ron [Property testing and its connection to learning and approximation, J ACM 45 (1998), 653&ndash;750] showed that certain graph properties, like k-colorability, admit an &egr;-test. In Alon, Fischer, Krivelevich, and Szegedy [Efficient testing of large graphs, Combinatorica 20 (2000), 451&ndash;476] a first step towards a logical characterization of the testable graph properties was made by proving that all first order properties of type &ldquo;&exist;&forall;&rdquo; are testable, while there exist first-order graph properties of type &ldquo;&exist;&forall;&rdquo; that are not testable. For proving the positive part, it was shown that all properties describable by a very general type of coloring problem are testable. While this result is tight from the standpoint of first order expressions, further steps towards the characterization of the testable graph properties can be taken by considering the coloring problem instead. It is proven here that other classes of graph properties, describable by various generalizations of the coloring notion used in Alon et al. [Combinatorica 20 (2000), 451&ndash;476], are testable, showing that this approach can broaden the understanding of the nature of the testable graph properties. The proof combines some generalizations of the methods used in Alon et al. with additional methods. &copy; 2004 Wiley Periodicals, Inc. Random Struct. Alg., 2005An extended abstract of this paper has appeared in the proceedings of the 12th ACM-SIAM SODA (2001), 873&ndash;882.
SODA	The probabilistic relationship between the assignment and asymmetric traveling salesman problems.	Alan M. Frieze,Gregory B. Sorkin	2001	We consider the gap between the cost of an optimal assignment in a complete bipartite graph with random edge weights, and the cost of an optimal traveling salesman tour in a complete directed graph with the same edge weights. Using an improved &ldquo;patching&rdquo; heuristic, we show that with high probability the gap is $O((\ln n)^2/n)$, and that its expectation is $\Omega(1/n)$. One of the underpinnings of this result is that the largest edge weight in an optimal assignment has expectation $\Theta(\ln n / n)$. A consequence of the small assignment-TSP gap is an $e^{\tilde{O}(\sqrt{n})}$-time algorithm which, with high probability, exactly solves a random asymmetric traveling salesman instance. In addition to the assignment-TSP gap, we also consider the expected gap between the optimal and second-best assignments; it is at least $\Omega(1/n^2)$ and at most $O(\ln n/n^2)$.
SODA	Reconstructing a collection of curves with corners and endpoints.	Stefan Funke,Edgar A. Ramos	2001	We present an algorithm which provably reconstructs a collection of curves with corners and endpoints from a sample set that satisfies a certain sampling condition. The algorithm outputs a polygonal reconstruction that contains the edges in the correct reconstruction of the curves and such that any additional edge between sample points is justified. Furthermore, we show that for any such collection of curves, there exists a sample set such that a slightly modified version of our algorithm outputs exactly the correct reconstruction. The algorithm also performs quite well in practice.
SODA	Distance labeling in graphs.	Cyril Gavoille,David Peleg,Stephane Perennes,Ran Raz	2001	We consider the problem of labeling the nodes of a graph in a way that will allow one to compute the distance between any two nodes directly from their labels (without using any additional information). Our main interest is in the minimal length of labels needed in different cases. We obtain upper bounds and (most importantly) lower bounds for several interesting families of graphs. In particular, our main results are the following: For general graphs, the length needed is &THgr;(n). For trees, the length needed is &THgr;(log2 n). For planar graphs, we show an upper bound of &Ogr;(&radic;n log n) and a lower bound of &OHgr;(n1/3). For bounded degree graphs, we show a lower bound of &OHgr;(&radic;n). The upper bounds for planar graphs and for trees follow by a more general upper bound for graphs with a r(n)- separator. The two lower bounds, however, are obtained by two different arguments that may be interesting in their own right. We also show some lower bounds on the length of the labels, even if it is only required that distances be approximated to a multiplicative factor s. For example, we show that for general graphs the required length is &OHgr;(n). We also consider the problem of the time complexity of the distance function once the labels are computed. We show that there are graphs with optimal labels of length 3 log n, such that if we use any labels with fewer than n bits per label, computing the distance function requires exponential time. A similar result is obtained for planar and bounded degree graphs.
SODA	Reductions among high dimensional proximity problems.	Ashish Goel,Piotr Indyk,Kasturi R. Varadarajan	2001	We present improved running times for a wide range of approximate high dimensional proximity problems. We obtain subquadratic running time for each of these problems. These improved running times are obtained by reduction to Nearest Neighbour queries. The problems we consider in this paper are Approximate Diameter, Approximate Furthest Neighbours, Approximate Discrete Center, Approximate Metric Facility Location, Approximate Bottleneck Matching, and Approximate Minimum Weight Matching.
SODA	Approximate majorization and fair online load balancing.	Ashish Goel,Adam Meyerson,Serge A. Plotkin	2001	This article relates the notion of fairness in online routing and load balancing to vector majorization as developed by Hardy et al. [1929]. We define &alpha;-supermajorization as an approximate form of vector majorization, and show that this definition generalizes and strengthens the prefix measure proposed by Kleinberg et al. [2001] as well as the popular notion of max-min fairness.The article revisits the problem of online load-balancing for unrelated 1-&infin; machines from the viewpoint of fairness. We prove that a greedy approach is O(log n)-supermajorized by all other allocations, where n is the number of jobs. This means the greedy approach is globally O(log n)-fair. This may be contrasted with polynomial lower bounds presented by Goel et al. [2001] for fair online routing.We also define a machine-centric view of fairness using the related concept of submajorization. We prove that the greedy online algorithm is globally O(log m)-balanced, where m is the number of machines.
SODA	Distributed admission control, scheduling, and routing with stale information.	Ashish Goel,Adam Meyerson,Serge A. Plotkin	2001	We study the problem of distributed online admission control and routing of permanent virtual circuits in a capacitated network. We assume that we have k distinct decision makers, each of which is responsible for gathering its own information about the state of the network. Through simulation, we demonstrate that an exponential based routing scheme will perform well in a distributed model provided granularity is sufficiently high. In order to ground these results theoretically, we prove that exponential-based schemes attain best-possible competitive ratios (same as for the centralized case) provided each edge can accommodate at least &OHgr;(k log n) requests. A matching lower-bound shows that no deterministic algorithm can attain best-possible competitive ratios without requiring the same level of granularity. In the randomized case, we present a modified exponential-based approach which obtains best-possible competitive ratios provided the granularity is at least &OHgr;(k + log n). Our results may be extended to the case where different requests have different profits, and where requests are allowed to be temporary. They also apply to admission control and scheduling for unrelated machines.
SODA	Competitive auctions and digital goods.	Andrew V. Goldberg,Jason D. Hartline,Andrew Wright	2001	We study a class of single round, sealed bid auctions for items in unlimited supply such as digital goods. We focus on auctions that are truthful and competitive. Truthful auctions encourage bidders to bid their utility; competitive auctions yield revenue within a constant factor of the revenue for optimal fixed pricing. We show that for any truthful auction, even a multi-price auction, the expected revenue does not exceed that for optimal fixed pricing. We also give a bound on how far the revenue for optimal fixed pricing can be from the total market utility. We show that several randomized auctions are truthful and competitive under certain assumptions, and that no truthful deterministic auction is competitive. We present simulation results which confirm that our auctions compare favorably to fixed pricing. Some of our results extend to bounded supply markets, for which we also get truthful and competitive auctions.
SODA	Improved algorithms for fault tolerant facility location.	Sudipto Guha,Adam Meyerson,Kamesh Munagala	2001	We consider a generalization of the classical facility location problem, where we require the solution to be fault-tolerant. Every demand point j is served by rj facilities instead of just one. The facilities other than the closest one are &ldquo;backup&rdquo; facilities for that demand, and will be used only if the closer facility (or the link to it) fails. Hence, for any demand, we assign non-increasing weights to the routing costs to farther facilities. The cost of assignment for demand j is the weighted linear combination of the assignment costs to its rj closest open facilities. We wish to minimize the sum of the cost of opening the facilities and the assignment cost of each demand j. We obtain a factor 4 approximation to this problem through the application of various rounding techniques to the linear relaxation of an integer program formulation. We further improve this result to 3.16 using randomization and to 2.47 using greedy local-search type techniques.
SODA	"Steiner points in tree metrics don't (really) help."	Anupam Gupta	2001	Consider an edge-weighted tree T = (V, E, w : E &rarrtl; R+), in which a subset R of the nodes (called the required nodes) are colored red and the remaining nodes in S = V\R are colored black (and called the Steiner nodes). The shortest-path distance according to the edge-weights defines a metric dT on the vertex set V. We now ask the following question: Is it possible to define another weighted tree T* = (R, E*, w* : E* &rarrtl; R+), this time on just the red vertices so that the shortest-path metric dT* induced by T* on the vertices in R is &ldquo;close&rdquo; to the metric dT restricted to the red vertices? I.e., does there exist a weighted tree T* = (R, E*, c*) and a (small) constant &agr; such that dT(u, v) &le; dT* (u, v) &le; &agr; dT(u, v) for any two red vertices u, v &isin; R? We answer this question in the affirmative, and give a linear time algorithm to obtain a tree T* with &agr; &le; 8. We also give two applications of this result: an upper bound, in which we show that emulating multicasts using unicasts can be almost as good as general multicasts for certain performance measures; and a lower bound, in which we give a simple combinatorial proof of the fact that the metric generated by a graph of girthg must suffer a distortion of at least &OHgr;(g) when approximated by a tree.
SODA	Inserting an edge into a planar graph.	Carsten Gutwenger,Petra Mutzel,René Weiskircher	2001	Computing a crossing minimum drawing of a given planar graph G augmented by an additional edge e in which all crossings involve e, has been a long standing open problem in graph drawing. Alternatively, the problem can be stated as finding a planar combinatorial embedding of a planar graph G in which the given edge e can be inserted with the minimum number of crossings. Many problems concerned with the optimization over the set of all combinatorial embeddings of a planar graph turned out to be NP-hard. Surprisingly, we found a conceptually simple linear time algorithm based on SPQR trees, which is able to find a crossing minimum solution.
SODA	On algorithms for efficient data migration.	Joseph Hall,Jason D. Hartline,Anna R. Karlin,Jared Saia,John Wilkes	2001	The data migration problem is the problem of computing an efficient plan for moving data stored on devices in a network from one configuration to another. Load balancing or changing usage patterns could necessitate such a rearrangement of data. In this paper, we consider the case where the objects are fixed-size and the network is complete. The direct migration problem is closely related to edge-coloring. However, because there are space constraints on the devices, the problem is more complex. Our main results are polynomial time algorithms for finding a near-optimal migration plan in the presence of space constraints when a certain number of additional nodes is available as temporary storage, and a 3/2-approximation for the case where data must be migrated directly to its destination.
SODA	Coloring k-colorable graphs using smaller palettes.	Eran Halperin,Ram Nathaniel,Uri Zwick	2001	We obtain the following new coloring results: A 3-colorable graph on n vertices with maximum degree &Dgr; can be colored, in polynomial time, using &Ogr;((&Dgr; log &Dgr;)1/3 &middot;log n) colors. This slightly improves an &Ogr;((&Dgr;1/3 log&frac12; &Dgr;) &middot; log n) bound given by Karger, Motwani and Sudan. More generally, k-colorable graphs with maximum degree &Dgr; can be colored, in polynomial time, using &Ogr;((&Dgr;1-2/k log1/k &Dgr;) &middot; log n) colors. A 4-colorable graph on n vertices can be colored, in polynomial time, using &Ogr;(n7/19) colors. This improves an &Ogr;(n2/5) bound given again by Karger, Motwani and Sudan. More generally, k-colorable graphs on n-vertices can be colored, in polynomial time, using &Ogr;(n&agr;k) colors, where &agr;5 = 97/207, &agr;6 = 43/79, &agr;7 = 1391/2315, &agr;8 = 175/271, &hellip; The first result is obtained by a slightly more refined probabilistic analysis of the semidefinite programming based coloring algorithm of Karger, Motwani and Sudan. The second result is obtained by combining the coloring algorithm of Karger, Motwani and Sudan, the combinatorial coloring algorithms of Blum and an extension of a technique of Alon and Kahale (which is based on the Karger, Motwani and Sudan algorithm) for finding relatively large independent sets in graphs that are guaranteed to have very large independent sets. The extension of the Alon and Kahale result may be of independent interest.
SODA	Combinatorial approximation algorithms for the maximum directed cut problem.	Eran Halperin,Uri Zwick	2001	We describe several combinatorial algorithms for the maximum directed cut problem. Among our results is a simple linear time 9/20-approximation algorithm for the problem, and a somewhat slower &frac12;-approximation algorithm that uses a bipartite matching routine. No better combinatorial approximation algorithms are known even for the easier maximum cut problem for undirected graphs. Our algorithms do not use linear programming, nor semidefinite programming. They are based on the observation that the maximum directed cut problem is equivalent to the problem of finding a maximum independent set in the line graph of the input graph, and that the linear programming relaxation of the problem is equivalent to the problem of finding a maximum fractional independent set of that line graph. The maximum fractional independent set problem can be easily reduced to a bipartite matching problem. As a consequence of this relation, we also get that the maximum directed cut problem for bipartite digraphs can be solved in polynomial time.
SODA	Online point location in planar arrangements and its applications.	Sariel Har-Peled,Micha Sharir	2001	"Recently, Har-Peled [17] presented a new randomized technique for online construction of the zone of a curve in a planar arrangement of arcs. In this paper: we present several applications of this technique, which yield improved solutions to a variety of problems. These applications include: (i) an efficient mechanism for performing online point location queries in an arrangement of arcs; (ii) an efficient algorithm for computing an approximation to the minimum-weight Steiner-tree of a set of points, where the weight is the number of intersections between the tree edges and a given collection of arcs; (iii) a subquadratic algorithm for cutting a set of pseudo-parabolas into pseudo-segments; (iv) an algorithm for cutting a set of line segments (`rods') in 3-space so as to eliminate all cycles in the vertical depth order; and (v) a near-optimal algorithm for reporting all bichromatic intersections between a set R of red arcs and a set B of blue arcs, where the unions of the arcs in each set are both connected."
SODA	Simplified kinetic connectivity for rectangles and hypercubes.	John Hershberger,Subhash Suri	2001	We consider the problem of maintaining connected components in a set of moving objects using the kinetic data structure (KDS) framework. We assume that the motion of each object can be specified by a low-degree algebraic trajectory; this trajectory, however, can be modified in an on-line fashion. While the objects move continuously, their connectivity changes at discrete times. A straightforward dynamic graph approach for maintaining connectivity of n objects has three shortcomings: the graph can have &OHgr;(n2) edges, the update bounds are amortized, and the algorithm is very complicated. Our first result shows that the connectivity for a set of n moving hypercubes can be maintained using a very simple, easy to determine graph with &Ogr;(n) edges. But this graph still requires a general-purpose dynamic graph scheme for connectivity maintenance. Our main result is a simplified connectivity data structure for moving rectangles in the plane. For this special but important case, we are able to overcome all three shortcomings mentioned above: our graph has &Ogr;(n) edges; our data structure supports updates in &Ogr;(log2 n) worst-case time; and the algorithm and data structures are quite a bit simpler than those based on a general dynamic graph scheme.
SODA	Geometric permutations of high dimensional spheres.	Yingping Huang,Jinhui Xu,Danny Z. Chen	2001	We prove the maximum number of geometric permutations, induced by line transversals to a set of n pairwise disjoint congruent spheres in Rd with d &gne; 3, is no more than 4 when n is sufficiently large, achieving the best known upper bound for this problem. We also prove the maximum number of geometric permutations of a set of n noncongruent spheres of bounded radius ratio in Rd, d &gne; 3, is at most 2[&radic;2M]+1, where M is the ratio or the largest radius and the smallest radius. Our result settles a conjecture in combinatorial geometry.
SODA	Optimal planar point location.	John Iacono	2001	Given a fixed distribution of point location queries among the regions of a triangulation of the plane, a data structure is presented that achieves, within constant multiplicative factors, the entropy bound on the expected point location query time.
SODA	Alternatives to splay trees with O(log n) worst-case access times.	John Iacono	2001	"Splay trees are a self adjusting form of search tree that supports access operations in &Ogr;(log n) amortized time. Splay trees also have several amazing distribution sensitive properties, the strongest two of which are the working set theorem and the dynamic finger theorem. However, these two theorems are shown to poorly bound the performance of splay trees on some simple access sequences. The unified conjecture is presented, which subsumes the working set theorem and dynamic finger theorem, and accurately bounds the performance of splay trees over some classes of sequences where the existing theorems' bounds are not tight. While the unified conjecture for splay trees is unproven, a new data structure, the unified structure, is presented where the unified conjecture does hold. This structure also has a worst case of &Ogr;(log n) per operation, in contrast to the &Ogr;(n) worst case runtime of splay trees. A second data structure, the working set structure, is introduced. The working set structure has the same performance attributed to splay trees through the working set theorem, except the runtime is worst case per operation rather than amortized."
SODA	Adversarial models in evolutionary game dynamics.	Gabriel Istrate,Madhav V. Marathe,S. S. Ravi	2001	Adversarial models in evolutionary game dynamics.
SODA	Performance study of phylogenetic methods: (unweighted) quartet methods and neighbor-joining.	Katherine St. John,Tandy Warnow,Bernard M. E. Moret,Lisa Vawter	2001	We present the results of a large-scale experimental study of quartet-based methods (quartet cleaning and puzzling) for phylogeny reconstruction. Our experiments include a broad range of problem sizes and evolutionary rates, and were carefully designed to yield statistically robust results despite the size of the sample space. We measure outcomes in terms of numbers of edges of the true tree correctly inferred by each method (true positives). Our results indicate that these quartet-based methods are much less accurate than the simple and efficient method of neighbor-joining, particularly for data composed of short to medium length sequences. We support our experimental findings by theoretical results that suggest that quartet-cleaning methods are unlikely to yield accurate trees with less than exponentially long sequences. We suggest that a proposed reconstruction method should first be compared to the neighbor-joining method and further studied only if it offers a demonstrable practical advantage.
SODA	A polynomial time recognition algorithm for probe interval graphs.	Julie L. Johnson,Jeremy Spinrad	2001	Probe interval graphs were introduced to model a problem arising in a form of DNA sequencing. This paper presents an &Ogr;(n2) algorithm for recognizing probe interval graphs. This is the first polynomial time recognition algorithm for this class.
SODA	Faster kinetic heaps and their use in broadcast scheduling.	Haim Kaplan,Robert Endre Tarjan,Kostas Tsioutsiouliklis	2001	We describe several implementations of the kinetic heap, a heap (priority queue) in which the key of each item, instead of being fixed, is a linear function of time. The kinetic heap is a simple example of a kinetic data structure of the kind considered by Basch, Guibas, and Hershberger. Kinetic heaps have many applications in computational geometry, and previous implementations were designed to address these applications. We describe an additional application, to broadcast scheduling. Each of our kinetic heap implementations improves on previous implementations by being simpler or asymptotically faster for some or all applications.
SODA	Static and kinetic geometric spanners with applications.	Menelaos I. Karavelas,Leonidas J. Guibas	2001	It is well known that the Delaunay Triangulation is a spanner graph of its vertices. In this paper we show that any bounded aspect ratio triangulation in two and three dimensions is a spanner graph of its vertices as well. We extend the notion of spanner graphs to environments with obstacles and show that both the Constrained Delaunay Triangulation and bounded aspect ratio conforming triangulations are spanners with respect to the corresponding visibility graph. We also show how to kinetize the Constrained Delaunay Triangulation. Using such time-varying triangulations we describe how to maintain sets of near neighbors for a set of moving points in both unconstrained and constrained environments. Such nearest neighbor maintenance is needed in many virtual environments where nearby agents interact. Finally, we show how to use the Constrained Delaunay Triangulation in order to maintain the relative convex hull of a set of points moving inside a simple polygon.
SODA	A new constructive root bound for algebraic expressions.	Chen Li,Chee-Keng Yap	2001	Computing effective root bounds for constant algebraic expressions is a critical problem in the Exact Geometric Computation approach to robust geometric programs. Classical root bounds are often non-constructive. Recently, various authors have proposed bounding methods which might be called constructive root bounds. For the important class of radical expressions, Burnikel et al (BFMS) have provided a constructive root bound which, in the division-free case, is an improvement over previously known bounds and is essentially tight. In the presence of division, their bound requires a quadratic blowup in root bit-bound compared to the division-free case. We present a new constructive root bound that avoids this quadratic blowup and which is applicable to a more general class of algebraic expressions. This leads to dramatically better performance in some computations. We also give an improved version of the degree-measure bound from Mignotte and BFMS. We describe our implementation in the context of the Core Library, and report on some experimental results.
SODA	Learning Markov networks: maximum bounded tree-width graphs.	David R. Karger,Nathan Srebro	2001	Markov networks are a common class of graphical models used in machine learning. Such models use an undirected graph to capture dependency information among random variables in a joint probability distribution. Once one has chosen to use a Markov network model, one aims to choose the model that &ldquo;best explains&rdquo; the data that has been observed&mdash;this model can then be used to make predictions about future data. We show that the problem of learning a maximum likelihood Markov network given certain observed data can be reduced to the problem of identifying a maximum weight low-treewidth graph under a given input weight function. We give the first constant factor approximation algorithm for this problem. More precisely, for any fixed treewidth objective k, we find a treewidth-k graph with an f(k) fraction of the maximum possible weight of any treewidth-k graph.
SODA	Loss-bounded analysis for differentiated services.	Alexander Kesselman,Yishay Mansour	2001	We consider a network providing Differentiated Services (Diffserv) which allow network service providers to offer different levels of Quality of Service (QoS) to different traffic streams. We focus on loss and first show that only trivial bounds could be obtained by means of traditional competitive analysis. Then we introduce a new approach for estimating loss of an online policy called loss-bounded analysis. In loss-bounded analysis the loss of an online policy are bounded by the loss of an optimal offline policy plus a constant fraction of the benefit of an optimal offline policy. We derive tight upper and lower bounds for various settings of Diffserv parameters using the new loss-bounded model. We believe that loss-bounded analysis is an important technique that may complement traditional competitive analysis and provide new insight and interesting results.
SODA	Approximating coloring and maximum independent sets in 3-uniform hypergraphs.	Michael Krivelevich,Ram Nathaniel,Benny Sudakov	2001	Approximating coloring and maximum independent sets in 3-uniform hypergraphs.
SODA	Shape matching using edit-distance: an implementation.	Philip N. Klein,Thomas B. Sebastian,Benjamin B. Kimia	2001	We report on our experience with the implementation of an algorithm for comparing shapes by computing the edit-distance between their medial axes. A shape-comparison method that is robust to various visual transformations has several applications in computer vision, including organizing and querying an image database, and object recognition. There are two components to research on this problem, mathematical formulation of the shape-comparison problem and the computational solution method. We have a clear, well-defined formulation and polynomial-time algorithms for solution. Previous research has involved either ill-defined formulations or heuristic methods for solution. Our starting-point for the implementation is the edit-distance algorithm of Klein et al. [6]. We discuss how we altered that algorithm to handle rotation-invariance while keeping down the time and storage requirements. Most important, we define costs for the edit-operations and give an algorithm for computing them. We use a database of shapes to illustrates that our approach performs intuitively in categorization and indexing tasks, and our results are better than previous approaches.
SODA	On polynomial approximation to the shortest lattice vector length.	Ravi Kumar,D. Sivakumar	2001	We obtain a 2&Ogr;(n/&isin;) time algorithm to approximate the length of the shortest vector in an n-dimensional lattice to within a factor of n3+&isin;.
SODA	On binary searching with non-uniform costs.	Eduardo Sany Laber,Ruy Luiz Milidiú,Artur Alves Pessoa	2001	Let us consider an ordered vector A[1 : n]. If the cost of testing each position is similar, then the standard binary search is the best strategy to search the vector. This is true in both average and worst case. However, if the costs are non-uniform, then the best strategy is not necessarily the standard binary search. The best algorithm to construct a strategy that minimizes the expected search cost runs in &Ogr;(n3) time and requires &Ogr;(n2) space. The same complexities hold for the best algorithm to construct a strategy that minimizes the worst case search cost. Here, we show how to efficiently construct search strategies that are at most at a constant factor from the optimal one. These constructions take linear time and use only linear space. For the problem of minimizing the expected search cost, we present an algorithm that requires &Ogr;(n) space and gives a (2 + &isin; + &Ogr;(1))-approximated solution in &Ogr;(n) time, for any fixed value of &isin; > 0. On the other hand, for the problem of minimizing the worst case search cost, we describe an algorithm that requires &Ogr;(n) space and gives a (2 + &isin; + &Ogr;(1))- approximated solution in &Ogr;(n) time, for any fixed value of &isin; > 0. These two problems arise when processing a query in a distributed text database indexed by a suffix array.
SODA	Performance guarentee for online deadline scheduling in the presence of overload.	Tak Wah Lam,Kar-Keung To	2001	Earliest deadline first (EDF) is a widely-used online algorithm for scheduling jobs with deadlines in real-time systems. Yet, existing results on the performance guarantee of EDF are limited to underloaded systems [6,12,14]. This paper initiates the study of EDF for overloaded systems, attaining similar performance guarantees as in the underloaded setting. Specifically, we show that EDF with a simple form of admission control is optimal for scheduling on both uniprocessor and multiprocessors when moderately faster processors are available (our analysis actually admits a tradeoff between speed and extra processors). This is the first result attaining optimality under overload. Another contribution of this paper is an improved analysis of the competitiveness for weighted deadline scheduling.
SODA	Polynomial algorithms for partitioning problems on graphs with fixed clique-width (extended abstract).	Daniel Kobler,Udi Rotics	2001	We consider three graph partitioning problems, both from the vertices and the edges point of view. These problems are dominating set, list-q-coloring with costs (fixed number of colors q) and coloring with non-fixed number of colors. They are all known to be NP-hard in general. We show that all these problems (except edge-coloring) can be solved in polynomial time on graphs with clique-width bounded by some constant k, if the k-expression of the input graph is also given. In particular, we present the first polynomial algorithms (on these classes) for chromatic number, edge-dominating set and list-q-coloring with costs (fixed number of colors q, both vertex and edge versions). Since these classes of graphs include classes like P4-sparse graphs, distance hereditary graphs and graphs with bounded treewidth, our algorithms also apply to these graphs.
SODA	On approximating the achromatic number.	Guy Kortsarz,Robert Krauthgamer	2001	The achromatic number problem is to legally color the vertices of an input graph with the maximum number of colors, denoted &psgr;*, so that every two color classes share at least one edge. This problem is known to be NP-hard. For general graphs we give an algorithm that approximates the achromatic number within ratio of &Ogr;(n &middot;log log n/ log n). This improves over the previously known approximation ratio of &Ogr;(n/&radic;log n), due to Chaudhary and Vishwanathan [4]. For graphs of girth at least 5 we give an algorithm with approximation ratio &Ogr;(min{n1/3, &radic;&psgr;*}). This improves over an approximation ratio &Ogr;(&radic;&psgr;*) = &Ogr;(n3/8) for the more restricted case of graphs with girth at least 6, due to Krista and Lorys [13]. We also give the first hardness result for approximating the achromatic number. We show that for every fixed &isin; > 0 there in no 2 - &isin; approximation algorithm, unless P = NP.
SODA	Gossip is synteny: incomplete gossip and an exact algorithm for syntenic distance.	David Liben-Nowell	2001	The syntenic distance between two genomes is given by the minimum number of fusions, fissions, and translocations required to transform one into the other, ignoring the order of genes within chromosomes. The problem of computing this distance is NP-complete. In this paper, we give an &Ogr;(2&Ogr;(n log n)) algorithm to exactly compute the syntenic distance between two genomes that contain at most n chromosomes. Our algorithm requires &Ogr;(2&Ogr;(d log d)) time when this distance is d, improving the &Ogr;(2&Ogr;(d2)) running time of the beat previous exact algorithm. Our result is based upon a tight connection between syntenic distance and a novel generalization of the classical gossip problem. We define the incomplete gossip problem, in which there are n gossipers who each have a unique piece of initial information. They communicate by phone calls in which the participants exchange all their information, and the goal is to minimize the total number of phone calls necessary to inform each gossiper of his set of relevant gossip which he desires to learn.
SODA	The diameter of random massive graphs.	Linyuan Lu	2001	Many massive graphs (such as the WWW graph and Call graphs) share certain universal characteristics which can be described by so-called the &ldquo;power law&rdquo;. Here we determine the diameter of random power law graphs up to a constant factor for almost all ranges of parameters. These results show a strong evidence that the diameters of most massive graphs are about logarithm of their sizes up to a constant factor.
SODA	Fast implementation of depth contours using topological sweep.	Kim Miller,Suneeta Ramaswami,Peter Rousseeuw,Joan Antoni Sellarès,Diane L. Souvaine,Ileana Streinu,Anja Struyf	2001	The concept of location depth was introduced in statistics as a way to extend the univariate notion of ranking to a bivariate configuration of data points. It has been used successfully for robust estimation, hypothesis testing, and graphical display. These require the computation of depth regions, which form a collection of nested polygons. The center of the deepest region is called the Tukey median. The only available implemented algorithms for the depth contours and the Tukey median are slow, which limits their usefulness. In this paper we describe an optimal algorithm which computes all depth contours in &Ogr;(n2) time and space, using topological sweep of the dual arrangement of lines. Once the contours are known, the location depth of any point is computed in &Ogr;(log2 n) time. We provide fast implementations of these algorithms to allow their use in everyday statistical practice.
SODA	Sublinear time approximate clustering.	Nina Mishra,Daniel Oblinger,Leonard Pitt	2001	Clustering is of central importance in a number of disciplines including Machine Learning, Statistics, and Data Mining. This paper has two foci: (1) It describes how existing algorithms for clustering can benefit from simple sampling techniques arising from work in statistics [Pol84]. (2) It motivates and introduces a new model of clustering that is in the spirit of the &ldquo;PAC (probably approximately correct)&rdquo; learning model, and gives examples of efficient PAC-clustering algorithms.
SODA	I/O-efficient algorithms for graphs of bounded treewidth.	Anil Maheshwari,Norbert Zeh	2001	We present I/O-efficient algorithms for the single source shortest path problem and NP-hard problems on graphs of bounded treewidth. The main step in these algorithms is a method to compute a tree-decomposition for the given graph I/O-efficiently.
SODA	Colored Tutte polynomials and Kaufman brackets for graphs of bounded tree width.	Johann A. Makowsky	2001	"Tutte polynomials are important graph invariants with rich applications in combinatorics, topology, knot theory, coding theory and even physics. The Tutte polynomial T(G, X, Y) is a polynomial in Z[X, Y] which depends on a graph G. Computing the coefficients of T(G, X, Y), and even evaluating T(G, X, Y) at specific points (x, y) is #P hard by a result of Jaeger et al. (Math. Proc. Cambridge Philos. Soc. 108 (1989) 35). On the other hand, Andrzejak (Discrete Math. 190 (1998) 39-54) and Noble (Combin. Probab. Comput. 7 (1998) 307-321) have shown independently, that, if G is a graph of bounded tree width, computing T(G, X, Y) can be done in polynomial time. We extend this result to the signed Tutte polynomials introduced in 1989 by Kauffman and the colored Tutte polynomials introduced in 1999 by Bollobas and Riordan. This allows us to prove similar results for the Jones polynomials and Kauffman brackets for knots and links which have a signed graph presentation of bounded tree width. Jones polynomials and Kauffman polynomials are the most prominent invariants of knot theory. For alternating links, they are easily computable from the Tutte polynomials of the signed graph representing the link by a result of Thistlethwaite (1988). For general links one has to use the colored Tutte polynomial instead. Knots and links can be presented as labeled planar graphs. The tree width of a link L is defined as the tree width of its graphical presentation D(L) as crossing diagrams. We show that for (not necessarily alternating) knots and links of tree width at most k, even the Kauffman square bracket [L] introduced by Bollobas and Riordan can be computed in polynomial time. Hence, the classical Kauffman bracket (L) and the Jones polynomial of links of tree width at most k are computable in polynomial time. Our proof is based on, but extends considerably previous work by B. Courcelle, U. Rotics and the author. It also gives a new proof of the result for Tutte polynomials and generalizes to a wide class of polynomials defined as generating functions definable in Monadic Second Order Logic with order, but invariant under it."
SODA	Representing dynamic binary trees succinctly.	J. Ian Munro,Venkatesh Raman,Adam J. Storm	2001	We introduce a new updatable representation of binary trees. The structure requires the information theoretic minimum 2n + &Ogr;(n) bits and supports basic navigational operations in constant time and subtree size in &Ogr;(lg n). In contrast to the linear update costs of previously proposed succinct representations, our representation supports updates in &Ogr;(lg2 n) amortized time.
SODA	Fast distributed graph coloring with O(Delta) colors.	Gianluca De Marco,Andrzej Pelc	2001	"We consider the problem of deterministic distributed coloring of an n-vertex graph with maximum degree &Dgr;, assuming that every vertex knows a priori only its own label and parameters n and &Dgr;. The aim is to get a fast algorithm using few colors. Linial [17] showed a vertex-coloring algorithm working in time &Ogr;(log* n) and using &Ogr;(&Dgr;2 colors. We improve both the time and the number of colors simultaneously by showing an algorithm working in time &Ogr;(log*(n/&Dgr;)) and using &Ogr;(&Dgr;) colors. This is the first known &Ogr;(&Dgr;)-vertex-coloring distributed algorithm which can work faster than in polylogarithmic time. Our method also gives an edge-coloring algorithm with the number of colors and time as above. On the other hand, it follows from Linial [17] that our time of &Ogr;(&Dgr;)-coloring cannot be improved in general. In addition we show how our method gives fast coloring algorithms in communication models weaker than Linial's."
SODA	Efficient oblivious transfer protocols.	Moni Naor,Benny Pinkas	2001	1 Introduction Oblivious Transfer (OT) protocols allow one party, the sender, to transmit part of its inputs to another party, the chooser, in a manner that protects both of them: the sender is assured that the chooser does not receive more information than it is entitled, while the chooser is assured that the sender does not learn which part of the inputs it received. OT is used as a key component in many applications of cryptography. Its computational requirements are quite demanding and they are likely to be the bottleneck in many applications that invoke it. 1.1 Contributions. This paper presents several significant improvements to oblivious transfer (OT) protocols of strings, and in particular: (i) Improving the efficiency of applications which many invocations of oblivious transfer. (ii) Providing the first two-round OT protocol whose security analysis does not invoke the random oracle model.
SODA	Tree packing and approximating k-cuts.	Joseph Naor,Yuval Rabani	2001	Tree packing and approximating k-cuts.
SODA	Constructing pseudo-random permutations with a prescribed structure.	Moni Naor,Omer Reingold	2001	Constructing pseudo-random permutations with a prescribed structure.
SODA	External memory BFS on undirected graphs with bounded degree.	Ulrich Meyer	2001	We give the first external memory algorithm for breadth-first search (BFS) which achieves &Ogr;(n) I/Os on arbitrary undirected graphs with n nodes and maximum node degree d. Let M and B < d denote the main memory size and block size, respectively. Using Sort(x) = &THgr;(x&divide;B &middot; log M/B x&divide;B), our algorithm needs &Ogr;(n&divide;&ggr;&middot;logdB + Sort(n &middot; B&ggr;)) I/Os and &Ogr;(n &middot; B&ggr;) external space for an arbitrary parameter 0 < &ggr; &lne; &frac12;. The result carries over to BFS, depth-first search (DFS) and single source shortest paths (SSSP) on undirected planar graphs with arbitrary node degrees.
SODA	Single-source shortest-paths on arbitrary directed graphs in linear average-case time.	Ulrich Meyer	2001	The quest for a linear-time single-source shortest-path (SSSP) algorithm on directed graphs with positive edge weights is an ongoing hot research topic. While Thorup recently found an &Ogr;(n + m) time RAM algorithm for undirected graphs with n nodes, m edges and integer edge weights in {0,&hellip;,2w - 1} where w denotes the word length, the currently best time bound for directed sparse graphs on a RAM is &Ogr;(n + m &middot; log log n). In the present paper we study the average-case complexity of SSSP. We give a simple algorithm for arbitrary directed graphs with random edge weights uniformly distributed in [0, 1] and show that it needs linear time &Ogr;(n + m) with high probability.
SODA	Web caching using access statistics.	Adam Meyerson,Kamesh Munagala,Serge A. Plotkin	2001	We consider the problem of caching web pages with the objective of minimizing latency of access. Demands for web domains/pages are computed using access statistics; the frequency with which these statistics change is considerably longer than the frequency of page requests. We model caches as being constrained by total size and total number of ports: each cache can handle only a limited request rate and can store only a limited number of domains (eg. modelling bounded update traffic). When the caches have fixed locations, we present a constant factor approximation to the optimum average latency while exceeding capacity constraints by a logarithmic factor. We demonstrate improved results in the special case where no replication of pages is allowed. In the alternate model where we are allowed to place our own caches in the network for a cost, we produce a constant approximation to the weighted sum of cost and average latency. Finally, we consider several other variants of the problem which might arise in practice.
SODA	Can entropy characterize performance of online algorithms?.	Gopal Pandurangan,Eli Upfal	2001	We focus in this work on an aspect of online computation that is not addressed by the standard competitive analysis. Namely, identifying request sequences for which non-trivial online algorithms are useful versus request sequences for which all algorithms perform equally bad. The motivation for this work are advanced system and architecture designs which allow the operating system to dynamically allocate resources to online protocols such as prefetching and caching. To utilize these features the operating system needs to identify data streams that can benefit from more resources. Our approach in this work is based on the relation between entropy, compression and gambling, extensively studied in information theory. It has been shown that in some settings entropy can either fully or at least partially characterize the expected outcome of an iterative gambling game. Viewing online problem with stochastic input as an iterative gambling game, our goal is to study the extent to which the entropy of the input characterizes the expected performance of online algorithms for problems that arise in computer applications. We study bounds based on entropy for three online problems &mdash; list accessing, prefetching and caching. We show that entropy is a good performance characterizer for prefetching, but not so good characterizer for online caching.
SODA	Game theory, algorithms, and the Internet.	Christos H. Papadimitriou	2001	Among the many characteristics of the Internet (huge and growing, available and unstructured, dynamic and chaotic), perhaps the most novel, distinguishing, and intellectually challenging one is that, unlike previous computational artifacts and systems, the Internet is built, operated, and used by a dazzling diversity of economic interests, in various degrees of collaboration and competition with each other. Consequently, it can be argued that the mathematical arsenal necessary for attaining an algorithmic and conceptual understanding of the Internet must include some kind of fusion between mathematical economics (especially game theory and its inverse problem, mechanism design) and algorithmic thinking. In this talk I shall survey recent formalisms and results aiming in this general direction, and discuss the research agenda that appears to be emerging.
SODA	Randomizing combinatorial algorithms for linear programming when the dimension is moderately high.	Marco Pellegrini	2001	In the last decade researchers in computational geometry have produced a series of algorithms for linear programming, based on a randomized combinatorial approach, which are tuned for linear programs where the number of variables d is small compared to the number n of constraints, although not so small to be considered a constant of the problem. One natural question is how practical are these algorithms for classes of LP instances not necessarily derived from problems in computational geometry. In this paper, building within the randomized combinatorial approach, we propose two algorithms for linear programming and we give evidence of their empirical running times on several classes of randomly generated instances. Comparisons with state of the art free software (lp-solve) and state of the art commercial software (Cplex) lead to the conclusion that the randomized combinatorial approach for systems with n &ap; d, at the present state of our research, can be competitive for dense systems and for sparse systems where a large fraction of the constraints are equalities. We also consider the case of dense systems where n > > d, which is typical in instances from computational geometry problems, for which we improve upon recent results of G&auml;tner and Sch&ouml;nherr [13].
SODA	Reconciling simplicity and realism in parallel disk models.	Peter Sanders	2001	For the design and analysis of algorithms that process huge data sets, a machine model is needed that handles parallel disks. There seems to be a dilemma between simple and flexible use of such a model and accurate modelling of details of the hardware. This paper explains how many aspects of this problem can be resolved. The programming model implements one large logical disk allowing concurrent access to arbitrary sets of variable size blocks. This model can be implemented efficienctly on multiple independent disks even if zones with different speed, communication bottlenecks and failed disks are allowed. These results not only provide useful algorithmic tools but also imply a theoretical justification for studying external memory algorithms using simple abstract models. The algorithmic approach is random redundant placement of data and optimal scheduling of accesses. The analysis generalizes a previous analysis for simple abstract external memory models in several ways (Higher efficiency, variable block sizes, more detailed disk model). As a side effect, an apparently new Chernoff bound for sums of weighted 0-1 random variables is derived.
SODA	Equitable colorings extend Chernoff-Hoeffding bounds.	Sriram V. Pemmaraju	2001	Equitable colorings extend Chernoff-Hoeffding bounds.
SODA	On the midpath tree conjuncture: a counter-example.	Rahul Shah,Martin Farach-Colton	2001	On the midpath tree conjuncture: a counter-example.
SODA	Robust algorithms for restricted domains.	Vijay Raghavan,Jeremy Spinrad	2001	"We introduce a new definition of efficient algorithms for restricted domains. Under this definition, an algorithm is required to be ""robust,"" i.e., it must produce correct output regardless of whether the input actually belongs to the restricted domain or not. This is to be contrasted with the ""promise"" version of solving problems on restricted domains, in which there is a guarantee that the input is in the class, and an algorithm to ""solve"" the problem need not function correctly or even terminate if this guarantee is not met. There exist problems that have a polynomial time promise solution, while being NP-hard if required to be robust. We show perhaps the surprising result that robustly finding a maximum independent set in a well-covered graph (i.e., a graph in which every maximal independent set is of the same size) is NP-hard. An argument can be made that this hardness result is more meaningful than the trivial polynomial time promise algorithm. We give a polynomial time robust algorithm for the maximum clique problem in unit disk graphs, i.e., given an input graph G in general form, the output is either a maximum clique for G or a certificate that G is not a unit disk graph. The existence of this algorithm is to be reconciled with the apparent contradiction posed by the facts: (1) Recognizing whether an input graph given in general form is a unit disk graph is NP-hard; in fact, it is not even known to be in NP. (2) Finding a maximum clique in an input graph given in general form is NP-hard."
SODA	Scheduling precedence-constrained jobs with stochastic processing times on parallel machines.	Martin Skutella,Marc Uetz	2001	We consider parallel machine scheduling problems where the jobs are subject to precedence constraints, and the processing times of jobs are governed by independent probability distributions. The objective is to minimize the weighted sum of job completion times &sum;, w, C, in expectation, where w, &gne; 0. Building upon an LP-relaxation from [3] and an idle time charging scheme from [1], we derive the first approximation algorithms for this model.
SODA	Approximately covering by cycles in planar graphs.	Dieter Rautenbach,Bruce A. Reed	2001	Let G = (V(G), E(G)) be a graph and let C be the collection of its cycles. Let p: E(G) &rarrtl; Z+&Ogr;? be a non-negative, integer-valued function on its edge set. The CYCLE COVER PROBLEM is the optimization problem of finding a multiset a of cycles of G such that each edge e &isin; E is in at least p(e) of the cycles in a and such that the sum of the lengths of all cycles in a is minimum. We will show how to approximate within a factor of 8 the optimum value of the cycle cover problem for planar graphs in polynomial time.
SODA	New approaches to covering and packing problems.	Aravind Srinivasan	2001	Covering and packing integer programs model a large family of combinatorial optimization problems. The current-best approximation algorithms for these are an instance of the basic probabilistic method: showing that a certain randomized approach produces a good approximation with positive probability. This approach seems inherently sequential; by employing the method of alteration we present the first RNC and NC approximation algorithms that match the best sequential guarantees. Extending our approach, we get the first RNC and NC approximation algorithms for certain multi-criteria versions of these problems. We also present the first NC algorithms for two packing and covering problems that are not subsumed by the above result: finding large independent sets in graphs, and rounding fractional Group Steiner solutions on trees.
SODA	Domatic partitions and the Lovász local lemma.	Aravind Srinivasan	2001	Domatic partitions and the Lovász local lemma.
SODA	Approximating the minimum strongly connected subgraph via a matching lower bound.	Adrian Vetta	2001	We present a 3/2-approximation algorithm for the problem of finding a minimum strongly connected spanning subgraph in a given directed graph. As a corollary we obtain a 3/2-approximation algorithm for the more general minimum equivalent digraph problem. The performance of our algorithm is measured against a lower bound obtained from a simple matching problem. The performance guarantee is optimal with respect to the lower bound.
SODA	Distribution sort with randomizing cycle.	Jeffrey Scott Vitter,David A. Hutchinson	2001	Parallel independent disks can enhance the performance of external memory (EM) algorithms, but the programming task is often difficult. In this paper we develop randomized variants of distribution sort for use with parallel independent disks. We propose a simple variant called randomized cycling distribution sort (RCD) and prove that it has optimal expected I/O complexity. The analysis uses a novel reduction to a model with significantly fewer probabilistic interdependencies. Experimental evidence is provided to support its practicality. Other simple variants are also examined experimentally and appear to offer similar advantages to RCD. Based upon ideas in RCD we propose general techniques that transparently simulate algorithms developed for the unrealistic multihead disk model so that they can be run on the realistic parallel disk model. The simulation is optimal for two important classes of algorithms; the class of multipass algorithms, which make a complete pass through their data before accessing any element a second time, and the algorithms based upon the well-known distribution paradigm of EM computation.
SODA	Absolute convergence: true trees from short sequences.	Tandy Warnow,Bernard M. E. Moret,Katherine St. John	2001	Fast-converging methods for reconstructing phylogenetic trees require that the sequences characterizing the taxa be of only polynomial length, a major asset in practice, since real-life sequences are of bounded length. However, of the half-dozen such methods proposed over the last few years, only two fulfill this condition without requiring knowledge of typically unknown parameters, such as the evolutionary rate(s) used in the model; this additional requirement severely limits the applicability of the methods. We say that methods that need such knowledge demonstrate relative fast convergence, since they rely upon an oracle. We focus on the class of methods that do not require such knowledge and thus demonstrate absolute fast convergence. We give a very general construction scheme that not only turns any relative fast-converging method into an absolute fast-converging one, but also turns any statistically consistent method that converges from sequence of length &Ogr;(e&Ogr;(diam(T))) into an absolute fast-converging method.
SODA	Assigning chain-like tasks to a chain-like network.	Gerhard J. Woeginger	2001	We investigate the allocation of a chain-like task system consisting of n tasks to a chain-like network of m computers so as to minimize the bottleneck processing cost. We present an &Ogr;(mn) time solution algorithm for this problem. This improves on a sequence of five slower algorithms by Bokhari [1988], Sheu & Chiang [1990], Hsu [1993], and Young & Chan [1993,1994].
SODA	Practical approximation algorithms for zero- and bounded-skew trees.	Alexander Zelikovsky,Ion I. Mandoiu	2001	The skew of an edge-weighted rooted tree is the maximum difference between any two root-to-leaf path weights. Zero- or bounded-skew trees are needed for achieving synchronization in many applications, including network multicasting [21] and VLSI clock routing [3, 18]. In these applications edge weights represent propagation delays, and a signal generated at the root should be received by multiple recipients located at the leaves (almost) simultaneously. The objective is to find zero- or bounded-skew trees of minimum total weight, since the weight of the tree is directly proportional to the amount of resources that must be allocated to the tree. Charikar et al. [9] have recently proposed the first strongly polynomial algorithms with proven constant approximation factors, 2e &ap; 5.44 and 16.86, for finding minimum weight zero- and bounded-skew trees, respectively. In this paper we introduce a new approach to these problems, based on zero-skew &ldquo;stretching&rdquo; of spanning trees, and obtain algorithms with improved approximation factors of 4 and 14. For the case when tree nodes are points in the plane and edge weights are given by the rectilinear metric our algorithms find zero- and bounded-skew trees of length at most 3 and 9 times the optimum. This case is of special interest in VLSI clock routing. An important feature of our algorithms is their practical running time, which is asymptotically the same as the time needed for computing the minimum spanning tree.
SODA	Shape sensitive geometric permutations.	Yunhong Zhou,Subhash Suri	2001	We prove that a set of n unit balls in Rd admits at most four distinct geometric permutations, or line transversals, thus settling a long-standing conjecture in combinatorial geometry. The constant bound significantly improves upon the &THgr;(nd-1) bound for the balls of arbitrary radii. Intrigued by this large gap between the two bounds, we also investigate how the number of geometric permutations varies as a function of shape, size, and spacing of objects. Our results include a tight bound of 2d-1 on the geometric permutations of n disjoint rectangular boxes in Rd, and a constant bound on the geometric permutations for disks in the plane when the ratio between the largest to smallest disks is bounded. An important consequence of the former theorem is that if the smallest bounding boxes containing a set of geometric objects in Rd are pairwise disjoint, then those objects admit only 2d-1 permutations, which is a significant improvement on the &Ogr;(n2d-2) bound known for general convex objects.
SODA	Proceedings of the Twelfth Annual Symposium on Discrete Algorithms, January 7-9, 2001, Washington, DC, USA.	S. Rao Kosaraju	2001	Proceedings of the Twelfth Annual Symposium on Discrete Algorithms, January 7-9, 2001, Washington, DC, USA.
STOC	A sharp threshold in proof complexity.	Dimitris Achlioptas,Paul Beame,Michael S. O. Molloy	2001	We give the first example of a sharp threshold in proof complexity. More precisely, we show that for any sufficiently small &egr;>0 and &Dgr;>2.28, random formulas consisting of (1-&egr;)n 2-clauses and &Dgr n 3-clauses, which are known to be unsatisfiable almost certainly, almost certainly require resolution and Davis-Putnam proofs of unsatisfiability of exponential size, whereas it is easily seen that random formulas with (1+&egr;)n 2-clauses (and &Dgr; n 3 clauses) have linear size proofs of unsatisfiability almost certainly.A consequence of our result also yields the first proof that typical random 3-CNF formulas at ratios below the generally accepted range of the satisfiability threshold (and thus expected to be satisfiable almost certainly) cause natural Davis-Putnam algorithms to take exponential time to find satisfying assignments.
STOC	Fast computation of low rank matrix.	Dimitris Achlioptas,Frank McSherry	2001	Fast computation of low rank matrix.
STOC	A sieve algorithm for the shortest lattice vector problem.	Miklós Ajtai,Ravi Kumar,D. Sivakumar	2001	We present a randomized 2^{O(n)} time algorithm to compute a shortest non-zero vector in an n-dimensional rational lattice. The best known time upper bound for this problem was 2^{O(n\log n)} first given by Kannan [7] in 1983. We obtain several consequences of this algorithm for related problems on lattices and codes, including an improvement for polynomial time approximations to the shortest vector problem. In this improvement we gain a factor of log log n in the exponent of the approximating factor.
STOC	Running time and program size for self-assembled squares.	Leonard M. Adleman,Qi Cheng,Ashish Goel,Ming-Deh A. Huang	2001	Recently Rothemund and Winfree [6] have considered the program size complexity of constructing squares by self-assembly. Here, we consider the time complexity of such constructions using a natural generalization of the Tile Assembly Model defined in [6]. In the generalized model, the Rothemund-Winfree construction of n \times n squares requires time &THgr;(n log n) and program size &THgr;(log n). We present a new construction for assembling n \times n squares which uses optimal time &THgr;(n) and program size &THgr;(\frac{log n}{log log n}). This program size is also optimal since it matches the bound dictated by Kolmogorov complexity. Our improved time is achieved by demonstrating a set of tiles for parallel self-assembly of binary counters. Our improved program size is achieved by demonstrating that self-assembling systems can compute changes in the base representation of numbers. Self-assembly is emerging as a useful paradigm for computation. In addition the development of a computational theory of self-assembly promises to provide a new conduit by which results and methods of theoretical computer science might be applied to problems of interest in biology and the physical sciences.
STOC	Quantitative solution of omega-regular games.	Luca de Alfaro,Rupak Majumdar	2001	We consider two-player games played for an infinite number of rounds, with ω-regular winning conditions. The games may be concurrent, in that the players choose their moves simultaneously and independently, and probabilistic, in that the moves determine a probability distribution for the successor state. We introduce quantitative game µ-calculus, and we show that the maximal probability of winning such games can be expressed as the fixpoint formulas in this calculus. We develop the arguments both for deterministic and for probabilistic concurrent games; as a special case, we solve probabilistic turn-based games with ω-regular winning conditions, which was also open. We also characterize the optimality, and the memory requirements, of the winning strategies. In particular, we show that while memoryless strategies suffice for winning games with safety and reachability conditions, Büchi conditions require the use of strategies with infinite memory. The existence of optimal strategies, as opposed to ε-optimal, is only guaranteed in games with safety winning conditions.
STOC	Optimal static range reporting in one dimension.	Stephen Alstrup,Gerth Stølting Brodal,Theis Rauhe	2001	We consider static one dimensional range searching problems. These problems are to build static data structures for an integer set S \subseteq U, where U = \{0,1,\dots,2^w-1\}, which support various queries for integer intervals of U. For the query of reporting all integers in S contained within a query interval, we present an optimal data structure with linear space cost and with query time linear in the number of integers reported. This result holds in the unit cost RAM model with word size w and a standard instruction set. We also present a linear space data structure for approximate range counting. A range counting query for an interval returns the number of integers in S contained within the interval. For any constant &egr;>0, our range counting data structure returns in constant time an approximate answer which is within a factor of at most 1+&egr; of the correct answer.
STOC	A new protocol and lower bounds for quantum coin flipping.	Andris Ambainis	2001	We present a new protocol and two lower bounds for quantum coin flipping. In our protocol, no dishonest party can achieve one outcome with probability more than 0.75. Then we show that out protocol is optimal among 3-round protocols of a certain form.For arbitrary quantum protocols, we show that if a protocol achieves a bias of at most ε, it must use at least Ω(log log 1ε) rounds of communication. This implies that the parallel repetition fails for quantum coin flipping. (The bias of a protocol cannot be arbitrarily decreased by running several copies of it in parallel.)
STOC	One-dimensional quantum walks.	Andris Ambainis,Eric Bach,Ashwin Nayak,Ashvin Vishwanath,John Watrous	2001	We define and analyze quantum computational variants of random walks on one-dimensional lattices. In particular, we analyze a quantum analog of the symmetric random walk, which we call the Hadamard walk. Several striking differences between the quantum and classical cases are observed. For example, when unrestricted in either direction, the Hadamard walk has position that is nearly uniformly distributed in the range [-t/\sqrt 2, t/\sqrt 2] after t steps, which is in sharp contrast to the classical random walk, which has distance O(\sqrt t) from the origin with high probability. With an absorbing boundary immediately to the left of the starting position, the probability that the walk exits to the left is 2/&pgr, and with an additional absorbing boundary at location n, the probability that the walk exits to the left actually increases, approaching 1/\sqrt 2 in the limit. In the classical case both values are 1.
STOC	Quantum walks on graphs.	Dorit Aharonov,Andris Ambainis,Julia Kempe,Umesh V. Vazirani	2001	We set the ground for a theory of quantum walks on graphs-the generalization of random walks on finite graphs to the quantum world. Such quantum walks do not converge to any stationary distribution, as they are unitary and reversible. However, by suitably relaxing the definition, we can obtain a measure of how fast the quantum walk spreads or how confined the quantum walk stays in a small neighborhood. We give definitions of mixing time, filling time, dispersion time. We show that in all these measures, the quantum walk on the cycle is almost quadratically faster then its classical correspondent. On the other hand, we give a lower bound on the possible speed up by quantum walks for general graphs, showing that quantum walks can be at most polynomially faster than their classical counterparts.
STOC	The complexity of analytic tableaux.	Noriko H. Arai,Toniann Pitassi,Alasdair Urquhart	2001	The method of analytic tableaux is employed in many introductory texts and has also been used quite extensively as a basis for automated theorem proving. In this paper, we discuss the complexity of the system as a method for refuting contradictory sets of clauses, and resolve several open questions. We discuss the three forms of analytic tableaux: clausal tableaux, generalized clausal tableaux, and binary tableaux. We resolve the relative complexity of these three forms of tableaux proofs and also resolve the relative complexity of analytic tableaux versus resolution. We show that there is a quasi-polynomial simulation of tree resolution by analytic tableaux; this simulation cannot be improved, since we give a matching lower bound that is tight to within a polynomial.
STOC	Local search heuristic for k-median and facility location problems.	Vijay Arya,Naveen Garg,Rohit Khandekar,Adam Meyerson,Kamesh Munagala,Vinayaka Pandit	2001	We analyze local search heuristics for the metric k-median and facility location problems. We define the locality gap of a local search procedure for a minimization problem as the maximum ratio of a locally optimum solution (obtained using this procedure) to the global optimum. For k-median, we show that local search with swaps has a locality gap of 5. Furthermore, if we permit up to p facilities to be swapped simultaneously, then the locality gap is 3+2/p. This is the first analysis of a local search for k-median that provides a bounded performance guarantee with only k medians. This also improves the previous known 4 approximation for this problem. For uncapacitated facility location, we show that local search, which permits adding, dropping, and swapping a facility, has a locality gap of 3. This improves the bound of 5 given by M. Korupolu, C. Plaxton, and R. Rajaraman [Analysis of a Local Search Heuristic for Facility Location Problems, Technical Report 98-30, DIMACS, 1998]. We also consider a capacitated facility location problem where each facility has a capacity and we are allowed to open multiple copies of a facility. For this problem we introduce a new local search operation which opens one or more copies of a facility and drops zero or more facilities. We prove that this local search has a locality gap between 3 and 4.
STOC	Spectral analysis of data.	Yossi Azar,Amos Fiat,Anna R. Karlin,Frank McSherry,Jared Saia	2001	Experimental evidence suggests that spectral techniques are valuable for a wide range of applications. A partial list of such applications include (i) semantic analysis of documents used to cluster documents into areas of interest, (ii) collaborative filtering --- the reconstruction of missing data items, and (iii) determining the relative importance of documents based on citation/link structure. Intuitive arguments can explain some of the phenomena that has been observed but little theoretical study has been done. In this paper we present a model for framing data mining tasks and a unified approach to solving the resulting data mining problems using spectral analysis. These results give strong justification to the use of spectral techniques for latent semantic indexing, collaborative filtering, and web site ranking.
STOC	Sampling algorithms: lower bounds and applications.	Ziv Bar-Yossef,Ravi Kumar,D. Sivakumar	2001	We develop a framework to study probabilistic sampling algorithms that approximate general functions of the form \genfunc, where \domain and \range are arbitrary sets. Our goal is to obtain lower bounds on the query complexity of functions, namely the number of input variables x_i that any sampling algorithm needs to query to approximate f(x_1,\ldots,x_n).We define two quantitative properties of functions --- the it block sensitivity and the minimum Hellinger distance --- that give us techniques to prove lower bounds on the query complexity. These techniques are quite general, easy to use, yet powerful enough to yield tight results. Our applications include the mean and higher statistical moments, the median and other selection functions, and the frequency moments, where we obtain lower bounds that are close to the corresponding upper bounds.We also point out some connections between sampling and streaming algorithms and lossy compression schemes.
STOC	Approximating min-sum -clustering in metric spaces.	Yair Bartal,Moses Charikar,Danny Raz	2001	The min-sum k-clustering problem in a metric space is to find a partition of the space into k clusters as to minimize the total sum of distances between pairs of points assigned to the same cluster. We give the first polynomial time non-trivial approximation algorithm for this problem. The algorithm provides an $\ratio$ approximation to the min-sum k-clustering problem in general metric spaces, with running time $\runtime$. The result is based on embedding of metric spaces into hierarchically separated trees. We also provide a bicriteria approximation result that provides a constant approximation factor solution with only a constant factor increase in the number of clusters. This result is obtained by modifying and drawing ideas from recently developed primal dual approximation algorithms for facility location.
STOC	Non-clairvoyant scheduling to minimize the average flow time on single and parallel machines.	Luca Becchetti,Stefano Leonardi	2001	Scheduling a sequence of jobs released over time when the processing time of a job is only known at its completion is a classical problem in CPU scheduling in time sharing operating systems. A widely used measure for the responsiveness of the system is the average flow time of the jobs, i.e. the average time spent by jobs in the system between release and completion.The Windows NT and the Unix operating system scheduling policies are based on the Multi-level Feedback algorithm [12, 1]. In this paper we prove that a randomized version of the Multi-level Feedback algorithm is competitive for single and parallel machine systems, in our opinion providing one theoretical validation of the goodness of an idea that has been very effective in practice along the last two decades.The randomized Multi-level Feedback algorithm (RMLF) was first proposed by Kalyanasundaram and Pruhs [7] for a single machine achieving an O(\log n \log\log n) competitive ratio to minimize the average flow time against the on-line adaptive adversary, where n is the number of jobs that are released. We present a version of RMLF working for any numberm of parallel machines. We show for RMLF a first O(\log n\log \frac{n}{m}) competitiveness result against the oblivious adversary on parallel machines. We also show that the same RMLF algorithm surprisingly achieves a tight O(\log n) competitive ratio against the oblivious adversary on a single machine, therefore matching the lower bound of [10].
STOC	A read-once branching program lower bound of Omega(2) for integer multiplication using universal.	Beate Bollig,Philipp Woelfel	2001	A read-once branching program lower bound of Omega(2) for integer multiplication using universal.
STOC	Sharp threshold and scaling window for the integer partitioning problem.	Christian Borgs,Jennifer T. Chayes,Boris Pittel	2001	We consider the problem of partitioning n integers chosen randomly between 1 and 2^m into two subsets such that the discrepancy, the absolute value of the difference of their sums, is minimized. A partition is called perfect if the optimum discrepancy is 0 when the sum of all n integers in the original set is even, or 1 when the sum is odd. Parameterizing the random problem in terms of &kgr; = m/n, we prove that the problem has a sharp threshold at &kgr; = 1, in the sense that for &kgr; , there are many perfect partitions with probability tending to 1 as n \to \infty, while for 1, there are no perfect partitions with probability tending to 1. Moreover, we show that the derivative of the so-called entropy is discontinuous at &kgr;=1.We also determine the scaling window about the transition point: &kgr;_n = 1 - (2n)^{-1}\log_2 n + &lgr;_n / n, by showing that the probability of a perfect partition tends to 0, 1, or some explicitly computable p(&lgr;) \in (0,1), depending on whether &lgr;_n tends to -\infty$, $\infty$, or $&lgr; \in (-\infty, \infty), respectively. For &lgr;_n \to -\infty fast enough, we show that the number of perfect partitions is Gaussian in the limit. For &lgr;_n \to \infty, we prove that with high probability the optimum partition is unique, and that the optimum discrepancy is &thgr;(&lgr;_n). Within the window, i.e., if |&lgr;_n| is bounded, we prove that the optimum discrepancy is bounded. Both for &lgr;_n \to \infty and within the window, the limiting distribution of the (scaled) discrepancy
STOC	The complexity of maximal constraint languages.	Andrei A. Bulatov,Andrei A. Krokhin,Peter Jeavons	2001	Many combinatorial search problems can be expressed as &ldquo;constraint satisfaction problems&rdquo; using an appropriate &ldquo;constraint language&rdquo;, that is, a set of relations over some fixed finite set of values. It is well-known that there is a trade-off between the expressive power of a constraint language and the complexity of the problems it can express. In the present paper we systematically study the complexity of all maximal constraint languages, that is, languages whose expressive power is just weaker than that of the language of all constraints. Using the algebraic invariance properties of constraints, we exhibit a strong necessary condition for tractability of such a constraint language. Moreover, we show that, at least for small sets of values, this condition is also sufficient.
STOC	Black-box concurrent zero-knowledge requires Omega~(log n) rounds.	Ran Canetti,Joe Kilian,Erez Petrank,Alon Rosen	2001	Black-box concurrent zero-knowledge requires Omega~(log n) rounds.
STOC	Clustering to minimize the sum of cluster diameters.	Moses Charikar,Rina Panigrahy	2001	We study the problem of clustering points in a metric space so as to minimize the sum of cluster diameters or the sum of cluster radii. Significantly improving on previous results, we present a primal-dual based constant factor approximation algorithm for this problem. We present a simple greedy algorithm that achieves a logarithmic approximation. This also applies when the distance function is asymmetric and the objective is to minimize the sum of cluster radii. The previous best-known result obtained a logarithmic approximation with a constant factor blowup in the number of clusters. We also obtain an incremental clustering algorithm that maintains a solution whose cost is at most a constant factor times that of optimal with a constant factor blowup in the number of clusters.
STOC	Lower bounds for intersection searching and fractional cascading in higher dimension.	Bernard Chazelle,Ding Liu	2001	Given an n-edge convex subdivision of the plane, is it possible to report its k intersections with a query line segment in O(k + polylog(n)) time, using subquadratic storage? If the query is a plane and the input is a polytope with n vertices, can one achieve O(k + polylog(n)) time with subcubic storage? Does any convex polytope have a boundary dominant Dobkin-Kirkpatrick hierarchy? Can fractional cascading be generalized to planar maps instead of linear lists? We prove that the answer to all of these questions is no, and we derive near-optimal solutions to these classical problems.
STOC	Algorithms for minimizing weighted flow time.	Chandra Chekuri,Sanjeev Khanna,An Zhu	2001	We study the problem of minimizing weighted flow time on a single machine in the preemptive setting. We present an O(\log^2 P)-competitive semi-online algorithm where P is the ratio of the maximum and minimum processing times of jobs in the system. In the offline setting we show that a (2+\eps)-approximation is achievable in quasi-polynomial time. These are the first non-trivial results for the weighted versions of minimizing flow time. For multiple machines we show that no competitive randomized online algorithm exists for weighted flow time. We also present an improved online algorithm for minimizing total stretch (a special case of weighted flow time) on multiple machines.
STOC	Optimal outlier removal in high-dimensional.	John Dunagan,Santosh Vempala	2001	We study the problem of finding an outlier-free subset of a set of points (or a probability distribution) in n-dimensional Euclidean space. A point x is defined to be a &bgr;-outlier if there exists some direction w in which its squared distance from the mean along w is greater than &bgr; times the average squared distance from the mean along w [1]. Our main theorem is that for any &egr;>0, there exists a (1-&egr;) fraction of the original distribution that has no O(\frac{n}{&egr;}(b+log \frac{n}{&egr;))-outliers, improving on the previous bound of O(n^7b/&egr;). This bound is shown to be nearly the best possible. The theorem is constructive, and results in a \frac{1}{1-&egr;} approximation to the following optimization problem: given a distribution &mgr; (i.e. the ability to sample from it), and a parameter &egr;>0, find the minimum &bgr; for which there exists a subset of probability at least (1-&egr;) with no &bgr;-outliers.
STOC	Complex tilings.	Bruno Durand,Leonid A. Levin,Alexander Shen	2001	We study the minimal complexity of tilings of a plane with a given tile set. We note that any tile set admits either no tiling or some tiling with \ooo(n) Kolmogorov complexity of its (n\times n)-squares. We construct tile sets for which this bound is nearly tight: all tilings have complexity >n/r(n), given any unbounded computable monotone r. This adds a quantitative angle to classical results on non-recursivity of tilings -- that we also develop in terms of Turing degrees of unsolvability.
STOC	Excellent codes from modular curves.	Noam D. Elkies	2001	We introduce a new construction of error-correcting codes from algebraic curves over finite fields. Modular curves of genus g\ra\infty over a field of size q_0^2 yield nonlinear codes more efficient than the linear Goppa codes obtained from the same curves. These new codes now have the highest asymptotic transmission rates known for certain ranges of alphabet size and error rate. Both the theory and possible practical use of these new record codes require the development of new tools. On the theoretical side, establishing the transmission rate depends on an error estimate for a theorem of Schanuel applied to the function field of an asymptotically optimal curve. On the computational side, actual use of the codes will hinge on the solution of new problems in the computational algebraic geometry of curves.
STOC	(1+epsilon, beta)-spanner constructions for general graphs.	Michael Elkin,David Peleg	2001	"An {\em $(\alpha,\beta)$-spanner} of a graph G is a subgraph H such that $\mathit{dist}_H(u,w)\le \alpha\cdot \mathit{dist}t_G(u,w)+\beta$ for every pair of vertices u,w, where distG'(u,w) denotes the distance between two vertices u and v in G'. It is known that every graph G has a polynomially constructible $(2\kappa-1,0)$-spanner (also known as multiplicative $(2\kappa-1)$-spanner) of size $O(n^{1+1/\kappa})$ for every integer $\kappa\ge 1$, and a polynomially constructible (1,2)-spanner (also known as additive 2-spanner) of size ${\tilde O}(n^{3/2})$. This paper explores hybrid spanner constructions (involving both multiplicative and additive factors) for general graphs and shows that the multiplicative factor can be made arbitrarily close to 1 while keeping the spanner size arbitrarily close to O(n), at the cost of allowing the additive term to be a sufficiently large constant. More formally, we show that for any constant $\epsilon, \lambda > 0$ there exists a constant $\beta = \beta(\epsilon, \lambda)$ such that for every $n$-vertex graph G there is an efficiently constructible $(1+ \epsilon, \beta)$-spanner of size $O(n^{1 + \lambda})$."
STOC	Biased dictionaries with fast insert/deletes.	Funda Ergün,Süleyman Cenk Sahinalp,Jonathan Sharp,Rakesh K. Sinha	2001	A dictionary data structure supports efficient search, insert, and delete operations on n keys from a totally ordered universe. Red-black trees, 2-3 trees, AVL trees, skip lists and other classic data structures facilitate O(logn) time search, insert and deletes, matching the information theoretic lower bound when access probabilities are uniform i.i.d. If access probabilities are non-uniform but still i.i.d., there are other weighted data structures such as D-trees, biased search trees, splay trees and treaps which can achieve optimality.In many applications, however, the source of nonuniformity in access probabilities is locality of reference: examples include memory, cache, disk and buffer management and emerging applications in internetwork traffic management. In such applications, the access probability of any given key is not i.i.d., but decreases with idle time since the last access to the key.It is possible to adjust the weighted dictionaries to achieve optimal search time even under time dependent distributions; however insert/delete times will be suboptimal at O(logn). In this paper, we present a lazy updating scheme which can be applied to weighted dictionaries to improve their amortized insert/delete performance when access probabilities decrease with time; optimality of search time is preserved. More speci%cally, let r(k) be the number of distinct keys accessed since the last access to key k- that is r(k) is the move-to-front rank of k. Let rmax(k) be the maximum rank of k during its lifetime. Then our lazy update scheme enables the abovementioned data structures to perform search in O(log r(k)) time and insert/delete in O(log rmax(k)) time. We illustrate our lazy update scheme in the context of a new Biased Skip List data structure and show that our bounds are optimal.
STOC	On the integrality ratio of semidefinite relaxations of MAX CUT.	Uriel Feige,Gideon Schechtman	2001	MAX CUT is the problem of partitioning the vertices of a graph into two sets, maximizing the number of edges joining these sets. This problem is NP-hard. Goemans and Williamson proposed an algorithm that first uses a semidefinite programming relaxation of MAX CUT to embed the vertices of the graph on the surface of an n dimensional sphere, and then uses a random hyperplane to cut the sphere in two, giving a cut of the graph. They show that the expected number of edges in the random cut is at least &agr; \cdot sdp, where &agr; \simeq 0.87856 and sdp is the value of the semidefinite program.This manuscript shows the following results:1. The integrality ratio of the semidefinite program is &agr;. The previously known bound on the integrality ratio was roughly 0.8845.2. In the presence of the so called &ldquo;triangle constraints&rdquo;, the integrality ratio is no better than roughly 0.891. The previously known bound was above 0.95.
STOC	Testing of matrix properties.	Eldar Fischer,Ilan Newman	2001	"Combinatorial property testing deals with the following relaxation of decision problems: Given a fixed property P and an input f, distinguish between the case that f satisfies P, and the case that no input that differs from f in less than some fixed fraction of the places satisfies P. An (&egr;,q)-test for P is a randomized algorithm that queries at most q places of an input x and distinguishes with probability 2/3 between the case that f has the property and the case that at least an &egr;-fraction of the places of f need to be changed in order for it to have the property.Here we concentrate on labeled, d-dimensional grids, where the grid is viewed as a partially ordered set (poset) in the standard way (i.e as a product order of total orders). The main result here is an (&egr,poly(1/&egr))-test for every property of 0/1 labeled, d-dimensional grids that is characterized by a finite collection of forbidden induced posets. Such properties include the `monotonicity' property and many other properties. A (less efficient) test for such properties with larger fixed size alphabets is also presented. Another result is a more efficient test than was previously known for a collection of bipartite graph properties.Both collections above are variants of properties that are defined by certain first order formulae with no quantifier alternation over the syntax containing the grid order relations (and some additional relations for the bipartite graph properties). We also show that with one quantifier alternation, a certain property can be defined, for which no test with query complexity of O(n^{1/10}) exists. The above results identify new classes of efficiently"
STOC	Compatible sequences and a slow Winkler percolation.	Péter Gács	2001	"Two infinite 0-1 sequences are called compatible when it is possible to cast out 0's from both in such a way that they become complementary to each other. Answering a question of Peter Winkler, we show that if the two 0-1-sequences are random i.i.d. and independent from each other, with probability p of 1's, then if p is sufficiently small they are compatible with positive probability. The question is equivalent to a certain dependent percolation with a power-law behavior: the probability that the origin is blocked at distance n but not closer decreases only polynomially fast and not, as usual, exponentially."
STOC	One line and n points.	Bernd Gärtner,József Solymosi,Falk Tschirschnitz,Emo Welzl,Pavel Valtr	2001	One line and n points.
STOC	The round complexity of verifiable secret sharing and secure multicast.	Rosario Gennaro,Yuval Ishai,Eyal Kushilevitz,Tal Rabin	2001	"The round complexity of interactive protocols is one of their most important complexity measures. In this work we study the exact round complexity of two basic secure computation tasks: Verifiable Secret Sharing (VSS) and Secure Multicast.VSS allows a dealer to share a secret among several players in a way that would later allow a unique reconstruction of the secret. It is a well-studied primitive, which is used as a building block in virtually every general protocol for secure multi-party computation. Secure multicast is perhaps the simplest non-trivial instance of a secure computation. It allows a dealer to securely distribute an identical message to all players in a prescribed subset M. Both types of protocols are parameterized by the number of players, n, and a security threshold, t, which bounds the total number of malicious players (possibly including the dealer).We focus on a standard setting of perfect information-theoretic security, where all players have access to secure point-to-point channels and a common broadcast medium. For both types of primitives we prove, using related techniques, tight tradeoffs between the round complexity and the achievable security threshold. Specifically, for the VSS problem we show:2-round VSS is possible iff n>4t, where the ``if'' direction is realized by an efficient protocol.3-round VSS is possible iff n>3t, where the ``if'' direction is realized by an inefficient protocol.4-round efficient VSS is possible if n>3t.For the secure multicast problem we show:2-round secure multicast is (efficiently) possible iff"
STOC	Approximation algorithms for MAX-3-CUT and other problems via complex semidefinite programming.	Michel X. Goemans,David P. Williamson	2001	A number of recent papers on approximation algorithms have used the square roots of unity, - 1 and 1, to represent binary decision variables for problems in combinatorial optimization, and have relaxed these to unit vectors in real space using semidefinite programming in order to obtain near optimum solutions to these problems. In this paper, we consider using the cube roots of unity, 1, ei2π/3, and ei4π/3, to represent ternary decision variables for problems in combinatorial optimization. Here the natural relaxation is that of unit vectors in complex space. We use an extension of semidefinite programming to complex space to solve the natural relaxation, and use a natural extension of the random hyperplane technique introduced by the authors in Goemans and Williamson (J. ACM 42 (1995) 1115-1145) to obtain near-optimum solutions to the problems. In particular, we consider the problem of maximizing the total weight of satisfied equations xu - xv ≡ c (mod 3) and inequations xu - xv ≢ c (mod 3), where xu ∈ {0, 1, 2} for all u. This problem can be used to model the MAX-3-CUT problem and a directed variant we call MAX-3-DICUT. For the general problem, we obtain a 0.793733-approximation algorithm. If the instance contains only inequations (as it does for MAX-3-CUT), we obtain a performance guarantee of 7/12 + 3/4π2 arccos2(-1/4) - ε > 0.836008. This compares with proven performance guarantees of 0.800217 for MAX-3-CUT (by Frieze and Jerrum (Algorithmica 18 (1997) 67-81) and 1/3 + 10-8 for the general problem (by Andersson et al. (J. Algorithms 39 (2001) 162-204)). It matches the guarantee of 0.836008 for MAX-3-CUT found independently by de Klerk et al. (On approximate graph colouring and Max-k-Cut algorithms based on the ℓ-function, Manuscript, October 2000). We show that all these algorithms are in fact equivalent in the case of MAX-3- CUT, and that our algorithm is the same as that of Anderson et al. in the general case.
STOC	Quantum mechanical algorithms for the nonabelian hidden subgroup problem.	Michelangelo Grigni,Leonard J. Schulman,Monica Vazirani,Umesh V. Vazirani	2001	We provide positive and negative results concerning the &ldquo;standard method&rdquo; of identifying a hidden subgroup of a nonabelian group using a quantum computer.
STOC	Computing crossing numbers in quadratic time.	Martin Grohe	2001	We show that for every fixed k ≥ 0 there is a quadratic time algorithm that decides whether a given graph has crossing number at most k and, if this is the case, computes a drawing of the graph into the plane with at most k crossings.
STOC	When is the evaluation of conjunctive queries tractable?	Martin Grohe,Thomas Schwentick,Luc Segoufin	2001	The evaluation of conjunctive queries is hard both with respect to its combined complexity (NP-complete) and its parameterized complexity (W[1]-complete). It becomes tractable (PTIME for combined complexity, FPT for parameterized complexity), when the underlying graphs of the conjunctive queries have bounded tree-width [2]. We show that, in some sense, this is optimal both with respect to combined and parameterized complexity: For every class C of graphs, the evaluation of all conjunctive queries whose underlying graph is in C is tractable if, and only if, C has bounded tree-width.A technical result of independent interest is that the colored grid homomorphism problem is NP-complete and, if parameterized by the grid size, W[1]-complete.
STOC	Data-streams and histograms.	Sudipto Guha,Nick Koudas,Kyuseok Shim	2001	Histograms have been used widely to capture data distribution, to represent the data by a small number of step functions. Dynamic programming algorithms which provide optimal construction of these histograms exist, albeit running in quadratic time and linear space. In this paper we provide linear time construction of 1 + &egr; approximation of optimal histograms, running in polylogarithmic space.Our results extend to the context of data-streams, and in fact generalize to give 1 + &egr; approximation of several problems in data-streams which require partitioning the index set into intervals. The only assumptions required are that the cost of an interval is monotonic under inclusion (larger interval has larger cost) and that the cost can be computed or approximated in small space. This exhibits a nice class of problems for which we can have near optimal data-stream algorithms.
STOC	A constant factor approximation for the single sink edge installation problems.	Sudipto Guha,Adam Meyerson,Kamesh Munagala	2001	We present the first constant approximation to the single sink buy-at-bulk network design problem, where we have to design a network by buying pipes of different costs and capacities per unit length to route demands at a set of sources to a single sink. The distances in the underlying network form a metric. This result improves the previous bound of $O(\log|R|)$, where $R$ is the set of sources. We also present a better constant approximation to the related Access Network Design problem. Our algorithms are randomized and combinatorial. As a subroutine in our algorithm, we use an interesting variant of facility location with lower bounds on the amount of demand an open facility needs to serve. We call this variant load balanced facility location and present a constant factor approximation for it, while relaxing the lower bounds by a constant factor.
STOC	Provisioning a virtual private network: a network design problem for multicommodity flow.	Anupam Gupta,Jon M. Kleinberg,Amit Kumar,Rajeev Rastogi,Bülent Yener	2001	Consider a setting in which a group of nodes, situated in a large underlying network, wishes to reserve bandwidth on which to support communication. Virtual private networks (VPNs) are services that support such a construct; rather than building a new physical network on the group of nodes that must be connected, bandwidth in the underlying network is reserved for communication within the group, forming a virtual &ldquo;sub-network.&rdquo;Provisioning a virtual private network over a set off terminals gives rise to the following general network design problem. We have bounds on the cumulative amount of traffic each terminal can send and receive; we must choose a path for each pair of terminals, and a bandwidth allocation for each edge of the network, so that any traffic matrix consistent with the given upper bounds can be feasibly routed. Thus, we are seeking to design a network that can support a continuum of possible traffic scenarios.We provide optimal and approximate algorithms for several variants of this problem, depending on whether the traffic matrix is required to be symmetric, and on whether the designed network is required to be a tree (a natural constraint in a number of basic applications). We also establish a relation between this collection of network design problems and a variant of the facility location problem introduced by Karger and Minkoff; we extend their results by providing a stronger approximation algorithm for this latter problem.
STOC	Private approximation of NP-hard functions.	Shai Halevi,Robert Krauthgamer,Eyal Kushilevitz,Kobbi Nissim	2001	The notion of private approximation was introduced recently by Feigenbaum, Fong, Strauss and Wright. Informally, a private approximation of a function f is another function F that approximates f in the usual sense, but does not yield any information on x other than what can be deduced from f(x). As such, F(x) is useful for private computation of f(x) (assuming that F can be computed more efficiently than f.In this work we examine the properties and limitations of this new notion. Specifically, we show that for many NP-hard problems, the privacy requirement precludes non-trivial approximation. This is the case even for problems that otherwise admit very good approximation (e.g., problems with PTAS). On the other hand, we show that slightly relaxing the privacy requirement, by means of leaking &ldquo;just a few bits of informationrdquo; about x, again permits good approximation.
STOC	A tight bound for the complexity of voroni diagrams under polyhedral convex distance functions in 3D.	Christian Icking,Lihong Ma	2001	A tight bound for the complexity of voroni diagrams under polyhedral convex distance functions in 3D.
STOC	Applications of approximation algorithms to cooperative games.	Kamal Jain,Vijay V. Vazirani	2001	Applications of approximation algorithms to cooperative games.
STOC	Online server allocation in a server farm via benefit task systems.	T. S. Jayram,Tracy Kimbrel,Robert Krauthgamer,Baruch Schieber,Maxim Sviridenko	2001	"A web content hosting service provider needs to dynamically allocate servers in a server farm to its customers' web sites. Ideally, the allocation to a site should always suffice to handle its load. However, due to a limited number of servers and the overhead incurred in changing the allocation of a server from one site to another, the system may become overloaded. The problem faced by the web hosting service provider is how to allocate the available servers in the most profitable way. Adding to the complexity of this problem is the fact that future loads of the sites are either unknown or known only for the very near future.In this paper we model this server allocation problem, and consider both its offline and online versions. We give a polynomial time algorithm for computing the optimal offline allocation. In the online setting, we show almost optimal algorithms (both deterministic and randomized) for any positive lookahead. The quality of the solution improves as the lookahead increases. We also consider several special cases of practical interest. Finally, we present some experimental results using actual trace data that show that one of our online algorithm performs very close to optimal.Interestingly, the online server allocation problem can be cast as a more general benefit task system that we define. Our results extend to this task system, which captures also the benefit maximization variants of the k-server problem and the metrical task system problem. It follows that the benefit maximization variants of these problems are more tractable than their cost minimization variants."
STOC	A polynomial-time approximation algorithm for the permanent of a matrix with non-negative entries.	Mark Jerrum,Alistair Sinclair,Eric Vigoda	2001	We present a fully-polynomial randomized approximation scheme for computing the permanent of an arbitrary matrix with non-negative entries.
STOC	Dynamic TCP acknowledgement and other stories about e/(e-1).	Anna R. Karlin,Claire Kenyon,Dana Randall	2001	We present the first optimal randomized online algorithms for the TCP acknowledgment problem [5] and the Bahncard problem [7]. These problems are well-known to be generalizations of the classical online ski rental problem, however, they appeared to be harder. In this paper, we demonstrate that a number of online algorithms which have optimal competitive ratios of e/(e-1), including these, are fundamentally no more complex than ski rental. Our results also suggest a clear paradigm for solving ski rental-like problems.
STOC	Spatial gossip and resource location protocols.	David Kempe,Jon M. Kleinberg,Alan J. Demers	2001	The dynamic behavior of a network in which information is changing continuously over time requires robust and efficient mechanisms for keeping nodes updated about new information. Gossip protocols are mechanisms for this task in which nodes communicate with one another according to some underlying deterministic or randomized algorithm, exchanging information in each communication step. In a variety of contexts, the use of randomization to propagate information has been found to provide better reliability and scalability than more regimented deterministic approaches.In many settings --- consider a network of sensors, or a cluster of distributed computing hosts --- new information is generated at individual nodes, and is most &ldquo;interesting&rdquo; to nodes that are nearby. Thus, we propose distance-based propagation bounds as a performance measure for gossip algorithms: a node at distance d from the origin of a new piece of information should be able to learn about this information with a delay that grows slowly with d, and is independent of the size of the network.For nodes arranged with uniform density in Euclidean space, we present natural gossip algorithms that satisfy such a guarantee: new information is spread to nodes at distance \DIST, with high probability, in O(\log^{1 + \ve} \DIST) time steps. Such a bound combines the desirable qualitative features of uniform gossip, in which information is spread with a delay that is logarithmic in the full network size, and deterministic flooding, in which information is spread with a delay that is linear in the distance and independent of the network size. Our algorithms and their analysis resolve a conjecture of Demers et al. We show an application of our gossip algorithms to a basic resource location problem, in which nodes seek to rapidly
STOC	Buffer overflow management in QoS switches.	Alexander Kesselman,Zvi Lotker,Yishay Mansour,Boaz Patt-Shamir,Baruch Schieber,Maxim Sviridenko	2001	We consider two types of buffering policies that are used in network switches supporting Quality of Service (QoS). In the FIFO type, packets must be transmitted in the order in which they arrive; the constraint in this case is the limited buffer space. In the bounded-delay type, each packet has a maximum delay time by which it must be transmitted, or otherwise it is lost. We study the case of overloads resulting in packet loss. In our model, each packet has an intrinsic value, and the goal is to maximize the total value of transmitted packets.Our main contribution is a thorough investigation of some natural greedy algorithms in various models. For the FIFO model we prove tight bounds on the competitive ratio of the greedy algorithm that discards packets with the lowest value when an overflow occurs. We also prove that the greedy algorithm that drops the earliest packets among all low-value packets is the best greedy algorithm. This algorithm can be as much as 1.5 times better than the tail-drop greedy policy, which drops the latest lowest-value packets.In the bounded-delay model we show that the competitive ratio of any on-line algorithm for a uniform bounded-delay buffer is bounded away from 1, independent of the delay size. We analyze the greedy algorithm in the general case and in three special cases: delay bound 2, link bandwidth 1, and only two possible packet values.Finally, we consider the off-line scenario. We give efficient optimal algorithms and study the relation between the bounded-delay and FIFO models in this case.
STOC	Concurrent and resettable zero-knowledge in poly-loalgorithm rounds.	Joe Kilian,Erez Petrank	2001	A proof is concurrent zero-knowledge if it remains zero-knowledge when many copies of the proof are run in an asynchronous environment, such as the Internet. Richardson and Kilian have shown that there exists a concurrent zero-knowledge proof for any language in NP, but with round complexity polynomial in the maximum number of concurrent proofs. In this paper, we present a concurrent zero-knowledge proof for all languages in NP with a poly-logarithmic round complexity: specifically, &ohgr;(log^2 k) rounds given at most k concurrent proofs. Finally, we show that a simple modification of our proof is a resettable zero-knowledge proof for NP, with &ohgr;(log^2 k) rounds; previously known protocols required a polynomial number of rounds.
STOC	Interaction in quantum communication and the complexity of set disjointness.	Hartmut Klauck,Ashwin Nayak,Amnon Ta-Shma,David Zuckerman	2001	One of the most intriguing facts about communication using quantum states is that these states cannot be used to transmit more classical bits than the number of qubits used, yet in some scenarios there are ways of conveying information with exponentially fewer qubits than possible classically [3, 26]. Moreover, these methods have a very simple structure---they involve only few message exchanges between the communicating parties.We consider the question as to whether every classical protocol may be transformed to a &ldquo;simpler&rdquo; quantum protocol---one that has similar efficiency, but uses fewer message exchanges. We show that for any constant k, there is a problem such that its k+1 message classical communication complexity is exponentially smaller than its k message quantum communication complexity, thus answering the above question in the negative. This in particular proves a round hierarchy theorem for quantum communication complexity, and implies via a simple reduction, an \Omega(N^{1/k}) lower bound for k message protocols for Set Disjointness for constant~k.Our result builds on two primitives, local transitions in bi-partite states (based on previous work) and average encoding which may be of significance in other contexts as well.
STOC	Randomness efficient identity testing of multivariate polynomials.	Adam Klivans,Daniel A. Spielman	2001	We present a randomized polynomial time algorithm to determine if a multivariate polynomial is zero using O(\log mn&dgr;) random bits where n is the number of variables, m is the number of monomials, and &dgr; is the total degree of the unknown polynomial. All other known randomized identity tests (see for example [7, 12, 1]) use &ohgr;(n) random bits even when the polynomial is sparse and has low total degree. In such cases our algorithm has an exponential savings in randomness. In addition, we obtain the first polynomial time algorithm for interpolating sparse polynomials over finite fields of large characteristic. Our approach uses an error correcting code combined with the randomness optimal isolation lemma of [8] and yields a generalized isolation lemma which works with respect to a set of linear forms over a base set.
STOC	Learning DNF in time 2.	Adam Klivans,Rocco A. Servedio	2001	Using techniques from learning theory, we show that any s-term DNF over n variables can be computed by a polynomial threshold function of degree O(n1/3 log s). This upper bound matches, up to a logarithmic factor, the longstanding lower bound given by Minsky and Papert in their 1968 book Perceptrons. As a consequence of this upper bound we obtain the fastest known algorithm for learning polynomial size DNF, one of the central problems in computational learning theory.
STOC	Euler paths in series parallel graphs.	S. Rao Kosaraju	2001	Given a series-parallel graph, we consider the problem of drawing its layout in the plane (and the planar dual of the layout) such that the euler count of the layout is minimized. This problem is of considerable importance to the design of CMOS circuits. Even though it was believed that there cannot exist a polynomial time algorithm for this problem, we have been able to design a polynomial time algorithm. The degree of the polynomial is unrealistically large. The main interest is in the existence of a polynomial time algorithm for the problem. We are not aware of any natural problem for which a natural dynamic programming based algorithm has such a large degree.
STOC	Explicit lower bound of for boolena circuits.	Oded Lachish,Ran Raz	2001	We prove a lower bound of 4.5n - o(n) for the circuit complexity of an explicit Boolean function (that is, a function constructible in deterministic polynomial time), over the basis U_2. That is, we obtain a lower bound of 4.5n - o(n) for the number of {and,or} gates needed to compute a certain Boolean function, over the basis {and,or,not} (where the not gates are not counted). Our proof is based on a new combinatorial property of Boolean functions, called Strongly-Two-Dependence, a notion that may be interesting in its own right. Our lower bound applies to any Strongly-Two-Dependent Boolean function.
STOC	The price of selfish routing.	Marios Mavronicolas,Paul G. Spirakis	2001	We study the problem of routing traffic through a congested network. We focus on the simplest case of a network consisting of m parallel links. We assume a collection of n network users, each employing a mixed strategy which is a probability distribution over links, to control the shipping of its own assigned traffic. Given a capacity for each link specifying the rate at which the link processes traffic, the objective is to route traffic so that the maximum expected latency over all links is minimized. We consider both uniform and non-uniform link capacities.How much decrease in global performace is necessary due to the absence of some central authority to regulate network traffic and implement an optimal assignment of traffic to links? We investigate this fundamental question in the context of Nash equilibria for such a system, where each network user selfishly routes its traffic only on those links available to it that minimize its expected latency cost, given the network congestion caused by the other users. We use the coordination ratio, defined by Koutsoupias and Papadimitriou [25] as the ratio of the maximum (over all links) expected latency in the worst possible Nash equlibrium, over the least possible maximum latency had global regulation been available, as a measure of the cost of lack of coordination among the network users.
STOC	Profit-earning facility location.	Adam Meyerson	2001	We consider opening facilities in order to gain a profit. We are given a set of demand points, and we must open some set of facilities such that every demand may be satisfied from a local facility and the total profit gained in this process is maximized. This contrasts with previous work on facility location and k-center problems, where opening a facility incurred a cost. The profit gained by opening a facility is a function of the amount of demand the facility satisfies. We model the dependence of profit on demand by creating many different possible facilities at each location, each of which provides a certain profit if opened and requires at least a certain amount of demand in order to open. Our model captures problem instances where profits may be positive or negative, and also instances where it is not necessary to satisfy every demand. Our algorithms provide the optimum total profit, while stretching the definition of locality by a constant and violating the required demands by a constant. We prove that without this stretch, the problem becomes NP-Hard to approximate.
STOC	Colouring graphs when the number of colours is nearly the maximum degree.	Michael Molloy,Bruce A. Reed	2001	We consider for graphs of maximum degree &Dgr;, the problem of determining whether &khgr;G) > &Dgr;-k for various values of k. We obtain sharp theorems characterizing when the barrier to &Dgr;-k colourability must be a local condition, i.e. a small subgraph, and when it can be global. We also show that for large fixed &Dgr;, this problem is either NP-complete or can be solved in linear time, and we determine precisely which values of k correspond to each case prove that Hitting Set with sets of size B is hard to approximate to within a factor $B^{1/19}$. The problem can be approximated to within a factor B [19], and it is the Vertex Cover problem for B=2. The relationship between hardness of approximation and set size seems to have not been explored before.
STOC	Edge isoperimetry and rapid mixing on matroids and geometric Markov chains.	Ravi Montenegro,Jung-Bae Son	2001	We show how to bound the mixing time and log-Sobolev constants of Markov chains by bounding the edge-isoperimetry of their underlying graphs. To do this we use two recent techniques, one involving Average Conductance and the other log-Sobolev constants. We show a sort of strong conductance bound on a family of geometric Markov chains, give improved bounds for the mixing time of a Markov chain on balanced matroids, and in both cases find lower bounds on the log-Sobolev constants of these chains.
STOC	Approximation algorithms for constrained for constrained node weighted steiner tree problems.	Anna Moss,Yuval Rabani	2001	"We consider a class of optimization problems, where the input is an undirected graph with two weight functions defined for each node, namely the node's profit and its cost. The goal is to find a connected set of nodes of low cost and high profit. We present approximation algorithms for three natural optimization criteria that arise in this context, all of which are NP-hard. The budget problem asks for maximizing the profit of the set subject to a budget constraint on its cost. The quota problem requires minimizing the cost of the set subject to a quota constraint on its profit. Finally, the prize collecting problem calls for minimizing the cost of the set plus the profit (here interpreted as a penalty) of the complement set. For all three problems, our algorithms give an approximation guarantee of O(\log n), where n is the number of nodes. To the best of our knowledge, these are the first approximation results for the quota problem and for the prize collecting problem, both of which are at least as hard to approximate as set cover. For the budget problem, our results improve on a previous O(\log^2 n) result of Guha, Moss, Naor, and Schieber. Our methods involve new theorems relating tree packings to (node) cut conditions. We also show similar theorems (with better bounds) using edge cut conditions. These imply bounds for the analogous budget and quota problems with edge costs which are comparable to known (constant factor) bounds."
STOC	Conditions on input vectors for consensus solvability in asynchronous distributed systems.	Achour Mostéfaoui,Sergio Rajsbaum,Michel Raynal	2001	"This article introduces and explores the condition-based approach to solve the consensus problem in asynchronous systems. The approach studies conditions that identify sets of input vectors for which it is possible to solve consensus despite the occurrence of up to f process crashes. The first main result defines acceptable conditions and shows that these are exactly the conditions for which a consensus protocol exists. Two examples of realistic acceptable conditions are presented, and proved to be maximal, in the sense that they cannot be extended and remain acceptable. The second main result is a generic consensus shared-memory protocol for any acceptable condition. The protocol always guarantees agreement and validity, and terminates (at least) when the inputs satisfy the condition with which the protocol has been instantiated, or when there are no crashes. An efficient version of the protocol is then designed for the message passing model that works when f < n/2, and it is shown that no such protocol exists when f &ge; n/2. It is also shown how the protocol's safety can be traded for its liveness."
STOC	On optimal slicing of parallel programs.	Markus Müller-Olm,Helmut Seidl	2001	Optimal program slicing determines for a statement S in a program &pgr; whether or not S affects a specified set of statements, given that all conditionals in &pgr; are interpreted as non-deterministic choices.Only recently, it has been shown that reachability of program points and hence also optimal slicing is undecidable for multi-threaded programs with (parameterless) procedures and synchronization [23]. Here, we sharpen this result by proving that slicing remains undecidable if synchronization is abandoned---although reachability becomes polynomial. Moreover, we show for multi-threaded programs without synchronization, that slicing stays PSPACE-hard when procedure calls are forbidden, and becomes NP-hard for loop-free programs. Since the latter two problems can be solved in PSPACE and NP, respectively, even in presence of synchronization, our new lower bounds are tight.Finally, we show that the above decidability and lower bound properties equally apply to other simple program analysis problems like copy constant propagation and true liveness of variables. This should be contrasted to the problems of strong copy constant propagation and (ordinary) liveness of variables for which polynomial algorithms have been designed [15, 14, 24].
STOC	Communication preserving protocols for secure function evaluation.	Moni Naor,Kobbi Nissim	2001	"A secure function evaluation protocol allows two parties to jointly compute a function f(x,y) of their inputs in a manner not leaking more information than necessary. A major result in this field is: &ldquo;any function f that can be computed using polynomial resources can be computed securely using polynomial resources&rdquo; (where &ldquo;resources&rdquo; refers to communication and computation). This result follows by a general transformation from any circuit for f to a secure protocol that evaluates f. Although the resources used by protocols resulting from this transformation are polynomial in the circuit size, they are much higher (in general) than those required for an insecure computation of f.We propose a new methodology for designing secure protocols, utilizing the communication complexity tree (or branching program) representation of f. We start with an efficient (insecure) protocol for f and transform it into a secure protocol. In other words, ``any function f that can be computed using communication complexity c can be can be computed securely using communication complexity that is polynomial in c and a security parameter''. We show several simple applications of this new methodology resulting in protocols efficient either in communication or in computation. In particular, we exemplify a protocol for the Millionaires problem, where two participants want to compare their values but reveal no other information. Our protocol is more efficient than previously known ones in either communication or computation."
STOC	Anti-presistence: history independent data structures.	Moni Naor,Vanessa Teague	2001	Many data structures give away much more information than they were intended to. Whenever privacy is important, we need to be concerned that it might be possible to infer information from the memory representation of a data structure that is not available through its &ldquo;legitimate&rdquo; interface. Word processors that quietly maintain old versions of a document are merely the most egregious example of a general problem.We deal with data structures whose current memory representation does not reveal their history. We focus on dictionaries, where this means revealing nothing about the order of insertions or deletions. Our first algorithm is a hash table based on open addressing, allowing O(1) insertion and search. We also present a history independent dynamic perfect hash table that uses space linear in the number of elements inserted and has expected amortized insertion and deletion time O(1). To solve the dynamic perfect hashing problem we devise a general scheme for history independent memory allocation. For fixed-size records this is quite efficient, with insertion and deletion both linear in the size of the record. Our variable-size record scheme is efficient enough for dynamic perfect hashing but not for general use. The main open problem we leave is whether it is possible to implement a variable-size record scheme with low overhead.
STOC	On the cell probe complexity of membership and perfect hashing.	Rasmus Pagh	2001	"We study two fundamental static data structure problems, membership and perfect hashing, in Yao's cell probe model. The first space and bit probe optimal worst case upper bound is given for the membership problem. We also give a new efficient membership scheme where the query algorithm makes just one adaptive choice, and probes a total of three words. A lower bound shows that two word probes generally do not suffice. For minimal perfect hashing we show a tight bit probe lower bound, and give a simple scheme achieving this performance, making just one adaptive choice. Linear range perfect hashing is shown to be implementable with the same number of bit probes, of which just one is adaptive. In contrast, we establish that for sufficiently sparse sets, non-adaptive perfect hashing needs exponentially more bit probes. This is the first such separation of adaptivity and non-adaptivity."
STOC	Algorithms, games, and the internet.	Christos H. Papadimitriou	2001	Algorithms, games, and the internet.
STOC	Testing metric properties.	Michal Parnas,Dana Ron	2001	Finite metric spaces, and in particular tree metrics play an important role in various disciplines such as evolutionary biology and statistics. A natural family of problems concerning metrics is deciding, given a matrix M, whether or not it is a distance metric of a certain predetermined type. Here we consider the following relaxed version of such decision problems: For any given matrix M and parameter ε, we are interested in determining, by probing M, whether M has a particular metric property P, or whether it is ε-far from having the property. In ε-far we mean that at least an ε-fraction of the entries of M must be modified so that it obtains the property. The algorithm may query the matrix on entries M[i,j] of its choice, and is allowed a constant probability of error.We describe algorithms for testing Euclidean metrics, tree metrics and ultrametrics. Furthermore, we present an algorithm that tests whether a matrix M is an approximate ultrametric. In all cases the query complexity and running time are polynomial in 1/ε and independent of the size of the matrix. Finally, our algorithms can be used to solve relaxed versions of the corresponding search problems in time that is sub-linear in the size of the matrix.
STOC	Regular resolution lower bounds for the weak pigeonhole principle.	Toniann Pitassi,Ran Raz	2001	We prove that any regular resolution proof for the weak pigeon hole principle, with n holes and any number of pigeons, is of length &OHgr;(2^{n^{&egr;}}), (for some global constant &egr; > 0$).
STOC	Lower bounds for matrix product, in bounded depth circuits with arbitrary gates.	Ran Raz,Amir Shpilka	2001	We prove super-linear lower bounds for the number of edges in constant depth circuits with n inputs and up to n outputs. Our lower bounds are proved for all types of constant depth circuits, e.g., constant depth arithmetic circuits and constant depth Boolean circuits with arbitrary gates. The bounds apply for several explicit functions, and, most importantly, for matrix product. In particular, we obtain the following results:We show that the number of edges in any constant depth arithmetic circuit for matrix product (over any field is super-linear in m^2 (where m \times m is the size of each matrix). That is, the lower bound is super-linear in the number of input variables. Moreover, if the circuit is bilinear the result applies also for the case where the circuit gets for free any product of two linear functions.We show that the number of edges in any constant depth arithmetic circuit for the trace of the product of 3 matrices (over fields with characteristic~0) is super-linear in m^2. (Note that the trace is a single-output function).We give explicit examples for n Boolean functions f_1,\dots,f_ , such that any constant depth for f_1,...,f_n has a super-linear number of edges. The lower bound is proved also for circuits with arbitrary gates over any finite field. The bound applies for matrix product over finite fields as well as for several other explicit functions.
STOC	Stackelberg scheduling strategies.	Tim Roughgarden	2001	"We study the problem of optimizing the performance of a system shared by selfish, noncooperative users. We consider the concrete setting of scheduling small jobs on a set of shared machines possessing latency functions that specify the amount of time needed to complete a job, given the machine load. We measure system performance by the total latency of the system. Assigning jobs according to the selfish interests of individual users, who wish to minimize only the latency that their own jobs experience, typically results in suboptimal system performance. However, in many systems of this type there is a mixture of ""selfishly controlled"" and ""centrally controlled"" jobs. The congestion due to centrally controlled jobs will influence the actions of selfish users, and we thus aspire to contain the degradation in system performance due to selfish behavior by scheduling the centrally controlled jobs in the best possible way.We formulate this goal as an optimization problem via Stackelberg games, games in which one player acts a leader (here, the centralized authority interested in optimizing system performance) and the rest as followers (the selfish users). The problem is then to compute a strategy for the leader (a Stackelberg strategy) that induces the followers to react in a way that (approximately) minimizes the total latency in the system.In this paper, we prove that it is NP-hard to compute an optimal Stackelberg strategy and present simple strategies with provably good performance guarantees. More precisely, we give a simple algorithm that computes a strategy inducing a job assignment with total latency no more than a constant times that of the optimal assignment of all of the jobs; in the absence of centrally controlled jobs and a Stackelberg strategy, no result of this type is possible. We also prove stronger performance guarantees in the special case where every machine latency function is linear in the machine load."
STOC	Learning mixtures of arbitrary gaussians.	Sanjeev Arora,Ravi Kannan	2001	Learning mixtures of arbitrary gaussians.
STOC	Smoothed analysis of algorithms: why the simplex algorithm usually takes polynomial time.	Daniel A. Spielman,Shang-Hua Teng	2001	We introduce the smoothed analysis of algorithms, which continuously interpolates between the worst-case and average-case analyses of algorithms. In smoothed analysis, we measure the maximum over inputs of the expected performance of an algorithm under small random perturbations of that input. We measure this performance in terms of both the input size and the magnitude of the perturbations. We show that the simplex algorithm has smoothed complexity polynomial in the input size and the standard deviation of Gaussian perturbations.
STOC	Decidability of string graphs.	Marcus Schaefer,Daniel Stefankovic	2001	"We show that string graphs can be recognized in nondeterministic exponential time by giving an exponential upper bound on the number of intersections for a drawing realizing the string graph in the plane. This upper bound confirms a conjecture by Kratochv\'{\i}l and Matou\v{s}ek~\cite{KM91} and settles the long-standing open problem of the decidability of string graph recognition (Sinden~\cite{S66}, Graham~\cite{G76}). Finally we show how to apply the result to solve another old open problem: deciding the existence of Euler diagrams, a central problem of topological inference (Grigni, Papadias, Papadimitriou~\cite{GPP95})."
STOC	Loss-less condensers, unbalanced expanders, and extractors.	Amnon Ta-Shma,Christopher Umans,David Zuckerman	2001	"An extractor is a procedure which extracts randomness from a detective random source using a few additional random bits. Explicit extractor constructions have numerous applications and obtaining such constructions is an important derandomization goal. Trevisan recently introduced an elegant extractor construction, but the number of truly random bits required is suboptimal when the input source has low-min-entropy. Significant progress toward overcoming this bottleneck has been made, but so far has required complicated recursive techniques that lose the simplicity of Trevisan's construction. We give a clean method for overcoming this bottleneck by constructing {\em loss-less condensers}. which compress the n-bit input source without losing any min-entropy, using O(\log n) additional random bits. Our condensers are built using a simple modification of Trevisan's construction, and yield the best extractor constructions to date. Loss-less condensers also produce unbalanced bipartite expander graphs with small (polylogarithmic) degree D and very strong expansion of (1-\epilon)D. We give other applications of our construction, including dispersers with entropy loss O(\log n), depth two super-concentrators whose size is within a polylog of optimal, and an improved hardness of approximation result."
STOC	Extractor codes.	Amnon Ta-Shma,David Zuckerman	2001	We define new error correcting codes based on extractors. We show that for certain choices of parameters these codes have better list decoding properties than are known for other codes, and are provably better than Reed-Solomon codes. We further show that codes with strong list decoding properties are equivalent to slice extractors, a variant of extractors. We give an application of extractor codes to extracting many hardcore bits from a one-way function, using few auxiliary random bits. Finally, we show that explicit slice extractors for certain other parameters would yield optimal bipartite Ramsey graphs.
STOC	Some perspective on computational complexity (abstract).	Andrew Chi-Chih Yao	2001	Some perspective on computational complexity (abstract).
STOC	Sparse polynomial approximation in finite fields.	Igor Shparlinski	2001	We consider a polynomial analogue of the hidden number problem which has recently been introduced by Boneh and Venkatesan. Namely we consider the sparse polynomial approximation problem of recovering an unknown polynomial f(X) \in \F_p[X] with at most $m$ non-zero terms from approximate values of f(t) at polynomially many points t \in \F_p selected uniformly at random. The case of a polynomial f(X) = &agr; X corresponds to the hidden number problem. The above problem is related to the noisy polynomial interpolation problem and to the sparse polynomial interpolation problem which have recently been considered in the literature. Our results are based on a combination of some number theory tools such as bounds of exponential sums and the number of solutions of congruences with the lattice reduction technique.
STOC	Computing with continuous-time Liapunov systems.	Jirí Síma,Pekka Orponen	2001	Computing with continuous-time Liapunov systems.
STOC	Fully-dynamic min-cut.	Mikkel Thorup	2001	"We show that we can maintain up to polylogarithmic edge connectivity for a fully-dynamic graph in $$\ifmmode\expandafter\tilde\else\expandafter\~\fi{O}{\left( {{\sqrt n }} \right)}$$ worst-case time per edge insertion or deletion. Within logarithmic factors, this matches the best time bound for 1-edge connectivity. Previously, no o(n) bound was known for edge connectivity above 3, and even for 3-edge connectivity, the best update time was O(n2/3), dating back to FOCS'92. Our algorithm maintains a concrete min-cut in terms of a pointer to a tree spanning one side of the cut plus ability to list the cut edges in O(log n) time per edge. By dealing with polylogarithmic edge connectivity, we immediately get a sampling based expected factor (1+o(1)) approximation to general edge connectivity in $$\ifmmode\expandafter\tilde\else\expandafter\~\fi{O}{\left( {{\sqrt n }} \right)}$$ time per edge insertion or deletion. This algorithm also maintains a pointer to one side of a near-minimal cut, but if we want to list the cut edges in O(log n) time per edge, the update time increases to $$\ifmmode\expandafter\tilde\else\expandafter\~\fi{O}{\left( {{\sqrt m }} \right)}$$."
STOC	Approximate distance oracles.	Mikkel Thorup,Uri Zwick	2001	"Let G=(V,E) be an undirected weighted graph with |V|=n and |E|=m. Let k\ge 1 be an integer. We show that G=(V,E) can be preprocessed in O(kmn^{1/k}) expected time, constructing a data structure of size O(kn^{1+1/k}), such that any subsequent distance query can be answered, approximately, in O(k) time. The approximate distance returned is of stretch at most 2k-1, i.e., the quotient obtained by dividing the estimated distance by the actual distance lies between 1 and 2k-1. We show that a 1963 girth conjecture of Erd{\H{o}}s, implies that &ohgr(n^{1+1/k}) space is needed in the worst case for any real stretch strictly smaller than 2k+1. The space requirement of our algorithm is, therefore, essentially optimal. The most impressive feature of our data structure is its constant query time, hence the name ``oracle''. Previously, data structures that used only O(n^{1+1/k}) space had a query time of &ohgr(n^{1/k}) and a slightly larger, non-optimal, stretch. Our algorithms are extremely simple and easy to implement efficiently. They also provide faster constructions of sparse spanners of weighted graphs, and improved tree covers and distance labelings of weighted or unweighted graphs.}"
STOC	Minimax parametric optimization problems and multi-dimensional parametric searching.	Takeshi Tokuyama	2001	The parametric minimax problem, which finds the parameter value minimizing the weight of a solution of a combinatorial maximization problem, is a fundamental problem in sensitivity analysis. Moreover, several problems in computational geometry can be formulated as parametric minimax problems. The parametric search paradigm gives an efficient sequential algorithm for a convex parametric minimax problem with one parameter if the original non-parametric problem has an efficient parallel algorithm. We consider the parametric minimax problem with d parameters for a constant d, and solve it by using multidimensional version of the parametric search paradigm. As a new feature, we give a feasible region in the parameter space in which the parameter vector must be located.Typical results obtained as applications are: (1) Efficient solutions for some geometric problems, including theoretically efficient solutions for the minimum diameter bridging problem in d-dimensional space between convex polytopes. (2) Parametric polymatroid optimization, for example, O(n log n) time algorithm to compute the parameter vector minimizing k-largest linear parametric elements with d dimensions.
STOC	Automata, circuits and hybrids: facets of continuous time.	Boris A. Trakhtenbrot	2001	Automata, circuits and hybrids: facets of continuous time.
STOC	Non-approximability results for optimization problems on bounded degree instances.	Luca Trevisan	2001	"par>We prove some non-approximability results for restrictions of basic combinatorial optimization problems to instances of bounded &ldquo;degree&r dquo;or bounded &ldquo;width.&rdquo; Specifically:We prove that the Max 3SAT problem on instances where each variable occurs in at most B clauses, is hard to approximate to within a factor $7/8 + O(1/\sqrt{B})$, unless $RP = NP$. H\aa stad [18] proved that the problem is approximable to within a factor $7/8 + 1/64B$ in polynomial time, and that is hard to approximate to within a factor $7/8 +1/(\log B)^{&OHgr;(1)}$. Our result uses a new randomized reduction from general instances of Max 3SAT to bounded-occurrences instances. The randomized reduction applies to other Max SNP problems as well.We observe that the Set Cover problem on instances where each set has size at most B is hard to approximate to within a factor $\ln B - O(\ln\ln B)$ unless $P=NP$. The result follows from an appropriate setting of parameters in Feige's reduction [11]. This is essentially tight in light of the existence of $(1+\ln B)$-approximate algorithms [20, 23, 9]We present a new PCP construction, based on applying parallel repetition to the ``inner verifier,'' and we provide a tight analysis for it. Using the new construction, and some modifications to known reductions from PCP to Hitting Set, we prove that Hitting Set with sets of size B is hard to approximate to within a factor $B^{1/19}$. The problem can be approximated to within a factor B [19], and it is the Vertex Cover problem for B=2. The relationship between hardness of approximation and set size seems to have not been explored before. We observe that the Independent Set problem on graphs having degree at most B is hard to approximate to within a factor $B/2^{O(sqrt{\log B})}$, unless P = NP. This follows from a comination of results by Clementi and Trevisan [28] and Reingold, Vadhan and Wigderson [27]. It had been observed that the problem is hard to approximate to within a factor $B^{&OHgr; (1)}$ unless P=NP [1]. An algorithm achieving factor $O (B)$ is also known [21, 2, 30, 16}."
STOC	Quantum computers that can be simulated classically in polynomial time.	Leslie G. Valiant	2001	A model of quantum computation based on unitary matrix operations was introduced by Feynman and Deutsch. It has been asked whether the power of this model exceeds that of classical Turing machines. We show here that a significant class of these quantum computations can be simulated classically in polynomial time. In particular we show that two-bit operations characterized by 4 \times 4 matrices in which the sixteen entries obey a set of five polynomial relations can be composed according to certain rules to yield a class of circuits that can be simulated classically in polynomial time. This contrasts with the known universality of two-bit operations, and demonstrates that efficient quantum computation of restricted classes is reconcilable with the Polynomial Time Turing Hypothesis. In other words it is possible that quantum phenomena can be used in a scalable fashion to make computers but that they do not have superpolynomial speedups compared to Turing machines for any problem. The techniques introduced bring the quantum computational model within the realm of algebraic complexity theory. In a manner consistent will one view of quantum physics, the wave function is simulated deterministically, and randomization arises only in the course of making measurements. The results generalize the quantum model in that they do not require the matrices to be unitary. In a different direction these techniques also yield deterministic polynomial time algorithms for the decision and parity problems for certain classes of read-twice Boolean formulae. All our results are based on the use of gates that are defined in terms of their graph matching properties.
STOC	Distribution functions of probabilistic automata.	Farrokh Vatan	2001	"Each probabilistic automaton M over an alphabet $\cal A$ defines a probability measure $\prob_M$ on the set of all finite and infinite words over $\cal A$. We can identify a k letter alphabet $\cal A$ with the set {0,1,&hellip;,k-1}, and, hence, we can consider every finite or infinite word w over $\cal A$ as a radix k expansion of a real number X(w) in the interval [0,1]. This makes X(w) a random variable and the distribution function of M is defined as usual: F(x):=\prob_M{w : X(w)}. Utilizing the fixed--point semantics (denotational semantics), extended to probabilistic computations, we investigate the distribution functions of probabilistic automata in detail. Automata with continuous distribution functions are characterized. By a new, and much more easier method, it is shown that the distribution function F(x) is an analytic function if it is a polynomial. Finally, answering a question posed by D. Knuth and A. Yao, we show that a polynomial distribution function F(x) on [0,1] can be generated by a probabilistic automaton iff all the roots of F'(x)=0 in this interval, if any, are rational numbers. For this, we define two dynamical systems on the set of polynomial distributions and study attracting fixed points of random composition of these two systems."
STOC	Almost optimal permutation routing on hypercubes.	Berthold Vöcking	2001	This paper deals with permutation routing on hypercube networks in the store-and-forward model. We introduce the first (on-line and off-line) algorithms routing any permutation on the d-dimensional hypercube in d+o(d) steps. The best previously known results were 2d+o(d) (oblivious on-line) and 2d-3 (off-line). In particular, we presenta randomized, oblivious on-line algorithm with routing time d + O(d/log d),a matching lower bound of d + &OHgr;(d/log d) for (randomized) oblivious on-line routing, anda deterministic, off-line algorithm with routing time d+O(\sqrt{d\log d}).Previous algorithms lose a factor of two mainly because packets are first sent to intermediate destinations in order to resolve congestion. As a consequence, the maximum path length becomes 2d - o(d). Our algorithms use intermediate destinations as well, but we introduce a simple, elegant trick ensuring that the routing paths are not stretched too much. In fact, we achieve small congestion using paths of length at most d.The main focus of our work, however, lies on the scheduling aspect. On one hand, we investigate well-known and practical scheduling policies for on-line routing, namely Farthest-to-Go and Nearest-to-Origin. On the other hand, we present a new off-line scheduling scheme that is based on frugal colorings of multigraphs. This scheme might be of interest for other sparse scheduling problems, too.
STOC	Estimating true evolutionary distances between genomes.	Li-San Wang,Tandy Warnow	2001	Evolution operates on whole genomes by operations that change the order and strandedness of genes within the genomes. This type of data presents new opportunities for discoveries about deep evolutionary rearrangement events, provided that sufficiently accurate methods can be developed to reconstruct evolutionary trees in these models [3, 6, 7, 15, 17]. A necessary component of any such method is the ability to accurately estimate true evolutionary distances between two genomes, which is the number of rearrangement events that took place in the evolutionary history between them. We present a new technique called IEBP, for estimating the true evolutionary distance between two genomes, whether signed or unsigned, circular or linear, and for any relative probabilities of rearrangement event classes. The method is highly accurate, as our simulation study shows. This simulation study also shows that the distance estimation technique improves the accuracy of the phylogenetic trees reconstructed by the popular distance-based method, neighbor joining [1, 20].
STOC	Quantum algorithms for solvable groups.	John Watrous	2001	In this paper we give a polynomial-time quantum algorithm for computing orders of solvable groups. Several other problems, such as testing membership in solvable groups, testing equality of subgroups in a given solvable group, and testing normality of a subgroup in a given solvable group, reduce to computing orders of solvable groups and therefore admit polynomial-time quantum algorithms as well. Our algorithm works in the setting of black-box groups, wherein none of these problems have polynomial-time classical algorithms. As an important byproduct, our algorithm is able to produce a pure quantum state that is uniform over the elements in any chosen subgroup of a solvable group, which yields a natural way to apply existing quantum algorithms to factor groups of solvable groups.
STOC	Proceedings on 33rd Annual ACM Symposium on Theory of Computing, July 6-8, 2001, Heraklion, Crete, Greece	Jeffrey Scott Vitter,Paul G. Spirakis,Mihalis Yannakakis	2001	Proceedings on 33rd Annual ACM Symposium on Theory of Computing, July 6-8, 2001, Heraklion, Crete, Greece
FOCS	The Asymptotic Order of the Random k -SAT Threshold.	Dimitris Achlioptas,Cristopher Moore	2002	"Form a random k-SAT formula on n variables by selecting uniformly and independently m = rn clauses out of all 2^k (_k^n ) possible k-clauses. The Satisfiability Threshold Conjecture asserts that for each k there exists a constant rk such that as n tends to infinity, the probability that the formula is satisfiable tends to 1 if r rk. It has long been known that 2 k/k 2k. We prove that rk > 2k - 1 ln 2 - dk, where dk ¿ (1 + ln 2)/2. Our proof also allows a blurry glimpse of the ""geometry"" of the set of satisfying truth assignments."
FOCS	Linear Diophantine Equations over Polynomials and Soft Decoding of Reed-Solomon Codes.	Michael Alekhnovich	2002	We generalize classical Knuth-Schiinhage algorithm computing GCD of two polynomials for solving arbitrary linear Diophantine systems over polynomials in time, quasi-linear in the maximal degree. As an application, we consider the following weighted curve fitting problem: given a set of points in the plain, find an algebraic curve (satisfying certain degree conditions) that goes through each point the prescribed number of times. The main motivation for this problem comes from the coding theory, namely it is ultimately related to the list decoding of Reed-Solomon codes.We present a new fast algorithm for the weighted curve fitting problem, based on the explicit construction of Groebner basis. This gives another fast algorithm for soft-decoding of Reed-Solomon codes different from the procedure proposed by Feng, which works in time (\frac{w}{r})^{0(1)} n\log ^2 n\log \log n, where r is the rate of the code, and w is the maximal weight assigned to a vertical line.
FOCS	On the Decidability of Self-Assembly of Infinite Ribbons.	Leonard M. Adleman,Jarkko Kari,Lila Kari,Dustin Reishus	2002	"Self-assembly, the process by which objects autonomously come together to form complex structures, is omnipresent in the physical world. A systematic study of self-assembly as a mathematical process has been initiated. The individual components are modelled as square tiles on the infinite two-dimensional plane. Each side of a tile is covered by a specific ""glue"", and two adjacent tiles will stick if they have matching glues on their abutting edges. Tiles that stick to each other may form various two-dimensional ""structures"" such as squares, rectangles, or may cover the entire plane. In this paper we focus on a special type of structure, called ribbon: A non-self-crossing sequence of tiles on the plane, in which successive tiles are adjacent along an edge, and abutting edges of consecutive tiles have matching glues. We prove that it is undecidable whether an arbitrary finite set of tiles with glues (infinite supply of each tile type available) can be used to assemble an infinite ribbon. The proof is based on a construction, due to Robinson, of a special set of tiles that allow onlyaperiodic tilings of the plane. This construction is used to create a special set of directed tiles (tiles with arrows painted on the top) with the ""strong plane-filling property"" - a variation of the ""plane-filling property"" previously defined by J. Kari. A construction of ""sandwich"" tiles is then used in conjunction with this special tile set, to reduce the well-known undecidable Tiling Problem to the problem of the existence of an infinite directed zipper (a special kind of ribbon). A ""motif"" construction is then introduced that allows one tile system to simulate another by using geometry to represent glues. Using motifs, the infinite directed zipper problem is reduced to the infinite ribbon problem, proving the latter undecidable.The result settles an open problemformerly known as the ""unlimited infinite snake problem"". Moreover, an immediate consequence is the undecidability of the existence of arbitrarily large structures self-assembled using tiles from a given tile set."
FOCS	Satisfiability, Branch-Width and Tseitin Tautologies.	Michael Alekhnovich,Alexander A. Razborov	2002	For a CNF_\tau, let wb(\tau ) be the bronch-width of its underlying hypergraph. In this paper we design an algorithm for solving SAT in time n^{0(1)} 2^0 (wb(\tau )). This in particular implies a polynomial algorithm for testing satisfiability on instances with tree-width O(log n).Our algorithm is a modification of the width based automated theorem prover (WBATP) which is a popular (at least on the theoretical level) heuristic for finding resolution refutations of unsatisfiable CNFs. We show that instead of the exhaustive enumerotion of all provable clauses, one can do a better search based on the Robertson-Seymour algorithm forapproximating the bronch-width of a graph. We call the resulting procedure Bronch- Width Based Automated Theorem Prover (BWBATP). As opposed to WBATP, it always produces regular refutations. Perhaps more importantly, the running time of our algorithm is boundedin terms of a clean combinatorial charocteristic that can be efficiently approximated, and that the algorithm also produces, within the same time, a satisfying assignment if \tauhappens to be satisfiable.In the second part of the paper we investigate the behavior of BWBATP on the well-studied class of Tseitin tautologies. We argue that in this case BWBATP is better than WBATP. Namely, we show that its running time on any Tseitin tautology \tau is \left| \tau\right|^{0(1)}\cdot 2^{0(w(\tau 1 - 0)} as opposed to the obvious bound n^{0(1)} 2^0 (wb(\tau ))\left| \tau\right|^{0(1)}\cdot 2^{0(w(\tau 1 - 0)} provided by WBATP.This in particular implies that Resolution is automatizable on those Tseitin tautologies for which we know the relation w(\tau 1 - 0) \leqslant 0(\log S(\tau )). We identify one such subclass and prove partial results toward establishing this relation for larger classes of graphs.
FOCS	Power from Random Strings.	Eric Allender,Harry Buhrman,Michal Koucký,Dieter van Melkebeek,Detlef Ronneburger	2002	"We show that sets consisting of strings of high Kolmogorov complexity provide examples of sets that are complete for several complexity classes under probabilistic and nonuniform reductions. These sets are provably not complete under the usual many-one reductions.Let ${{R_{\rm C}}}, {{R_{\rm Kt}}}, {{R_{\rm KS}}}, {{R_{\rm KT}}}$ be the sets of strings $x$ having complexity at least $|x|/2$, according to the usual Kolmogorov complexity measure ${\mbox{\rm C}}$, Levin&apos;s time-bounded Kolmogorov complexity ${\mbox{\rm Kt}}$ [L. Levin, Inform. and Control, 61 (1984), pp. 15-37], a space-bounded Kolmogorov measure ${\mbox{\rm KS}}$, and a new time-bounded Kolmogorov complexity measure ${\mbox{\rm KT}}$, respectively.Our main results are as follows:\begin{remunerate} \item ${{R_{\rm KS}}}$ and ${{R_{\rm Kt}}}$ are complete for ${{\rm{PSPACE}}}$ and {\mbox{\rm EXP}}, respectively, under ${\mbox{\rm P/poly}}$-truth-table reductions. Similar results hold for other classes with ${{\rm{PSPACE}}}$-robust Turing complete sets.\item ${\mbox{\rm EXP}} = {\mbox{\rm NP}}^{{{R_{\rm Kt}}}}.$\item ${{\rm{PSPACE}}} = {\mbox{\rm ZPP}}^{{{R_{\rm KS}}}} \subseteq {\mbox{\rm P}}^{{{R_{\rm C}}}}$.\item The Discrete Log, Factoring, and several lattice problems are solvable in ${\mbox{\rm BPP}}^{{{R_{\rm KT}}}}$. \end{remunerate}Our hardness result for ${{\rm{PSPACE}}}$ gives rise to fairly natural problems that are complete for ${{\rm{PSPACE}}}$ under ${\mbox{$\leq^{\rm p}_{\rm T}$}}$ reductions, but not under ${\mbox{$\leq^{\rm log}_{\rm m}$}}$ reductions.Our techniques also allow us to show that all computably enumerable sets are reducible to ${{R_{\rm C}}}$ via ${\mbox{\rm P/poly}}$-truth-table reductions. This provides the first ""efficient"" reduction of the halting problem to ${{R_{\rm C}}}$."
FOCS	Bounded-Depth Frege Lower Bounds for Weaker Pigeonhole Principles.	Josh Buresh-Oppenheim,Paul Beame,Toniann Pitassi,Ran Raz,Ashish Sabharwal	2002	We prove a quasi-polynomial lower bound on the size of bounded-depth Frege proofs of the pigeonhole principle $PHP^{m}_n$ where $m= (1+1/{\polylog n})n$. This lower bound qualitatively matches the known quasi-polynomial-size bounded-depth Frege proofs for these principles. Our technique, which uses a switching lemma argument like other lower bounds for bounded-depth Frege proofs, is novel in that the tautology to which this switching lemma is applied remains random throughout the argument.
FOCS	Learning a Hidden Matching.	Noga Alon,Richard Beigel,Simon Kasif,Steven Rudich,Benny Sudakov	2002	We consider the problem of learning a matching (i.e., a graph in which all vertices have degree 0 or 1) in a model where the only allowed operation is to query whether a set of vertices induces an edge. This is motivated by a problem that arises in molecular biology. In the deterministic nonadaptive setting, we prove a $(\frac{1}{2}+o(1)){n \choose 2} $ upper bound and a nearly matching $0.32{n \choose 2}$ lower bound for the minimum possible number of queries. In contrast, if we allow randomness, then we obtain (by a randomized, nonadaptive algorithm) a much lower O(n log n) upper bound, which is best possible (even for randomized fully adaptive algorithms).
FOCS	Explicit Unique-Neighbor Expanders.	Noga Alon,Michael R. Capalbo	2002	"We present a simple, explicit construction of an infinite family F of bounded-degree 'unique-neighbor' expanders \Gamma; i.e., there are strictly positive constants \alpha and, such that all \Gamma = (X,E(\Gamma)) \varepsilon F satisfy the following property. For each subset S of X with no more than \alpha|X| vertices, there are at least \varepsilon|S| vertices in X \S that are adjacent in \Gamma to exactly one verte in S. The construction of F is simple to specify, and each \Gamma \varepsilon F is 6-regular. We then extend the technique and present easy to describe explicit infinite families of 4-regular and 3-regular unique-neighbor expanders, as well as explicit families of bipartite graphs with non equal color classes and similar properties.This has several applications and settles an open problem considered by various researchers."
FOCS	Random Lattices and a Conjectured 0 - 1 Law about Their Polynomial Time Computable Properties.	Miklós Ajtai	2002	We formulate a conjecture about random n-dimensional lattices with a suitable distribution. The conjecture says that every polynomial time computable property of a random lattice holds with a probabiltiy either close to 0 or close to 1. Accepting the conjecture we get a large classof hard lattice problems. We describe an analogy between our conjecture and a set theoretical axiom, which cannot be proved in ZFC. This axiom says that there exists a nontrivial \sigma -additive 0 - 1 measure defined on the set of all subsets of some set S.
FOCS	Small Induced-Universal Graphs and Compact Implicit Graph Representations.	Stephen Alstrup,Theis Rauhe	2002	We show that there exists a graph G with n \cdot 2^{0(\log* n)} nodes, where any forest with n nodes is a node-induced subgraph of G. Furthermore, the result implies existence of a graph with n^k 2^{0(\log* n)}nodes that contains all n-node graphs of fixed arboricity k as node-induced subgraphs. We provide a lower bound of \Omega (n^k) for the size of such a graph. The upper bound is obtained through a simple labeling scheme for parent queries in rooted trees.
FOCS	Scheduling Over a Time-Varying User-Dependent Channel with Applications to High Speed Wireless Data.	Matthew Andrews,Lisa Zhang	2002	In a wireless network, a basestation transmits data to mobiles at time-varying, mobile-dependent rates due to the ever changing nature of the communication channels. In this article, we consider a wireless system in which the channel conditions and data arrival processes are governed by an adversary. We first consider a single server and a set of users. At each time step t, the server can only transmit data to one user. If user i is chosen, the transmission rate is ri(t). We say that the system is (w, &epsiv;)-admissible if in any window of w time steps the adversary can schedule the users so that the total data arriving to each user is at most 1&minus;&epsiv; times the total service it receives.Our objective is to design online scheduling algorithms to ensure stability in an admissible system. We first show, somewhat surprisingly, that the admissibility condition alone does not guarantee the existence of a stable online algorithm, even in a subcritical system (i.e., &epsiv; > 0). For example, if the nonzero rates in an infinite rate set can be arbitrarily small, then a subcritical system can be unstable for any deterministic online algorithm.On a positive note, we present a tracking algorithm that attempts to mimic the behavior of the adversary. This algorithm ensures stability for all (w, &epsiv;)-admissible systems that are not excluded by our instability results. As a special case, if the rate set is finite, then the tracking algorithm is stable even for a critical system (i.e., &epsiv; &equals; 0). Moreover, the queue sizes are independent of &epsiv;. For subcritical systems, we also show that a simpler max weight algorithm is stable as long as the user rates are bounded away from zero.The offline version of our problem resembles the problem of scheduling unrelated machines and can be modeled by an integer program. We present a rounding algorithm for its linear relaxation and prove that the rounding technique cannot be substantially improved.
FOCS	Proving Integrality Gaps without Knowing the Linear Program.	Sanjeev Arora,Béla Bollobás,László Lovász	2002	Proving integrality gaps for linear relaxations of NP optimization problems is a difficult task and usually undertaken on a case-by-case basis. We initiate a more systematic approach. We prove an integrality gap of 2 - o(1) for three families of linear relaxations for vertex cover, and our methods seem relevant to other problems as well.
FOCS	Graph Isomorphism is in SPP.	Vikraman Arvind,Piyush P. Kurur	2002	We show that Graph Isomorphism is in the complexity class SPP, and hence it is in ⊕P (in fact, in ModkP for each k ≥ 2). These inclusions for Graph Isomorphism were not known prior to membership in SPP. We derive this result as a corollary of a more general result: we show that a generic problem FIND-GROUP has an FPSPP algorithm. This general result has other consequences: for example, it follows that the hidden subgroup problem for permutation groups, studied in the context of quantum algorithms, has an FPSPP algorithm. Also, some other algorithmic problems over permutation groups known to be at least as hard as Graph Isomorphism (e.g., coset intersection) are in SPP, and thus in ModkP for each k ≥ 2.
FOCS	Correlation Clustering.	Nikhil Bansal,Avrim Blum,Shuchi Chawla	2002	We consider the following clustering problem: we have a complete graph on n vertices (items), where each edge (u, v) is labeled either + or &minus; depending on whether u and v have been deemed to be similar or different. The goal is to produce a partition of the vertices (a clustering) that agrees as much as possible with the edge labels. That is, we want a clustering that maximizes the number of + edges within clusters, plus the number of &minus; edges between clusters (equivalently, minimizes the number of disagreements: the number of &minus; edges inside clusters plus the number of + edges between clusters). This formulation is motivated from a document clustering problem in which one has a pairwise similarity function f learned from past data, and the goal is to partition the current set of documents in a way that correlates with f as much as possible&semi; it can also be viewed as a kind of &ldquo;agnostic learning&rdquo; problem.An interesting feature of this clustering formulation is that one does not need to specify the number of clusters k as a separate parameter, as in measures such as k-median or min-sum or min-max clustering. Instead, in our formulation, the optimal number of clusters could be any value between 1 and n, depending on the edge labels. We look at approximation algorithms for both minimizing disagreements and for maximizing agreements. For minimizing disagreements, we give a constant factor approximation. For maximizing agreements we give a PTAS, building on ideas of Goldreich, Goldwasser, and Ron (1998) and de la Veg (1996). We also show how to extend some of these results to graphs with edge labels in [&minus;1, +1], and give some results for the case of random noise.
FOCS	An Information Statistics Approach to Data Stream and Communication Complexity.	Ziv Bar-Yossef,T. S. Jayram,Ravi Kumar,D. Sivakumar	2002	We present a new method for proving strong lower bounds in communication complexity. This method is based on the notion of the conditional information complexity, of a function which is the minimum amount of information about the inputs that has to be revealed by a communication protocol for the function. While conditional information complexity is a lower bound on communication complexity, we show that it also admits a direct sum theorem. Direct sum decomposition reduces our task to that of proving conditional information complexity lower bounds for simple problems (such as the AND of two bits). For the latter, we develop novel techniques based on Hellinger distance and its generalizations.Our paradigm leads to two main results: (1) An improved lower bound for the multi-party set-disjointness problem in the general communication complexity model, and a nearly optimal lower bound in the one-way communication model. As a consequence, we show that for any real k > 2, approximating the kth frequency moment in the data stream model requires essentially Ω(n1-2/k) space; this resolves a conjecture of Alon et al. (J. Comput. System Sci. 58(1) (1999) 137).(2) A lower bound for the Lp approximation problem in the general communication model: this solves an open problem of Saks and Sun (in: Proceedings of the 34th Annual ACM Symposium on Theory of Computing (STOC), 2002, pp. 360-369). As a consequence, we show that for p > 2, approximating the Lp norm to within a factor of nε in the data stream model with constant number of passes requires Ω(n1-4ε-2/p) space.
FOCS	Constant-Round Coin-Tossing with a Man in the Middle or Realizing the Shared Random String Model.	Boaz Barak	2002	"We present the first constant-round non-malleable commitment scheme and the first constant-round non-malleable zero-knowledge argument system, as defined by Dolev, Dwork and Naor. Previous constructions either used a non-constant number of rounds, or were onlysecure under stronger setup assumptions. An example of such an assumption is the shared random string model where we assume all parties have access to a reference string that was chosen uniformly at random by a trusted dealer.We obtain these results by defining an adequate notion of non-malleable coin-tossing, and presenting a constant-round protocol that satisfies it. This protocol allows us to transform protocols that are non-malleable in (a modified notion of) the shared random string model into protocols that are non-malleable in the plain model (without any trusted dealer or setup assumptions). Observing that known constructions of a non-interactive non-malleable zero-knowledge argument systems in the shared random string model (De Santis et. al., 2001) are in fact non-malleable in the modified model, and combining them with our coin-tossing protocol we obtain the results mentioned above.The techniques we use are different from those used in previous constructions of non-malleable protocols. In particular our protocol uses diagonalization and a non-black-box proof of security (in a sense similar to Barak's zero-knowledge argument)."
FOCS	Authentication of Quantum Messages.	Howard Barnum,Claude Crépeau,Daniel Gottesman,Adam Smith,Alain Tapp	2002	Authentication is a well-studied area of classical cryptography: a sender A and a receiver B sharing a classical secret key want to exchange a classical message with the guarantee that the message has not been modified or replaced by a dishonest party with control of the communication line. In this paper we study the authentication of messages composed of quantum states.We give a formal definition of authentication in the quantum setting. Assuming A and B have access to an insecure quantum channel and share a secret, classical random key, we provide a non-interactive scheme that enables A to both encrypt and authenticate an m qubitmessage by encoding it into m + s qubits, where the error probability decreases exponentially in the security parameter s . The scheme requires a secret key of size 2m +O(s). To achieve this, we give a highly efficient protocol for testing the purity of shared EPR pairs.It has long been known that learning information about a general quantum state will necessarily disturb it. We refine this result to show that such a disturbance can be done with few side effects, allowing it to circumvent cryptographic protections. Consequently, any scheme to authenticate quantum messages must also encrypt them. In contrast, no such constraint exists classically.This reasoning has two important consequences: It allows us to give a lower bound of 2m key bits for authenticating m qubits, which makes our protocol asymptotically optimal. Moreover, we use it to show that digitally signing quantum states is impossible.
FOCS	Breaking the O(n1/(2k-1)) Barrier for Information-Theoretic Private Information Retrieval.	Amos Beimel,Yuval Ishai,Eyal Kushilevitz,Jean-François Raymond	2002	Private Information Retrieval (PIR) protocols allow a user to retrieve a data item from a database while hiding the identity of the item being retrieved. Specifically, in information-theoretic, k-server PIR protocols the database is replicated among k servers, and each server learns nothing about the item the user retrieves. The cost of such protocols is measured by the communication complexity of retrieving one out of n bits of data. For any fixed k, the complexity of the best protocols prior to our work was 0(n^{\frac{1}{{2k - 1}}}) (Ambainis, 1997). Since then several methods were developed in an attempt to beat this bound, but all these methods yielded the same asymptotic bound.In this work, this barrier is finally broken and the complexity of information-theoretic k-server PIR is improved to n^{0(\frac{{\log \log k}}{{k\log k}})}. The new PIR protocols can also be used to construct k-query binary locally decodable codes of length exp (n^{0(\frac{{\log \log k}}{{k\log k}})}), compared to exp(n^{\frac{1}{{k - 1}}}) in previous constructions. The improvements presented in this paper apply even for small values of k: the PIR protocols are more efficient than previous ones for every k \geqslant 3, and the locally decodable codes are shorter for every k \geqslant 4.
FOCS	Global Information from Local Observation.	Itai Benjamini,László Lovász	2002	"We observe a certain random process on a graph ""locally"", i.e., in the neighborhood of a node, and would like to derive information about ""global"" properties of the graph. For example, what can we know about a graph based on observing the returns of a random walk to a given node?Our main result concerns a graph embedded in an orientable surface with genus g, and a process, consisting of random excitations of edges and random balancing around nodes and faces. It is shown how to obtain the genus of the surface in polynomial time from local observations of the process restricted to a connected subgraph whose size is (essentially)O(g2)."
FOCS	Auctions with Severely Bounded Communication.	Liad Blumrosen,Noam Nisan	2002	We study auctions with severe bounds on the communication allowed: each bidder may only transmit t bits of information to the auctioneer. We consider both welfare-maximizing and revenue-maximizing auctions under this communication restriction. For both measures, we determine the optimal auction and show that the loss incurred relative to unconstrained auctions is mild. We prove non-surprising properties of these kinds of auctions, e.g. thatdiscrete prices are informationally efficient, as well as some surprising properties, e.g. that asymmetric auctions are better than symmetric ones.
FOCS	A Lower Bound for Testing 3-Colorability in Bounded-Degree Graphs.	Andrej Bogdanov,Kenji Obata,Luca Trevisan	2002	We consider the problem of testing 3-colorability in the bounded-degree model.We show that, for small enough \varepsilon, every tester for 3-colorability must have query complexity \Omega \text{(n)}. This is the first linear lower bound for testing a natural graph property in the bounded-degree model. An \Omega (\sqrt n ) lower bound was previously known.For one-sided error testers, we also show an \Omega \text{(n)} lower bound for testers that distinguish 3-colorable graphs from graphs that are({\raise0.7ex\hbox{$1$} \!\mathord{\left/ {\vphantom {1 3}}\right.\kern-\nulldelimiterspace} \!\lower0.7ex\hbox{$3$}} - \alpha )- far from 3-colorable, for arbitrarily small \alpha. In contrast a polynomial time algorithm by Frieze and Jerrum distinguishes 3-colorable graphs from graphs that are {1 \mathord{\left/{\vphantom {1 5}} \right.\kern-\nulldelimiterspace} 5}-far from 3-colorable.As a by-product of our techniques, we obtain tight unconditional lower bounds on the approximation ratios achievable by sublinear time algorithms for Max E3SAT, Max E3LIN-2 and other problems.
FOCS	Dynamic Planar Convex Hull.	Gerth Stølting Brodal,Riko Jacob	2002	In this paper we determine the computational complexity of the dynamic convex hull problem in the planar case. We present a data structure that maintains a finite set of n points in the plane under insertion and deletion of points in amortized O(log n) time per operation. Thespace usage of the data structure is O(n). The data structure supports extreme point queries in a given direction, tangent queries through a given point, and queries for the neighboring points on the convex hull in O(log n) time. The extreme point queries can be used to decide whether or not a given line intersects the convex hull, and the tangent queries to determine whether a given point is inside the convex hull. We give a lower bound on the amortized asymptotic time complexity that matches the performance of this data structure.
FOCS	PAC = PAExact and Other Equivalent Models in Learning.	Nader H. Bshouty,Dmitry Gavinsky	2002	The Probably Almost Exact model (PAExact) [BJT02] can be viewed as the Exact model relaxed so that:1. The counterexamples to equivalence queries are distributionally drawn rather than adversarially chosen.2. The output hypothesis is equal to the target with negligible error (1/w (poly) for any poly)This model allows studying (Almost) Exact learnability of infinite classes and is in some sense analogous to the Exact-learning model for finite classes.It is known that PAExact-learnable \RightarrowPAC-learnable [BJT02]. In this paper we show that if a class is PAC-learnable (in polynomial time) then it is PAExact-learnable (in polynomial time). Therefore, PAExact-learnable = PAC-learnable.It follows from this result that if a class is PAC-learnable then it is learnable in the Probabilistic Prediction model from examples with an algorithm that runs in polynomial time for each prediction (polynomial in log (the number of trials)) and that after polynomial number of mistakes achieves a hypothesis that predicts the target with probability 1 - 1/2poly.We also show that if a class is PAC-learnable in parallel then it is PAExact-learnable in parallel.Those and other results mentioned in theintroduction answer the open problems posed in [B97, BJT02].
FOCS	A Dichotomy Theorem for Constraints on a Three-Element Set.	Andrei A. Bulatov	2002	The Constraint Satisfaction Problem (CSP) provides a common framework for many combinatorial problems. The general CSP is known to be NP-complete; however, certainrestrictions on the possible form of constraints may affect the complexity, and lead to tractable problem classes. There is, therefore, a fundamental research direction, aiming to separate those subclasses of the CSP which are tractable, from those which remain NP-complete.In 1978 Schaefer gave an exhaustive solution of this problem for the CSP on a 2-element domain. In this paper we generalise this result to a classification of the complexity of CSPs on a 3-element domain. The main result states that every subclass of the CSP defined by a set of allowed constraints is either tractable or NP-complete, and the criterion separating them is that conjectured in [6, 8]. We also exhibit a polynomial time algorithmwhich, for a given set of allowed constraints, determines whether if this set gives rise to a tractable problem class. To obtain the main result and the algorithm we extensively use the algebraic technique for the CSP developed in [17] and [6, 8].
FOCS	Lower Bounds on the Bounded Coefficient Complexity of Bilinear Maps.	Peter Bürgisser,Martin Lotz	2002	"We prove lower bounds of order n log n for both the problem of multiplying polynomials of degree n, and of dividing polynomials with remainder, in the model of bounded coefficient arithmetic circuits over the complex numbers. These lower bounds are optimal up to order of magnitude. The proof uses a recent idea of R. Raz [Proc. 34th STOC 2002] proposed for matrix multiplication. It reduces the linear problem of multiplying a random circulant matrix with a vector to the bilinear problem of cyclic convolution. We treat the arising linear problem by extending J. Morgenstern's bound [J. ACM 20, pp. 305--306, 1973] in a unitarily invariant way. This establishes a new lower bound on the bounded coefficient complexity of linear forms in terms of the singular values of the corresponding matrix. In addition, we extend these lower bounds for linear and bilinear maps to a model of circuits that allows a restricted number of unbounded scalar multiplications."
FOCS	Packing 2-Dimensional Bins in Harmony.	Alberto Caprara	2002	We consider 2-Dimensional (Finite) Bin Packing (2BP), which is one of the most important generalizations of the well-known Bin Packing (BP) and calls for orthogonally packing a given set of rectangles (that cannot be rotated) into the minimum number of unit size squares.There are many open questions concerning the approximability of 2BP, whereas the situation for the 2-stage case, in which the items must first be packed into shelves that are then packed into bins, is essentially settled. For this reason, we study the asymptotic worst-case ratio between the optimal solution values of the 2-stage and general 2BP, showing that it is equal to {\rm T}\infty= 1.691 \ldots, the well-known worst-case ratio of the Harmonic algorithm for BP. This ratio is achieved by packing the items into shelves by decreasing heights as in the Harmonic algorithm and then optimally packing the resulting shelves into bins. This immediately yields polynomial time approximation algorithms for 2BP whose asymptotic worst-case ratio is arbitrarily close to {\rm T}\infty, i.e. substantially smaller than 2 + \varepsilon, that was the best ratio achievable so far and constituted the first (recent) improvement over the 2.125 ratio shown in the early 80s. In particular, we manage to push the approximability threshold below 2, which is often a critical value in approximation.The main idea in our analysis is to use the fact that the fractional and integer BP solutions have almost the same value, which is implicit in the approximation schemes for the problem, as a stand-alone structural result. This implies the existence of modified heights for the shelves whose sum yields approximately the number of bins needed to pack them. With this in mind, our proof can easily be adapted to different cases. For instance, we can derive new upperbounds on the worst-case ratio of several shelf heuristics for 2BP, among which a bound of(\frac{{17}}{{10}})(\frac{{11}}{9}) = 2.077 \ldots (rather than 2:125) on the 20-years-lasting champion mentioned above. Moreover, we can easily derive the asymptotic worst-case ratio between the 2-stage and general 2BP solution values as a function of the maximum width of the rectangles, showing that this ratio is independent of the maximum height. Finally, under a conjecture that appears to be supported by experimental evidence, we show that our main heuristic has an asymptotic worst-case ratio in the interval (1:490, 1:507) when all the rectangles to be packed are squares. This would improve the current best worst-case ratio of \frac{{14}}{9} = 1.555 \ldots for this special case.
FOCS	Low-Dimensional Linear Programming with Violations.	Timothy M. Chan	2002	Two decades ago, Megiddo and Dyer showed that linear programming (LP) in two and three dimensions (and subsequently any constant number of dimensions) can be solved in linear time. In this paper, we consider the LP problem with at most k violations, i.e., finding a point inside all but at most k halfspaces, given a set of n halfspaces. We present a simple algorithm in two dimensions that runs in O((n+k2)log n) expected time; this is faster than earlier algorithms by Everett, Robert, and van Kreveld (1993) and Matousek (1994) for many values of k and is probably near-optimal. An extension of our algorithm in three dimensions runs in near O(n+k11/4n1/4) expected time. Interestingly, the idea is based on concave-chain decompositions (or covers) of the $(\le k)$-level, previously used in proving combinatorial k-level bounds.Applications in the plane include improved algorithms for finding a line that misclassifies the fewest among a set of bichromatic points, and finding the smallest circle enclosing all but k points. We also discuss related problems of finding local minima in levels.
FOCS	Covering Problems with Hard Capacities.	Julia Chuzhoy,Joseph Naor	2002	"We consider the classical vertex cover and set cover problems with the addition of hard capacity constraints. This means that a set (vertex) can only cover a limited number of its elements (adjacent edges) and the number of available copies of each set (vertex) is bounded. This is a natural generalization of the classical problems that also captures resource limitations in practical scenarios.We obtain the following results. For the unweighted vertex cover problem with hard capacities we give a 3-approximation algorithm which is based on randomized rounding with alterations. We prove that the weighted version is at least as hard as the set cover problem. This is an interesting separation between the approximability of weighted and unweighted versions of a ""natural"" graph problem. A logarithmic approximation factor for both the set cover and the weighted vertex cover problem with hard capacities follows from the work of Wolsey [23] on submodular set cover. We provide in this paper a simple and intuitive proof for this bound."
FOCS	Static Optimality Theorem for External Memory String Access.	Valentina Ciriani,Paolo Ferragina,Fabrizio Luccio,S. Muthukrishnan	2002	"Data warehouses are increasingly storing and managing large scale string data, and dealing with large volume of transactions that update and search string data. Motivated by this context, we initiate the study of self-adjusting data structures for string dictionary operations, that is, data structures that are designed to be efficient on an entire sequence rather than individual string operations. Furthermore, we study this problem in the external memory modelwhere string data is too massive to be stored in internal memory and has to reside in disks; each access to a disk page fetches B items, and the cost of the operations is the number of pages accessed (I/Os).We show that given a dictionary of n strings S_1 , \ldots ,S_n of total length N, asequence of m string searches S_{i_1 } ,S_{i_2 } , \ldots ,S_{i_m } takes 0(\sum\limits_{j = 1}^m {(\frac{{\left| {S_{i_j } } \right|}}{B}}+ \sum\limits_{i = 1}^n {(n_i } \log _B \frac{m}{{n_i }})) expected I/Os, where ni is the number of times Si is queried. Inserting or deleting a string S takes 0(\frac{{\left| S \right|}}{B} + \log _B n) expected amortized I/Os. The \sum\nolimits_{j = 1}^m \frac{{\left| {S_{i_j } } \right|}}{B} term is a lower bound for reading the input; the \sum\nolimits_{i = 1}^n {n_i } \log _B \frac{m}{{n_i }} term is the entropy of the query sequence and is a standard information-theoretic lower bound. This is the Static Optimality Theorem for external-memory string access. The static optimality theorem was first formalized and proved by Tarjan and Sleator for numerical dictionary in their classic ""splay"" trees paper in 1985 [16]; they left open the B-tree case for numerical values (page 684), and a fortiori, the case of string data in an external-memory setting, that we settle here. We obtain our result not by using traditional ""splay"" operations on search trees as in [16], but by designing a novel and conceptually simple self-adjusting data structure based on the well-known skip lists."
FOCS	Dimension Reduction in the \ell _1 Norm.	Moses Charikar,Amit Sahai	2002	The Johnson-Lindenstrauss Lemma shows that any set of n points in Euclidean space can be mapped linearly down to O0({{(\log n)} \mathord{\left/ {\vphantom {{(\log n)} {\varepsilon ^2 }}} \right. \kern-\nulldelimiterspace} {\varepsilon ^2 }}) dimensions such that all pairwise distances are distorted by at most 1 + \varepsilon. We study the following basic question: Does there exist an analogue of the Johnson-Lindenstrauss Lemma for the \ell _1 norm?Note that Johnson-Lindenstrauss Lemma gives a linear embedding which is independent of the point set. For the \ell _1 norm, we show that one cannot hope to use linear embeddingsas a dimensionality reduction tool for general point sets, even if the linear embedding is chosen as a function of the given point set. In particular, we construct a set of O(n) points in n\ell _1^n such that any linear embedding into \ell _1^d must incur a distortion of \Omega (\sqrt {{n \mathord{\left/ {\vphantom {n d}} \right. \kern-\nulldelimiterspace} d}}). This bound is tight up to a log n factor. We then initiate a systematic study of general classes of \ell _1 embeddable metrics that admit low dimensional, small distortion embeddings. In particular, we show dimensionality reduction theorems for tree metrics, circular-decomposable metrics, and metrics supported on K2,3-free graphs, giving embeddings into \ell _1 withconstant distortion. Finally, we also present lower bounds on dimension reduction techniques for other \ell _p norms.Our work suggests that the notion of a stretch-limited embedding, where no distance is stretched by more than a factor d in any dimension, is important to the study of dimension reduction for \ell _1. We use such stretch limited embeddings as a tool for proving lower bounds for dimension reduction and also as an algorithmic tool for proving positive results.
FOCS	Rapidly Mixing Markov Chains for Sampling Contingency Tables with a Constant Number of Rows.	Mary Cryan,Martin E. Dyer,Leslie Ann Goldberg,Mark Jerrum,Russell A. Martin	2002	"We consider the problem of sampling almost uniformly from the set of contingency tables with given row and column sums, when the number of rows is a constant. Cryan and Dyer [J. Comput. System Sci., 67 (2003), pp. 291-310] have recently given a fully polynomial randomized approximation scheme (fpras) for the related counting problem, which employs Markov chain methods indirectly. They leave open the question as to whether a natural Markov chain on such tables mixes rapidly. Here we show that the ""2 x 2 heat-bath"" Markov chain is rapidly mixing. We prove this by considering first a heat-bath chain operating on a larger window. Using techniques developed by Morris [Random Walks in Convex Sets, Ph. D. thesis, Department of Statistics, University of California, Berkeley, CA, 2000] and Morris and Sinclair [SIAM J. Comput., 34 (2004), pp. 195-226] for the multidimensional knapsack problem, we show that this chain mixes rapidly. We then apply the comparison method of Diaconis and Saloff-Coste [Ann. Appl. Probab., 3 (1993), pp. 696-730] to show that the 2 x 2 chain is also rapidly mixing."
FOCS	Abstract Combinatorial Programs and Efficient Property Testers.	Artur Czumaj,Christian Sohler	2002	Property testing is a relaxation of classical decision problems which aims at distinguishing between functions having a predetermined property and functions being far from any function having the property. In this paper we present a novel framework for analyzing property testing algorithms. Our framework is based on a connection of property testing and a new class of problems which we call abstract combinatorial programs. We show that if the problem of testing a property can be reduced to an abstract combinatorial program of small dimension, then the property has an efficient tester.We apply our framework to a variety of problems. We present efficient property testing algorithms for geometric clustering problems, for the reversal distance problem, and for graph and hypergraph coloring problems. We also prove that, informally, any hereditary graph property can be efficiently tested if and only if it can be reduced to an abstract combinatorial program of small size.Our framework allows us to analyze all our testers in a unified way, and the obtained complexity bounds either match or improve the previously known bounds. Furthermore, even if the asymptotic complexity of the testers is not improved, the obtained proofs are significantly simpler than the previous ones. We believe that our framework will help to understand the structure of efficiently testable properties.
FOCS	Market Equilibrium via a Primal-Dual-Type Algorithm.	Nikhil R. Devanur,Christos H. Papadimitriou,Amin Saberi,Vijay V. Vazirani	2002	"Although the study of market equilibria has occupied center stage within Mathematical Economics for over a century, polynomial time algorithms for such questions have so far evaded researchers. We provide the first such algorithm for the linear version of a problem defined by Irving Fisher in 1891. Our algorithm is modeled after Kuhn's primal-dual algorithm for bipartite matching."
FOCS	The Hardness of 3 - Uniform Hypergraph Coloring.	Irit Dinur,Oded Regev,Clifford D. Smyth	2002	"We prove that coloring a 3-uniform 2-colorable hypergraph with c colors is NP-hard for any constant c. The best known algorithm [20] colors such a graph using O(n1/5) colors. Our result immediately implies that for any constants k &#x2265; 3 and c2 > c1 > 1, coloring a k-uniform c1-colorable hypergraph with c2 colors is NP-hard; the case k = 2, however, remains wide open.This is the first hardness result for approximately-coloring a 3-uniform hypergraph that is colorable with a constant number of colors. For k &#x2265; 4 such a result has been shown by [14], who also discussed the inherent difference between the k = 3 case and k &#x2265; 4.Our proof presents a new connection between the Long-Code and the Kneser graph, and relies on the high chromatic numbers of the Kneser graph [19,22] and the Schrijver graph [26]. We prove a certain maximization variant of the Kneser conjecture, namely that any coloring of the Kneser graph by fewer colors than its chromatic number, has &#x2018;many&#x2019; non-monochromatic edges."
FOCS	On the (non)Universality of the One-Time Pad.	Yevgeniy Dodis,Joel Spencer	2002	"Randomization is vital in cryptography: secret keys should be randomly generated and most cryptographic primitives (e.g., encryption) must be probabilistic. As a common abstraction, it is assumed that there is a source of truly random bits available to all the participants of the system. While convenient, this assumption is often highly unrealistic, and cryptographic systems have to be built based on imperfect sources of randomness. Remarkably, this fundamental problem has received little or no attention so far, despite the fact that a related question of simulating probabilistic (BPP) algorithms with imperfect random sources has a long and rich history.In this work we initiate the quantitative study concerning feasibility of building secure cryptographic primitives using imperfect random sources. Specifically, we concentrate on symmetric-key encryption and message authentication, where the shared secret key comes from an imperfect random source instead of being assumed truly random. In each case, we compare the class of ""cryptographic"" sources for the task at hand with the classes of ""extractable"" and ""simulatable"" sources, where: (1) ""cryptographic"" refers to sources for which the corresponding symmetric-key primitive can be build; (2) ""extractable"" refers to a very narrow class of sources from which one can extract nearly perfect randomness; and (3) ""simulatable"" refers to a very general class of weak random sources which are known to suffice for BPP simulation. For both encryption and authentication, we show that the corresponding cryptographic sources lie strictly in between extractable and simulatable sources, which implies that ""cryptographic usage"" of randomness is more demanding than the corresponding ""algorithmic usage"", but still does not require perfect randomness. Interestingly,cryptographic sources for encryption and authentication are also quite different from each other, which suggests that there might not be an elegant way to describe imperfect sources sufficient for ""general cryptographic use"". We believe that our initial investigation in this new area will inspire a lot of further research."
FOCS	The 3-XORSAT Threshold.	Olivier Dubois,Jacques Mandler	2002	We prove the existence of the 3-XORSAT threshold, establishing its value as a function of the root of a transcendental equation.
FOCS	Conflict-Free Colorings of Simple Geometric Regions with Applications to Frequency Assignment in Cellular Networks.	Guy Even,Zvi Lotker,Dana Ron,Shakhar Smorodinsky	2002	Motivated by a frequency assignment problem in cellular networks, we introduce and study a new coloring problem that we call minimum conflict-free coloring (min-CF-coloring). In its general form, the input of the min-CF-coloring problem is a set system $(X,{\cal S})$, where each $S \in {\cal S}$ is a subset of X. The output is a coloring $\chi$ of the sets in ${\cal S}$ that satisfies the following constraint: for every $x \in X$ there exists a color $i$ and a unique set $S \in {\cal S}$ such that $x \in S$ and $\chi(S) = i$. The goal is to minimize the number of colors used by the coloring $\chi$. Min-CF-coloring of general set systems is not easier than the classic graph coloring problem. However, in view of our motivation, we consider set systems induced by simple geometric regions in the plane. In particular, we study disks (both congruent and noncongruent), axis-parallel rectangles (with a constant ratio between the smallest and largest rectangle), regular hexagons (with a constant ratio between the smallest and largest hexagon), and general congruent centrally symmetric convex regions in the plane. In all cases we have coloring algorithms that use O(log n) colors (where n is the number of regions). Tightness is demonstrated by showing that even in the case of unit disks, $\Theta(\log n)$ colors may be necessary. For rectangles and hexagons we also obtain a constant-ratio approximation algorithm when the ratio between the largest and smallest rectangle (hexagon) is a constant. We also consider a dual problem of CF-coloring points with respect to sets. Given a set system $(X,{\cal S})$, the goal in the dual problem is to color the elements in X with a minimum number of colors so that every set $S \in {\cal S}$ contains a point whose color appears only once in S. We show that O(log |X|) colors suffice for set systems in which X is a set of points in the plane and the sets are intersections of X with scaled translations of a convex region. This result is used in proving that O(log n) colors suffice in the primal version.
FOCS	Graphs with Tiny Vector Chromatic Numbers and Huge Chromatic Numbers.	Uriel Feige,Michael Langberg,Gideon Schechtman	2002	"Karger, Motwani, and Sudan [J. ACM, 45 (1998), pp. 246--265] introduced the notion of a vector coloring of a graph. In particular, they showed that every $k$-colorable graph is also vector k-colorable, and that for constant k, graphs that are vector k-colorable can be colored by roughly $\Delta^{1 - 2/k}$ colors. Here $\Delta$ is the maximum degree in the graph and is assumed to be of the order of $n^{\delta}$ for some $0 We show that for every positive integer k there are graphs that are vector k-colorable but do not have independent sets significantly larger than $n/\Delta^{1 - 2/k}$ (and hence cannot be colored with significantly fewer than $\Delta^{1 - 2/k}$ colors). For $k = O(\log n/\log\log n)$ we show vector k-colorable graphs that do not have independent sets of size (log n)c, for some constant c. This shows that the vector chromatic number does not approximate the chromatic number within factors better than n/polylog n. As part of our proof, we analyze ""property testing"" algorithms that distinguish between graphs that have an independent set of size n/k, and graphs that are ""far"" from having such an independent set. Our bounds on the sample size improve previous bounds of Goldreich, Goldwasser, and Ron [J. ACM, 45 (1998), pp. 653--750] for this problem."
FOCS	Decoding Turbo-Like Codes via Linear Programming.	Jon Feldman,David R. Karger	2002	We introduce a novel algorithm for decoding turbo-like codes based on linear programming. We prove that for the case of repeat-accumulate codes, under the binary symmetric channel with a certain constant threshold bound on the noise, the error probability of our algorithm is bounded by an inverse polynomial in the code length.Our linear program (LP) minimizes the distance between the received bits and binary variables representing the code bits. Our LP is based on a representation of the code where codewords are paths through a graph. Consequently, the LP bears a strong resemblance to the rain-cost flow LP. The error bounds are based on an analysis of the probability, over the random noise of the channel, that the optimum solution to the LP is the path corresponding to the original transmitted codeword.
FOCS	The Parameterized Complexity of Counting Problems.	Jörg Flum,Martin Grohe	2002	"We develop a parameterized complexity theory for counting problems. As the basis of this theory, we introduce a hierarchy of parameterized counting complexity classes #W$[t]$, for $t\ge 1$, that corresponds to Downey and Fellows's W-hierarchy [R. G. Downey and M. R. Fellows, Parameterized Complexity, Springer-Verlag, New York, 1999] and we show that a few central W-completeness results for decision problems translate to \#W-completeness results for the corresponding counting problems. Counting complexity gets interesting with problems whose decision version is tractable, but whose counting version is hard. Our main result states that counting cycles and paths of length k in both directed and undirected graphs, parameterized by k, is #W$[1]-complete. This makes it highly unlikely that these problems are fixed-parameter tractable, even though their decision versions are fixed-parameter tractable. More explicitly, our result shows that most likely there is no $f(k) \cdot n^c$-algorithm for counting cycles or paths of length k in a graph of size n for any computable function $f: \mathbb{N} \to \mathbb{N}$ and constant c, even though there is a $2^{O(k)} \cdot n^{2.376}$ algorithm for finding a cycle or path of length k [N. Alon, R. Yuster, and U. Zwick, J. ACM, 42 (1995), pp. 844--856]."
FOCS	Implicit B-Trees: New Results for the Dictionary Problem.	Gianni Franceschini,Roberto Grossi,J. Ian Munro,Linda Pagli	2002	"We reopen the issue of finding an implicit data structure for the dictionary problem. In particular, we examine the problem of maintaining n data values in the first n locations of an array in such a way that we can efficiently perform the operations insert, delete and search. No information other than n and the data is to be retained; and the only operations which we may perform on the data values (other than reads and writes) are comparisons. Our structure supports these operations in 0(\log ^2 n/\log \log n) time, marking the first improvement on the problem since the mid 1980's. En route we develop a number of space efficient techniques for handling segments of a large array in a memory hierarchy. We achieve a cost of 0(\log _B n) block transfers like in regular B-trees, under the realistic assumption that a block stores B = \Omega (\log n) keys, so that reporting r consecutive keys in sorted order has a cost of 0(\log _B n + {r \mathord{\left/ {\vphantom {r B}} \right. \kern-\nulldelimiterspace} B}) block transfers. Being implicit, our B-tree occupies exactly \left\lceil {{\raise0.7ex\hbox{$n$} \!\mathord{\left/ {\vphantom n B}}\right.\kern-\nulldelimiterspace} \!\lower0.7ex\hbox{$B$}}} \right\rceilblocks after each update."
FOCS	Testing Juntas.	Eldar Fischer,Guy Kindler,Dana Ron,Shmuel Safra,Alex Samorodnitsky	2002	We show that a boolean valued function over n variables, where each variable ranges in an arbitrary probability space, can be tested for the property of depending on only J of them using a number of queries that depends only polynomially on J and the approximation parameter ε. We present several tests that require a number of queries that is polynomial in J and linear in ε-1. We showa non-adaptive tests that has one-sided error, an adaptive version of it that requires fewer queries, and a non-adaptive two-sided version of the test that requires the least number of queries. We also show a two-sided non-adaptive test that applies to functions over n boolean variables, and has a more compact analysis.We then provide a lower bound of Ω˜(√J) on the number of queries required for the nonadaptive testing of the above property; a lower bound of Ω(log(J + 1)) for adaptive algorithms naturally follows from this. In establishing this lower bound we also prove a result about random walks on the group Z2q that may be interesting in its own right. We show that for some t(q) = Ω˜(q2), the distributions of the random walk at times t and t + 2 are close to each other, independently of the step distribution of the walk.We also discuss related questions. In particular, when given in advance a known J-junta function h, we show how to test a function f for the property of being identical to h up to a permutation of the variables, in a number of queries that is polynomial in J and ε-1.
FOCS	On Random Symmetric Travelling Salesman Problems.	Alan M. Frieze	2002	Let the edges of the complete graphK nbe assigned independent uniform [0, 1] random edge weights. LetZTSP andZ2FAC be the weights of the minimum length travelling salesman tour and minimum weight 2-factor, respectively. We show thatwhp | ZTSP -Z2FAC| =o(1). The proof is obtained by the analysis of a polynomial time algorithm that finds a tour only a little longer thanZ2FAC.
FOCS	A Simple Algorithmic Characterization of Uniform Solvability.	Eli Gafni	2002	The Herlihy-Shavit (HS) conditions characterizing the solvability of asynchronous tasks over n processors have been a milestone in the development of the theory of distributed computing. Yet, they were of no help when researcher sought algorithms that do not depend on n.Tohelp in this pursuit we investigate the uniform solvability of an infinite uniform sequence of tasks T0, T1, T2, ¿,where Ti is a task over processors p0, p1,¿, pi , and Ti extends Ti- 1. We say that such a sequence is uniformly solvable if there exit protocols to solve each Ti and the protocol for Ti extends the protocol for Ti. This paper establishes that although each Ti may be solvable, the uniform sequence is not necessarily uniformly solvable. We show this by proposing a novel uniform sequence of solvable tasks and proving that the sequence is not amenable to a uniform solution. We then extend the HS conditions for a task over n processors, to uniform solvability in a natural way. The technique we use to accomplish this is to generalize the alternative algorithmic proof, by Borowsky and Gafni, of the HS conditions, by showing that the infinite uniform sequence of task of Immediate Snapshots is uniformly solvable. A side benefit of the technique is a widely applicable methodology for thedevelopment of uniform protocols.
FOCS	Dependent Rounding in Bipartite Graphs.	Rajiv Gandhi,Samir Khuller,Srinivasan Parthasarathy,Aravind Srinivasan	2002	We combine the pipage rounding technique of Ageev & Sviridenko with a recent rounding method developed by Srinivasan, to develop a new randomized rounding approachfor fractional vectors defined on the edge-sets of bipartite graphs. We show various ways of combining this technique with other ideas, leading to the following applications:richer random-graph models for graphs with a given degree-sequence;improved approximation algorithms for: (i) throughput-maximization in broadcast scheduling, (ii) delay-minimization in broadcast scheduling, and (iii) capacitated vertex cover;fair scheduling of jobs on unrelated parallel machines.A useful feature of our method is that it lets us prove certain (probabilistic) per-user fairness properties.
FOCS	Fast Approximation Algorithms for Fractional Steiner Forest and Related Problems.	Naveen Garg,Rohit Khandekar	2002	We give a fully polynomial time approximation scheme (FPTAS) for the optimum fractional solution to the Steiner forest problem. This can easily be generalized to obtain an FPTAS for a hitting set problem on a collection of clutters. We also identify three other problems on collections of clutters and show how these four problems are related when the clutters have the max-flow min-cut (MFMC) property. Two of these problems which are generalizations of maximum multicommodity flow and maximum concurrent flow have been well studied in the past and this paper is the first attempt at designing efficient algorithms for the other two problems.Our algorithms are very simple to describe and have running times better than those of existing algorithms. For clutters that do not satisfy the MFMC property (e.g., k-spanner, multicommodity flows, T-cuts, T-joins etc.), our algorithms are the only ones known (other than the generic algorithms for linear programming) for solving these hitting set problems.
FOCS	On-Line End-to-End Congestion Control.	Naveen Garg,Neal E. Young	2002	Congestion control in the current Internet is accomplished mainly by TCP/IP. To understand the macroscopic network behavior that results from TCP/IP and similar end-to-end protocols, one main analytic technique is to show that the the protocol maximizes some global objective function of the network traffic.Here we analyze a particular end-to-end, MIMD (multiplicative-increase, multiplicative-decrease) protocol. We show that if all users of the network use the protocol, and all connections last for at least logarithmically many rounds, then the total weighted throughput (value of all packets received) is near the maximum possible. Our analysis includes round-trip-times, and (in contrast to most previous analyses) gives explicit convergence rates, allows connections to start and stop, and allows capacities to change.
FOCS	Zero-Knowledge.	Oded Goldreich	2002	Zero-Knowledge.
FOCS	Locally Testable Codes and PCPs of Almost-Linear Length.	Oded Goldreich,Madhu Sudan	2002	We initiate a systematic study of locally testable codes; that is, error-correcting codes that admit very efficient membership tests. Specifically, these are codes accompanied with tests that make a constant number of (random) queries into any given word and reject non-codewords with probability proportional to their distance from the code.Locally testable codes are believed to be the combinatorial core of PCPs. However, the relation is less immediate than commonly believed. Nevertheless, we show that certain PCP systems can be modified to yield locally testable codes. On the other hand, we adapt techniques that we develop for the construction of the latter to yield new PCPs.Our main results are locally testable codes and PCPs of almost-linear length. Specifically, we prove the existence of the following constructs:---Locally testable binary (linear) codes in which k information bits are encoded by a codeword of length k &sdot; exp(&Otilde;(&radic;(log k))). This improves over previous results that either yield codewords of exponential length or obtained almost quadratic length codewords for sufficiently large nonbinary alphabet.---PCP systems of almost-linear length for SAT. The length of the proof is n &sdot; exp(&Otilde;(&radic;(log n))) and verification in performed by a constant number (i.e., 19) of queries, as opposed to previous results that used proof length n(1 &plus; O(1/q)) for verification by q queries.The novel techniques in use include a random projection of certain codewords and PCP-oracles that preserves local-testability, an adaptation of PCP constructions to obtain &ldquo;linear PCP-oracles&rdquo; for proving conjunctions of linear conditions, and design of PCPs with some new soundness properties---a direct construction of locally testable (linear) codes of subexponential length.
FOCS	Integer Sorting in 0(n sqrt (log log n)) Expected Time and Linear Space.	Yijie Han,Mikkel Thorup	2002	"We present a randomized algorithm sorting n integers in 0(n\sqrt {\log \log n}) expected time and linear space. This improves the previous O(n log log n) bound by Anderson et al. from STOC'95. As an immediate consequence, if the integers are bounded by U, we can sort them in 0(n\sqrt {\log \log U}) expected time. This is the first improvement over the O(n log log U) bound obtained with van Emde Boas' data structure from FOCS'75.At the heart of our construction, is a technical deterministic lemma of independent interest; namely, that we split n integers into subsets of size at most \sqrt nin linear time and space. This also implies improved bounds for deterministic string sorting and integer sorting without multiplication."
FOCS	"Erratum to ""Vickrey Pricing and Shortest Paths: What is an Edge Worth?""."	John Hershberger,Subhash Suri	2002	"Erratum to ""Vickrey Pricing and Shortest Paths: What is an Edge Worth?""."
FOCS	Privacy and Interaction in Quantum Communication Complexity and a Theorem about the Relative Entropy of Quantum States.	Rahul Jain,Jaikumar Radhakrishnan,Pranab Sen	2002	"We prove a fundamental theorem about the relative entropy of quantum states, which roughly states that if the relative entropy, S(\rho \left\| \sigma\right.) \triangleqTr \rho (\log \rho- \log \sigma ), of two quantum states \rho and \sigma is at most c, then \frac{\rho }{{2^0 (c)}} sits inside' \sigma. Using this substate' theorem, we give tight lower bounds for the privacy loss of bounded error quantum communication protocols for the index function problem. We also use the substate' theorem to give tight lower bounds for the k-round bounded error quantum communication complexity of the pointer chasing problem, when the wrong player starts, and all the log n bits of the kth pointer are desired."
FOCS	Spectral Gap and log-Sobolev Constant for Balanced Matroids.	Mark Jerrum,Jung-Bae Son	2002	"We compute tight lower bounds on the log-Sobolev constant of a class of inductively defined Markov chains, which contains the bases ¿ exchange walks for balanced matroidsstudied by Feder and Mihail. As a corollary, we obtain improved upper bounds for the mixing time of a variety of Markov chains. An example: the ""natural"" random walk on spanning trees of a graph G as proposed by Broder ¿ which has been studied by a number of authors ¿ mixes in time O(mn log n),wheren is the number of vertices of G and m the number of edges. This beats the best previous upper bound on this walk by a factor n2."
FOCS	Protocols and Impossibility Results for Gossip-Based Communication Mechanisms.	David Kempe,Jon M. Kleinberg	2002	"In recent years, gossip-based algorithms have gained prominence as a methodology for designing robust and scalable communication schemes in large distributed systems. The premise underlying distributed gossip is very simple: in each time step, each node v in the system selects some other node w as a communication partner ¿ generally by a simple randomized rule ¿ and exchanges information with w ; over a period of time, information spreads through the system in an ""epidemic fashion"".A fundamental issue which is not well understood is the following: how does the underlying low-level gossip mechanism ¿ the means by which communication partners are chosen ¿ affect one's ability to design efficient high-level gossip-based protocols? We establish one of the first concrete results addressing this question, by showing a fundamentallimitation on the power of the commonly used uniform gossip mechanism for solving nearest-resource location problems. In contrast, very efficient protocols for this problem can be designed using a non-uniform spatial gossip mechanism, as established in earlier work with Alan Demers.We go on to consider the design of protocols for more complex problems, providing an efficient distributed gossip-based protocol for a set of nodes in Euclidean space to construct an approximate minimum spanning tree. Here too, we establish a contrasting limitation on the power of uniform gossip for solving this problem. Finally, we investigate gossip-based packet routing as a primitive that underpins the communication patterns in many protocols, and as away to understand the capabilities of different gossip mechanisms at a general level."
FOCS	Hardness Results for Coloring 3 -Colorable 3 -Uniform Hypergraphs.	Subhash Khot	2002	"In this paper, we consider the problem of coloring a 3-colorable 3-uniform hypergraph. In the minimization version of this problem, given a 3-colorable 3-uniform hypergraph, one seeks an algorithm to color the hypergraph with as few colors as possible. We show that it is NP-hard to color a 3-colorable 3-uniform hypergraph with constantly many colors. In fact, we show a stronger result that it is NP-hard to distinguish whether a 3-uniform hypergraph with nvertices is 3-colorable or it contains no independent set of size \delta n for an arbitrarily small constant \delta >0. In the maximization version of the problem, given a 3-uniform hypergraph,the goal is to color the vertices with 3 colors so as to maximize the number of non-monochromatic edges. We show that it is NP-hard to distinguish whether a 3-uniformhypergraph is 3-colorable or any coloring of the vertices with 3 colors has at most \frac{8}{9} + \varepsilonfraction of the edges non-monochromatic where \varepsilon > 0 is an arbitrarily small constant. This result is tight since assigning a random color independently to every vertex makes \frac{8}{9} fraction of the edges non-monochromatic.These results are obtained via a new construction of a probabilistically checkable proof system (PCP) for NP. We develop a new construction of the PCP Outer Verifier. An important feature of this construction is smoothening of the projection maps.Dinur, Regev and Smyth [6] independently showed that it is NP-hard to color a 2-colorable 3-uniform hypergraph with constantly many colors. In the ""good case"", the hypergraph they construct is 2-colorable and hence their result is stronger. In the ""bad case"" however, the hypergraph we construct has a stronger property, namely, it does not even contain an independent set of size \delta n."
FOCS	Learning Intersections and Thresholds of Halfspaces.	"Adam Klivans,Ryan O'Donnell,Rocco A. Servedio"	2002	We give the first polynomial time algorithm to learn any function of a constant number of halfspaces under the uniform distribution on the Boolean hypercube to within any constant error parameter. We also give the first quasipolynomial time algorithm for learning any Boolean function of a polylog number of polynomial-weight halfspaces under any distribution on the Boolean hypercube. As special cases of these results we obtain algorithms for learning intersections and thresholds of halfspaces. Our uniform distribution learning algorithms involve a novel non-geometric approach to learning halfspaces; we use Fourier techniques together with a careful analysis of the noise sensitivity of functions of halfspaces. Our algorithms for learning under any distribution use techniques from real approximation theory to construct low-degree polynomial threshold functions. Finally, we also observe that any function of a constant number of polynomial-weight halfspaces can be learned in polynomial time in the model of exact learning from membership and equivalence queries.
FOCS	The Partition Technique for Overlays of Envelopes.	Vladlen Koltun,Micha Sharir	2002	"We obtain a near-tight bound of 0(n^{3 + \varepsilon }), for any \varepsilon > 0, on the complexity of the overlay of the minimization diagrams of two collections of surfaces in four dimensions. This settles a long-standing problem in the theory of arrangements, most recently cited by Agarwal and Sharir [3, Open Problem 2], and substantially improves and simplifies a result previously published by the authors [15]. Our bound has numerous algorithmic and combinatorial applications, some of which are presented in this paper.Our result is obtained by introducing a new approach to the analysis of combinatorial structures arising in geometric arrangements of surfaces. This approach, which we call the partition technique', is based on k-fold divide and conquer, in which a given collection F of n surfaces is partitioned into k subcollections Fi of {n \mathord{\left/ {\vphantom {n k}} \right. \kern-\nulldelimiterspace} k} surfaces each, and the complexity of the relevant combinatorial structure in F is recursively related to the complexities of the corresponding structures in each of the Fi's. We introduce this approach by applying it first to obtain a new simple proof for the known near-quadratic bound on the complexity of an overlay of two minimization diagrams of collections of surfaces in \mathbb{R}^3, thereby simplifying the previously available proof [2]."
FOCS	Deterministic Broadcasting Time in Radio Networks of Unknown Topology.	Dariusz R. Kowalski,Andrzej Pelc	2002	In a seminal paper [3], Bar-Yehuda, Goldreich and Itai considered broadcasting in radio networks whose nodes know only their own label and labels of their neighbors. They claimed a linear lower bound on the time of deterministic broadcasting in such radio networks, by constructing a class of graphs of diameter 3, with the property that every broadcasting algorithm requires linear time on one of these graphs. Due to a subtle error in the argument, this result is incorrect. We construct an algorithm that broadcasts in logarithmic time on all graphs from [3]. Moreover, we show how to broadcast in sublinear time on all n -node graphs of diameter 0(log log n). On the other hand, we construct a class of graphs of diameter 4, such that every broadcasting algorithm requires time \Omega (\sqrt[4]{n}) on one of these graphs. In view of the randomized algorithm from [3], runnning in expected time O(Dlogn + log2n) on all n -node graphs of diameter D, our lower bound gives the first correct proof of an exponential gap between determinism and randomization in the time of radio broadcasting.
FOCS	A Constant-Factor Approximation Algorithm for the Multicommodity.	Amit Kumar,Anupam Gupta,Tim Roughgarden	2002	We present the first constant-factor approximation algorithm for network design with multiple commodities and economies of scale. We consider the rent-or-buy problem, a type of multicommodity buy-at-bulk network design in which there are two ways to install capacity on any given edge. Capacity can be rented, with cost incurred on a per-unit of capacity basis, or bought, which allows unlimited use after payment of a large fixed cost. Given a graph and a set of source-sink pairs, we seek a minimum-cost way of installing sufficient capacity on edges so that a prescribed amount of flow can be sent simultaneously from each source to the corresponding sink.Recent work on buy-at-bulk network design has concentrated on the special case where all sinks are identical; existing constant-factor approximation algorithms for this special case make crucial use of the assumption that all commodities ship flow to the same sink vertex and do not obviously extend to the multicommodity rent-or-buy problem. Prior to our work, the best heuristics for the multicommodity rent-or-buy problem achieved only logarithmic performance guarantees and relied on the machinery of relaxed metrical task systems or of metric embeddings. By contrast, we solve the network design problem directly via a novel primal-dual algorithm.
FOCS	Forbidden Information.	Leonid A. Levin	2002	There appears to be a gap between usual interpretations of Godel Theorem and what is actually proven. Closing this gap does not seem obvious and involves complexity theory. (This is unrelated to, well studied before, complexity quantifications of the usual Godel effects.) Similar problems and answers apply to other unsolvability results for tasks where required solutions are not unique, such as, e.g., non-recursive tilings.
FOCS	LT Codes.	Michael Luby	2002	We introduce LT codes, the first rateless erasure codes that are very efficient as the data length grows.
FOCS	Generalized Compact Knapsacks, Cyclic Lattices, and Efficient One-Way Functions from Worst-Case Complexity Assumptions.	Daniele Micciancio	2002	We study a generalization of the compact knapsack problem for arbitrary rings: given m = O(log n) ring elements a_1 , \ldots ,a_m \varepsilon R and a target value b\varepsilon R, find coefficients x_1 , \ldots ,x_m \varepsilon X (where X is a subset of R of size 2^n) such thatsum {a_i } x_i= b. The computational complexity of this problem depends on the choice of the ring R and set of coefficients X. This problem is known to be solvable in quasi polynomial time when R is the ring of the integers and X is the set of small integers { 0, \ldots ,2^n- 1}. We show that if R is an appropriately chosen ring of modular polynomials and X is the subset of polynomials with small coefficients, then the compact knapsack problem is as hard to solve on the average as the worst case instance of approximating the covering radius (or the length of the shortest vector, or various other well known lattice problems) of any cyclic lattice within a polynomial factor. Our proof adapts, to the cyclic lattice setting, techniques initially developed by Ajtai for the case of general lattices.
FOCS	Load Balancing with Memory.	Michael Mitzenmacher,Balaji Prabhakar,Devavrat Shah	2002	"A standard load balancing model considers placing n balls into n bins by choosing d possible locations for each ball independently and uniformly at random and sequentially placing each in the least loaded of its chosen bins. It is well known that allowing just a small amount of choice(d = 2) greatly improves performance over random placement (d = 1). In this paper, we show that similar performance gains occur by introducing memory. We focus on the situation where each time a ball is placed, the least loaded of that ball's choices after placement is remembered and used as one of the possible choices for the next ball. For example, we show that when each ball gets just one random choice, but can also choose the best of the last ball's choices, the maximum number of balls in a bin is l{{\log \log n} \mathord{\left/ {\vphantom {{\log \log n} {2\log \phi+ 0(1)}}} \right. \kern-\nulldelimiterspace} {2\log \phi+ 0(1)}} with high probability, where \phi= ({{1 + \sqrt 5 )} \mathord{\left/ {\vphantom {{1 + \sqrt 5 )} 2}} \right. \kern-\nulldelimiterspace} 2} is the golden ratio. The asymptotic performance is therefore better with one random choice and one choice from memory than with two fresh random choices for each ball; the performance with memory asymptoticallymatches the asymmetric policy using two choices introduced by Vöcking. More generally, we find that a small amount of memory, like a small amount of choice, can dramatically improve the load balancing performance. We also investigate continuous time variations corresponding to queueing systems, where we find similar results."
FOCS	Quantum Lower Bounds for the Collision and the Element Distinctness Problems.	Yaoyun Shi	2002	Given a function f as an oracle, the collision problem is to find two distinct inputs i and j such that f(i) = f(j) under the promise that such inputs exist. In this paper, we prove that any quantum algorithm for finding a collision in an r -to-one function must evaluate the function\Omega (({n \mathord{\left/ {\vphantom {n r}} \right. \kern-\nulldelimiterspace} r}){1 \mathord{\left/ {\vphantom {1 {3)}}} \right. \kern-\nulldelimiterspace} {3)}} times, where n is the size of the domain and {r \mathord{\left/ {\vphantom {r n}} \right. \kern-\nulldelimiterspace} n}. This lower bound matches, up to a constant factor, the upper bound of Brassard, Hyer, and Tapp [ACM SIGACT News, 28:14-19, 1997], which uses the quantum algorithm of Grover [Proceedings of the Twenty-Eighth Annual ACM Symposium on the Theory of Computing, pages 212-219, 1996] in a novel way. The previously best quantum lower bound is \Omega (({n \mathord{\left/ {\vphantom {n {r)^{{1 \mathord{\left/ {\vphantom {1 5}} \right. \kern-\nulldelimiterspace} 5}} }}} \right. \kern-\nulldelimiterspace} {r)^{{1 \mathord{\left/ {\vphantom {1 5}} \right. \kern-\nulldelimiterspace} 5}} }}) evaluations, due to Aaronson [Proceedings of the Thirty-Fourth Annual ACM Symposium on the Theory of Computing, pages 635-642, 2002]. Our result implies a quantum lower bound of \Omega (n^{{2 \mathord{\left/ {\vphantom {2 3}} \right. \kern-\nulldelimiterspace} 3}}) queries to the inputs for another well studied problem, the element distinctness problem, which is to determine whether or not the given n real numbers are distinct. The previous best lower bound is \Omega (\sqrt n ) queries in the black-box model; and \Omega (\sqrt n \log n) comparisons in the comparisons-only model, due to Hyer, Neerbek, and Shi [Lecture Notes in ComputerScience, Vol. 2076, pp. 346-357, 2001].
FOCS	Concurrent Zero Knowledge with Logarithmic Round-Complexity.	Manoj Prabhakaran,Alon Rosen,Amit Sahai	2002	We show that every language in NP has a (black-box) concurrent zero-knowledge proof system using \widetilde0(\log n) rounds of interaction. The number of rounds in our protocol is optimal, in the sense that any language outside BPP requires at least \widetilde\Omega (\log n) rounds of interaction in order to be proved in black-box concurrent zero-knowledge. The zero-knowledge property of our main protocol is proved under the assumption that there exists a collection of claw-free functions. Assuming only the existence of one-way functions, we show the existence of \widetilde0(\log n)-round concurrent zero-knowledge arguments for all languages in NP .
FOCS	An Inverse-Ackermann Style Lower Bound for the Online Minimum Spanning Tree.	Seth Pettie	2002	"We consider the problem of preprocessing an edge-weighted tree T in order to quickly answer queries of the following type: does a given edge e belong in the minimum spanning tree of T \cup \{ e\}? Whereas the offline minimum spanning tree verification problem admits a lovely linear time solution, we demonstrate an inherent inverse-Ackermann type tradeoff in the online MST verification problem. In particular, any scheme that answers queries in t comparisons must invest \Omega (n\log \lambda _t (n)) time preprocessing the tree, where \lambda _tis the inverse of the tth row of Ackermann's function. This implies a query lower bound of \Omega (\alpha (n)) for the case of linear preprocessing time. We also show that our lower bound is tight to within a factor of 2 in the t parameter."
FOCS	Improved Dynamic Reachability Algorithms for Directed Graphs.	Liam Roditty,Uri Zwick	2002	We obtain several new dynamic algorithms for maintaining the transitive closure of a directed graph and several other algorithms for answering reachability queries without explicitly maintaining a transitive closure matrix. Among our algorithms are: (i) A decremental algorithm for maintaining the transitive closure of a directed graph, through an arbitrary sequence of edge deletions, in $O(mn)$ total expected time, essentially the time needed for computing the transitive closure of the initial graph. Such a result was previously known only for acyclic graphs. (ii) Two fully dynamic algorithms for answering reachability queries. The first is deterministic and has an amortized insert/delete time of $O(m\sqrt{n})$, and worst-case query time of $O(\sqrt{n})$. The second is randomized and has an amortized insert/delete time of $O(m^{0.58}n)$ and worst-case query time of $O(m^{0.43})$. This significantly improves the query times of algorithms with similar update times. (iii) A fully dynamic algorithm for maintaining the transitive closure of an acyclic graph. The algorithm is deterministic and has a worst-case insert time of $O(m)$, constant amortized delete time of $O(1)$, and a worst-case query time of $O(n/\log n)$. Our algorithms are obtained by combining several new ideas, one of which is a simple sampling idea used for detecting decompositions of strongly connected components, with techniques of Even and Shiloach [J. ACM, 28 (1981), pp. 1-4], Italiano [Inform. Process. Lett., 28 (1988), pp. 5-11], Henzinger and King [Proceedings of the $36$th Annual Symposium on Foundations of Computer Science, Milwaukee, WI, 1995, pp. 664-672], and Frigioni et al. [ACM J. Exp. Algorithmics, 6 (2001), (electronic)].
FOCS	On the Hardness of Optimal Auctions.	Amir Ronen,Amin Saberi	2002	"We study a fundamental problem in micro economics called optimal auction design: A seller wishes to sell an item to a group of self-interested agents. Each agent i has a privately known valuation vi for the object. Given a distribution on these valuations, the goal is to construct an optimal auction, i.e. a truth revealing protocol that maximizes the seller's expected revenue.We study this problem from a computational perspective and show several lower bounds. In particular we prove that no deterministic polynomial time ascending auction can achieve an approximation ratio better than \frac{3}{4}. The probability distribution constructed in our example has sensitive dependencies among the agents. On the flip side, we show that if the dependency between the agents' valuations is bounded, the problem can be approximated with a factor close to 1."
FOCS	Minimizing Congestion in General Networks.	Harald Räcke	2002	A principle task in parallel and distributed systems is to reduce the communication load in the interconnection network, as this is usually the major bottleneck for the performance of distributed applications. In this paper we introduce a framework for solving on-line problems that aim to minimize the congestion (i.e. the maximum load of a network link) in general topology networks.We apply this framework to the problem of on-line routing of virtual circuits and to a dynamic data management problem. For both scenarios we achieve a competitive ratioof O(log3n) with respect to the congestion of the network links.Our on-line algorithm for the routing problem has the remarkable property that it is oblivious, i.e., the path chosen for a virtual circuit is independent of the current network load. Oblivious routing strategies can easily be implemented in distributed environments and have thereforebeen intensively studied for certain network topologies as e.g. meshes, tori and hypercubic networks. This is the first oblivious path selection algorithm that achieves a polylogarithmiccompetitive ratio in general networks.
FOCS	Quantum Computation and Lattice Problems.	Oded Regev	2002	We present the first explicit connection between quantum computation and lattice problems. Namely, our main result is a solution to the unique shortest vector problem (SVP) under the assumption that there exists an algorithm that solves the hidden subgroup problem on the dihedral group by coset sampling. Additionally, we present an approach to solving the hidden sub-group problem on the dihedral group by using an average case subset sum routine.
FOCS	A Switching Lemma for Small Restrictions and Lower Bounds for k - DNF Resolution.	Nathan Segerlind,Samuel R. Buss,Russell Impagliazzo	2002	We prove a new switching lemma that works for restrictions that set only a small fraction of the variables and is applicable to formulas in disjunctive normal form (DNFs) with small terms. We use this to prove lower bounds for the Res(k) propositional proof system, an extension of resolution which works with k-DNFs instead of clauses. We also obtain an exponential separation between depth d circuits of bottom fan-in k and depth d circuits of bottom fan-in k + 1.Our results for Res(k) are as follows: The 2n to n weak pigeonhole principle requires exponential size to refute in Res(k) for $k \leq \sqrt{\log n / \log \log n } $. For each constant k, there exists a constant w > k so that random w-CNFs require exponential size to refute in Res(k). For each constant k, there are sets of clauses which have polynomial size Res(k + 1) refutations but which require exponential size Res(k) refutations.
FOCS	Equivalence between Priority Queues and Sorting.	Mikkel Thorup	2002	"We present a general deterministic linear space reduction from priority queues to sorting implying that if we can sort up to n keys in S(n) time per key, then there is a priority queue supporting delete and insert in O(S(n)) time and find-min in constant time. Conversely, a priority queue can trivially be used for sorting: first insert all keys to be sorted, then extract them in sorted order by repeatedly deleting the minimum. Asymptotically, this settles the complexity of priority queues in terms of that of sorting. Previously, at SODA'96, such a result was presented by the author for the special case of monotone priority queues where the minimum is not allowed to decrease. Besides nailing down the complexity of priority queues to that of sorting, and vice versa, our result yields several improved bounds for linear space integer priority queues with find-min in constant time: Deterministically. We get O(log log n) update time using a sorting algorithm of Han from STOC'02. This improves the O((log log n)(log log log n)) update time of Han from SODA'01. Randomized. We get O(&sqrt;log log n) expected update time using a randomized sorting algorithm of Han and Thorup from FOCS'02. This improves the O(log log n) expected update time of Thorup from SODA'96. Deterministically in AC0 (without multiplication). For any &epsiv; > 0, we get O((log log n)1&plus;&epsiv;) update time using an AC0 sorting algorithm of Han and Thorup from FOCS'02. This improves the O((log log n)2) update time of Thorup from SODA'98. Randomized in AC0. We get O(log log n) expected update time using a randomized AC0 sorting algorithm of Thorup from SODA'97. This improves the O((log log n)1&plus;&epsiv;) expected update time of Thorup also from SODA'97. The above bounds assume that each integer is stored in a single word and that word operations take unit time as in the word RAM."
FOCS	Randomness Extractors and their Many Guises.	Salil P. Vadhan	2002	Since its introduction by Nisan and Zuckerman (STOC93) nearly a decade ago, the notion of a randomness extractor has proven to be a fundamental and powerful one. Extractors and their variants have found widespread application in a variety of areas, including pseudorandomness and derandomization, combinatorics, cryptography, data structures, and computational complexity. Equally striking has been a sequence of discoveries showing that, under different interpretations, extractors are close relatives of a number of other important objects, such as expander graphs, hash functions, error-correcting codes, pseudorandom generators, and sampling algorithms. Through these connections, extractors have unified the study of these objects and have led to new and improved constructions of each.In this tutorial, we give an introduction to the study of extractors. The structure of the tutorial is built around the connections between extractors and the other objects mentionedabove. Within the context of these connections, we hope to convey an understanding of the definition of extractors, some intuition for how they are constructed, and a glimpse of their use in applications.
FOCS	On Approximating the Radii of Point Sets in High Dimensions.	Kasturi R. Varadarajan,Srinivasan Venkatesh,Jiawei Zhang	2002	"Let P be a set of n points in \mathbb{R}^d. For any 1 \leqslant k \leqslant d, the outer k-radius of P, denoted by Rk (P), is the minimum, over all (d - k)-dimensional flats F, of \max _{p\varepsilon P} d(p,f), where d (p, F) is the Euclidean distance between the pointp and flat F . We consider the scenario when the dimension d is not fixed and can be as large as n. Computing the various radii of point sets is a fundamental problem in computational convexity with many applications.The main result of this paper is a randomized polynomial time algorithm that approximates Rk(P) to within a factor of 0(\sqrt {\log n \cdot \log d}) for any 1 \leqslant k \leqslant d. This algorithm is obtained using techniques from semidefinite programming and dimension reduction. Previously, good approximation algorithms were known only for the case k =1and for the case when k = d - c for any constant c ; there are polynomial time algorithms that approximate Rk(P) to within a factor of (1 + \varepsilon), for any e>0, when d - k is any fixed constant [23, 7]. On the other hand, some results from the mathematical programming community on approximating certain kinds of quadratic programs [28, 27] imply an 0(\sqrt {\log n} ) approximation for R1(P), the width of the pointset P.We also prove an inapproximability result for computing Rk(P), which easily yields the conclusion that our approximation algorithm performs quite well for a large range ofvalues of k . Our inapproximability result for Rk(P) improves the previous known hardness result of Brieden [13], and is proved by improving the parameters in Brieden's construction using basic ideas from PCP theory."
FOCS	A Spectral Algorithm for Learning Mixtures of Distributions.	Santosh Vempala,Grant Wang	2002	"We show that a simple spectral algorithm for learning a mixture of k spherical Gaussians in Rn works remarkably well ¿ it succeeds in identifying the Gaussians assuming essentially the minimum possible separation between their centers that keeps them unique (solving an open problem of [1]). The sample complexity and running time are polynomial in both n and k. The algorithm also works for the more general problem of learning a mixture of ""weakly isotropic"" distributions (e.g. a mixture of uniform distributions on cubes)."
FOCS	Optimal System of Loops on an Orientable Surface.	Éric Colin de Verdière,Francis Lazarus	2002	Optimal System of Loops on an Orientable Surface.
FOCS	"Kolmogorov's Structure Functions with an Application to the Foundations of Model Selection."	Nikolai K. Vereshchagin,Paul M. B. Vitányi	2002	"In 1974 Kolmogorov proposed a non-probabilistic approach to statistics, an individual combinatorial relation between the data and its model. We vindicate, for the first time, the rightness of the original ""structure function"", proposed by Kolmogorov: minimizing the data-to-model code length (finding the ML estimator or MDL estimator), in a class of contemplated models of prescribed maximal (Kolmogorov) complexity, always results in a model of best fit (expressed as minimal randomness deficiency). We show that both the structure function and the minimum randomness deficiency function can assume all shapes over their full domain (improving an old result of L.A. Levin and both an old and a recent one of V.V. Vyugin). We determine the (un)computability properties of the various functions and ""algorithmic sufficient statistic."""
FOCS	Nash Equilibria in Competitive Societies, with Applications to Facility Location, Traffic Routing and Auctions.	Adrian Vetta	2002	We consider the following class of problems. The value of an outcome to a society is measured via a submodular utility function (submodularity has a natural economic interpretation: decreasing marginal utility). Decisions, however are controlled by non-cooperative agents who seek to maximise their own private utility. We present, under some basic assumptions, guarantees on the social performance of Nash equilibria. For submodular utility functions, any Nash equilibrium gives an expected social utility within a factor 2 of optimal, subject to a function-dependent additive term. For non-decreasing, submodular utility functions, any Nash equilibrium gives an expected social utility within a factor 1 + \deltaof optimal, where 0 \leqslant \delta\leqslant 1 is a number based upon the discrete curvature of the function. A condition under which all sets of social and private utility functions induce pure strategy Nash equilibria is presented. The case in which agents, themselves, make use of approximation algorithms in decision making is discussed and performance guarantees given. Finally we present some specific problems that fall into our framework. These include the competitive versions of the facility location problem and k-median problem, a maximisation version of the traffic routing problem studied by Roughgarden and Tardos [9], and multiple-item auctions.
FOCS	On-Line Confidence Machines Are Well-Calibrated.	Vladimir Vovk	2002	Transductive Confidence Machine (TCM) and its computationally efficient modification, Inductive Confidence Machine (ICM), are ways of complementing machine-learning algorithms with practically useful measures of confidence. We show that when TCM and ICM are used in the on-line mode, their confidence measures are well-calibrated, in the sense that predictive regions at confidence level 1 - \delta will be wrong with relative frequency at most \delta (approaching \delta in the case of randomised TCM and ICM) in the long run. This is not just an asymptotic phenomenon: actually the error probability of randomised TCM and ICM is \delta at every trial and errors happen independently at different trials.
FOCS	imits on the Power of Quantum Statistical Zero-Knowledge.	John Watrous	2002	In this paper we propose a definition for (honest verifier) quantum statistical zero-knowledge interactive proof systems and study the resulting complexity class, which we denote QSZKHV. We prove several facts regarding this class, including:The following problem is a complete promise problem for QSZKHV: given instructions for preparing two mixed quantum states, are the states close together or far apart in the trace norm metric? This problem is a quantum generalization of the complete promise problem of Sahai and Vadhan [25] for (classical) statistical zero-knowledge.QSZKHV is closed under complement.QSZKHV \subseteq PSPACE. (At present it is not known if arbitrary quantum interactive proof systems can be simulated in PSPACE, even for one-round proof systems.)Any polynomial-round honest verifier quantum statistical zero-knowledge proof system can be simulated by a two-message (i.e., one-round) honest verifier quantum statistical zero-knowledge proof system. Similarly, any polynomial-round honest verifier quantum statistical zero-knowledge proof system can be simulated by a three-message public-coin honest verifier quantum statistical zero-knowledge proof system.These facts establish close connections between classical statistical zero-knowledge and our definition for quantum statistical zero-knowledge, and give some insight regarding the effect of this zero-knowledge restriction on quantum interactive proof systems. The relationship between our definition and possible definitions of general (i.e., not necessarily honest) quantum statistical zero-knowledge are also discussed.
FOCS	43rd Symposium on Foundations of Computer Science (FOCS 2002), 16-19 November 2002, Vancouver, BC, Canada, Proceedings		2002	43rd Symposium on Foundations of Computer Science (FOCS 2002), 16-19 November 2002, Vancouver, BC, Canada, Proceedings
SODA	Is the internet fractal?	Cedric Adjih,Leonidas Georgiadis,Philippe Jacquet,Wojciech Szpankowski	2002	One of the main benefits of multicast communication is the overall reduction of network load. To quantify this reduction, when compared to traditional unicast, experimental studies by Chuang and Sirbu indicated the so called power law which asserts that the ratio R(n) of the average number of links in a multicast delivery tree connecting n sites to the average number of links in a unicast path is &Theta;(n0.8). Our goal is to explain theoretically this behavior. Claiming that the essence of the phenomenon lies in the geometry of the internet and its modeling assumptions, we introduce the model of self-similar trees with similarity factor 0 &le; &theta; < 1. Under this assumption, we analyze R(n) and prove that it is &Theta;(n1-&theta;). We also discuss some experimental results of real networks that confirm the power law and show that these networks have the self similar profile. In particular, we find experimentally that the power law holds with &theta;exp &asymp; 0.12. Our theoretical findings are established by analytical techniques of the precise analysis of algorithms such as Mellin transform and complex asymptotics.
SODA	Guessing secrets efficiently via list decoding.	Noga Alon,Venkatesan Guruswami,Tali Kaufman,Madhu Sudan	2002	We consider the guessing secrets problem defined by Chung et al. [2001]. This is a variant of the standard 20 questions game where the player has a set of k > 1 secrets from a universe of N possible secrets. The player is asked Boolean questions about the secret. For each question, the player picks one of the k secrets adversarially, and answers according to this secret. We present an explicit set of O(log N) questions together with an efficient (i.e., poly(log N) time) algorithm to solve the guessing secrets problem for the case of 2 secrets. This answers the main algorithmic question left unanswered by Chung et al. [2001]. The main techniques we use are small &epsis;-biased spaces and the notion of list decoding. We also establish bounds on the number of questions needed to solve the k-secrets game for k > 2, and discuss how list decoding can be used to get partial information about the secrets, specifically to find a small core of secrets that must intersect the actual set of k secrets.
SODA	Testing satisfiability.	Noga Alon,Asaf Shapira	2002	Let &Phi; be a set of general boolean functions on n variables, such that each function depends on exactly k variables, and each variable can take a value from [1,d]. We say that &Phi; is &epsilon;-far from satisfiable, if one must remove at least &epsilon;nk functions in order to make the set of remaining functions satisfiable. Our main result is that if &Phi; is &epsilon;-far from satisfiable, then most of the induced sets of functions, on sets of variables of size c(k,d)&epsilon;2, are not satisfiable, where c(k,d) depends only on k and d. Using the above claim, we obtain similar results for k-SAT and k-NAEQ-SAT.Assume we relax the decision problem of whether an instance of one of the above mentioned problems is satisfiable or not, to the problem of deciding whether an instance is satisfiable or &epsilon;-far from satisfiable. While the above decision problems are NP-hard, our result implies that we can solve their relaxed versions, that is, distinguishing between satisfiable and &epsilon;-far from satisfiable instances, in randomized constant time.From the above result we obtain as a special case, previous results of Alon and Krivelevich [3] and of Czumaj and Sohler [8], concerning testing of graphs and hypergraphs colorability. We also discuss the problem of testing whether a graph G can be d-colored, such that it does not contain any copy of a colored graph from a fixed, given set of colored graphs.
SODA	Pricing multicasting in more practical network models.	Micah Adler,Dan Rubenstein	2002	The problem of designing efficient algorithms for sharing the cost of multicasting has recently seen considerable attention. In this paper, we examine the effect on the complexity of pricing when two practical considerations are incorporated into the network model. In particular, we study a model where the session is offered at a number of different rates of transmission, and where there is a cost for enabling multicasting at each node of the network. We consider two techniques that have been used in practice to provide multiple rates: using a layered transmission scheme (called the layered paradigm) and using different multicast groups for each possible rate (called the split session paradigm). We demonstrate that the difference between these two paradigms has a significant impact on the complexity of pricing multicasting.For the layered paradigm, we provide a distributed algorithm for computing pricing efficiently in terms of local computation and message complexity. For the split session paradigm, on the other hand, we demonstrate that this problem can be solved in polynomial time if the number of possible rates is fixed, but if the number of rates is part of the input, then the problem becomes NP-Hard even to approximate. We also examine the effect of delivering the transmissions for the various rates from different locations within the network. We show that in this case, the pricing problem becomes NP-Hard for the split session paradigm even for a fixed constant number of possible rates, but if layering is used, then it can be solved in polynomial time by formulating the problem as a totally unimodular integer program.
SODA	Improved labeling scheme for ancestor queries.	Stephen Alstrup,Theis Rauhe	2002	"We present a labeling scheme for rooted trees that supports ancestor queries. Given a tree, the scheme assigns to each node a label which is a binary string. Given the labels of any two nodes u and v, it can in constant time be determined whether u is ancestor to v alone from these labels. For trees of size n our scheme assigns labels of size bounded by log n + O(&radic;log n) bits to each node. This improves a recent result of Abiteboul, Kaplan and Milo at SODA'01, where a labeling scheme with labels of size 3/2log n + O(log log n) was presented. The problem is among other things motivated in connection with efficient representation of information for XML-based search engines for the internet."
SODA	Computing the writhing number of a polygonal knot.	Pankaj K. Agarwal,Herbert Edelsbrunner,Yusu Wang	2002	The writhing number measures the global geometry of a closed space curve or knot. We show that this measure is related to the average winding number of its Gauss map. Using this relationship, we give an algorithm for computing the writhing number for a polygonal knot with n edges in time roughly proportional to n1.6. We also implement a different, simple algorithm and provide experimental evidence for its practical efficiency.
SODA	Pseudo-line arrangements: duality, algorithms, and applications.	Pankaj K. Agarwal,Micha Sharir	2002	"A finite collection of x-monotone unbounded Jordan curves in the plane is called a family of pseudo-lines if every pair of curves intersect in at most one point, and the two curves cross each other there. Let L be such a collection of n pseudo-lines, and let P be a set of m points in $\reals^2$. Extending a result of Goodman [Discrete Math., 32 (1980), pp. 27--35], we define a duality transform that maps L to a set L* of points in $\reals^2$ and P to a set P* of (x-monotone) pseudo-lines in $\reals^2$, so that the incidence and the ""above-below"" relations between the points and the pseudo-lines are preserved. We present an efficient algorithm for computing the dual arrangement {\eus A}$(P^*)$ under an appropriate model of computation. We also present a dynamic data structure for reporting, in $O(m^\eps + k)$ time, all k points of P that lie below a query arc, which is either a circular arc or a portion of the graph of a polynomial of fixed degree. This result is needed for computing the dual arrangement for certain classes of pseudo-lines arising in several applications, but is also interesting in its own right. We present a few applications of our dual arrangement algorithm, such as computing incidences between points and pseudo-lines and computing a subset of faces in a pseudo-line arrangement.Next, we present an efficient algorithm for cutting a set of circles into arcs so that every pair of arcs intersect in at most one point, i.e., the resulting arcs constitute a collection of pseudo-segments. By combining this algorithm with our algorithm for computing the dual arrangement of pseudo-lines, we obtain efficient algorithms for several problems involving arrangements of circles or circular arcs, such as reporting or counting incidences between points and circles and computing a set of marked faces in arrangements of circles."
SODA	Separable attributes: a technique for solving the sub matrices character count problem.	Amihood Amir,Kenneth Ward Church,Emanuel Dar	2002	"The subsequence character count problem has as its input an array S = s1, &iexcl;&shy;, sn of symbols over alphabet &brvbar;&sup2; and a natural number m. Its output is: for every i, i = 1, &iexcl;&shy;, n - m + 1, the number of different alphabet symbols occurring in the subsequence si, si+1, &iexcl;&shy;, si+m-1. The subsequence character count problem is a natural problem that has many uses. It can be solved in linear time for fixed finite alphabets and in time O(n log m) for infinite alphabets. In [1] the problem was used to solve the parameterized matching problem. The character count problem can be generalized to two dimensions and becomes the submatrix character count problem. Its input is an n x n matrix T over alphabet &brvbar;&sup2; and a natural number m. Its output is: for every i,j, i,j = 1, &iexcl;&shy;, n - m + 1, the number of different alphabet symbols occurring in the submatrix T[i + k,j + &ell;], k = 0, &iexcl;&shy;, m - 1;&ell; = 0, &iexcl;&shy;, m - 1. This problem was motivated by parameterized matching in two dimensions which is a good model for seeking a pattern in an image with a change of color map. The number of different colors in a subarea of an image is considered a ""signature"". There are many image processing tools that use this measure (see e.g. [5]). The straightforward one dimensional solution slides a window along the text adding an element and deleting an element at every step. The problem with two dimensions is that at every move of the window there are m elements added and m deleted. In this paper we present an alternate solution that generalizes to two dimensions. We achieve a O(n2) time solution to the submatrix character count problem over finite fixed alphabet and a O(n2 log m) solution over an infinite alphabet. The submatrix character count problem is a special case of the color range query problem, where one needs to preprocess a two dimensional nxn array T of symbols over alphabet &brvbar;&sup2; - the colors. Subsequently we are interested in answers to queries of the type: Given intervals [i1,j1] and [i2,j2], i1,i2,j1,j 2 &brvbar;&Aring; {1, &iexcl;&shy;, n} and i1 &iexcl;&Uuml; j1, i2 &iexcl;&Uuml; j2 give the number of different alphabet symbols (colors) occurring in the submatrix T[k,&ell;], k = i1, &iexcl;&shy;,j1, &ell; = i2,&iexcl;&shy;,j2. Jonardan and Lopez [6] showed that with a O(n2 log2 n) preprocessing one can answer queries in time O(log2 n). This means that the submatrices character count problem can be solved in time O(n2 log2 n) by preprocessing and then querying, for every location, the m x m submatrix starting at that location. We are not aware of a faster direct approach for solving the submatrix character count problem. However, problems with a similar flavor, where the desired calculation is a convolution, are solved in electrical engineering by a method called Separable Convolutions or Separable Filters [4]. A similar notion was used by Bird [3] and Baker [2] to solve the two dimensional pattern matching problem. The contributions of this paper are two-fold. First, We generalize the notion of separable convolutions to separable attributes. We believe it is important to keep this method in mind as an element of the basic algorithmic toolkit. It has proven useful in the past and, we think, will prove useful for solving various two-dimensional problems in the future. Secondly, We use the separable attributes method for providing the fastest algorithm yet for the submatrices character count problem. A full version of this paper can be found at http://www.cs.biu.ac.il/~amir/Postscripts/sep.ps."
SODA	On-line scheduling of a single machine to minimize total weighted completion time.	Edward J. Anderson,Chris N. Potts	2002	This paper considers the on-line scheduling of a single machine in which jobs arrive over time, and preemption is not allowed. The goal is to minimize the total weighted completion time. We show that a simple modification of the shortest weighted processing time rule has a competitive ratio of 2. This result is established using a new proof technique which does not rely explicitly on a lower bound on the optimal objective function value. Since it is known that no on-line algorithm can have a competitive ratio of less than 2, we have resolved the open issue of determining the minimum competitive ratio for this problem.
SODA	Scheduling protocols for switches with large envelopes.	Matthew Andrews,Lisa Zhang	2002	Traditionally, switches make scheduling decisions on the granularity of a packet. However, this is becoming increasingly difficult since network bandwidth is growing rapidly whereas packet sizes remain largely unchanged. Therefore the service time of an individual packet is decreasing rapidly. In this paper we study switches that make scheduling decisions on the granularity of an envelope which can be much larger than a packet in size.For an output-queued switch with envelope size E, each output chooses one input every E time steps and transmits packets from this chosen input during the next E steps. For an input-queued switch with envelope size E, one matching from the inputs to the outputs is computed every E steps and only the input---output pairs that are defined by this matching are allowed to transmit packets during the next E steps. Traditional switches correspond to envelope size E = 1 and almost all previous scheduling work deals with this case exclusively.We first show how some stable protocols for scheduling networks of output-queued switches with E = 1 fail for arbitrary E when these protocols are generalized in the most straightforward manner. We then present an extremely simple protocol that does guarantee network stability for output-queued switches for any E ¿ 1.For input-queued switches we first present a max-weight matching protocol that is stable for a single switch with arbitrary E. We then present a more complex protocol that achieves stability for a network of input-queued switches for any E ¿ 1.
SODA	Frugal path mechanisms.	Aaron Archer,Éva Tardos	2002	Frugal path mechanisms.
SODA	The freeze-tag problem: how to wake up a swarm of robots.	Esther M. Arkin,Michael A. Bender,Sándor P. Fekete,Joseph S. B. Mitchell,Martin Skutella	2002	"An optimization problem that naturally arises in the study of swarm robotics is the Freeze-Tag Problem (FTP) of how to awaken a set of ""asleep"" robots, by having an awakened robot move to their locations. Once a robot is awake, it can assist in awakening other slumbering robots. The objective is to have all robots awake as early as possible. While the FTP bears some resemblance to problems from areas in combinatorial optimization such as routing, broadcasting, scheduling, and covering, its algorithmic characteristics are surprisingly different. We consider both scenarios on graphs and in geometric environments. In graphs, robots sleep at vertices and there is a length function on the edges. Awake robots travel along edges, with time depending on edge length. For most scenarios, we consider the offline version of the problem, in which each awake robot knows the position of all other robots. We prove that the problem is NP-hard, even for the special case of star graphs. We also establish hardness of approximation, showing that it is NP-hard to obtain an approximation factor better than 5/3, even for graphs of bounded degree. These lower bounds are complemented with several positive algorithmic results, including: &#x00b7; We show that the natural greedy strategy on star graphs has a tight worst-case performance of 7/3 and give a polynomial-time approximation scheme (PTAS) for star graphs. &#x00b7; We give a simple O(log &#x03b4;)-competitive online algorithm for graphs with maximum degree &#x03b4; and locally bounded edge weights. &#x00b7; We give a PTAS, running in nearly linear time, for geometrically embedded instances."
SODA	Temporary tasks assignment resolved.	Amitai Armon,Yossi Azar,Leah Epstein,Oded Regev	2002	Among all basic on-line load balancing problems, the only unresolved problem was load balancing of temporary tasks on unrelated machines. This open problem exists for almost a decade, see [Borodin El-Yaniv]. We resolve this problem by providing an unapproximability result. In addition, a newer open question is to identify the dependency of the competitive ratio on the durations of jobs in the case where durations are known. We resolve this problem by characterizing this dependency. Finally, we provide a PTAS for the off-line problem with a fixed number of machines and show a 2 unapproximability for the general case.
SODA	A randomized online algorithm for bandwidth utilization.	Sanjeev Arora,Bo Brinkman	2002	"Protocols for data transmission over an IP computer network should not only lead to efficient network utilization but also be fair to different users. Current networks accomplish these goals by some form of end-to-end congestion control. Existing protocols, however, assume somewhat altruistic behavior from hosts. Karp et al. (2000) have initiated a study of whether or not a single host's optimum strategy (in a system where other hosts are well behaved) is altruistic. We carry this exploration further by developing an efficient randomized algorithm for bandwidth utilization in their model. The competitive ratio of this algorithm is optimal up to a constant factor. Karp et al. had earlier studied the deterministic case and left open the randomized case. What may be of some interest is that our algorithm is essentially the classical multiplicative increase, multiplicative decrease strategy, which is very aggressive and non-altruistic."
SODA	Linear-size approximate voronoi diagrams.	Sunil Arya,Theocharis Malamatos	2002	Given a set S of n points in IRd, a (t, &epsilon;)-approximate Voronoi diagram (AVD) is a partition of space into constant complexity cells, where each cell c is associated with t representative points of S, such that for any point in c, one of the associated representatives approximates the nearest neighbor to within a factor of (1 + &epsilon;). The goal is to minimize the number and complexity of the cells in the AVD. We show that it is possible to construct an AVD consisting of O(n/&epsilon;d) cells for t = 1, and O(n) cells for t = O(1/&epsilon;(d-1)/2). In general, for a real parameter 2 &le; &gamma; &le; 1/&epsilon;, we show that it is possible to construct a (t, &epsilon;)-AVD consisting of O(n&gamma;d) cells for t = O(1/(&epsilon;&gamma;)(d-1)/2). The cells in these AVDs are cubes or differences of two cubes. All these structures can be used to efficiently answer approximate nearest neighbor queries. Our algorithms are based on the well-separated pair decomposition and are very simple.
SODA	Matrix rounding under the Lp-discrepancy measure and its application to digital halftoning.	Tetsuo Asano,Naoki Katoh,Koji Obokata,Takeshi Tokuyama	2002	"We study the problem of rounding a real-valued matrix into an integer-valued matrix to minimize an Lp-discrepancy measure between them. To define the Lp-discrepancy measure, we introduce a family ${\cal F}$ of regions (rigid submatrices) of the matrix and consider a hypergraph defined by the family. The difficulty of the problem depends on the choice of the region family ${\cal F}$. We first investigate the rounding problem by using integer programming problems with convex piecewise-linear objective functions and give some nontrivial upper bounds for the Lp discrepancy. We propose ""laminar family"" for constructing a practical and well-solvable class of ${\cal F}$. Indeed, we show that the problem is solvable in polynomial time if ${\cal F}$ is the union of two laminar families. Finally, we show that the matrix rounding using L1 discrepancy for the union of two laminar families is suitable for developing a high-quality digital-halftoning software."
SODA	Sampling from a moving window over streaming data.	Brian Babcock,Mayur Datar,Rajeev Motwani	2002	"We introduce the problem of sampling from a moving window of recent items from a data stream and develop two algorithms for this problem. The first algorithm, ""chain-sample"", extends reservoir sampling to deal with the expiration of data elements from the sample. The expected memory usage of our algorithm is O(k) when maintaining a sample of size k over a window of the n most recent elements from the data stream, and with high probability the algorithm requires no more than O(k log n) memory.When the number of elements in the window is variable, as is the case when the size of the window is defined as a time duration rather than as a fixed number of data elements, the sampling problem becomes harder. Our second algorithm, ""priority-sample"", works even when the number of elements in the window can vary dynamically over time. With high probability, the ""priority-sample"" algorithm uses no more than O(k log n) memory."
SODA	Competitive on-line switching policies.	Amotz Bar-Noy,Ari Freund,Shimon Landa,Joseph Naor	2002	A switch, or server, serves n input queues, processing messages arriving at these queues to a single output channel. At each time slot the switch can process a single message from one of the queues. The goal of a switching policy is to minimize the size of the buffers at the input queues that maintain the messages that have not yet been processed. This is a typical on-line setting in which decisions are made based on the current state without knowledge of future events. This general scenario models multiplexing tasks in various systems such as communication networks, cable modem systems, and traffic control. Traditionally, researchers analyzed the performance of a given policy assuming some distribution on the arrival rates of messages at the input queues, or by assuming that the service rate is at least the aggregate of all the input rates. We use competitive analysis to analyze switching service policies, thus avoiding any prior assumptions on the input. Specifically, we show O(log n)-competitive switching policies for the problem and demonstrate matching lower bounds.
SODA	Throughput maximization of real-time scheduling with batching.	Amotz Bar-Noy,Sudipto Guha,Yoav Katz,Joseph Naor,Baruch Schieber,Hadas Shachnai	2002	We consider the following scheduling with batching problem that has many applications, e.g., in multimedia-on-demand and manufacturing of integrated circuits. The input to the problem consists of n jobs and k parallel machines. Each job is associated with a set of time intervals in which it can be scheduled (given either explicitly or non-explicitly), a weight, and a family. Each family is associated with a processing time. Jobs that belong to the same family can be batched and executed together on the same machine. The processing time of each batch is the processing time of the family of jobs it contains. The goal is to find a non-preemptive schedule with batching that maximizes the weight of the scheduled jobs. We give constant factor (4 or 4 + &epsilon;) approximation algorithms for two variants of the problem, depending on the precise representation of the input. When the batch size is unbounded and each job is associated with a time window in which it can be processed, these approximation ratios reduce to 2 and 2 + &epsilon;, respectively. We also show exact algorithms for several special cases.
SODA	Windows scheduling problems for broadcast systems.	Amotz Bar-Noy,Richard E. Ladner	2002	"The windows scheduling problem is defined by the positive integers n, h, and w1, ...,wn. There are n pages where the window wi is associated with page i, and h is the number of slotted channels available for broadcasting the pages. A schedule that solves the problem assigns pages to slots such that the gap between any two consecutive appearances of page i is at most wi slots. We investigate two optimization problems. (i) The optimal windows scheduling problem: given w1, ..., wn find a schedule in which h is minimized. (ii) The optimal harmonic windows scheduling problem: given h find a schedule for the windows wi = i in which n is maximized. The former is a formulation of the problem of minimizing the bandwidth in push systems that support guaranteed delay, and the latter is a formulation of the problem of minimizing the startup delay in media-on-demand systems. For the optimal windows scheduling problem we present an algorithm that constructs asymptotically close to optimal schedules, and for the optimal harmonic windows scheduling problem we show how to achieve the largest known n's for all values of h."
SODA	Scheduling split intervals.	Reuven Bar-Yehuda,Magnús M. Halldórsson,Joseph Naor,Hadas Shachnai,Irina Shapira	2002	We consider the problem of scheduling jobs that are given as groups of non-intersecting segments on the real line. Each job Jj is associated with an interval, Ij, which consists of up to t segments, for some t &ge; 1, a positive weight, wj, and two jobs are in conflict if any of their segments intersect. Such jobs show up in a wide range of applications, including the transmission of continuous-media data, allocation of linear resources (e.g. bandwidth in linear processor arrays), and in computational biology/geometry. The objective is to schedule a subset of non-conflicting jobs of maximum total weight.In a single machine environment, our problem can be formulated as the problem of finding a maximum weight independent set in a t-interval graph (the special case of t = 1 is an ordinary interval graph). We show that, for t &ge; 2, this problem is APX-hard, even for highly restricted instances. Our main result is a 2t-approximation algorithm for general instances, based on a novel fractional version of the Local Ratio technique. Previously, the problem was considered only for proper union graphs, a restricted subclass of t-interval graphs, and the approximation factor achieved was (2t - 1 + 1/2t). A bi-criteria polynomial time approximation scheme (PTAS) is developed for the subclass of t-union graphs.In the online case, we consider uniform weight jobs that consist of at most two segments. We show that when the resulting 2-interval graph is proper, a simple greedy algorithm is 3-competitive, while any randomized algorithm has competitive ratio at least 2.5. For general instances, we give a randomized O(log2 R)-competitive (or O((log R)2+&epsilon;)-competitive) algorithm, where R is the known (unknown) ratio between the longest and the shortest segment in the input sequence.
SODA	Incentive-compatible online auctions for digital goods.	Ziv Bar-Yossef,Kirsten Hildrum,Felix Wu	2002	Goldberg et al. [6] recently began the study of incentive-compatible auctions for digital goods, that is, goods which are available in unlimited supply. Many digital goods, however, such as books, music, and software, are sold continuously, rather than in a single round, as is the case for traditional auctions. Hence, it is important to consider what happens in the online version of such auctions. We define a model for online auctions for digital goods, and within this model, we examine auctions in which bidders have an incentive to bid their true valuations, that is, incentive-compatible auctions. Since the best offline auctions achieve revenue comparable to the revenue of the optimal fixed pricing scheme, we use the latter as our benchmark. We show that deterministic auctions perform poorly relative to this benchmark, but we give a randomized auction which is within a factor O(exp&radic;log log h) of the benchmark, where h is the ratio between the highest and lowest bids. As part of this result, we also give a new offline auction, which improves upon the previously best auction in a certain class of auctions for digital goods. We also give lower bounds for both randomized and deterministic online auctions for digital goods.
SODA	Reductions in streaming algorithms, with an application to counting triangles in graphs.	Ziv Bar-Yossef,Ravi Kumar,D. Sivakumar	2002	We introduce reductions in the streaming model as a tool in the design of streaming algorithms. We develop the concept of list-efficient streaming algorithms that are essential to the design of efficient streaming algorithms through reductions.Our results include a suite of list-efficient streaming algorithms for basic statistical primitives. Using the reduction paradigm along with these tools, we design streaming algorithms for approximately counting the number of triangles in a graph presented as a stream.A specific highlight of our work is the first algorithm for the number of distinct elements in a data stream that achieves arbitrary approximation factors. (Independently, Trevisan [Tre01] has solved this problem via a different approach; our algorithm has the advantage of being list-efficient.)
SODA	Adaptive intersection and t-threshold problems.	Jérémy Barbay,Claire Kenyon	2002	"Consider the problem of computing the intersection of k sorted sets. In the comparison model, we prove a new lower bound which depends on the non-deterministic complexity of the instance, and implies that the algorithm of Demaine, L&oacute;pez-Ortiz and Munro [2] is usually optimal in this ""adaptive"" sense. We extend the lower bound and the algorithm to the t-Threshold Problem, which consists in finding the elements which are in at least t of the k sets. These problems are motivated by boolean queries in text database systems."
SODA	Efficient proper 2-coloring of almost disjoint hypergraphs.	József Beck,Sachin Lodha	2002	Let A be an n-uniform hypergraph. Assume that the maximum degree of A is D = D(A) (local condition), and |A| = N = N(A) (global condition). By the Lov&aacute;sz Local Lemma (L.L.L.), if D < 2n/8n, then A has a proper 2-coloring (i.e. there is no monochromatic edge) independently of the value of N (N can be infinite). Unfortunately L.L.L. is a pure existence argument which does not give any clue of how to find a proper 2-coloring. A hypergraph with the property that any two edges have at most one point in common is called almost disjoint (e.g. a family of lines). Assume that A is an n-uniform almost disjoint hypergraph. In this special case, we provide a polynomial time (in terms of N) algorithm to find a proper 2-coloring under the slightly weaker condition that D < (2 - &delta;)n and N is less than a doubly exponential function of n.
SODA	A locality-preserving cache-oblivious dynamic dictionary.	Michael A. Bender,Ziyang Duan,John Iacono,Jing Wu	2002	This paper presents a simple dictionary structure designed for a hierarchical memory. The proposed data structure is cache-oblivious and locality-preserving. A cache-oblivious data structure has memory performance optimized for all levels of the memory hierarchy even though it has no memory-hierarchy-specific parameterization. A locality-preserving dictionary maintains elements of similar key values stored close together for fast access to ranges of data with consecutive keys.The data structure presented here is a simplification of the cache-oblivious B-tree of Bender, Demaine, and Farach-Colton. The structure supports search operations on N data items using O(logB N + 1) block transfers at a level of the memory hierarchy with block size B. Insertion and deletion operations use O(logBN + log2 N/B + 1) amortized block transfers. Finally, the data structure returns all k data items in a given search range using O(logB N + k/B + 1) block transfers.This data structure was implemented and its performance was evaluated on a simulated memory hierarchy. This paper presents the results of this simulation for various combinations of block and memory sizes.
SODA	Improved algorithms for stretch scheduling.	Michael A. Bender,S. Muthukrishnan,Rajmohan Rajaraman	2002	We study the basic problem of preemptive scheduling of an online stream of jobs on a single processor. The ith job arrives at time r(i) and has processing time p(i) that is known at the time of its arrival. If C(i) is the completion time of job i, then the flow time is C(i) - r(i) and stretch of a job is the ratio of its flow time to its processing time; that is, C(i)-r(i)/p(i). Flow time considers the time a job is in the system regardless of the service it requested; the stretch measure relies on the intuition that a job that requested long service must be prepared to wait longer than the small jobs.In this paper, we present improved algorithmic results in stretch scheduling. We first show that a simple online algorithm that takes amortized O(1) time per job arrival is O(&Delta;1/2)-competitive with respect to maximum stretch, where &Delta; is the ratio of the largest processing time to the smallest processing time. This is significantly more efficient than the best known online algorithm for this problem which takes &omega;(n2) per scheduling step (n is the number of jobs seen thus far). We next present a polynomial time approximation scheme for average stretch scheduling. The previous best polynomial-time algorithm is the shortest remaining processing time algorithm, which achieves a 2-approximation. Finally, we consider the impact of incomplete knowledge of job sizes on the average stretch performance of scheduling algorithms. We show that a constant-factor competitive ratio for average stretch is achievable even if the processing times (or remaining processing times) of jobs are known only to within a constant factor of accuracy.
SODA	Slice and dice: a simple, improved approximate tiling recipe.	Piotr Berman,Bhaskar DasGupta,S. Muthukrishnan	2002	We are given a two dimensional array A[1 &sdot;&sdot;&sdot; n, 1 &sdot;&sdot;&sdot; n] where each A[i, j] stores a non-negative number. A (rectangular) tiling of A is a collection of rectangular portions A[l &sdot;&sdot;&sdot; r, t &sdot;&sdot;&sdot; b], called tiles, such that no two tiles overlap and each entry A[i, j] is contained in a tile. The weight of a tile is the sum of all array entries in it.In the MAX-MIN problem, we are given a weight bound W and our goal is to find a tiling such that (a) each tile is of weight at least W (the MIN condition) and (b) the number of tiles is maximized (the MAX condition). In the MIN-MAX problem, we are given a weight bound W again and our goal is to find a tiling such that (a) each tile has weight at most W and (b) the number of tiles is minimized. These two basic problems have many variations depending on the weight functions, whether some areas of A must not be covered, or whether some portion of A may be discarded, etc. These problems are not only natural combinatorial problems, but also arise in a plethora of applications, e.g., in databases and data mining, video compression, load balancing, building index structures, manufacturing and so forth.Both the above tiling problems (as well as all of their variations relevant to this paper) are known to be NP-hard. In this paper, we present approximations algorithms for solving these problems based on epicurean methods : variations of a basic slice-and-dice technique. Surprisingly, these simple algorithms yield small constant factor approximations for all these problems. For some of the problems, our results are the first known approximations; for others, our results improve the known algorithms significantly in approximation bounds and/or running time. Of independent interest are the tight bounds we show for sizes of the binary space partition trees for isothetic rectangles.
SODA	Simple approximation algorithm for nonoverlapping local alignments.	Piotr Berman,Bhaskar DasGupta,S. Muthukrishnan	2002	Simple approximation algorithm for nonoverlapping local alignments.
SODA	Approximating minimum unsatisfiability of linear equations.	Piotr Berman,Marek Karpinski	2002	We consider the following optimization problem: given a system of m linear equations in n variables over a certain field, a feasible solution is any assignment of values to the variables, and the minimized objective function is the number of equations that are not satisfied. For the case of the finite field GF[2], this problem is also known as the Nearest Codeword problem. In this note we show that for any constant c there exists a randomized polynomial time algorithm that approximates the above problem, called the Minimum Unsatisfiability of Linear Equations (MIN-UNSATISFY for short), with n/(c log n) approximation ratio. Our results hold for any field in which systems of linear equations can be solved in polynomial time.
SODA	An 8/13-approximation algorithm for the asymmetric maximum TSP.	Markus Bläser	2002	We present a polynomial time approximation algorithm for the asymmetric maximum traveling salesperson problem that achieves performance ratio 8/13 (1 - 1/n). The running time of our algorithm is O(n3).
SODA	Static optimality and dynamic search-optimality in lists and trees.	Avrim Blum,Shuchi Chawla,Adam Kalai	2002	"Adaptive data structures form a central topic of on-line algorithms research, beginning with the results of Sleator and Tarjan showing that splay trees achieve static optimality for search trees, and that Move-to-Front is constant competitive for the list update problem [ST85a, ST85b]. This paper is inspired by the observation that one can in fact achieve a 1 + &epsilon; ratio against the best static object in hindsight for a wide range of data structure problems via ""weighted experts"" techniques from Machine Learning, if computational decision-making costs are not considered.In this paper, we give two results. First, we show that for the case of lists, we can achieve a 1 + &epsilon; ratio with respect to the best static list in hindsight, by a simple efficient algorithm. This algorithm can then be combined with existing results to simultaneously achieve good static and dynamic bounds. Second, for trees, we show a (computationally inefficient) algorithm that achieves what we call ""dynamic search optimality"": dynamic optimality if we allow the online algorithm to make free rotations after each request. We hope this to be a step towards solving the longstanding open problem of achieving true dynamic optimality for trees."
SODA	Smoothed analysis of the perceptron algorithm for linear programming.	Avrim Blum,John Dunagan	2002	The smoothed complexity [1] of an algorithm is the expected running time of the algorithm on an arbitrary instance under a random perturbation. It was shown recently that the simplex algorithm has polynomial smoothed complexity. We show that a simple greedy algorithm for linear programming, the perceptron algorithm, also has polynomial smoothed complexity, in a high probability sense; that is, the running time is polynomial with high probability over the random perturbation.
SODA	Online algorithms for market clearing.	Avrim Blum,Tuomas Sandholm,Martin Zinkevich	2002	In this article, we study the problem of online market clearing where there is one commodity in the market being bought and sold by multiple buyers and sellers whose bids arrive and expire at different times. The auctioneer is faced with an online clearing problem of deciding which buy and sell bids to match without knowing what bids will arrive in the future. For maximizing profit, we present a (randomized) online algorithm with a competitive ratio of ln(pmax &minus; pmin) &plus; 1, when bids are in a range [pmin, pmax], which we show is the best possible. A simpler algorithm has a ratio twice this, and can be used even if expiration times are not known. For maximizing the number of trades, we present a simple greedy algorithm that achieves a factor of 2 competitive ratio if no money-losing trades are allowed. We also show that if the online algorithm is allowed to subsidize matches---match money-losing pairs if it has already collected enough money from previous pairs to pay for them---then it can actually be 1-competitive with respect to the optimal offline algorithm that is not allowed subsidy. That is, for maximizing the number of trades, the ability to subsidize is at least as valuable as knowing the future. We also consider objectives of maximizing buy or sell volume and social welfare. We present all of these results as corollaries of theorems on online matching in an incomplete interval graph.We also consider the issue of incentive compatibility, and develop a nearly optimal incentive-compatible algorithm for maximizing social welfare. For maximizing profit, we show that no incentive-compatible algorithm can achieve a sublinear competitive ratio, even if only one buy bid and one sell bid are alive at a time. However, we provide an algorithm that, under certain mild assumptions on the bids, performs nearly as well as the best fixed pair of buy and sell prices, a weaker but still natural performance measure. This latter result uses online learning methods, and we also show how such methods can be used to improve our &ldquo;optimal&rdquo; algorithms to a broader notion of optimality. Finally, we show how some of our results can be generalized to settings in which the buyers and sellers themselves have online bidding strategies, rather than just each having individual bids.
SODA	(Incremental) priority algorithms.	Allan Borodin,Morten N. Nielsen,Charles Rackoff	2002	"We study the question of what optimization problems can be optimally or approximately solved by ""greedy-like"" algorithms. For definiteness, we will limit the present discussion to some well-studied scheduling problems although the underlying issues apply in a much more general setting. Of course, the main benefit of greedy algorithms lies in both their conceptual simplicity and their computational efficiency. Based on the experience from online competitive analysis, it seems plausible that we should be able to derive approximation bounds for ""greedy-like"" algorithms exploiting only the conceptual simplicity of these algorithms. To this end, we will provide a precise definition of what we mean by greedy and greedy-like. A full version of this paper is available at http://www.cs.toronto.edu/~ bor/priority.ps."
SODA	Cache oblivious search trees via binary trees of small height.	Gerth Stølting Brodal,Rolf Fagerberg,Riko Jacob	2002	We propose a version of cache oblivious search trees which is simpler than the previous proposal of Bender, Demaine and Farach-Colton and has the same complexity bounds. In particular, our data structure avoids the use of weight balanced B-trees, and can be implemented as just a single array of data elements, without the use of pointers. The structure also improves space utilization.For storing n elements, our proposal uses (1 + &epsilon;)n times the element size of memory, and performs searches in worst case O(logB n) memory transfers, updates in amortized O((log2 n)/(&epsilon;B)) memory transfers, and range queries in worst case O(logB n + k/B) memory transfers, where k is the size of the output.The basic idea of our data structure is to maintain a dynamic binary tree of height log n+O(1) using existing methods, embed this tree in a static binary tree, which in turn is embedded in an array in a cache oblivious fashion, using the van Emde Boas layout of Prokop.We also investigate the practicality of cache obliviousness in the area of search trees, by providing an empirical comparison of different methods for laying out a search tree in memory.
SODA	Improving table compression with combinatorial optimization.	Adam L. Buchsbaum,Glenn S. Fowler,Raffaele Giancarlo	2002	We study the problem of compressing massive tables within the partition-training paradigm introduced by Buchsbaum et al. [2000], in which a table is partitioned by an off-line training procedure into disjoint intervals of columns, each of which is compressed separately by a standard, on-line compressor like gzip. We provide a new theory that unifies previous experimental observations on partitioning and heuristic observations on column permutation, all of which are used to improve compression rates. Based on this theory, we devise the first on-line training algorithms for table compression, which can be applied to individual files, not just continuously operating sources; and also a new, off-line training algorithm, based on a link to the asymmetric traveling salesman problem, which improves on prior work by rearranging columns prior to partitioning. We demonstrate these results experimentally. On various test files, the on-line algorithms provide 35--55&percnt; improvement over gzip with negligible slowdown; the off-line reordering provides up to 20&percnt; further improvement over partitioning alone. We also show that a variation of the table compression problem is MAX-SNP hard.
SODA	Closest-point problems simplified on the RAM.	Timothy M. Chan	2002	Closest-point problems simplified on the RAM.
SODA	Semi-online maintenance of geometric optima and measures.	Timothy M. Chan	2002	We give the first nontrivial worst-case results for dynamic versions of various basic geometric optimization and measure problems under the semi-online model, where during the insertion of an object we are told when the object is to be deleted. Problems that we can solve with sublinear update time include the Hausdorff distance of two point sets, discrete 1-center, largest empty circle, convex hull volume in three dimensions, volume of the union of axis-parallel cubes, and minimum enclosing rectangle. The decision versions of the Hausdorff distance and discrete 1-center problems can be solved fully dynamically. Some applications are mentioned.
SODA	On semidefinite programming relaxations for graph coloring and vertex cover.	Moses Charikar	2002	We investigate the power of a strengthened SDP relaxation for graph coloring whose value is equal to a variant of the Lov&aacute;sz &thetasym;-function. We show families of graphs where the value of the relaxation is 2 + &epsilon; for any fixed &epsilon; > 0, yet the chromatic number is n&delta; for some fixed &delta; > 0, which is a function of &epsilon;. This demonstrates the bound provided by the SDP is not strong enough to color a 3-colorable graph with no(1) colors.Kleinberg and Goemans considered an SDP relaxation for vertex cover whose value is n - &thetasym;1/2 (&thetasym;1/2 being the variant of the &thetasym;-function introduced by Schrijver). They asked whether this is within a ratio of 2 - &epsilon; of the optimal vertex cover for any &epsilon; > 0. Our construction answers this question negatively.
SODA	Quality meshing with weighted Delaunay refinement.	Siu-Wing Cheng,Tamal K. Dey	2002	Delaunay meshes with bounded circumradius to shortest edge length ratio have been proposed in the past for quality meshing. The only poor quality tetrahedra, called slivers, that can occur in such a mesh can be eliminated by the sliver exudation method. This method has been shown to work for periodic point sets, but not with boundaries. Recently a randomized point-placement strategy has been proposed to remove slivers while conforming to a given boundary. In this paper we present a deterministic algorithm for generating a weighted Delaunay mesh which respects the input boundary and has no poor quality tetrahedron including slivers. As in previous work, we assume that no input angle is acute. Our result is achieved by combining the weight pumping method for sliver exudation and the Delaunay refinement method for boundary conformation.
SODA	Motorcycle graphs and straight skeletons.	Siu-Wing Cheng,Antoine Vigneron	2002	We present a new algorithm to compute motorcycle graphs. It runs in $O(n \sqrt{n}\log n)$ time when n is the number of motorcycles. We give a new characterization of the straight skeleton of a nondegenerate polygon. For a polygon with n vertices and h holes, we show that it yields a randomized algorithm that reduces the straight skeleton computation to a motorcycle graph computation in expected $O(n\sqrt{h+1}\log^2 n)$ time. Combining these results, we can compute the straight skeleton of a nondegenerate polygon with h holes and with n vertices, among which r are reflex vertices, in $O(n\sqrt{h+1}\log^2 n+r \sqrt{r} \log r)$ expected time. In particular, we cancompute the straight skeleton of a nondegenerate polygon with n vertices in $O(n\sqrt{n}\log^2n)$ expected time.
SODA	Center and diameter problems in plane triangulations and quadrangulations.	Victor Chepoi,Feodor F. Dragan,Yann Vaxès	2002	In this note, we present first linear time algorithms for computing the center and the diameter of several classes of face regular plane graphs: triangulations with inner vertices of degree &ge; 6, quadrangulations with inner vertices of degree &ge; 4 and the subgraphs of the regular hexagonal grid bounded by a simple circuit of this grid.
SODA	Delaunay triangulation programs on surface data.	Sunghee Choi,Nina Amenta	2002	"The Delaunay triangulation of a set of points in 3D can have size &Theta;(n2) in the worst case, but this is rarely if ever observed in practice. We compare three production-quality Delaunay triangulation programs on some 'real-world' sets of points lying on or near 2D surfaces."
SODA	Guessing secrets with inner product questions.	Fan R. K. Chung,Ronald L. Graham,Linyuan Lu	2002	"Suppose we are given some fixed (but unknown) subset X of a set &Omega; = F2n, where F2 denotes the field of two elements. We would like to learn as much as possible about the elements X by asking certain binary questions. Each ""question"" Q is some element of &Omega;, and the ""answer"" to Q is just the inner product Q&middot;x (in F2) for some x &epsilon; X. However, the choice of x is made by a truthful (but possibly malevolent) adversary A, whom we may assume is trying to choose answers so as to as yield as little information as possible about X. In this paper, we study various aspects of this problem. In particular, we are interested in extracting as much information as possible about X from A's answers. Although A can prevent us from learning the identity of any particular element of X, with appropriate questions we can still learn a lot about X. We determine the maximum amount of information that can be recovered and discuss the optimal strategies for selecting questions. For the case that |X| = 2, we give an O(n3) algorithm for an optimal strategy. However, for the case that |X| &ge; 3, we show that no such polynomial-time algorithm can exist, unless P = NP."
SODA	Reachability and distance queries via 2-hop labels.	Edith Cohen,Eran Halperin,Haim Kaplan,Uri Zwick	2002	Reachability and distance queries in graphs are fundamental to numerous applications, ranging from geographic navigation systems to Internet routing. Some of these applications involve huge graphs and yet require fast query answering. We propose a new data structure for representing all distances in a graph. The data structure is distributed in the sense that it may be viewed as assigning labels to the vertices, such that a query involving vertices u and v may be answered using only the labels of u and v.Our labels are based on 2-hop covers of the shortest paths, or of all paths, in a graph. For shortest paths, such a cover is a collection S of shortest paths such that, for every two vertices u and v, there is a shortest path from u to v that is a concatenation of two paths from S. We describe an efficient algorithm for finding an almost optimal 2-hop cover of a given collection of paths. Our approach is general and can be applied to directed or undirected graphs, exact or approximate shortest paths, or to reachability queries.We study the proposed data structure using a combination of theoretical and experimental means. We implemented our algorithm and checked the size of the resulting data structure on several real-life networks from different application areas. Our experiments show that the total size of the labels is typically not much larger than the network itself, and is usually considerably smaller than an explicit representation of the transitive closure of the network.
SODA	A note on random 2-SAT with prescribed literal degrees.	Colin Cooper,Alan M. Frieze,Gregory B. Sorkin	2002	"Two classic ""phase transitions"" in discrete mathematics are the emergence of a giant component in a random graph as the density of edges increases, and the transition of a random 2-SAT formula from satisfiable to unsatisfiable as the density of clauses increases. The random-graph result has been extended to the case of prescribed degree sequences, where the almost-sure nonexistence or existence of a giant component is related to a simple property of the degree sequence. We similarly extend the satisfiability result, by relating the almost-sure satisfiability or unsatisfiability of a random 2-SAT formula to an analogous property of a prescribed literal sequence."
SODA	The diameter of a long range percolation graph.	Don Coppersmith,David Gamarnik,Maxim Sviridenko	2002	"We consider the following long-range percolation model: an undirected graph with the node set {0, 1, ..., N}d, has edges (x, y) selected with probability ≈ β/||x -y||s if ||x - y|| < 1, and with probability 1 if ||x - y|| = 1, for some parameters β, s < 0. This model was introduced by Benjamini and Berger [2], who obtained bounds on the diameter of this graph for the one-dimensional case d = 1 and for various values of s, but left cases s = 1, 2 open. We show that, with high probability, the diameter of this graph is Θ(log N/log log N) when s = d, and, for some constants 0 >' η1 > η2 > 1, it is at most Nη2 when s = 2d, and is at least Nη1 when d = 1, s = 2, β > 1 or when s > 2d. We also provide a simple proof that the diameter is at most log O(1) N with high probability, when d > s > 2d, established previously in [2]."
SODA	The string edit distance matching problem with moves.	Graham Cormode,S. Muthukrishnan	2002	The edit distance between two strings S and R is defined to be the minimum number of character inserts, deletes, and changes needed to convert R to S. Given a text string t of length n, and a pattern string p of length m, informally, the string edit distance matching problem is to compute the smallest edit distance between p and substrings of t. We relax the problem so that: (a) we allow an additional operation, namely, substring moves; and (b) we allow approximation of this string edit distance. Our result is a near-linear time deterministic algorithm to produce a factor of O(log n log&ast; n) approximation to the string edit distance with moves. This is the first known significantly subquadratic algorithm for a string edit distance problem in which the distance involves nontrivial alignments. Our results are obtained by embedding strings into L1 vector space using a simplified parsing technique, which we call edit-sensitive parsing (ESP).
SODA	A sub-quadratic sequence alignment algorithm for unrestricted cost matrices.	Maxime Crochemore,Gad M. Landau,Michal Ziv-Ukelson	2002	The classical algorithm for computing the similarity between two sequences [36, 39] uses a dynamic programming matrix, and compares two strings of size n in O(n2) time. We address the challenge of computing the similarity of two strings in sub-quadratic time, for metrics which use a scoring matrix of unrestricted weights. Our algorithm applies to both local and global alignment computations.The speed-up is achieved by dividing the dynamic programming matrix into variable sized blocks, as induced by Lempel-Ziv parsing of both strings, and utilizing the inherent periodic nature of both strings. This leads to an O(n2/log n) algorithm for an input of constant alphabet size. For most texts, the time complexity is actually O(hn2/log n) where h &le; 1 is the entropy of the text.
SODA	Approximability of dense and sparse instances of minimum 2-connectivity, TSP and path problems.	Béla Csaba,Marek Karpinski,Piotr Krysta	2002	We study the approximability of dense and sparse instances of the following problems: the minimum 2-edge-connected (2-EC) and 2-vertex-connected (2-VC) spanning subgraph, metric TSP with distances 1 and 2 (TSP (1,2)), maximum path packing, and the longest path (cycle) problems. The approximability of dense instances of these problems was left open in Arora et al. [3]. We characterize the approximability of all these problems by proving tight upper (approximation algorithms) and lower bounds (inapproximability). We prove that 2-EC, 2-VC and TSP (1,2) are Max SNP-hard even on 3-regular graphs, and provide explicit hardness constants, under P &ne; NP. We also improve the approximation ratio for 2-EC and 2-VC on graphs with maximum degree 3. These are the first explicit hardness results on sparse and dense graphs for these problems. We apply our results to prove bounds on the integrality gaps of LP relaxations for dense and sparse 2-EC and TSP (1,2) problems, related to the famous metric TSP conjecture, due to Goemans [17].
SODA	Tight bounds for worst-case equilibria.	Artur Czumaj,Berthold Vöcking	2002	We study the problem of traffic routing in noncooperative networks. In such networks, users may follow selfish strategies to optimize their own performance measure and therefore, their behavior does not have to lead to optimal performance of the entire network. In this article we investigate the worst-case coordination ratio, which is a game-theoretic measure aiming to reflect the price of selfish routing. Following a line of previous work, we focus on the most basic networks consisting of parallel links with linear latency functions. Our main result is that the worst-case coordination ratio on m parallel links of possibly different speeds is &Theta;(log m/log log log m). In fact, we are able to give an exact description of the worst-case coordination ratio, depending on the number of links and ratio of speed of the fastest link over the speed of the slowest link. For example, for the special case in which all m parallel links have the same speed, we can prove that the worst-case coordination ratio is &Gamma;(&minus;1) (m) &plus; &Theta;(1), with &Gamma; denoting the Gamma (factorial) function. Our bounds entirely resolve an open problem posed recently by Koutsoupias and Papadimitriou [1999].
SODA	An algorithm for counting maximum weighted independent sets and its applications.	Vilhelm Dahllöf,Peter Jonsson	2002	We present an O(1.3247n) algorithm for counting the number of independent sets with maximum weight in graphs. We show how this algorithm can be used solving a number of different counting problems: counting exact covers, exact hitting sets, weighted set packing and satisfying assignments in 1-in-k SAT.
SODA	Maintaining stream statistics over sliding windows (extended abstract).	Mayur Datar,Aristides Gionis,Piotr Indyk,Rajeev Motwani	2002	"We consider the problem of maintaining aggregates and statistics over data streams, with respect to the last N data elements seen so far. We refer to this model as the sliding window model. We consider the following basic problem: Given a stream of bits, maintain a count of the number of 1's in the last N elements seen from the stream. We show that using O(1/e log2N) bits of memory, we can estimate the number of 1's to within a factor of 1 + &epsilon;. We also give a matching lower bound of &Omega;(1/e log2 N) memory bits for any deterministic or randomized algorithms. We extend our scheme to maintain the sum of the last N positive integers. We provide matching upper and lower bounds for this more general problem as well. We apply our techniques to obtain efficient algorithms for the Lp norms (for p &epsilon; [1, 2]) of vectors under the sliding window model. Using the algorithm for the basic counting problem, one can adapt many other techniques to work for the sliding window model, with a multiplicative overhead of O(1/&epsilon;log N) in memory and a 1 + &epsilon; factor loss in accuracy. These include maintaining approximate histograms, hash tables, and statistics or aggregates such as sum and averages."
SODA	Oracles for distances avoiding a link-failure.	Camil Demetrescu,Mikkel Thorup	2002	"For a directed graph G we consider queries of the form: ""What is the shortest path distance from vertex x to vertex y in G avoiding a failed link (u, v), and what edge leaving x should we use to get on a such a shortest path?"" We show that an oracle for such queries can be stored in O(n2 log n) space with a query time of O(log n). No non-trivial solution was known for this problem."
SODA	Shape dimension and approximation from samples.	Tamal K. Dey,Joachim Giesen,Samrat Goswami,Wulue Zhao	2002	There are many scientific and engineering applications where an automatic detection of shape dimension from sample data is necessary. Topological dimensions of shapes constitute an important global feature of them. We present a Voronoi based dimension detection algorithm that assigns a dimension to a sample point which is the topological dimension of the manifold it belongs to. Based on this dimension detection, we also present an algorithm to approximate shapes of arbitrary dimension from their samples. Our empirical results with data sets in three dimensions support our theory.
SODA	Tree exploration with little memory.	Krzysztof Diks,Pierre Fraigniaud,Evangelos Kranakis,Andrzej Pelc	2002	A robot with k-bit memory has to explore a tree whose nodes are unlabeled and edge ports are locally labeled at each node. The robot has no a priori knowledge of the topology of the tree or of its size, and its aim is to traverse all the edges. While O(log Δ) bits of memory suffice to explore any tree of maximum degree Δ if stopping is not required, we show that bounded memory is not sufficient to explore with stop all trees of bounded degree (indeed Ω (log log log n) bits of memory are needed for some such trees of size n). For the more demanding task requiring to stop at the starting node after completing exploration, we show a sharper lower bound Ω (log n) on required memory size, and present an algorithm to accomplish this task with O(log2 n)-bit memory, for all n-node trees.
SODA	Balls and bins models with feedback.	Eleni Drinea,Alan M. Frieze,Michael Mitzenmacher	2002	We examine generalizations of the classical balls and bins models, where the probability a ball lands in a bin is proportional to the number of balls already in the bin raised to some exponent p. Such systems exhibit positive or negative feedback, depending on the exponent p, with a phase transition occurring at p = 1. Similar models have proven useful in economics and chemistry; for example, systems with positive feedback (p > 1) tend naturally toward monopoly. We provide several results and useful heuristics for these models, including showing a bound on the time to achieve monopoly with high probability.
SODA	Broadcast scheduling: when fairness is fine.	Jeff Edmonds,Kirk Pruhs	2002	We investigate server scheduling policies to minimize user perceived latency in a client-server system where the server uses broadcast communication. We show that no O(1)-competitive online algorithms exist for this problem. We consider the intuitive algorithm BEQUI that broadcasts all requested files at a rate proportional to the number of out-standing requests for that file. We show that BEQUI is an O(1)-speed O(1)-approximation algorithm. We give another algorithm BEQUI-EDF, and show that BEQUI-EDF is also an O(1)-speed O(1)-approximation algorithm. However, BEQUI-EDF has the advantage that it preempts each broadcast on average at most once and will never preempt if the data items have unit size.
SODA	Covering shapes by ellipses.	Alon Efrat,Frank Hoffmann,Christian Knauer,Klaus Kriegel,Günter Rote,Carola Wenk	2002	Covering shapes by ellipses.
SODA	0/1 optimization and 0/1 primal separation are equivalent.	Friedrich Eisenbrand,Giovanni Rinaldi,Paolo Ventura	2002	"The 0/1 primal separation problem is: Given an extreme point x of a 0/1 polytope P and some point x*, find an inequality which is tight at x, violated by x* and valid for P or assert that no such inequality exists. It is known that this separation variant can be reduced to the standard separation problem for P. We show that 0/1 optimization and 0/1 primal separation are polynomial time equivalent. This implies that the problems 0/1 optimization, 0/1 standard separation, 0/1 augmentation, and 0/1 primal separation are polynomial time equivalent.We apply this result to the perfect matching problem. Here, primal separation is easier than its standard version. We present an algorithm for primal separation, which rests only on simple max-flow computations. Consequently, we obtain a very simple proof that a maximum weight perfect matching of a graph can be computed in polynomial time. In contrast, the known standard separation method involves Padberg and Rao's minimum odd cut algorithm, which itself is based on the construction of a Gomory-Hu tree."
SODA	Derandomized dimensionality reduction with applications.	"Lars Engebretsen,Piotr Indyk,Ryan O'Donnell"	2002	"The Johnson-Lindenstrauss lemma provides a way to map a number of points in high-dimensional space into a low-dimensional space, with only a small distortion of the distances between the points. The proofs of the lemma are non-constructive: they show that a random mapping induces small distortions with high probability, but they do not construct the actual mapping. In this paper, we provide a procedure that constructs such a mapping deterministically in time almost linear in the number of distances to preserve times the dimension of the original space. We then use that result (together with Nisan's pseudorandom generator) to obtain an efficient derandomization of several approximation algorithms based on semidefinite programming."
SODA	Harmonic broadcasting is optimal.	Lars Engebretsen,Madhu Sudan	2002	Harmonic broadcasting was introduced by Juhn and Tseng as a way to reduce the bandwidth requirements required for video-on-demand broadcasting. In this paper, we note that harmonic broadcasting is actually a special case of the priority encoded transmission scheme introduced by Albanese et al. and prove---using an information theoretic argument---that it is impossible to achieve the design goals of harmonic broadcasting using a shorter encoding.
SODA	"Dense point sets have sparse Delaunay triangulations: or ""... but not too nasty""."	Jeff Erickson	2002	"Dense point sets have sparse Delaunay triangulations: or ""... but not too nasty""."
SODA	NP-hardness of broadcast scheduling and inapproximability of single-source unsplittable min-cost flow.	Thomas Erlebach,Alexander Hall	2002	We consider the version of broadcast scheduling where a server can transmit W messages of a given set at each time-step, answering previously made requests for these messages. The goal is to minimize the average response time (ART) if the amount of requests is known in advance for each time-step and message. We prove that this problem is NP-hard, thus answering an open question stated by Kalyanasundaram, Pruhs and Velauthapillai (Proceedings of ESA 2000, LNCS 1879, 2000, pp. 290---301). Furthermore, we present an approximation algorithm that is allowed to send several messages at once. Using six channels for transmissions, the algorithm achieves an ART that is at least as good as the optimal solution using one channel.From the NP-hardness of broadcast scheduling we derive a new inapproximability result of (2 ¿ ¿, 1) for the (congestion, cost) bicriteria version of the single source unsplittable min-cost flow problem, for arbitrary ¿ > 0. The result holds even in the often considered case where the maximum demand is less than or equal to the minimum edge capacity (d max ¿ u min), a case for which an algorithm with ratio (3, 1) was presented by Skutella.
SODA	An approximation algorithm for the group Steiner problem.	Guy Even,Guy Kortsarz	2002	"The input in the Group-Steiner Problem consists of an undirected connected graph with a cost function p(e) over the edges and a collection of subsets of vertices {gi}. Each subset gi is called a group and the vertices in &cup; gi are called terminals. The goal is to find a minimum cost tree that contains at least one terminal from every group.We give the first combinatorial polylogarithmic ratio approximation for the problem on trees. Let m denote the number of groups and S denote the number of terminals. The approximation ratio of our algorithm is O(log S &middot; log m/log log S) = O(log2n/log log n). This is an improvement by a &Theta;(log log n) factor over the previously best known approximation ratio for the Group Steiner Problem on trees [GKR98].Our result carries over to the Group Steiner Problem on general graphs and to the Covering Steiner Problem. Garg et al. [GKR98] presented a reduction of the Group Steiner Problem on general graphs to trees. Their reduction employs Bartal's [B98] approximation of graph metrics by tree metrics. Our algorithm on trees implies an approximation algorithm of ratio O(log S &middot; log m &middot; log n &middot; log log n/log log S) = O(log3n) for the Group Steiner Problem on general graphs. The previously best known approximation ratio for this problem on general graphs, as a function of n, is O(log3n &middot; log log n) [GKR98]. Our algorithm in conjunction with ideas of [EKS01] gives an O(log S &middot; log m &middot; log n &middot; log log n/log log S) = O(log3n)-approximation ratio for the more general Covering Steiner Problem, improving the best known approximation ratio (as a function of n) for the Covering Steiner Problem by a &Theta;(log log n) factor."
SODA	Layout area of the hypercube (extended abstract).	Shimon Even,Roni Kupershtok	2002	In this paper we study the square grid area required for laying out Hl, the Boolean hypercube of N = 2l vertices. It is shown that this area is 4/9N2 + o(N2). We describe a layout which occupies this much area and prove that no layout of less area exists.
SODA	Web caching with request reordering.	Tomás Feder,Rajeev Motwani,Rina Panigrahy,An Zhu	2002	Current web caching algorithms process requests in the order of the arrival. While such restriction is inevitable in system paging due to the sequential nature of a program, the HTTP requests are (essentially) independent at a high volume proxy server. This gives a proxy server the flexibility to reorder requests, provided no request is inordinately delayed. The expectation is that reordering requests may lead to better performance. We formulate an online k-reordering problem that captures such phenomenon for unit caches. We give a dynamic programming algorithm to solve the offline case. We give O(1) upper and lower bound on the competitive ratio of the online algorithms. We also generalize this problem to any metric space.
SODA	Censorship resistant peer-to-peer content addressable networks.	Amos Fiat,Jared Saia	2002	We present a censorship resistant peer-to-peer Content Addressable Network for accessing n data items in a network of n nodes. Each search for a data item in the network takes O(log n) time and requires at most O(log2n) messages. Our network is censorship resistant in the sense that even after adversarial removal of an arbitrarily large constant fraction of the nodes in the network, all but an arbitrarily small fraction of the remaining nodes can obtain all but an arbitrarily small fraction of the original data items. The network can be created in a fully distributed fashion. It requires only O(log n) memory in each node. We also give a variant of our scheme that has the property that it is highly spam resistant: an adversary can take over complete control of a constant fraction of the nodes in the network and yet will still be unable to generate spam.
SODA	Experimental analysis of simple, distributed vertex coloring algorithms.	Irene Finocchi,Alessandro Panconesi,Riccardo Silvestri	2002	We perform an extensive experimental evaluation of very simple, distributed, randomized algorithms for (&Delta; + 1)- and so-called Brooks-Vizing vertex colorings, i.e., colorings using considerably fewer than &Delta; colors. We consider variants of algorithms known from the literature, boosting them with a distributed independent set computation. Our study clearly determines the relative performance of the algorithms w.r.t. the number of communication rounds and the number of colors. The results are confirmed by all the experiments and instance families. The empirical evidence shows that some algorithms are extremely fast and very effective, thus being amenable to be used in practice.
SODA	Smooth-surface reconstruction in near-linear time.	Stefan Funke,Edgar A. Ramos	2002	A surface reconstruction algorithm takes as input a set of sample points from an unknown closed and smooth surface in 3-d space, and produces a piece-wise linear approximation of the surface that contains the sample points. Recently, several algorithms with a correctness guarantee have been proposed. They have unfortunately a worst-case running time that is quadratic in the size of the input because they are based on the construction of 3-d Voronoi diagrams or Delaunay tetrahedrizations which can have quadratic size. In this paper, we describe a new algorithm that also has a correctness guarantee but whose worst-case running time is O(n log n) where n is the input size. This is actually optimal. As in some of the previous algorithms, the piece-wise linear approximation produced by the new algorithm is a triangulation which is a subset of the 3-d Delaunay tetrahedrization.
SODA	An ear decomposition approach to approximating the smallest 3-edge connected spanning subgraph of a multigraph.	Harold N. Gabow	2002	This paper gives a 3/2 approximation algorithm for the smallest 3-edge connected spanning subgraph of an undirected multigraph. The previous best algorithm of Khuller and Raghavachari [J. Algorithms, 21 (1996), pp. 434--450] has approximation ratio $5/3$. The algorithm of Cheriyan and Thurimella [SIAM J. Comput., 30 (2000), pp. 528--560] achieves ratio 3/2 for simple graphs. Our approach, based on the close relationship between an ear decomposition of a 2-edge connected graph and 3-edge connected components, enables us to achieve running time $O( m \alpha(m,n) )$.
SODA	Expansion of product replacement graphs.	Alexander Gamburd,Igor Pak	2002	"We establish a connection between the expansion coefficient of the product replacement graph &#x0393;k(G) and the minimal expansion coefficient of a Cayley graph of G with k generators. In particular, we show that the product replacement graphs &#x0393;k(PSL(2,p)) form an expander family, under assumption that all Cayley graphs of PSL(2,p), with at most k generators are expanders. This gives a new explanation of the outstanding performance of the product replacement algorithm and supports the speculation that all product replacement graphs are expanders [42,52]."
SODA	On adaptive deterministic gossiping in ad hoc radio networks.	Leszek Gasieniec,Andrzej Lingas	2002	We study deterministic algorithms for gossiping problem in ad hoc radio networks. The gossiping problem is a communication task in which each node of the network possesses a unique single message that is to be communicated to all other nodes in the network. The efficiency of a communication algorithm in radio networks is very often expressed in terms of: max-eccentricity D, max-indegree &Delta;, and size (number of nodes) n of underlying graph of connections. The max-eccentricity D of a network is the maximum of the lengths of shortest directed paths from a node u to a node v, taken over all ordered pairs (u, v) of nodes in the network. The max-indegree &Delta; of a network is the maximum of indegrees of its nodes.We propose a new method that leads to several improvements in deterministic gossiping. It combines communication techniques designed for both known as well as unknown ad hoc radio networks. First we show how to subsume the O(Dn)-time bound yield by the Round-Robin procedure proposing a new &Otilde;(&radic;Dn)-time gossiping algorithm. Our algorithm is more efficient than the known &Otilde;(n3/2)-time gossiping algorithms [3, 6], whenever D = O(n&alpha;) and &alpha; < 1. For large values of max-eccentricity D, we give another gossiping algorithm that works in time O(D&Delta;3/2 log3 n) which subsumes the O(D&Delta2 log3 n) upper bound presented in [4].
SODA	The wake up and report problem is time-equivalent to the firing squad synchronization problem.	Darin Goldstein,Nick Meyer	2002	"We consider several problems relating to strongly-connected directed networks of identical finite-state processors that work synchronously in discrete time steps. The conceptually simplest of these problems is the Wake Up and Report Problem; this is the problem of having a unique ""root"" processor send a signal to all other processors in the network and then enter a special ""done"" state only when all other processors have received the signal. The most difficult of the problems we consider is the classic Firing Squad Synchronization Problem; this is the much-studied problem of achieving macro-synchrorization in a network given micro-synchronization. We show via a complex algorithmic application of the ""snake"" data stucture first introduced in Even, Litman, and Winkler[6] that these two problems in particular are asymptotically time-equivalent up to a constant factor. This result leads immediately to the inclusion of several other related problems into this new asymptotic time-class."
SODA	Caching with expiration times.	Parikshit Gopalan,Howard J. Karloff,Aranyak Mehta,Milena Mihail,Nisheeth K. Vishnoi	2002	Caching data together with expiration times beyond which the data is no longer valid is a standard method for promoting information consistency in distributed systems, including the Internet and WWW, large databases, and mobile telecommunications. We use the framework of competitive analysis of online algorithms and study page eviction strategies in the case where data has expiration times. We show that suitable adaptations of LRU and its generalizations, namely marking algorithms, are asymptotically optimal and, in the worst case, within a multiplicative factor 2 of the lower bounds. A key technical ingredient of our analysis is a covering invariant that captures some of the subtleties introduced by expiration times. The additional difficulty of dealing with expiration times is also reflected in our analysis of the randomized online marking algorithm, as well as the offline version of the problem for which we obtain a factor 3 approximation. We complement our theoretical findings with experiments on real and synthetic data.
SODA	Light spanners and approximate TSP in weighted graphs with forbidden minors.	Michelangelo Grigni,Papa Sissokho	2002	Given an edge weighted graph G with n vertices and no K&tau;-minor and a small positive constant &epsilon;, we show that a simple greedy algorithm [1] finds a spanning subgraph approximating all shortest-path distances within a factor of 1 + &epsilon;, and with total edge weight at most O((&tau;&radic;log&tau; &middot; logn)/&epsilon;) times the weight of a minimum spanning tree. This result implies a quasi-polynomial time approximation scheme (QPTAS) for the traveling salesman problem (TSP) in such graphs, with running time nO((&tau;4&radic;log&tau;&middot;log n&middot;log log n)/&epsilon;2).Our analysis shows that a graph with detour gap number [5] &Omega;(&tau;&radic;log&tau; &middot; log n) has a K&tau;-minor. We also show that this dependence on n is nearly tight, by exhibiting graphs with no K6-minor (apex graphs) and detour gap number &Omega;((log n)/log log n).As a step towards eliminating the log n factors the first paragraph, we propose a generalized detour gap number, now depending on &epsilon;, and we show that it remains bounded for apex graphs and some similar graph families.
SODA	Approximate distance oracles for geometric graphs.	Joachim Gudmundsson,Christos Levcopoulos,Giri Narasimhan,Michiel H. M. Smid	2002	Given a geometric t-spanner graph G in Ed with n points and m edges, with edge lengths that lie within a polynomial (in n) factor of each other. Then, after O(m+n log n) preprocessing, we present an approximation scheme to answer (1+&epsilon;)-approximate shortest path queries in O(1) time. The data structure uses O(n log n) space.
SODA	Capacitated vertex covering with applications.	Sudipto Guha,Refael Hassin,Samir Khuller,Einat Or	2002	In this paper we study the capacitated vertex cover problem, a generalization of the well known vertex cover problem. Given a graph G = (V, E) with weights on the vertices, the goal is to cover all the edges by picking a cover of minimum weight from the vertices. When we pick a copy of a vertex, we pay the weight of the vertex and cover upto a pre-specified number of edges incident on this vertex (its capacity). The problem is NP-hard. We give a primal-dual based 2 approximation and study several generalizations, as well as the problem restricted to trees.
SODA	Improved algorithms for the data placement problem.	Sudipto Guha,Kamesh Munagala	2002	We study the data placement problem [1, 3], where the goal is to place certain data objects (with possible replication) in fixed capacity caches in a network to optimize latency of access. The locations of the caches are given and each cache has capacities both on the number of objects it can store and the number of users it can serve. Each user has a demand for a specific object.The end objective is to optimize the average user latency of accessing the objects. We present a constant approximation, while blowing up the cache capacities by a constant factor. This improves the previous results, which either ignore the bound on the number of users [1], or which need to blow up the capacities by a logarithmic factor [3]. Our solution technique involves writing an integer program for this problem and rounding its linear relaxation.We note that our result is the best possible that can be obtained by LP rounding. The problem is MAX-SNP hard as shown in [1], and the linear program has unbounded integrality gap unless we relax the capacity constraints [5].Our basic technique is to separate the rounding into two stages:Opening Objects: In this stage, we consider each object separately, and open copies in the network. We ignore the interaction of this object with other objects due to the cache capacity constraints. We use the capacitated facility location rounding from [5].Packing Objects: In this stage, we pack the objects into the cache so that cache capacity constraints are satisfied. We use the GAP rounding from [4].
SODA	Generalized clustering.	Sudipto Guha,Kamesh Munagala	2002	Generalized clustering.
SODA	MAX CUT in cubic graphs.	Eran Halperin,Dror Livnat,Uri Zwick	2002	We present an improved semidefinite programming based approximation algorithm for the MAX CUT problem in graphs of maximum degree at most 3. The approximation ratio of the new algorithm is at least 0.9326. This improves, and also somewhat simplifies, a result of Feige, Karpinski and Langberg. We also observe that results of Hopkins and Staton and of Bondy and Locke yield a simple combinatorial 4/5-approximation algorithm for the problem. Finally, we present a combinatorial 22/27-approximation algorithm for the MAX CUT problem for regular cubic graphs.
SODA	An optimal (expected time) algorithm for minimizing lab costs in DNA sequencing.	David Hart	2002	"The final step for obtaining very accurate DNA sequence data is known as ""finishing."" Most steps of DNA sequencing are highly automated, but it is only recently that researchers have looked at automating the finishing step. Our perspective is to look at automated finishing as an optimization problem, with the goal to minimize lab costs.We give new algorithms for solving this problem. We look at a model of the problem for which previous researchers gave an O(n4) algorithm (where n is the length of the DNA measured in reads). We give an algorithm that runs in O(n2⅓) worst case time. We then show that the algorithm runs in O(n) expected time, if we make an assumption, accepted by many molecular biologists, about randomness in the input data."
SODA	Polynomial time recognition of P4-structure.	Ryan B. Hayward,Stefan Hougardy,Bruce A. Reed	2002	"A P4 is a set of four vertices of a graph that induces a chordless path; the P4-structure of a graph is the set of all P4's. Va&scaron;ek Chv&aacute;tal asked if there is a polynomial time algorithm to determine whether an arbitrary four-uniform hypergraph is the P4-structure of some graph. The answer is yes; we present such an algorithm."
SODA	Symmetric drawings of triconnected planar graphs.	Seok-Hee Hong,Brendan D. McKay,Peter Eades	2002	Symmetry is one of the most important aesthetic criteria in graph drawing because it reveals structure in the graph. To draw graphs symmetrically, we need two steps. The first step is to find appropriate automorphisms. The second step is to draw the graph to display the automorphisms. Our aim in this paper is to construct maximally symmetric straight-line drawings of triconnected planar graphs in linear time. Previously known algorithms run in quadratic time. We show that an algorithm of Fontet can be used to find an embedding in the plane with the maximum number of symmetries, and present a new algorithm for finding a straight line drawing that achieves that maximum. Both algorithms run in linear time.
SODA	Explicit constructions of selectors and related combinatorial structures, with applications.	Piotr Indyk	2002	In this paper we present explicit constructions of several combinatorial objects: selectors [CGR00] and selective families [CGGPR00], pseudo-random generators for proof systems [ABRW00] and fixed waking schedules [GPP00]. As a result, we obtain almost optimal deterministic protocols for broadcasting in unknown directed radio networks [CGR00] and wake-up problem [GPP00]. We also show application of selectors (and its variants) to explicit construction of test sets for coin-weighting problems [DH00]. The parameters of our constructions come close to the best known non-constructive bounds. The constructions are achieved using a common technique, which could be of use for other problems.
SODA	On-line algorithms for the dynamic traveling repair problem.	Sandy Irani,Xiangwen Lu,Amelia Regan	2002	We consider the dynamic traveling repair problem in which requests with deadlines arrive through time on points in a metric space. Servers move from point to point at constant speed. The goal is to plan the motion of servers so that the maximum number of requests are met by their deadline. We consider a restricted version of the problem in which there is a single server and the length of time between the arrival of a request and its deadline is constant. We give upper bounds for the competitive ratio of two very natural algorithms as well as several lower bounds for any deterministic algorithm. Most of the results in this paper are expressed as a function of β, the diameter of the metric space. In particular, we prove that the upper bound given for one of the two algorithms is within a constant factor of the best possible competitive ratio.
SODA	A fully combinatorial algorithm for submodular function minimization.	Satoru Iwata	2002	This paper presents a strongly polynomial algorithm for submodular function minimization using only additions, subtractions, comparisons, and oracle calls for function values.
SODA	Generating random factored numbers, easily.	Adam Kalai	2002	Generating random factored numbers, easily.
SODA	"Efficient pattern-matching with don't cares."	Adam Kalai	2002	"We present a randomized algorithm for the string matching with don't cares problem. Based on the simple fingerprint method of Karp and Rabin for ordinary string matching [4], our algorithm runs in time O(n log m) for a text of length n and a pattern of length m and is simpler and slightly faster than the previous algorithms [3, 5, 1]."
SODA	A comparison of labeling schemes for ancestor queries.	Haim Kaplan,Tova Milo,Ronen Shabo	2002	Motivated by a recent application in XML search engines we study the problem of labeling the nodes of a tree (XML file) such that given the labels of two nodes one can determine whether one node is an ancestor of the other. We describe several new prefix-based labeling schemes, where an ancestor query roughly amounts to testing whether one label is a prefix of the other. We compare our new schemes to a simple interval-based scheme currently used by search engines, as well as, to schemes with the best theoretical guarantee on the maximum label length. We performed our experimental evaluation on real XML data and on some families of random trees.
SODA	Union-find with deletions.	Haim Kaplan,Nira Shafrir,Robert Endre Tarjan	2002	"In the classical union-find problem we maintain a partition of a universe of n elements into disjoint sets subject to the operations union and find. The operation union(A, B, C) replaces sets A and B in the partition by their union, given the name C. The operation find(x) returns the name of the set containing the element x. In this paper we revisit the union-find problem in a context where the underlying partitioned universe is not fixed. Specifically, we allow a delete(x) operation which removes the element x from the set containing it. We consider both worst-case performance and amortized performance. In both settings the challenge is to dynamically keep the size of the structure representing each set proportional to the number of elements in the set which may now decrease as a result of deletions.For any fixed k, we describe a data structure that supports find and delete in O(logkn) worst-case time and union in O(k) worst-case time. This matches the best possible worst-case bounds for find and union in the classical setting. Furthermore, using an incremental global rebuilding technique we obtain a reduction converting any union-find data structure to a union-find with deletions data structure. Our reduction is such that the time bounds for find and union change only by a constant factor. The time it takes to delete an element x is the same as the time it takes to find the set containing x plus the time it takes to unite a singleton set with this set.In an amortized setting a classical data structure of Tarjan supports a sequence of m finds and at most n unions on a universe of n elements in O(n + m&alpha;(m + n, n, log n)) time where &alpha;(m, n, l) = min{k | Ak(&lfloor;m/n&rfloor;) > l} and Ai(j) is Ackermann's function as described in [6]. We refine the analysis of this data structure and show that in fact the cost of each find is proportional to the size of the corresponding set. Specifically, we show that one can pay for a sequence of union and find operations by charging a constant to each participating element and O(&alpha;(m, n, log(l))) for a find of an element in a set of size l. We also show how keep these amortized costs for each find and each participating element while allowing deletions. The amortized cost of deleting an element from a set of l elements is the same as the amortized cost of finding the element; namely, O(&alpha;(m, n, log(l)))."
SODA	Faster approximation schemes for fractional multicommodity flow problems.	George Karakostas	2002	We present fully polynomial approximation schemes for concurrent multicommodity flow problems that run in time of the minimum possible dependencies on the number of commodities k. We show that by modifying the algorithms by Garg and K&ouml;nemann [1998] and Fleischer [2000], we can reduce their running time on a graph with n vertices and m edges from &Otilde;(&epsiv;&minus;2(m2 &plus; km)) to &Otilde;(&epsiv;&minus;2m2) for an implicit representation of the output, or &Otilde;(&epsiv;&minus;2(m2 &plus; kn for an explicit representation, where &Otilde;(f) denotes a quantity that is O(f logO(1)m). The implicit representation consists of a set of trees rooted at sources (there can be more than one tree per source), and with sinks as their leaves, together with flow values for the flow directed from the source to the sinks in a particular tree. Given this implicit representation, the approximate value of the concurrent flow is known, but if we want the explicit flow per commodity per edge, we would have to combine all these trees together, and the cost of doing so may be prohibitive. In case we want to calculate explicitly the solution flow, we modify our schemes so that they run in time polylogarithmic in nk (n is the number of nodes in the network). This is within a polylogarithmic factor of the trivial lower bound of time &Omega;(nk) needed to explicitly write down a multicommodity flow of k commodities in a network of n nodes. Therefore our schemes are within a polylogarithmic factor of the minimum possible dependencies of the running time on the number of commodities k.
SODA	Labeling schemes for flow and connectivity.	Michal Katz,Nir A. Katz,Amos Korman,David Peleg	2002	This paper studies labeling schemes for flow and connectivity functions. A flow labeling scheme using O(logn?log[^(w)])-bit labels is presented for general n-vertex graphs with maximum (integral) capacity [^(w)]. This is shown to be asymptotically optimal. For edge-connectivity, this yields a tight bound of Q(log2 n) bits. A k-vertex connectivity labeling scheme is then given for general n-vertex graphs using at most 3logn bits for k = 2, 5logn bits for k = 3 and 2klogn bits for k < 3. Finally, a lower bound of W(klogn) is established for k-vertex connectivity on n-vertex graphs where k is polylogarithmic in n.
SODA	Hardware-assisted computation of depth contours.	Shankar Krishnan,Nabil H. Mustafa,Suresh Venkatasubramanian	2002	Given a set of points P in the plane, the location depth of a point u is the minimum number of points of P lying in a closed halfplane defined by a line through u. The set of all points in the plane having location depth at least k is called the depth contour of depth k. In this paper, we present an algorithm that makes extensive use of modern graphics architectures to compute the approximate depth contours of a set of points. The output of our algorithm presents the contours as a coloring of each point with its depth value, as opposed to computing the geometric description of the contour boundary. Our algorithm performs significantly better than currently known implementations, outperforming them by at least one order of magnitude and having a strictly better asymptotic growth rate.
SODA	How to cut a cake almost fairly.	Sven Oliver Krumke,Maarten Lipmann,Willem de Paepe,Diana Poensgen,Jörg Rambau,Leen Stougie,Gerhard J. Woeginger	2002	"In the cake cutting problem, n &ge; 2 players want to cut a cake into n pieces so that every player gets a ""fair"" share of the cake by his own measure. We describe a protocol with n - 1 cuts in which each player can enforce to get a share of at least 1/(2n - 2) of the cake. Moreover we show that no protocol with n - 1 cuts can guarantee a better fraction."
SODA	Preprocessing an undirected planar network to enable fast approximate distance queries.	Philip N. Klein	2002	We describe a method for preprocessing a weighted planar undirected graph and representing the results of the preprocessing so as to facilitate subsequent approximate distance queries. For any 0 < &epsilon; < 1/10, a representation can be constructed so that computing an &epsilon;-approximate distance from one node to another takes O(&epsilon;-1) time, principally consisting of about 15&epsilon;-1 additions. The representation requires storage of 7.2&epsilon;-1n log2 n distances. By using compressed representation of the distances, the number of bytes required is about .5n&epsilon;-1(9 + 3 log &epsilon;-1)log2 n (at the expense of a small increase in query time).
SODA	An optimal algorithm for checking regularity (extended abstract).	Yoshiharu Kohayakawa,Vojtech Rödl,Lubos Thoma	2002	We present a deterministic algorithm A that, in O(m2) time, verifies whether a given m by m bipartite graph G is regular, in the sense of Szemer&eacute;di [18]. In the case in which G is not regular enough, our algorithm outputs a witness to this irregularity. Algorithm A may be used as a subroutine in an algorithm that finds an &epsilon;-regular partition of a given n-vertex graph &Gamma; in time O(n2). This time complexity is optimal, up to a constant factor, and improves upon the bound O(M(n)), proved by Alon, Duke, Lefmann, R&ouml;dl, and Yuster [1, 2], where M(n) = O(n2.376) is the time required to square a 0-1 matrix over the integers.Our approach is elementary, except that it makes use of linear-sized expanders to accomplish a suitable form of deterministic sampling.
SODA	Flows over time with load-dependent transit times.	Ekkehard Köhler,Martin Skutella	2002	"More than forty years ago, Ford and Fulkerson studied maximum s-t-flows over time (also called ""dynamic"" flows) in networks with fixed transit times on the arcs and a fixed time horizon. Here, flow on arcs may change over time and transit times specify the amount of time it takes for flow to travel through a particular arc. Ford and Fulkerson proved that there always exists an optimal solution which sends flow on certain s-t-paths at a constant rate as long as there is enough time left for the flow along a path to arrive at the sink; a flow over time featuring this simple structure is called ""temporally repeated.""Although this result does not hold for the more general and also more realistic setting where transit times depend on the current flow situation, we show that there always exists a provably good temporally repeated solution. Moreover, such a solution can be determined very efficiently by only one minimum convex cost flow computation. Our results rest upon a new model of flow-dependent transit times. It is based on two assumption on the pace of flow on a particular arc. First, the pace of flow on an arc is assumed to be uniform for all flow units on an arc for each point in time. Second, this uniform pace is for each moment determined by the actual amount of flow on this arc. Finally, we show that the resulting flow-over-time problem is strongly NP-hard and cannot be approximated with arbitrary precision in polynomial time, unless P=NP."
SODA	Improved bounds for the unsplittable flow problem.	Petr Kolman,Christian Scheideler	2002	In this paper we consider the unsplittable flow problem (UFP): given a directed or undirected network G=(V,E) with edge capacities and a set of terminal pairs (or requests) with associated demands, find a subset of the pairs of maximum total demand for which a single flow path can be chosen for each pair so that for every edge, the sum of the demands of the paths crossing the edge does not exceed its capacity. We present a collection of new results for the UFP both in the offline (all requests are given from the beginning) and the online (requests arrive at the system one after the other) setting. A fundamental ingredient of our analysis is the introduction of a new graph parameter, the flow number, that aims to capture global communication properties of the network. With the help of the flow number we develop a general method for transforming arbitrary multicommodity flow solutions into solutions that use short paths only. This generalizes a well-known theorem of Leighton and Rao [J. ACM 46 (6) (1999) 787-832] that applies to uniform flows only. Both the parameter and the method may therefore be of independent interest.
SODA	On the overlay of envelopes in four dimensions.	Vladlen Koltun,Micha Sharir	2002	We show that the complexity of the overlay of two envelopes of arrangements of n semi-algebraic surfaces or surface patches of constant description complexity in four dimensions is O(n4-1/&lceil;s/2&rceil;+&epsilon;), for any &epsilon; > 0, where s is a constant related to the maximal degree of the surfaces. This is the first non-trivial (sub-quartic) bound for this problem, and for s = 1, 2 it almost matches the near-cubic lower bound. We discuss several applications of this result, including (i) an improved bound for the complexity of the region enclosed between two envelopes in four dimensions, (ii) an improved bound for the complexity of the space of all hyperplane transversals of a collection of simply-shaped convex sets in 4-space, (iii) an improved bound for the complexity of the space of all line transversals of a similar collection of sets in 3-space, and (iv) improved bounds for the complexity of the union of certain families of objects in four dimensions. The analysis technique we introduce is quite general, and has already proved useful in unrelated contexts.
SODA	Approximation algorithms for grammar-based compression.	Eric Lehman,Abhi Shelat	2002	Several recently-proposed data compression algorithms are based on the idea of representing a string by a context-free grammar. Most of these algorithms are known to be asymptotically optimal with respect to a stationary ergodic source and to achieve a low redundancy rate. However, such results do not reveal how effectively these algorithms exploit the grammar-model itself; that is, are the compressed strings produced as small as possible? We address this issue by analyzing the approximation ratio of several algorithms, that is, the maximum ratio between the size of the generated grammar and the smallest possible grammar over all inputs. On the negative side, we show that every polynomial-time grammar-compression algorithm has approximation ratio at least 8569/8568 unless P = NP. Moreover, achieving an approximation ratio of o(log n/log log n) would require progress on an algebraic problem in a well-studied area. We then upper and lower bound approximation ratios for the following four previously-proposed grammar-based compression algorithms: SEQUENTIAL, BISECTION, GREEDY, and LZ78, each of which employs a distinct approach to compression. These results seem to indicate that there is much room to improve grammar-based compression algorithms.
SODA	Linear-time compression of bounded-genus graphs into information-theoretically optimal number of bits.	Hsueh-I Lu	2002	This extended abstract summarizes a new result for the graph compression problem, addressing how to compress a graph G into a binary string Z with the requirement that Z can be decoded to recover G. Graph compression finds important applications in 3D model compression of Computer Graphics [12, 17-20] and compact routing table of Computer Networks [7]. For brevity, let a &brvbar;&ETH;-graph stand for a graph with property &brvbar;&ETH;. The information-theoretically optimal number of bits required to represent an n-node &brvbar;&ETH;-graph is &lceil;log2 N&brvbar;&ETH;(n)&rceil;, where N&brvbar;&ETH;(n) is the number of distinct n-node &brvbar;&ETH;-graphs. Although determining or approximating the close forms of N&brvbar;&ETH;(n) for nontrivial classes of &brvbar;&ETH; is challenging, we provide a linear-time methodology for graph compression schemes that are information-theoretically optimal with respect to continuous super-additive functions (abbreviated as optimal for the rest of the extended abstract). Specifically, if &brvbar;&ETH; satisfies certain properties, then we can compress any n-node m-edge &brvbar;&ETH;-graph G into a binary string Z such that G and Z can be computed from each other in O(m + n) time, and that the bit count of Z is at most &brvbar;&Acirc;(n) + o(&brvbar;&Acirc;(n)) for any continuous super-additive function &brvbar;&Acirc;(n) with log2N&brvbar;&ETH;(n) &iexcl;&Uuml; &brvbar;&Acirc;(n) + o(&brvbar;&Acirc;(n)). Our methodology is applicable to general classes of graphs; this extended abstract focuses on graphs with sublinear genus. For example, if the input n-node &brvbar;&ETH;-graph G is equipped with an embedding on its genus surface, which is a reasonable assumption for graphs arising from 3D model compression, then our methodology is applicable to any &brvbar;&ETH; satisfying the following statements: F1. The genus of any n-node &brvbar;&ETH;-graph is o(n/log2 n); F2. Any subgraph of a &brvbar;&ETH;-graph remains a &brvbar;&ETH;-graph; F3. log N &brvbar;&ETH;(n) = &brvbar;&cedil;(n); and F4. There is an integer k = O(1) such that it takes O(n) time to determine whether an O(log(k) n)-node graph satisfies property &brvbar;&ETH;. For instance, &brvbar;&ETH; can be the property of being a directed 3-colorable simple graph with genus no more than ten. The result is a novel application of planarization algorithm for bounded-genus graphs [5] and separator decomposition tree of planar graphs [9]. Rooted trees were the only known nontrivial class of graphs with linear-time optimal coding schemes. He, Kao, and Lu [11] provided O(n log n)-time compression schemes for planar and plane graphs that are optimal. Our results significantly enlarge the classes of graphs that admit efficient optimal compression schemes. More results on various versions of graph compression problems or succinct graph representations can be found in [1-4, 6, 8, 10, 14, 15] and the references therein.
SODA	Mixing time and long paths in graphs.	Igor Pak	2002	We prove that regular graphs with large degree and small mixing time contain long paths and some other families of graphs as subgraphs. We present then an efficient algorithm for finding long paths. We apply the results to size Ramsey numbers and self-avoiding walks in graphs.
SODA	Tiling groups for Wang tiles.	Cristopher Moore,Ivan Rapaport,Eric Rémila	2002	"We apply tiling groups and height functions to tilings of regions in the plane by Wang tiles, which are squares with colored boundaries where the colors of shared edges must match. We define a set of tiles as unambiguous if it contains all tiles equivalent to the identity in its tiling group. For all but one set of unambiguous tiles with two colors, we give efficient algorithms that tell whether a given region with colored boundary is tileable, show how to sample random tilings, and how to calculate the number of local moves or ""flips"" required to transform one tiling into another. We also analyze the lattice structure of the set of tilings, and study several examples with three and four colors as well."
SODA	I/O-optimal algorithms for planar graphs using separators.	Anil Maheshwari,Norbert Zeh	2002	We present I/O-optimal algorithms for several fundamental problems on planar graphs. Our main contribution is an I/O-efficient algorithm for computing a small vertex separator of an unweighted planar graph. This algorithm is superior to all existing external memory algorithms for this problem, as it requires neither a breadth-first search tree nor an embedding of the graph as part of the input. In fact, we derive I/O-optimal algorithms for planar embedding, breadth-first search, depth-first search, single source shortest paths, and computing weighted separators of planar graphs from our unweighted separator algorithm.
SODA	Efficient algorithms for document retrieval problems.	S. Muthukrishnan	2002	"We are given a collection D of text documents d1,&hellip;,dk, with &sum;i = n, which may be preprocessed. In the document listing problem, we are given an online query comprising of a pattern string p of length m and our goal is to return the set of all documents that contain one or more copies of p. In the closely related occurrence listing problem, we output the set of all positions within the documents where pattern p occurs. In 1973, Weiner [24] presented an algorithm with O(n) time and space preprocessing following which the occurrence listing problem can be solved in time O(m + output) where output is the number of positions where p occurs; this algorithm is clearly optimal. In contrast, no optimal algorithm is known for the closely related document listing problem, which is perhaps more natural and certainly well-motivated.We provide the first known optimal algorithm for the document listing problem. More generally, we initiate the study of pattern matching problems that require retrieving documents matched by the patterns; this contrasts with pattern matching problems that have been studied more frequently, namely, those that involve retrieving all occurrences of patterns. We consider document retrieval problems that are motivated by online query processing in databases, Information Retrieval systems and Computational Biology. We present very efficient (optimal) algorithms for our document retrieval problems. Our approach for solving such problems involve performing ""local"" encodings whereby they are reduced to range query problems on geometric objects --- points and lines --- that have color. We present improved algorithms for these colored range query problems that arise in our reductions using the structural properties of strings. This approach is quite general and yields simple, efficient, implementable algorithms for all the document retrieval problems in this paper."
SODA	Construction of probe interval models.	Ross M. McConnell,Jeremy Spinrad	2002	An interval graph for a set of intervals on a line consists of one vertex for each interval, and an edge for each pair of intersecting intervals. A probe interval graph is obtained from an interval graph by designating a subset P of vertices as probes, and removing the edges between pairs of vertices in the remaining set N of non-probes. We examine the problem of finding and representing possible layouts of the intervals, given a probe interval graph. We obtain an O(n + m log n) bound, where n is the number of vertices and m is the number of edges. The problem is motivated by an application to molecular biology.
SODA	A new algorithm for protein folding in the HP model.	Alantha Newman	2002	"We consider the problem of protein folding in the HP model on the two-dimensional square lattice. This problem is combinatorially equivalent to folding a string of 0's and 1's so that the string forms a self-avoiding walk on the lattice and the number of adjacent pairs of 1's is maximized. We present a linear-time 1/3-approximation algorithm for this problem, improving on the previous best approximation factor of 1/4. The approximation guarantee of this algorithm is based on an upper bound presented by Hart and Istrail [6] and used in all previous papers that address this problem. We show that this upper bound cannot be used to obtain an approximation factor better than 1/2."
SODA	Optimal time-space trade-offs for non-comparison-based sorting.	Rasmus Pagh,Jakob Pagter	2002	We study the problem of sorting n integers of w bits on a unit-cost RAM with word size w, and in particular consider the time-space trade-off (product of time and space in bits) for this problem. For comparison-based algorithms, the time-space complexity is known to be &Theta;(n2). A result of Beame shows that the lower bound also holds for non-comparison-based algorithms, but no algorithm has met this for time below the comparison-based &Omega;(nlgn) lower bound.We show that if sorting within some time bound &Ttilde; is possible, then time T = O(&Ttilde; + nlg* n) can be achieved with high probability using space S = O(n2/T + w), which is optimal. Given a deterministic priority queue using amortized time t(n) per operation and space nO(1), we provide a deterministic algorithm sorting in time T = O(n(t(n) + lg* n)) with S = O(n2/T + w). Both results require that w &le; n1-&Omega;(1). Using existing priority queues and sorting algorithms, this implies that we can deterministically sort time-space optimally in time &Theta;(T) for T &ge; n(lg lg n)2, and with high probability for T &ge; nlg lg n.Our results imply that recent space lower bounds for deciding element distinctness in o(nlgn) time are nearly tight.
SODA	The mathematics of playing golf.	Giovanni Rinaldi,Ulrich Voigt,Gerhard J. Woeginger	2002	We consider a class of non-linear mixed integer programs with n integer variables and k continuous variables. Solving instances from this class to optimality is an NP-hard problem. We show that for the cases with k &le; 2, every optimal solution is integral. In strong contrast to this, for every k &ge; 3 there exist instances where every optimal solution takes non-integral values.
SODA	Edge dominating and hypomatchable sets.	Ojas Parekh	2002	"The weighted edge dominating set problem (EDS) generalizes both the weighted vertex cover problem and the problem of covering the edges of graph by a minimum cost set of both vertices and edges. Although EDS was proven NP-complete in 1980, not much progress had been made in improving its approximability to match that of weighted vertex cover until 2000. In this paper we develop a 2-approximation for weighted EDS by honing the technique of a recent 2 1/10-approximation which exploits the close polyhedral relationship between EDS and the edge cover problem. For the sake of completeness we also present a new direct proof of Edmonds and Johnson's characterization of the edge cover polyhedron. Our approximation guarantee is tight in the sense that the existence of a (2-&epsilon;)-approximation for weighted EDS for some constant, &epsilon; would imply a (2-&epsilon;)-approximation for weighted vertex cover, constituting a major breakthrough in the field."
SODA	Succinct representations of lcp information and improvements in the compressed suffix arrays.	Kunihiko Sadakane	2002	We introduce two succinct data structures to solve various string problems. One is for storing the information of lcp, the longest common prefix, between suffixes in the suffix array, and the other is an improvement in the compressed suffix array which supports linear time counting queries for any pattern. The former occupies only 2n + o(n) bits for a text of length n for computing lcp between adjacent suffixes in lexicographic order in constant time, and 6n + o(n) bits between any two suffixes. No data structure in the literature attained linear size. The latter has size proportional to the text size and it is applicable to texts on any alphabet &Sigma; such that |&Sigma;| = logO(1) n. These space-economical data structures are useful in processing huge amounts of text data.
SODA	Computing shortest paths with comparisons and additions.	Seth Pettie,Vijaya Ramachandran	2002	"We present an undirected all-pairs shortest paths (APSP) algorithm which runs on a pointer machine in time O(mn&alpha;(m,n)) while making O(mnlog &alpha;(m, n)) comparisons and additions, where m and n are the number of edges and vertices, respectively, and &alpha;(m, n) is Tarjan's inverse-Ackermann function. This improves upon all previous comparison & addition-based APSP algorithms when the graph is sparse, i.e., when m = o(n log n).At the heart of our APSP algorithm is a new single-source shortest paths algorithm which runs in time O(m&alpha;(m, n) + n log log r) on a pointer machine, where r is the ratio of the maximum-to-minimum edge length. So long as r < 2no(1) this algorithm is faster than any implementation of Dijkstra's classical algorithm in the comparison-addition model.For directed graphs we give an O(m + n log r)-time comparison & addition-based SSSP algorithm on a pointer machine. Similar algorithms assuming integer weights or the RAM model were given earlier."
SODA	Minimizing randomness in minimum spanning tree, parallel connectivity, and set maxima algorithms.	Seth Pettie,Vijaya Ramachandran	2002	There are several fundamental problems for which there are optimal randomized algorithms, but whose deterministic complexity remains unresolved. Among such problems are the minimum spanning tree problem, the set maxima problem, the problem of computing connected components and (minimum) spanning trees in parallel and the problem of performing sensitivity analysis on shortest path trees and minimum spanning trees. For each of these problems there is an optimal randomized algorithm which uses a linear number of random bits. We propose new algorithms (or adapt old ones) for these problems which preserve optimality while saving an exponential number of random bits. In the case of computing minimum spanning trees and MST/SSSP sensitivity analysis, we reduce the dependence on randomness to log* n random bits.We also consider the problem of selection, for which we give two algorithms which make an expected 1.5n + o(n) comparisons; one uses O(log n) random bits and is uniform, the other uses O(log log n) random bits and is non-uniform.
SODA	New bounds for multi-dimensional packing.	Steven S. Seiden,Rob van Stee	2002	New upper and lower bounds are presented for a multi-dimensional generalization of bin packing called box packing.Several variants of this problem, including bounded space box packing, square packing, variable sized box packing and resource augmented box packing are also studied. The main results, stated for d = 2, are as follows: A new upper bound of 2.66013 for online box packing, a new 14/9 + &epsilon; polynomial time offline approximation algorithm for square packing, a new upper bound of 2.43828 for online square packing, a new lower bound of 1.62176 for online square packing, a new lower bound of 2.28229 for bounded space online square packing and a new upper bound of 2.32571 for online two-sized box packing.
SODA	Undiscretized dynamic programming: faster algorithms for facility location and related problems on trees.	Rahul Shah,Martin Farach-Colton	2002	In the Uncapacitated Facility Location (UFL) problem, there is a fixed cost for opening a facility, and some distance matrix d that determines the cost of distributing commodities from any facility i to any consumer j. The problem is NP-hard in general and when d consists of a distance metric in a graph [7, 12]. However, for the case where the commodity transportation costs are given by path lengths in a tree, an O(n2) dynamic programming algorithm was given by [4, 7]. We improve this dynamic programming algorithm by using the geometry of piecewise linear functions and fast merging of the binary search trees used to store these functions. We achieve the complexity bound of O(n log n) for the Tree Location Problem and some related problems. Our approach gives a general method for solving tree dynamic programming problems.
SODA	Roundtrip spanners and roundtrip routing in directed graphs.	Liam Roditty,Mikkel Thorup,Uri Zwick	2002	We introduce the notion of roundtrip-spanners of weighted directed graphs and describe efficient algorithms for their construction. We show that for every integer k &ge; 1 and any &epsi; > 0, any directed graph on n vertices with edge weights in the range [1, W] has a (2k + &epsi;)-roundtrip-spanner with O(min{(k2/&epsi;) n1 + 1/k (log(nW), (k/&epsi;)2 n1 + 1/k,(log n)2&minus;1/k}) edges. We then extend these constructions and obtain compact roundtrip routing schemes. For every integer k &ge; 1 and every &epsi; > 0, we describe a roundtrip routing scheme that has stretch 4k + &epsi;, and uses at each vertex a routing table of size &Otilde;((k2/&epsi;)n1/k log(nW)). We also show that any weighted directed graph with arbitrary/ positive edge weights has a 3-roundtrip-spanner with O(n3/2) edges. This result is optimal. Finally, we present a stretch 3 roundtrip routing scheme that uses local routing tables of size &Otilde;(n1/2). This routing scheme is essentially optimal. The roundtrip-spanner constructions and the roundtrip routing schemes for directed graphs that we describe are only slightly worse than the best available spanners and routing schemes for undirected graphs. Our roundtrip routing schemes substantially improve previous results of Cowen and Wagner. Our results are obtained by combining ideas of Cohen, Cowen and Wagner, Thorup and Zwick, with some new ideas.
SODA	Succinct indexable dictionaries with applications to encoding k-ary trees and multisets.	Rajeev Raman,Venkatesh Raman,S. Srinivasa Rao	2002	We consider the indexable dictionary problem which consists in storing a set S &sube; {0,&hellip;, m - 1} for some integer m, while supporting the operations of rank(x), which returns the number of elements in S that are less than x if x &epsilon; S, and -1 otherwise; and select(i) which returns the i-th smallest element in S.We give a structure that supports both operations in O(1) time on the RAM model and requires B(n,m) + o(n) + O(lg lg m) bits to store a set of size n, where B(n,m) = &lceil;lg (nm)&rceil; is the minimum number of bits required to store any n-element subset from a universe of size m. Previous dictionaries taking this space only supported (yes/no) membership queries in O(1) time. In the cell probe model we can remove the O(lg lg m) additive term in the space bound, answering a question raised by Fich and Miltersen, and Pagh.We also present two applications of our dictionary structure:&bull; An information-theoretically optimal representation for k-ary cardinal trees (aka k-ary tries). Our structure uses C(n,k) + o(n + lg k) bits to store a k-ary tree with n nodes and can support parent, i-th child, child labeled i, and the degree of a node in constant time, where C(n,k) is the minimum number of bits to store any n-node k-ary tree. Previous space efficient representations for cardinal k-ary trees required C(n,k) + &Omega;(n) bits.&bull; An optimal representation for multisets where (appropriate generalisations of) the select and rank operations can be supported in O(1) time. Our structure uses B(n, m + n) + o(n) + O(lg lg m) bits to represent a multiset of size n from an m element set; the first term is the minimum number of bits required to represent such a multiset.
SODA	Existence theorems, lower bounds and algorithms for scheduling to meet two objectives.	April Rasala,Clifford Stein,Eric Torng,Patchrawat Uthaisombut	2002	We give general results about the existence of schedules which simultaneously minimize two criteria. Our results are general in that (i) they apply to any scheduling environment and (ii) they apply to all pairs of metrics in which the first metric is one of maximum flow time, makespan, or maximum lateness and the second metric is one of average flow time, average completion time, average lateness, or number of on-time jobs. For most of the pairs of metrics we consider, we show the existence of near-optimal schedules for both metrics as well as some lower bound results. For some pairs of metrics such as (maximum flow time, average weighted flow time) and (maximum flow time, number of on-time jobs), we prove negative results on the ability to approximate both criteria within a constant factor of optimal. For many other criteria we present lower bounds that match or approach our bicriterion existence results.
SODA	Approximating k-cuts via network strength.	R. Ravi,Amitabh Sinha II	2002	Approximating k-cuts via network strength.
SODA	Erratum: an approximation algorithm for minimum-cost vertex-connectivity problems.	R. Ravi,David P. Williamson	2002	"There is an error in our paper ""An Approximation Algorithm for Minimum-Cost Vertex-Connectivity Problems,"" which appeared in SODA '95 [2] (see also the journal version [3]). Below we briefly describe the problem and discuss which of our results can be shown to hold.A complete version of our erratum can be found at www.almaden.ibm.com/cs/people/dpw."
SODA	How unfair is optimal routing?	Tim Roughgarden	2002	"We are given a network and a rate of traffic between a source node and a destination node, and seek an assignment of traffic to source-destination paths. We assume that each network user controls a negligible fraction of the overall traffic, so that feasible assignments of traffic to paths in the network can be modeled as network flows. We also assume that the time needed to traverse a single link of the network is load-dependent, that is, the common latency suffered by all traffic on the link increases as the link becomes more congested.We consider two types of traffic assignments. In the first, we measure the quality of an assignment by the total latency incurred by network users; an optimal assignment is a feasible assignment that minimizes the total latency. On the other hand, it is often difficult in practice to impose optimal routing strategies on the traffic in a network, leaving network users free to act according to their own interests. We assume that, in the absence of network regulation, users act in a selfish manner. Under this assumption, we can expect network traffic to converge to the second type of assignment that we consider, an assignment at Nash equilibrium. An assignment is at Nash equilibrium if no network user has an incentive to switch paths; this occurs when all traffic travels on minimum-latency paths.The following question motivates our work: is the optimal assignment really a ""better"" assignment than an assignment at Nash equilibrium? While the optimal assignment obviously dominates one at Nash equilibrium from the viewpoint of total latency, it may lack desirable fairness properties. For example, consider a network consisting of two nodes, s and t, and two edges, e1 and e2, from s to t. Suppose further that one unit of traffic wishes to travel from s to t, that the latency of edge e1 is always 2(1 - &epsilon;) (independent of the edge congestion, where &epsilon; > 0 is a very small number), and that the latency of edge e2 is the same as the edge congestion (i.e., if x units of traffic are on edge e2, then all of this flow incurs x units of latency). In the assignment at Nash equilibrium, all traffic is on the second link; in the minimum-latency assignment, 1 - &epsilon; units of traffic use edge e2 while the remaining &epsilon; units of traffic use edge e1. Roughly, a small fraction of the traffic is sacrificed to the slower edge because it improves the overall social welfare (by reducing the congestion experienced by the overwhelming majority of network users); needless to say, these martyrs may not appreciate a doubling of their travel time in the name of ""the greater good""! Indeed, this drawback of routing traffic optimally has inspired practitioners to find traffic assignments that minimize total latency subject to explicit length constraints [1], which require that no network user experiences much more latency than in an assignment at Nash equilibrium. The central question of this paper is how much worse off can network users be in an optimal assignment than in one at Nash equilibrium? After reviewing some technical preliminaries in the next section (all of which are classical; see [2] for historical references), we provide an exact solution to this problem under weak hypotheses on the class of allowable latency functions."
SODA	Binary space partitions for line segments with a limited number of directions.	Csaba D. Tóth	2002	We show that there is always a binary space partition (BSP) of size O(n log k) and an autopartition of size O(nk) for n disjoint line segments in the plane, assuming that the segments have k distinct orientations. In particular, if k is a constant, these bounds imply that there is a linear-size BSP and autopartition. Our proof is constructive and can be turned into algorithms computing such a BSP or autopartition in O(n2) and O(n2k) times.
SODA	Algorithms for quantified Boolean formulas.	Ryan Williams	2002	We present algorithms for solving quantified Boolean formulas (QBF, or sometimes QSAT) with worst case runtime asymptotically less than O(2n) when the clause-to-variable ratio is smaller or larger than some constant. We solve QBFs in conjunctive normal form (CNF) in O(1.709m) time and space, where m is the number of clauses. Extending the technique to a quantified version of constraint satisfaction problems (QCSP), we solve QCSP with domain size d = 3 in O(1.953m) time, and QCSPs with d &ge; 4 in O(dm/2+&epsilon;) time and space for &epsilon; < 0, where m is the number of constraints. For 3-CNF QBF, we describe an polynomial space algorithm with time complexity O(1.619n) when the number of 3-CNF clauses is equal to n; the bound approaches 2n as the clause-to-variable ratio approaches 2. For 3-CNF &Pi;2-SAT (3-CNF QBFs of the form &forall;u1&hellip;uj&exist;xj+1&hellip;xnF), an improved polyspace algorithm has runtime varying from O(1.840m) to O(1.415m), as a particular clause-to-variable ratio increases from 1.
SODA	On directed Steiner trees.	Leonid Zosin,Samir Khuller	2002	The directed Steiner tree problem is the following: given a directed graph G = (V, E) with weights on the edges, a set of terminals S &sube; V, and a root vertex r, find a minimum weight out-branching T rooted at r, such that all vertices in S are included in T. This problem is known to be NP-hard. Recently, non-trivial polynomial time approximation algorithms have been developed for this problem with worst case approximation guarantees of O(k&epsilon;) for any fixed &epsilon; > 0. We consider a natural LP relaxation of this problem. Using a dual formulation we construct a simple deterministic (D + 1)-approximation algorithm for a special case when the subgraph induced by V \ S is a tree with depth D (for example, this can be shown to include the group Steiner tree problem as a special case, by the loss of poly-log factors in the approximation guarantee). We also show that this LP has an integrality gap of &Theta;(&radic;k) for the general problem.
SODA	Jenga.	Uri Zwick	2002	"Jenga is a popular block game played by two players. Each player in her turn has to remove a block from a stack, without toppling the stack, and then add it the top of the stack. We analyze the game mathematically and describe the optimal strategies of both players. We show that 'physics', that seems to play a dominant role in this game, does not really add much to the complexity of the (idealized) game, and that Jenga is, in fact, a Nim-like game. In particular, we show that a game that starts with n full layers of blocks is a win for the first player if and only if n = 2, or n &equiv; 1, 2 (mod 3) and n &ge; 4. We also suggest some several natural extensions of the game."
SODA	Computer assisted proof of optimal approximability results.	Uri Zwick	2002	We obtain computer assisted proofs of several spherical volume inequalities that appear in the analysis of semidefinite programming based approximation algorithms for Boolean constraint satisfaction problems. These inequalities imply, in particular, that the performance ratio achieved by the MAX 3-SAT approximation algorithm of Karloff and Zwick is indeed 7/8, as conjectured by them, and that the performance ratio of the MAX 3-CSP algorithm of the author is indeed 1/2. Other results are also implied. The computer assisted proofs are obtained using a system called REALSEARCH, written by the author. This system uses interval arithmetic to produce rigorous proofs that certain collections of constraints in real variables have no real solution.
SODA	Approximating minimum quartet inconsistency (abstract).	Gianluca Della Vedova,Tao Jiang,Jing Li,Jianjun Wen	2002	Approximating minimum quartet inconsistency (abstract).
SODA	Proceedings of the Thirteenth Annual ACM-SIAM Symposium on Discrete Algorithms, January 6-8, 2002, San Francisco, CA, USA.	David Eppstein	2002	Proceedings of the Thirteenth Annual ACM-SIAM Symposium on Discrete Algorithms, January 6-8, 2002, San Francisco, CA, USA.
STOC	Quantum lower bound for the collision problem.	Scott Aaronson	2002	(MATH) The collision problem is to decide whether a function X: { 1,&ldots;,n} &rarr; { 1, &ldots;,n} is one-to-one or two-to-one, given that one of these is the case. We show a lower bound of &Omega;(n1/5) on the number of queries needed by a quantum computer to solve this problem with bounded error probability. The best known upper bound is O(n1/3), but obtaining any lower bound better than &Omega;(1) was an open problem since 1997. Our proof uses the polynomial method augmented by some new ideas. We also give a lower bound of &Omega;(n1/7) for the problem of deciding whether two sets are equal or disjoint on a constant fraction of elements. Finally we give implications of these results for quantum complexity theory.
STOC	Almost all graphs with average degree 4 are 3-colorable.	Dimitris Achlioptas,Cristopher Moore	2002	We analyze a randomized version of the Brelaz heuristic on sparse random graphs. We prove that almost all graphs with average degree d ≤ 4.03, i.e., G(n,p = d/n), are 3-colorable and that a constant fraction of all 4-regular graphs are 3-colorable.
STOC	Approximate counting of inversions in a data stream.	Miklós Ajtai,T. S. Jayram,Ravi Kumar,D. Sivakumar	2002	(MATH) Inversions are used as a fundamental quantity to measure the sortedness of data, to evaluate different ranking methods for databases, and in the context of rank aggregation. Considering the volume of the data sets in these applications, the data stream model {14, 2] is a natural setting to design efficient algorithms.We obtain a suite of space-efficient streaming algorithms for approximating the number of inversions in a permutation. The best space bound we achieve is $O(\log n \log \log n)$ through a deterministic algorithm. In contrast, we derive an $\Omega(n)$ lower bound for randomized exact computation for this problem; thus approximation is essential.(MATH) We also consider two generalizations of this problem: (1) approximating the number of inversions between two permutations, for which we obtain a randomized $O(\sqrt{n} \log n)$-space algorithm, and (2) approximating the number of inversions in a general list, for which we obtain a randomized $O(\sqrt{n} \log^2 n)$-space two-pass algorithm. In contrast, we derive $\Omega(n)$-space lower bounds for deterministic approximate computation for these problems; thus both randomization and approximation are essential.All our algorithms use only O(log n) time per data item.
STOC	Combinatorial optimization problems in self-assembly.	Leonard M. Adleman,Qi Cheng,Ashish Goel,Ming-Deh A. Huang,David Kempe,Pablo Moisset de Espanés,Paul W. K. Rothemund	2002	"Self-assembly is the ubiquitous process by which simple objects autonomously assemble into intricate complexes. It has been suggested that intricate self-assembly processes will ultimately be used in circuit fabrication, nano-robotics, DNA computation, and amorphous computing. In this paper, we study two combinatorial optimization problems related to efficient self-assembly of shapes in the Tile Assembly Model of self-assembly proposed by Rothemund and Winfree [18]. The first is the Minimum Tile Set Problem, where the goal is to find the smallest tile system that uniquely produces a given shape. The second is the Tile Concentrations Problem, where the goal is to decide on the relative concentrations of different types of tiles so that a tile system assembles as quickly as possible. The first problem is akin to finding optimum program size, and the second to finding optimum running time for a ""program"" to assemble the shape.Self-assembly is the ubiquitous process by which simple objects autonomously assemble into intricate complexes. It has been suggested that intricate self-assembly processes will ultimately be used in circuit fabrication, nano-robotics, DNA computation, and amorphous computing. In this paper, we study two combinatorial optimization problems related to efficient self-assembly of shapes in the Tile Assembly Model of self-assembly proposed by Rothemund and Winfree [18]. The first is the Minimum Tile Set Problem, where the goal is to find the smallest tile system that uniquely produces a given shape. The second is the Tile Concentrations Problem, where the goal is to decide on the relative concentrations of different types of tiles so that a tile system assembles as quickly as possible. The first problem is akin to finding optimum program size, and the second to finding optimum running time for a ""program"" to assemble the shape.We prove that the first problem is NP-complete in general, and polynomial time solvable on trees and squares. In order to prove that the problem is in NP, we present a polynomial time algorithm to verify whether a given tile system uniquely produces a given shape. This algorithm is analogous to a program verifier for traditional computational systems, and may well be of independent interest. For the second problem, we present a polynomial time $O(\log n)$-approximation algorithm that works for a large class of tile systems that we call partial order systems."
STOC	On randomized online scheduling.	Susanne Albers	2002	(MATH) We study one of the most basic problems in online scheduling. A sequence of jobs has to be scheduled on $m$ identical parallel machines so as to minimize the makespan. Whenever a new job arrives, its processing time is known in advance. The job has to be scheduled immediately on one of the machines without knowledge of any future jobs. In the sixties Graham presented the famous List scheduling algorithm which is $(2-{1\over m})$-competitive. In the last ten years deterministic online algorithms with an improved competitiveness have been developed. The first algorithm with a performance guarantee asymptotically smaller than 2 was 1.986- competitive. The competitive ratio was first improved to 1.945 and then to 1.923 and 1.9201. Randomized competitive algorithms that are better than (known) deterministic algorithms were proposed for specific values of $m$, i.e. for $m\in\{2,\ldots,7\}$.(MATH) In this paper we present the first randomized online algorithm that performs better than known deterministic algorithms for general $m$. The algorithm is a combination of two deterministic scheduling strategies $A_1$ and $A_2$. Initially, when starting the scheduling process, a scheduler chooses $A_i$, $i\in\{1,2\}$, with probability ${1\over 2}$ and then serves the entire job sequence using the chosen algorithm. The new randomized algorithm is 1.916-competitive. We prove that this performance cannot be achieved by a deterministic algorithm based on analysis techniques that have been used in the literature so far: Using know techniques (or generalizations) it is impossible to prove a competitiveness smaller than 1.919 for any deterministic online algorithm. Our results strictly limit the performance that can be achieved with existing techniques.
STOC	On paging with locality of reference.	Susanne Albers,Lene M. Favrholdt,Oliver Giel	2002	"Motivated by the fact that competitive analysis yields too pessimistic results when applied to the paging problem, there has been considerable research interest in refining competitive analysis and in developing alternative models for studying online paging. In this paper, we propose a new, simple model for studying paging with locality of reference. The model is closely related to Denning's working set concept and directly reflects the amount of locality that request sequences exhibit. We use the page fault rate to evaluate the quality of paging algorithms, which is the performance measure used in practice. We develop tight or nearly tight bounds on the fault rates achieved by popular paging algorithms such as LRU, FIFO, deterministic Marking strategies and LFD. These bounds show that LRU is an optimal online algorithm, whereas FIFO and Marking strategies are not optimal in general. We present an experimental study comparing the page fault rates proven in our analyses to the page fault rates observed in practice."
STOC	Tradeoffs in probabilistic packet marking for IP traceback.	Micah Adler	2002	There has been considerable recent interest in probabilistic packet marking schemes for the problem of tracing a sequence of network packets back to an anonymous source. An important consideration for such schemes is the number of packet header bits that need to be allocated to the marking protocol. Let b denote this value. All previous schemes belong to a class of protocols for which b must be at least log n, where n is the number of bits used to represent the path of the packets. In this paper, we introduce a new marking technique for tracing a sequence of packets sent along the same path. This new technique is effective even when b=1. In other words, the sequence of packets can be traced back to their source using only a single bit in the packet header. With this scheme, the number of packets required to reconstruct the path is O(22n), but we also show that &omega;(2n) packets are required for any protocol where b=1. We also study the tradeoff between b and the number of packets required. We provide a protocol and a lower bound that together demonstrate that for the optimal protocol, the number of packets required (roughly) increases exponentially with n, but decreases doubly exponentially with b. The protocol we introduce is simple enough to be useful in practice. We also study the case where the packets are sent along k different paths. For this case, we demonstrate that any protocol must use at least log(2k&mdash;1) header bits. We also provide a protocol that requires &lceil;log(2k+1)&rceil; header bits in some restricted scenarios. This protocol introduces a new coding technique that may be of independent interest.
STOC	An exponential separation between regular and general resolution.	Michael Alekhnovich,Jan Johannsen,Toniann Pitassi,Alasdair Urquhart	2002	Two distinct proofs of an exponential separation between regular resolution and unrestricted resolution are given. The previous best known separation between these systems was quasi-polynomial.
STOC	3-manifold knot genus is NP-complet.	Ian Agol,Joel Hass,William P. Thurston	2002	3-manifold knot genus is NP-complet.
STOC	Random sampling and approximation of MAX-CSP problems.	Noga Alon,Wenceslas Fernandez de la Vega,Ravi Kannan,Marek Karpinski	2002	We present a new efficient sampling method for approximating r-dimensional Maximum Constraint Satisfaction Problems, MAX-rCSP, on n variables up to an additive error &egr;nr. We prove a newgeneral paradigm in that it suffices, for a given set of constraints, to pick a small uniformly random subset of its variables, and the optimum value of the subsystem induced on these variables gives (after a direct normalization and with high probability) an approximation to the optimum of the whole system up to an additive error of &egr;nr. Our method gives for the first time a polynomial in &egr;&mdash;1 bound on the sample size necessary to carry out the above approximation. Moreover, this bound is independent in the exponent on the dimension r. The above method gives a completely uniform sampling technique for all the MAX-rCSP problems, and improves the best known sample bounds for the low dimensional problems, like MAX-CUT. The method of solution depends on a new result on t he cut norm of random subarrays, and a new sampling technique for high dimensional linear programs. This method could be also of independent interest.
STOC	Deterministic sorting in O(nlog log n) time and linear space.	Yijie Han	2002	"We present a fast deterministic algorithm for integer sorting in linear space. Our algorithm sorts n integers in the range {0, 1, 2, &1dots;, m&mdash;1} in linear space in O(n log log n) time. This improves our previous result [8] which sorts in O(n log log n log log log n) time and linear space. This also improves previous best deterministic sorting algorithm [3, 11] which sorts in O(nlog log n) time but uses O(m&egr;) space. Our results can also be compared with Thorup's previous result [16] which sorts in O(nlog log n) time and linear space but uses randomization."
STOC	The invasiveness of off-line memory checking.	Miklós Ajtai	2002	"Memory checking is the task of checking the correctness of a sequence of ""store"" and ""retrieve"" operations. The operations are performed in a large unreliable memory. A checker using a much smaller but completely reliable memory tries to decide whether they were executed correctly. M. Blum, W. Evans, P. Gemmel, S. Kannan and M. Naor, has shown in 1991 that the off-line checking of a sequence of memory operations concerning a RAM consisting of n registers can be done, in a probabilistic sense, by a checker using only O(log n) reliable memory and a constant number of RAM operation per each ""store"" and ""retrieve"" operations (with log n word length), moreover no unproven cryptographic assumptions are needed in the proof. The probability of error will be polynomially small in n. The solution however requires the checker to store some extra information in the unreliable memory, that is, the checking protocol is invasive. (In this solution the time of each ""store"" operation must be stored together with the data and must be supplied to the checker at the time of the corresponding retrieve operation.) In this paper we prove that off-line memory checking, in the sense described above, is necessarily invasive, even if we make the problem somewhat easier for the checker to exclude trivial counter-examples. We show that even if the checker is allowed to read a constant number of registers from the large memory after each ""store"" or ""retrieve"" instruction, off-line non-invasive memory checking is not possible. Moreover for the case when the invasiveness consists of storing some extra information together with each piece of data and retrieving it together with the data we give a quantitative lower bound on the amount of extra ""invasive"" information stored in the memory. Namely, if the checker has O(log n) memory and the probability of error is polynomially small than the ""invasiveness"" of the mentioned method of [5] is optimal upto a constant factor. With other words the total number of extra bits that must be written in the memory is at least &egr;T log T, where T is the number of store and retrieve operations. In the lower bounds we do not restrict the computational power of the checker at all, in fact we only assume that the checker is an n-way branching program with O(log n) bits of memory."
STOC	Computing the betti numbers of arrangements.	Saugata Basu	2002	(MATH) In this paper, we consider the problem of computing the Betti numbers of an arrangement of $n$ compact semi-algebraic sets, $S_1,\ldots,S_n \subset \R^k$, where each $S_i$ is described using a constant number of polynomials with degrees bounded by a constant. Such arrangements are ubiquitous in computational geometry. We give an algorithm for computing $\ell$-th Betti number, $\beta_\ell(\cup_i S_i), 0 \leq \ell \leq k-1$, using $O(n^{\ell+2})$ algebraic operations. Additionally, one has to perform linear algebra on matrices of size bounded by $O(n^{\ell+1})$. All previous algorithms for computing the Betti numbers of arrangements, triangulated the arrangement giving rise to a complex of size $O(n^{2^k})$ in the worst case. To our knowledge this is the first algorithm for computing $\beta_\ell(\cup_i S_i)$ that does not rely on such a global triangulation, and has a graded complexity which depends on $\ell$.
STOC	Stability of load balancing algorithms in dynamic adversarial systems.	Elliot Anshelevich,David Kempe,Jon M. Kleinberg	2002	In the dynamic load balancing problem, we seek to keep the job load roughly evenly distributed among the processors of a given network. The arrival and departure of jobs is modeled by an adversary restricted in its power. Muthukrishnan and Rajaraman [An adversarial model for distributed dynamic load balancing, in Proceedings of the 10th ACM Symposium on Parallel Algorithms and Architectures, ACM, New York, 1998] gave a clean characterization of a restriction on the adversary that can be considered the natural analogue of a cut condition. They proved that a simple local balancing algorithm proposed by Aiello et al. [Approximate load balancing on dynamic and asynchronous networks, in Proceedings of the 25th ACM Symposium on Theory of Computing, ACM, New York, 1993] is stable against such an adversary if the insertion rate is restricted to a $(1-\varepsilon)$ fraction of the cut size. They left as an open question whether the algorithm is stable at rate 1. In this paper, we resolve this question positively, by proving stability of the local algorithm at rate 1. Our proof techniques are very different from the ones used by Muthukrishnan and Rajaraman and yield a simpler proof and tighter bounds on the difference in loads. In addition, we introduce a multicommodity version of this load balancing model and show how to extend the result to the case of balancing two different kinds of loads at once (obtaining as a corollary a new proof of the 2-commodity Max-Flow Min-Cut Theorem). We also show how to apply the proof techniques to the problem of routing packets in adversarial systems. Awerbuch et al. [Simple routing strategies for adversarial systems, in Proceedings of the 42nd IEEE Symposium on Foundations of Computer Science, IEEE Computer Society, Los Alamitos, CA, 2001] showed that the same load balancing algorithm is stable against an adversary, inserting packets at rate 1 with a single destination in dynamically changing networks. Our techniques give a much simpler proof for a different model of adversarially changing networks.
STOC	Cache-oblivious priority queue and graph algorithm applications.	Lars Arge,Michael A. Bender,Erik D. Demaine,Bryan Holland-Minkley,J. Ian Munro	2002	(MATH) In this paper we develop an optimal cache-oblivious priority queue data structure, supporting insertion, deletion, and deletemin operations in O(1 \over B logM/BN \over B) amortized memory transfers, where M and B are the memory and block transfer sizes of any two consecutive levels of a multilevel memory hierarchy. In a cache-oblivious data structure, M and B are not used in the description of the structure. The bounds match the bounds of several previously developed external-memory (cache-aware) priority queue data structures, which all rely crucially on knowledge about M and B. Priority queues are a critical component in many of the best known external- memory graph algorithms, and using our cache-oblivious priority queue we develop several cache- oblivious graph algorithms.
STOC	Fitting algebraic curves to noisy data.	Sanjeev Arora,Subhash Khot	2002	"We introduce the following problem which is motivated by applications in vision and pattern detection: We are given pairs of datapoints (x1,y1), (x2,y2),...,(xm, ym) ∈ [- 1, 1] × [- 1, 1], a noise parameter δ > 0, a degree bound d, and a threshold ρ > 0. We desire an algorithm that enlists every degree d polynomial h such that |h(xi) - yi| ≤ δ for at least δ fraction of the indices i. If δ = 0, this is just the list decoding problem that has been popular in complexity theory and for which Sudan gave a poly(m,d) time algorithm. However, for δ > 0, the problem as stated becomes ill-posed and one needs a careful reformulation (see the Introduction). We prove a few basic results about this (reformulated) problem. We show that the problem has no polynomial-time algorithm (our counterexample works for ρ = 0.5). This is shown by exhibiting an instance of the problem where the number of solutions is as large as exp(d0.5-ε) and every pair of solutions is far from each other in ℓ∞ norm. On the algorithmic side, we give a rigorous analysis of a brute force algorithm that runs in exponential time. Also, in surprising contrast to our lowerbound, we give a polynomial-time algorithm for learning the polynomials assuming the data is generated using a mixture model in which the mixing weights are ""nondegenerate."""
STOC	Space-efficient approximate Voronoi diagrams.	Sunil Arya,Theocharis Malamatos,David M. Mount	2002	(MATH) Given a set $S$ of $n$ points in $\IR^d$, a {\em $(t,\epsilon)$-approximate Voronoi diagram (AVD)} is a partition of space into constant complexity cells, where each cell $c$ is associated with $t$ representative points of $S$, such that for any point in $c$, one of the associated representatives approximates the nearest neighbor to within a factor of $(1+\epsilon)$. Like the Voronoi diagram, this structure defines a spatial subdivision. It also has the desirable properties of being easy to construct and providing a simple and practical data structure for answering approximate nearest neighbor queries. The goal is to minimize the number and complexity of the cells in the AVD.(MATH) We assume that the dimension $d$ is fixed. Given a real parameter $\gamma$, where $2 \le \gamma \le 1/\epsilon$, we show that it is possible to construct a $(t,\epsilon)$-AVD consisting of \[O(n \epsilon^{\frac{d-1}{2}} \gamma^{\frac{3(d-1)}{2}} \log \gamma) \] cells for $t = O(1/(\epsilon \gamma)^{(d-1)/2})$. This yields a data structure of $O(n \gamma^{d-1} \log \gamma)$ space (including the space for representatives) that can answer $\epsilon$-NN queries in time $O(\log(n \gamma) + 1/(\epsilon \gamma)^{(d-1)/2})$. (Hidden constants may depend exponentially on $d$, but do not depend on $\epsilon$ or $\gamma$).(MATH) In the case $\gamma = 1/\epsilon$, we show that the additional $\log \gamma$ factor in space can be avoided, and so we have a data structure that answers $\epsilon$-approximate nearest neighbor queries in time $O(\log (n/\epsilon))$ with space $O(n/\epsilon^{d-1})$, improving upon the best known space bounds for this query time. In the case $\gamma = 2$, we have a data structure that can answer approximate nearest neighbor queries in $O(\log n + 1/\epsilon^{(d-1)/2})$ time using optimal $O(n)$ space. This dramatically improves the previous best space bound for this query time by a factor of $O(1/\epsilon^{(d-1)/2})$.(MATH) We also provide lower bounds on the worst-case number of cells assuming that cells are axis-aligned rectangles of bounded aspect ratio. In the important extreme cases $\gamma \in \{2, 1/\epsilon\}$, our lower bounds match our upper bounds asymptotically. For intermediate values of $\gamma$ we show that our upper bounds are within a factor of $O((1/\epsilon)^{(d-1)/2}\log \gamma)$ of the lower bound.
STOC	Wait-free consensus with infinite arrivals.	James Aspnes,Gauri Shah,Jatin Shah	2002	A randomized algorithm is given that solves the wait-free consensus problem for a shared-memory model with infinitely many processes. The algorithm is based on a weak shared coin algorithm that uses weighted voting to achieve a majority outcome with at least constant probability that cannot be disguised even if a strong adversary is allowed to destroy infinitely many votes. The number of operations performed by process i is a polynomial function of i. Additional algorithms are given for solving consensus more efficiently in models with an unknown upper bound b on concurrency or an unknown upper bound n on the number of active processes; under either of these restrictions, it is also shown that the problem can be solved even with infinitely many anonymous processes by prefixing each instance of the shared coin with a naming algorithm that breaks symmetry with high probability. For many of these algorithms, matching lower bounds are proved that show that their per-process work is nearly optimal as a function of i, b, or n. The case of n active processes gives an algorithm for anonymous, adaptive consensus that requires only O(n log2 n) per-process work, which is within a constant factor of the best previously known non-adaptive algorithm for a strong adversary. Finally, it is shown that standard universal constructions based on consensus continue to work with infinitely many processes with only slight modifications. This shows that in infinite distributed systems, as in finite ones, with randomness all things are possible.
STOC	Average case analysis for batched disk scheduling and increasing subsequences.	Eitan Bachmat	2002	"(MATH) We consider the problem of estimating the tour length and finding approximation algorithms for the asymmetric traveling salesman problem arising from the disk scheduling problem. Given N requests, we show that if the seek function has positive derivative at 0 the tour length is concentrated in probability around the value Cf,pN1/2 for an explicit constant Cf,p dependent on the seek function and the distribution of requests. For linear seek function we provide even tighter bounds and provide an O(Nlog(N)) time algorithm for finding the optimal tour. The proof uses several results on the size and location of maximal increasing subsequences. To handle more general seek functions we introduce a more general concept of increasing subsequences. we provide order of magnitude estimates on the tour length for a wide class of seek functions with vanishing derivative at 0. For general seek functions we use some geometric information on the location of maximal generalized increasing subsequences obtained via Talagrand's isoperimetric inequalities to produce a probabilistic 1+&egr; approximation algorithm. These results complement the results on guaranteed approximation algorithms for this problem presented in [2]."
STOC	Approximate clustering via core-sets.	Mihai Badoiu,Sariel Har-Peled,Piotr Indyk	2002	In this paper, we show that for several clustering problems one can extract a small set of points, so that using those core-sets enable us to perform approximate clustering efficiently. The surprising property of those core-sets is that their size is independent of the dimension.Using those, we present a (1+ &egr;)-approximation algorithms for the k-center clustering and k-median clustering problems in Euclidean space. The running time of the new algorithms has linear or near linear dependency on the number of points and the dimension, and exponential dependency on 1/&egr; and k. As such, our results are a substantial improvement over what was previously known.We also present some other clustering results including (1+ &egr;)-approximate 1-cylinder clustering, and k-center clustering with outliers.
STOC	Strict polynomial-time in simulation and extraction.	Boaz Barak,Yehuda Lindell	2002	"The notion of efficient computation is usually identified in cryptography and complexity with (strict) probabilistic polynomial-time. However, until recently, in order to obtain \emph{constant-round} zero-knowledge proofs and proofs of knowledge, one had to allow simulators and knowledge extractors to run in time that is only polynomial on the average (i.e., expected polynomial-time). Recently Barak gave the first constant-round zero-knowledge argument with a strict (in contrast to expected) polynomial-time simulator. The simulator in his protocol is a nonblack-box simulator (i.e., it makes inherent use of the description of the code of the verifier).In this paper, we further address the question of strict polynomial-time in constant-round zero-knowledge proofs and arguments of knowledge. First, we show that there exists a constant-round zero-knowledge argument of knowledge with a strict polynomial-time knowledge extractor. As in the simulator of Barak's zero-knowledge protocol, the extractor for our argument of knowledge is not black-box and makes inherent use of the code of the prover. On the negative side, we show that nonblack-box techniques are essential for both strict polynomial-time simulation and extraction. That is, we show that no (nontrivial) constant-round zero-knowledge proof or argument can have a strict polynomial-time black-box simulator. Similarly, we show that no (nontrivial) constant-round zero-knowledge proof or argument of knowledge can have a strict polynomial-time black-box knowledge extractor."
STOC	Improved decremental algorithms for maintaining transitive closure and all-pairs shortest paths.	Surender Baswana,Ramesh Hariharan,Sandeep Sen	2002	This paper presents improved algorithms for the following problem: given an unweighted directed graph G(V,E) and a sequence of on-line shortest-path/reachability queries interspersed with edge-deletions, develop a data-structure that can answer each query in optimal time, and can be updated efficiently after each edge-deletion. The central idea underlying our algorithms is a scheme for implicitly storing all-pairs reachability/shortest-path information, and an efficient way to maintain this information. Our algorithms are randomized and have one-sided inverse polynomial error for query.
STOC	The complexity of approximating entropy.	Tugkan Batu,Sanjoy Dasgupta,Ravi Kumar,Ronitt Rubinfeld	2002	(MATH) We consider the problem of approximating the entropy of a discrete distribution under several models. If the distribution is given explicitly as an array where the i-th location is the probability of the i-th element, then linear time is both necessary and sufficient for approximating the entropy.We consider a model in which the algorithm is given access only to independent samples from the distribution. Here, we show that a &lgr;-multiplicative approximation to the entropy can be obtained in O(n(1+&eta;)/&lgr;2 < poly(log n)) time for distributions with entropy &Omega;(&lgr; &eta;), where n is the size of the domain of the distribution and &eta; is an arbitrarily small positive constant. We show that one cannot get a multiplicative approximation to the entropy in general in this model. Even for the class of distributions to which our upper bound applies, we obtain a lower bound of &Omega;(nmax(1/(2&lgr;2), 2/(5&lgr;2&mdash;2)).We next consider a hybrid model in which both the explicit distribution as well as independent samples are available. Here, significantly more efficient algorithms can be achieved: a &lgr;-multiplicative approximation to the entropy can be obtained in O(&lgr;2.Finally, we consider two special families of distributions: those for which the probability of an element decreases monotonically in the label of the element, and those that are uniform over a subset of the domain. In each case, we give more efficient algorithms for approximating the entropy.
STOC	Time-space tradeoffs, multiparty communication complexity, and nearest-neighbor problems.	Paul Beame,Erik Vee	2002	"Recently, the first non-trivial time-space tradeoff lower bounds have been shown for decision problems in P, using notions derived from the study of two-party communication complexity. These results are proven directly for branching programs, natural generalizations of decision trees to directed graphs that provide elegant models of both non-uniform time T and space S simultaneously.We develop a new lower bound criterion, based on extending two-party communication complexity ideas to multiparty communication complexity. Applying this criterion to an explicit Boolean function based on a multilinear form overGF(2^s) for suitable s, we show lower bounds that yield T=\Omega(n\log^2 n) whenS\le n^{1-\epsilon}\log |D| for large input domain D. This improves the previous best lower bounds for general branching programs of T=\Omega(n\log (n/S)).Using these ideas, we also give a conceptually simple proof of the relationship between multiparty communication complexity and time-space tradeoffs for oblivious branching programs (previously shown by Babai et al.). This relationship yields time-space tradeoff lower bounds of the form T=\Omega(n\log^2(n/S)) for 1GAP on oblivious branching programs. Since 1GAP has a trivial general branching program of time n and space O(\log n), this provides the first separation between general and oblivious branching program computation.Finally, we develop lower bounds for nearest-neighbor problems involving n data points in a variety of d-dimensional metric spaces. In Yao's general cell-probe model, Borodin et al. showed that time \Omega(d/\log n) is required for nearest-neighbor queries over \{0,1\}^d. We consider slightly more restricted data structure algorithms that are charged for access to individual components of the query.In this model, for certain d-dimensional metric spaces, we prove query time lower bounds \Omega(d\log d) or \Omega(d\sqrt{\log d/\log\log d}), depending on the metric. These follow using a general relationship, suggested by Miltersen et al., between data structure bounds and time-space tradeoff bounds for branching programs. The above bounds use coordinates of size polynomial in d. Over \{0,1\}^d, we prove query time lower bounds of \Omega(d) in general and \Omega(d\log d) when the data structure corresponds to an oblivious branching program."
STOC	Size space tradeoffs for resolution.	Eli Ben-Sasson	2002	We investigate tradeoffs of various basic complexity measures such as size, space, and width. We show examples of formulas that have optimal proofs with respect to any one of these parameters, but optimizing one parameter must cost an increase in the other. These results have implications to the efficiency (or rather, inefficiency) of some commonly used SAT solving heuristics. Our proof relies on a novel connection of the variable space of a proof to the black-white pebbling measure of an underlying graph.
STOC	Hard examples for bounded depth frege.	Eli Ben-Sasson	2002	Hard examples for bounded depth frege.
STOC	Solving convex programs by random walks.	Dimitris Bertsimas,Santosh Vempala	2002	Minimizing a convex function over a convex set in n-dimensional space is a basic, general problem with many interesting special cases. Here, we present a simple new algorithm for convex optimization based on sampling by a random walk. It extends naturally to minimizing quasi-convex functions and to other generalizations.
STOC	Optimal finger search trees in the pointer machine.	Gerth Stølting Brodal,George Lagogiannis,Christos Makris,Athanasios K. Tsakalidis,Kostas Tsichlas	2002	We develop a new finger search tree with worst-case constant update time in the pointer machine (PM) model of computation. This was a major problem in the field of Data Structures and was tantalizingly open for over 20 years, while many attempts by researchers were made to solve it. The result comes as a consequence of the innovative mechanism that guides the rebalancing operations, combined with incremental multiple splitting and fusion techniques over nodes.
STOC	Universally composable two-party and multi-party secure computation.	Ran Canetti,Yehuda Lindell,Rafail Ostrovsky,Amit Sahai	2002	We show how to securely realize any multi-party functionality in a universally composable way, regardless of the number of corrupted participants. That is, we consider a multi-party network with open communication and an adversary that can adaptively corrupt as many parties as it wishes. In this setting, our protocols allow any subset of the parties (with pairs of parties being a special case) to securely realize any desired functionality of their local inputs, and be guaranteed that security is preserved regardless of the activity in the rest of the network. This implies that security is preserved under concurrent composition of an unbounded number of protocol executions, it implies non-malleability with respect to arbitrary protocols, and more. Our constructions are in the common reference string model and make general intractability assumptions.
STOC	Randomness conductors and constant-degree lossless expanders.	Michael R. Capalbo,Omer Reingold,Salil P. Vadhan,Avi Wigderson	2002	"The main concrete result of this paper is the first explicit construction of constant degree ""lossless"" expanders. In these graphs, the expansion factor is almost as large as possible: (1-eps)D, where D is the degree and eps is an arbitrarily small constant. Such graphs are known to have many applications, e.g. in constructing networks that can implement fast distributed, routing algorithms, expander-based linear codes, various storage schemes, and hard tautologies for various proof systems. The best previous explicit constructions gave expansion factor D/2, which is too weak for many applications. The D/2 bound was obtained via the eigenvalue method, and is known that that method cannot give better bounds.The main abstract contribution of this paper is the introduction and initial study of ""randomness conductors,"" a notion which generalizes extractors, expanders, condensers and other similar objects. In all these functions, certain guarantee on the input ""entropy"" is converted to a guarantee on the output ""entropy"". For historical reasons, specific objects used specific guarantees of different flavors (e.g., in expanders entropy means ""support size"", and their property is satisfied whenever input entropy is small. In contrast, in extractors, entropy means ""min-entropy"" and their property is satisfied whenever input entropy is large). We show that the flexibility afforded by the conductor definition leads to interesting combinations of these objects, and to better constructions such as those above.The main technical tool in these constructions is a natural generalization to conductors of the zig-zag graph product, previously defined for expanders and extractors."
STOC	Dynamic subgraph connectivity with geometric applications.	Timothy M. Chan	2002	Inspired by dynamic connectivity applications in computational geometry, we consider a problem we call dynamic subgraph connectivity: design a data structure for an undirected graph $G=(V,E)$ and a subset of vertices $S \subseteq V$ to support insertions/deletions in $S$ and connectivity queries (are two vertices connected?) in the subgraph induced by $S$. We develop the first sublinear, fully dynamic method for this problem for general sparse graphs, using a combination of several simple ideas. Our method requires $\widetilde O(|E|^{4\omega/(3\omega+3)})=O(|E|^{0.94})$ amortized update time, and $\widetilde O(|E|^{1/3})$ query time, after $\widetilde O(|E|^{(5\omega+1)/(3\omega+3)})$ preprocessing time, where &ohgr; is the matrix multiplication exponent and $\widetilde O$ hides polylogarithmic factors.
STOC	A unified analysis of hot video schedulers.	Wun-Tat Chan,Tak Wah Lam,Hing-Fung Ting,Prudence W. H. Wong	2002	In this paper we consider the notion of relative competitive analysis, which is a simple generalization of the conventional competitive analysis and extra-resource analysis for on-line algorithms. We apply this analysis to study on-line schedulers for stream merging in two different video-on-demand (VOD) systems, which are based on two common approaches, namely, piggybacking and skimming. Our new analysis, in its simplest form, reveals a 3-competitive algorithm for stream merging based on skimming as well as piggybacking. This improves all previous results [4, 8]. We also show how to obtain guarantee on the performance improvement based on adding extra resources, and more interestingly, we provide a unified methodology to compare piggybacking and skimming. We believe that our result gives a clue to system designers for choosing desirable configurations.
STOC	Similarity estimation techniques from rounding algorithms.	Moses Charikar	2002	(MATH) A locality sensitive hashing scheme is a distribution on a family $\F$ of hash functions operating on a collection of objects, such that for two objects x,y, Prh&egr;F[h(x) = h(y)] = sim(x,y), where sim(x,y) &egr; [0,1] is some similarity function defined on the collection of objects. Such a scheme leads to a compact representation of objects so that similarity of objects can be estimated from their compact sketches, and also leads to efficient algorithms for approximate nearest neighbor search and clustering. Min-wise independent permutations provide an elegant construction of such a locality sensitive hashing scheme for a collection of subsets with the set similarity measure sim(A,B) = \frac{|A &Pgr; B|}{|A &Pgr B|}.(MATH) We show that rounding algorithms for LPs and SDPs used in the context of approximation algorithms can be viewed as locality sensitive hashing schemes for several interesting collections of objects. Based on this insight, we construct new locality sensitive hashing schemes for:<ol>A collection of vectors with the distance between &rarr; \over u and &rarr; \over v measured by &Oslash;(&rarr; \over u, &rarr; \over v)/&pgr;, where &Oslash;(&rarr; \over u, &rarr; \over v) is the angle between &rarr; \over u) and &rarr; \over v). This yields a sketching scheme for estimating the cosine similarity measure between two vectors, as well as a simple alternative to minwise independent permutations for estimating set similarity.A collection of distributions on n points in a metric space, with distance between distributions measured by the Earth Mover Distance (EMD), (a popular distance measure in graphics and vision). Our hash functions map distributions to points in the metric space such that, for distributions P and Q, EMD(P,Q) &xie; Eh&egr;\F [d(h(P),h(Q))] &xie; O(log n log log n). EMD(P, Q).</ol>.
STOC	Approximating the smallest grammar: Kolmogorov complexity in natural models.	Moses Charikar,Eric Lehman,Ding Liu,Rina Panigrahy,Manoj Prabhakaran,April Rasala,Amit Sahai,Abhi Shelat	2002	"We consider the problem of finding the smallest context-free grammar that generates exactly one given string of length n. The size of this grammar is of theoretical interest as an efficiently computable variant of Kolmogorov complexity. The problem is of practical importance in areas such as data compression and pattern extraction.The smallest grammar is known to be hard to approximate to within a constant factor, and an o(logn/log logn) approximation would require progress on a long-standing algebraic problem [10]. Previously, the best proved approximation ratio was O(n1/2) for the Bisection algorithm [8]. Our main result is an exponential improvement of this ratio; we give an O(log (n/g*)) approximation algorithm, where g* is the size of the smallest grammar.We then consider other computable variants of Kolomogorov complexity. In particular we give an O(log2 n) approximation for the smallest non-deterministic finite automaton with advice that produces a given string. We also apply our techniques to ""advice-grammars"" and ""edit-grammars"", two other natural models of string complexity."
STOC	Approximation schemes for preemptive weighted flow time.	Chandra Chekuri,Sanjeev Khanna	2002	(MATH) We present the first approximation schemes for minimizing weighted flow time on a single machine with preemption. Our first result is an algorithm that computes a (1+&egr;)-approximate solution for any instance of weighted flow time in O(nO(ln W ln P/&egr;3)) time; here P is the ratio of maximum job processing time to minimum job processing time, and W is the ratio of maximum job weight to minimum job weight. This result directly gives a quasi-PTAS for weighted flow time when P and W are poly-bounded, and a PTAS when they are both O(1). We strengthen the former result to show that in order to get a quasi- PTAS it suffices to have just one of P and W to be poly-bounded. Our result provides strong evidence to the hypothesis that the weighted flow time problem has a PTAS. We note that the problem is strongly NP-hard even when P and W are O(1). We next consider two important special cases of weighted flow time, namely, when P is O(1) and W is arbitrary, and when the weight of a job is inverse of its processing time referred to as the stretch metric. For both of the above special cases we obtain a (1+&egr;)-approximation for any &egr; &rho; 0 by using a randomized partitioning scheme to reduce an arbitrary instance to several instances all of which have P and W bounded by a constant that depends only on &egr;.
STOC	Approximation algorithms for minimum-cost k-vertex connected subgraphs.	Joseph Cheriyan,Santosh Vempala,Adrian Vetta	2002	"(MATH) We present two new algorithms for the problem of finding a minimum-cost k-vertex connected spanning subgraph. The first algorithm works on undirected graphs with at least 6k2 vertices and achieves an approximation factor of 6 times the kth harmonic number, which is $O(\log k)$. The second algorithm works on directed and undirected graphs. It gives an $O(\sqrt{ n /\keps})$-approximation algorithm for any $\keps > 0$ and $k \le (1-\keps)n$. The latter algorithm also extends to other problems in network design with vertex connectivity requirements. Our main tools are setpair relaxations, a theorem of Mader's (in the undirected case) and iterative rounding (general case)."
STOC	Clifford algebras and approximating the permanent.	Steve Chien,Lars Eilstrup Rasmussen,Alistair Sinclair	2002	We study approximation algorithms for the permanent of an n × n (0,1) matrix A based on the following simple idea: obtain a random matrix B by replacing each 1-entry of A independently by ±e, where e is a random basis element of a suitable algebra; then output |det(B)|2. This estimator is always unbiased, but it may have exponentially large variance. In our first main result we show that, if we take the algebra to be a Clifford algebra of dimension polynomial in n, then we get an estimator with small variance. Hence, only a constant number of trials suffices to estimate the permanent to good accuracy. The idea of using Clifford algebras is a natural extension of earlier work by Godsil and Gutman, Karmarkar et al., and Barvinok, who used the real numbers, complex numbers and quaternions, respectively. The above result implies that, in principle, this approach gives a fully-polynomial randomized approximation scheme for the permanent, provided |det(B)|2 can be efficiently computed in the Clifford algebras. Since these algebras are noncommutative it is not clear how to do this. However, our second main result shows how to compute in polynomial time an estimator with the same mean and variance over the 4-dimensional algebra (which is the quaternions, and is non-commutative); in addition to providing some hope that the computations can be performed in higher dimensions, this quaternion algorithm provides an exponential improvement in the variance over that of the 2-dimensional complex version studied by Karmarkar et al.
STOC	Verifying candidate matches in sparse and wildcard matching.	Richard Cole,Ramesh Hariharan	2002	(MATH) This paper obtains the following results on pattern matching problems in which the text has length n and the pattern has length mAn O(nlog m) time deterministic algorithm for the String Matching with Wildcards problems, even when the alphabet is large.An O(klog2 m) time Las Vegas algorithm for the Sparse String Matching with Wildcards problem, where k&laquo;n is the number of non-zeros in the text. We also give Las Vegas algorithms for the higher dimensional version of this problem.As an application of the above, an O(nlog2 m) time Las Vegas algorithm for the Subset Matching and Tree Pattern Matching problems, and a Las Vegas algorithm for the Geometric Pattern Matching problem.Finally, an O(nlog2 m) time deterministic algorithm for Subset Matching and Tree Pattern Matching..The crucial new idea underlying the first three results above is that of confirming matches by convolving vectors obtained by coding characters in the alphabet with non-boolean (i.e., rational or even complex) entries; in contrast, almost all previous pattern matching algorithms consider only boolean codes for the alphabet. The crucial new idea underlying the fourth result is a simpler method of shifting characters which ensures that each character occurs as a singleton in some shift.
STOC	Crawling on web graphs.	Colin Cooper,Alan M. Frieze	2002	Crawling on web graphs.
STOC	Secure multi-party quantum computation.	Claude Crépeau,Daniel Gottesman,Adam Smith	2002	Secure multi-party computing, also called secure function evaluation, has been extensively studied in classical cryptography. We consider the extension of this task to computation with quantum inputs and circuits. Our protocols are information-theoretically secure, i.e. no assumptions are made on the computational power of the adversary. For the weaker task of verifiable quantum secret sharing, we give a protocol which tolerates any t &xi; n/4 cheating parties (out of n). This is shown to be optimal. We use this new tool to show how to perform any multi-party quantum computation as long as the number of dishonest players is less than n/6.
STOC	A polynomial-time algorithm to approximately count contingency tables when the number of rows is constant.	Mary Cryan,Martin E. Dyer	2002	"We consider the problem of counting the number of contingency tables with given row and column sums. This problem is known to be #P-complete, even when there are only two rows (Random Structures Algorithms 10(4) (1997) 487). In this paper we present the first fully polynomial randomized approximation scheme for counting contingency tables when the number of rows is constant. A novel feature of our algorithm is that it is a hybrid of an exact counting technique with an approximation algorithm, giving two distinct phases. In the first, the columns are partitioned into ""small"" and ""large"". We show that the number of contingency tables can be expressed as the weighted sum of a polynomial number of new instances of the problem, where each instance consists of some new row sums and the original large column sums. In the second phase, we show how to approximately count contingency tables when all the column sums are large. In this case, we show that the solution lies in approximating the volume of a single convex body, a problem which is known to be solvable in polynomial time (J. ACM 38 (1) (1991) 1)."
STOC	Selfish traffic allocation for server farms.	Artur Czumaj,Piotr Krysta,Berthold Vöcking	2002	We investigate the price of selfish routing in non-cooperative networks in terms of the coordination and bicriteria ratios in the recently introduced game theoretic network model of Koutsoupias and Papadimitriou. We present the first thorough study of this model for general, monotone families of cost functions and for cost functionsm from Queueing Theory. Our main results can be summarized as follows.We give a precise characterization of cost functions having a bounded/unbounded coordination ratio. For example, cost functions that describe the expected delay in queueing systems have an unbounded coordination ratio.We show that an unbounded coordination ratio implies additionally an extremely high performance degradation under bicriteria measures. We demonstrate that the price of selfish routing can be as high as a bandwidth degradation by a factor that is linear in the network size.We separate the game theoretic (integral) allocation model from the (fractional) flow model by demonstrating that even a very small, in fact negligible, amount of integrality can lead to a dramatic performance degradation.We unify recent results on selfish routing under different objectives by showing that an unbounded coordination ratio under the min-max objective implies an unbounded coordination ratio under the average-cost (or total-latency) objective and vice versa..Our special focus lies on cost functions describing the behavior of Web servers that can open only a limited number of TCP connections. In particular, we compare the performance of queueing systems that serve all incoming requests with servers that reject requests in case of overload.From the result presented in this paper we conclude that queuing systems without rejection cannot give any reasonable guarantee on the expected delay of requests under selfish routing even when the injected load is far away from the capacity of the system. In contrast, Web server farms that are allowed to reject requests can guarantee a high quality of service for every individual request stream even under relatively high injection rates.
STOC	On the complexity of equilibria.	Xiaotie Deng,Christos H. Papadimitriou,Shmuel Safra	2002	We prove complexity, approximability, and inapproximability results for the problem of finding an exchange equilibrium in markets with indivisible (integer) goods, most notably a polynomial-time algorithm that approximates the market equilibrium arbitrarily closely when the number of goods is bounded and the utilities are linear. We also show a communication complexity lower bound, implying that the ideal informational economy of a market with unique individual optima is unattainable in general.
STOC	The importance of being biased.	Irit Dinur,Shmuel Safra	2002	(MATH) We show that the Minimum Vertex Cover problem is NP-hard to approximate to within any factor smaller than $10\sqrt{5}-21 \approx 1.36067$, improving on the previously known hardness result for a $\frac{7}{6}$ factor.
STOC	Competitive recommendation systems.	Petros Drineas,Iordanis Kerenidis,Prabhakar Raghavan	2002	A recommendation system tracks past purchases of a group of users to make product recommendations to individual members of the group. In this paper we present a notion of competitive recommendation systems, building on recent theoretical work on this subject. We reduce the problem of achieving competitiveness to a problem in matrix reconstruction. We then present a matrix reconstruction scheme that is competitive: it requires a small overhead in the number of users and products to be sampled, delivering in the process a net utility that closely approximates the best possible with full knowledge of all user-product preferences.
STOC	2-round zero knowledge and proof auditors.	Cynthia Dwork,Larry J. Stockmeyer	2002	We construct 2-round (ie, 2-message), public-coin, black-box (concurrent) zero-knowledge proof systems and arguments for any language in NP under the assumption that the prover is resource-bounded during the execution of the protocol.
STOC	Tight security proofs for the bounded-storage model.	Stefan Dziembowski,Ueli M. Maurer	2002	"(MATH) In the bounded-storage model for information-theoretically secure encryption and key-agreement one can prove the security of a cipher based on the sole assumption that the adversary's storage capacity is bounded, say by s bits, even if her computational power is unlimited. Assume that a random t-bit string R is either publicly available (e.g. the signal of a deep space radio source) or broadcast by one of the legitimate parties. If s$xi;t, the adversary can store only partial information about R. The legitimate sender Alice and receiver Bob, sharing a short secret key K initially, can therefore potentially generate a very long n-bit one-time pad X with n&raquo;|K| about which the adversary has essentially no information, thus at first glance apparently contradicting Shannon's bound on the key size of a perfect cipher.All previous results in the bounded-storage model were partial or far from optimal, for one of the following reasons: either the secret key K had in fact to be longer than the derived one-time pad, or t had to be extremely large (t&rho;ns), or the adversary was assumed to be able to store only actual bits of R rather than arbitrary s bits of information about R, or the adversary could obtain a non-negligible amount of information about X.In this paper we prove the first non-restricted security result in the bounded-storage model, exploiting the full potential of the model: K is short, X is very long (e.g. gigabytes), t needs to be only moderately larger than s, and the security proof is optimally strong. In fact, we prove that s/t can be arbitrarily close to 1 and hence the storage bound is essentially optimal."
STOC	New results on monotone dualization and generating hypergraph transversals.	Thomas Eiter,Georg Gottlob,Kazuhisa Makino	2002	We consider the problem of dualizing a monotone CNF (equivalently, computing all minimal transversals of a hypergraph) whose associated decision problem is a prominent open problem in NP-completeness. We present a number of new polynomial time, respectively, output-polynomial time results for significant cases, which largely advance the tractability frontier and improve on previous results. Furthermore, we show that duality of two monotone CNFs can be disproved with limited nondeterminism. More precisely, this is feasible in polynomial time with O(log2 n/\log log n) suitably guessed bits. This result sheds new light on the complexity of this important problem.
STOC	Combinatorial logarithmic approximation algorithm for directed telephone broadcast problem.	Michael Elkin,Guy Kortsarz	2002	(MATH) Consider a synchronous network of processors, modeled by directed or undirected graph G = (V,E), in which on each round every processor is allowed to choose one of its neighbors and to send him a message. Given a processor s &egr; V, and a subset T &sube; V of processors, the telephone multicast problem requires to compute the shortest schedule (in terms of the number of rounds) that delivers a message from s to all the processors of T. The particular case T = V is called telephone broadcast problem.These problems have multiple applications in distributed computing. Several approximation algorithms with polylogarithmic ratio, including one with logarithmic ratio, for the undirected variants of these problems are known. However, all these algorithms involve solving large linear programs. Devising a polylogarithmic approximation algorithm for the directed variants of these problems is anopen problem, posed in [15].We devise a combinatorial logarithmic approximation algorithm for these problems, that applies also for the directed broadcast problem. Our algorithm has significantly smaller running time, and seems to reveal more information about the combinatorial structure of the solution, than the previous algorithms, that are based on linear programming.(MATH) We also improve the lower bounds on the approximation threshold of these problems. Both problems are known to be 3/2-inapproximable. For the undirected (resp., directed) broadcast problem we show that it is NP-hard (resp., impossible unless $NP &supe; DTIME(nO(log n))) to approximate it within a ratio of 3 &mdash;&egr; for any &egr; &rho; 0 (resp., &omega;(\sqrt log n)).Finally, we study the radio broadcast problem. Its setting is similar to the telephone broadcast problem, but in every round every processor may either send a message to all its neighbors or may not send it at all. A processor is informed in a certain round if and only if it receives a message from precisely one neighbor.(MATH) This problem was known to admit O(log2 n)-approximation algorithm, but no hardness of approximation was known. In this paper we show that the problem is &omega;(log n)-inapproximable unless NP &sube; BPTIME(nlog log n}).
STOC	Relations between average case complexity and approximation complexity.	Uriel Feige	2002	We investigate relations between average case complexity and the complexity of approximation. Under the assumption that refuting 3SAT is hard on average on a natural distribution, we derive new hardness of approximation results.
STOC	Competitive generalized auctions.	Amos Fiat,Andrew V. Goldberg,Jason D. Hartline,Anna R. Karlin	2002	"We describe mechanisms for auctions that are simultaneously truthful (alternately known as strategy-proof or incentive compatible) and guarantee high ""net"" profit. We make use of appropriate variants of competitive analysis of algorithms in designing and analyzing our mechanisms. Thus, we do not require any probabilistic assumptions on bids.We present two new concepts regarding auctions, that of a cancellable auction and that of a generalized auction. We use cancellable auctions in the design of generalized auctions, but they are of independent interest as well. Cancellable auctions have the property that if the revenue collected does not meet certain predetermined criteria, then the auction can be cancelled and the resulting auction is still truthful. The trivial approach (run a truthful auction and cancel if needed) yields an auction that is not necessarily truthfu.Generalized auctions can be used to model many problems previously considered in the literature, as well as numerous new problems. In particular, we give the first truthful profit-maximizing auctions for problems such as conditional financing and multicast."
STOC	Monotonicity testing over general poset domains.	Eldar Fischer,Eric Lehman,Ilan Newman,Sofya Raskhodnikova,Ronitt Rubinfeld,Alex Samorodnitsky	2002	"The field of property testing studies algorithms that distinguish, using a small number of queries, between inputs which satisfy a given property, and those that are `far' from satisfying the property. Testing properties that are defined in terms of monotonicity has been extensively investigated, primarily in the context of the monotonicity of a sequence of integers, or the monotonicity of a function over the n-dimensional hypercube {1,&ldots;,m}n. These works resulted in monotonicity testers whose query complexity is at most polylogarithmic in the size of the domain.We show that in its most general setting, testing that Boolean functions are close to monotone is equivalent, with respect to the number of required queries, to several other testing problems in logic and graph theory. These problems include: testing that a Boolean assignment of variables is close to an assignment that satisfies a specific 2-CNF formula, testing that a set of vertices is close to one that is a vertex cover of a specific graph, and testing that a set of vertices is close to a clique.We then investigate the query complexity of monotonicity testing of both Boolean and integer functions over general partial orders. We give algorithms and lower bounds for the general problem, as well as for some interesting special cases. In proving a general lower bound, we construct graphs with combinatorial properties that may be of independent interest."
STOC	Clairvoyant scheduling of random walks.	Péter Gács	2002	Two infinite walks on the same finite graph are called compatible if it is possible to introduce delays into them in such a way that they never collide. About 10 years ago, Peter Winkler asked the question: for which graphs are two independent walks compatible with positive probability. Up to now, no such graphs were found. We show in this paper that large complete graphs have this property. The question is equivalent to a certain dependent percolation with a power-law behavior: the probability that the origin is blocked at distance n but not closer decreases only polynomially fast and not, as usual, exponentially.
STOC	Fast, small-space algorithms for approximate histogram maintenance.	Anna C. Gilbert,Sudipto Guha,Piotr Indyk,Yannis Kotidis,S. Muthukrishnan,Martin Strauss	2002	"(MATH) A vector A of length N is defined implicitly, via a stream of updates of the form ""add 5 to A3."" We give a sketching algorithm, that constructs a small sketch from the stream of updates, and a reconstruction algorithm, that produces a B-bucket piecewise-constant representation (histogram) H for A from the sketch, such that ||A&mdash;H||&xie;(1+&egr;)||A&mdash;Hopt|&#124, where the error ||A&mdash;H|| is either $\ell_1$ (absolute) or $\ell_2$ (root-mean-square) error. The time to process a single update, time to reconstruct the histogram, and size of the sketch are each bounded by poly(B,log(N),log||A,1/&egr;. Our result is obtained in two steps. First we obtain what we call a robust histogram approximation for A, a histogram such that adding a small number of buckets does not help improve the representation quality significantly. From the robust histogram, we cull a histogram of desired accruacy and B buckets in the second step. This technique also provides similar results for Haar wavelet representations, under $\ell_2$ error. Our results have applications in summarizing data distributions fast and succinctly even in distributed settings."
STOC	Near-optimal sparse fourier representations via sampling.	Anna C. Gilbert,Sudipto Guha,Piotr Indyk,S. Muthukrishnan,Martin Strauss	2002	(MATH) We give an algorithm for finding a Fourier representation R of B terms for a given discrete signal signal A of length N, such that $\|\signal-\repn\|_2^2$ is within the factor (1 +&egr;) of best possible $\|\signal-\repn_\opt\|_2^2$. Our algorithm can access A by reading its values on a sample set T &sube;[0,N), chosen randomly from a (non-product) distribution of our choice, independent of A. That is, we sample non-adaptively. The total time cost of the algorithm is polynomial in B log(N)log(M)&egr; (where M is the ratio of largest to smallest numerical quantity encountered), which implies a similar bound for the number of samples.
STOC	The complexity of choosing an H-colouring (nearly) uniformly at random.	Leslie Ann Goldberg,Steven Kelk,Mike Paterson	2002	"Cooper, Dyer, and Frieze [J. Algorithms, 39 (2001), pp. 117--134] studied the problem of sampling H-colorings (nearly) uniformly at random. Special cases of this problem include sampling colorings and independent sets and sampling from statistical physics models such as the Widom--Rowlinson model, the Beach model, the Potts model and the hard-core lattice gas model. Cooper et al. considered the family of ""cautious"" ergodic Markov chains with uniform stationary distribution and showed that, for every fixed connected ""nontrivial "" graph H, every such chain mixes slowly. In this paper, we give a complexity result for the problem. Namely, we show that for any fixed graph H with no trivial components, there is unlikely to be any polynomial almost uniform sampler (PAUS) for H-colorings. We show that if there were a PAUS for the H-coloring problem, there would also be a PAUS for sampling independent sets in bipartite graphs, and, by the self-reducibility of the latter problem, there would be a fully polynomial randomized approximation scheme (FPRAS) for #BIS---the problem of counting independent sets in bipartite graphs. Dyer, Goldberg, Greenhill, and Jerrum have shown that #BIS is complete in a certain logically defined complexity class. Thus, a PAUS for sampling H-colorings would give an FPRAS for the entire complexity class. In order to achieve our result we introduce the new notion of sampling-preserving reduction which seems to be more useful in certain settings than approximation-preserving reduction."
STOC	Concurrent zero-knowledge with timing, revisited.	Oded Goldreich	2002	Following Dwork, Naor, and Sahai (30th STOC, 1998), we consider concurrent execution of protocols in a semi-synchronized network. Specifically, we assume that each party holds a local clock such that a constant bound on the relative rates of these clocks is a-priori known, and consider protocols that employ time-driven operations (i.e., time-out in-coming messages and delay out-going messages).We show that the constant-round zero-knowledge proof for NP of Goldreich and Kahan (Jour. of Crypto., 1996) preserves its security when polynomially-many independent copies are executed concurrently under the above timing model.We stress that our main result establishes zero-knowledge of interactive proofs, whereas the results of Dwork et al are either for zero-knowledge arguments or for a weak notion of zero-knowledge (called &egr;-knowledge) proofs.Our analysis identifies two extreme schedulings of concurrent executions under the above timing model: the first is the case of parallel execution of polynomially-many copies, and the second is of concurrent execution of polynomially-many copies such the number of copies that are simultaneously active at any time is bounded by a constant (i.e., bounded simultaneity). Dealing with each of these extreme cases is of independent interest, and the general result (regarding concurrent executions under the timing model) is obtained by combining the two treatments.
STOC	Huffman coding with unequal letter costs.	Mordecai J. Golin,Claire Kenyon,Neal E. Young	2002	(MATH) In the standard Huffman coding problem, one is given a set of words and for each word a positive frequency. The goal is to encode each word w as a codeword c(w) over a given alphabet. The encoding must be prefix free (no codeword is a prefix of any other) and should minimize the weighted average codeword size &Sgr;w freq w, &124;c(w)&124;. The problem has a well-known polynomial-time algorithm due to Huffman [15].Here we consider the generalization in which the letters of the encoding alphabet may have non-uniform lengths. The goal is to minimize the weighted average codeword length &Sgr;w freq (w) cost(c(w)), where cost s is the sum of the (possibly non-uniform) lengths of the letters in s. Despite much previous work, the problem is not known to be NP-hard, nor was it previously known to have a polynomial-time approximation algorithm. Here we describe a polynomial-time approximation scheme (PTAS) for the problem.
STOC	Limits to list decodability of linear codes.	Venkatesan Guruswami	2002	"We consider the problem of the best possible relation between the list decodability of a binary linear code and its minimum distance. We prove, under a widely-believed number-theoretic conjecture, that the classical ""Johnson bound"" gives, in general, the best possible relation between the list decoding radius of a code and its minimum distance. The analogous result is known to hold by a folklore random coding argument for the case of non-linear codes, but the linear case is more subtle and has remained open.We prove our result by exhibiting an infinite family of binary linear codes of ""large"" minimum distance with a super-polynomial number (in blocklength) of codewords all within a Hamming ball of radius close to the Johnson bound. Even the existence of codes with a super-polynomial number of codewords in a ball of radius bounded away from the minimum distance (let alone radius close to the Johnson bound) was open prior to our work. We also unconditionally prove the ""tightness"" of the Johnson bound for decoding with list size that is an arbitrarily large constant."
STOC	Near-optimal linear-time codes for unique decoding and new list-decodable codes over smaller alphabets.	Venkatesan Guruswami,Piotr Indyk	2002	"We present an explicit construction of linear-time encodable and decodable codes of rate r which can correct a fraction (1&mdash:r&egr;)/2 of errors over an alphabet of constant size depending only on &egr;, for every 0 < r < 1 and arbitrarily small &egr;> 0. The error-correction performance of these codes is optimal as seen by the Singleton bound (these are ""near-MDS"" codes). Such near-MDS linear-time codes were known for the decoding from erasures [2]; our construction generalizes this to handle errors as well. Concatenating these codes with good, constant-sized binary codes gives a construction of linear-time binary codes which meet the so-called ""Zyablov bound"". In a nutshell, our results match the performance of the previously known explicit constructions of codes that had polynomial time encoding and decoding, but in addition have linear time encoding and decoding algorithms.We also obtain some results for list decoding targeted at the situation when the fraction of errors is very large, namely (1&mdash;&egr;) for an arbitrarily small constant &egr; > 0. The previously known constructions of such codes of good rate over constant-sized alphabets either used algebraic-geometric codes and thus suffered from complicated constructions and slow decoding, or as in the recent work of the authors [9], had fast encoding/decoding, but suffered from an alphabet size that was exponential in 1/&egr;. We present two constructions of such codes with rate close to &OHgr;(&egr;2) over an alphabet of size quasi-polynomial in 1/&egr;. One of the constructions, at the expense of a slight worsening of the rate, can achieve an alphabet size which is polynomial in 1/&egr;. It also yields constructions of codes for list decoding from erasures which achieve new trade-offs. In particular, we construct codes of rate close to the optimal &OHgr;(&egr;) rate which can be efficiently list decoded from a fraction (1&mdash;&egr;) of erasures."
STOC	"Polynomial-time quantum algorithms for Pell's equation and the principal ideal problem."	Sean Hallgren	2002	"We give polynomial-time quantum algorithms for three problems from computational algebraic number theory. The first is Pell's equation. Given a positive nonsquare integer d, Pell's equation is x2 &minus; dy2 &equals; 1 and the goal is to find its integer solutions. Factoring integers reduces to finding integer solutions of Pell's equation, but a reduction in the other direction is not known and appears more difficult. The second problem we solve is the principal ideal problem in real quadratic number fields. This problem, which is at least as hard as solving Pell's equation, is the one-way function underlying the Buchmann--Williams key exchange system, which is therefore broken by our quantum algorithm. Finally, assuming the generalized Riemann hypothesis, this algorithm can be used to compute the class group of a real quadratic number field."
STOC	On the advantage over a random assignment.	Johan Håstad,Srinivasan Venkatesh	2002	We initiate the study of a new measure of approximation. This measure compares the performance of an approximation algorithm to the random assignment algorithm. This is a useful measure for optimization problems where the random assignment algorithm is known to give essentially the best possible polynomial time approximation. In this paper, we focus on this measure for the optimization problems Max-Lin-2 in which we need to maximize the number of satisfied linear equations in a system of linear equations modulo 2, and Max-k-Lin-2, a special case of the above problem in which each equation has at most k variables. The main techniques we use, in our approximation algorithms and inapproximability results for this measure, are from Fourier analysis and derandomization.
STOC	Exact learning of DNF formulas using DNF hypotheses.	Lisa Hellerstein,Vijay Raghavan	2002	We show the following: (a) For any @e>0, log^(^3^+^@e^)n-term DNF cannot be polynomial-query learned with membership and strongly proper equivalence queries. (b) For sufficiently large t, t-term DNF formulas cannot be polynomial-query learned with membership and equivalence queries that use t^1^+^@e-term DNF formulas as hypotheses, for some @e
STOC	Vertex cover on 4-regular hyper-graphs is hard to approximate within 2-epsilon.	Jonas Holmerin	2002	Vertex cover on 4-regular hyper-graphs is hard to approximate within 2-epsilon.
STOC	Learnability beyond AC0.	Jeffrey C. Jackson,Adam Klivans,Rocco A. Servedio	2002	Learnability beyond AC0.
STOC	A new greedy approach for facility location problems.	Kamal Jain,Mohammad Mahdian,Amin Saberi	2002	We present a simple and natural greedy algorithm for the metric uncapacitated facility location problem achieving an approximation guarantee of 1.61. We use this algorithm to find better approximation algorithms for the capacitated facility location problem with soft capacities and for a common generalization of the k-median and facility location problems. We also prove a lower bound of 1+2/e on the approximability of the k-median problem. At the end, we present a discussion about the techniques we have used in the analysis of our algorithm, including a computer-aided method for proving bounds on the approximation factor.
STOC	Equitable cost allocations via primal-dual-type algorithms.	Kamal Jain,Vijay V. Vazirani	2002	Perhaps the strongest notion of truth-revealing in a cost sharing method is group strategyproofness. However, matters are not so clear-cut on fairness, and many different, sometimes even conflicting, notions of fairness have been proposed which have relevance in different situations. We present a large class of group strategyproof cost sharing methods, for submodular cost functions, satisfying a wide range of fairness criteria, thereby allowing the service provider to choose a method that best satisfies the notion of fairness that is most relevant to her application. Our class includes the Dutta-Ray egalitarian method as a special case. It also includes a new cost sharing method, which we call the opportunity egalitarian method.
STOC	Meldable heaps and boolean union-find.	Haim Kaplan,Nira Shafrir,Robert Endre Tarjan	2002	In the classical meldable heap data type we maintain an item-disjoint collection of heaps under the operations find-min, insert, delete, decrease-key, and meld. In the usual definition decrease-key and delete get the item and the heap containing it as parameters. We consider the modified problem where decrease-key and delete get only the item but not the heap containing it. We show that for this problem one of the operations find-min, decrease-key, or meld must take non-constant time. This is in contrast with the original data type in which data structures supporting all these three operations in constant time are known (both in an amortized and a worst-case setting).To establish our results for meldable heaps we consider a weaker version of the union-find problem that is of independent interest, which we call Boolean union-find. In the Boolean union-find problem the find operation is a binary predicate that gets an item x and a set A and answers positively if and only if &khgr; &egr; A. We prove that the lower bounds which hold for union-find in the cell probe model hold for Boolean union-find as well.We also suggest new heap data structures implementing the modified meldable heap data type that are based on redundant binary counters. Our data structures have good worst-case bounds. The best of our data structures matches the worst-case lower bounds which we establish for the problem. The simplest of our data structures is an interesting generalization of binomial queues.
STOC	Random sampling in residual graphs.	David R. Karger,Matthew S. Levine	2002	Consider an n-vertex, m-edge, undirected graph with maximum flow value v. We give a new &Otilde;(m+nv)-time maximum flow algorithm based on finding augmenting paths in random samples of the edges of residual graphs. After assigning certain special sampling probabilities to edges in &Otilde;(m) time, our algorithm is very simple: repeatedly find an augmenting path in a random sample of edges from the residual graph.
STOC	Finding nearest neighbors in growth-restricted metrics.	David R. Karger,Matthias Ruhl	2002	Most research on nearest neighbor algorithms in the literature has been focused on the Euclidean case. In many practical search problems however, the underlying metric is non-Euclidean. Nearest neighbor algorithms for general metric spaces are quite weak, which motivates a search for other classes of metric spaces that can be tractably searched.In this paper, we develop an efficient dynamic data structure for nearest neighbor queries in growth-constrained metrics. These metrics satisfy the property that for any point q and number r the ratio between numbers of points in balls of radius 2r and r is bounded by a constant. Spaces of this kind may occur in networking applications, such as the Internet or Peer-to-peer networks, and vector quantization applications, where feature vectors fall into low-dimensional manifolds within high-dimensional vector spaces.
STOC	Hardness results for approximate hypergraph coloring.	Subhash Khot	2002	"(MATH) Guruswami et al [6] show the hardness of coloring 2-colorable 4-uniform hypergraphs on n vertices with &omega;(log log n \over log log log n}) colors assuming NP $\not\subseteq$ DTIME(nO log log n)). We obtain a stronger hardness result for approximate coloring of p-colorable 4-uniform hypergraphs for any fixed integer p &rhoe; 7. We prove that there exists an absolute constant c &rho; 0 such that for every fixed integer p &rhoe; 7, it is hard to color a p-colorable 4-uniform hypergraph with (log n)cp colors assuming NP $\not \subseteq$ DTIME(2(log n)O(1)).This work builds on the idea of ""covering complexity"" of probabilistically checkable proof systems (PCPs) developed in [6] and we introduce some new techniques as well. Firstly, we define a new code which we call the Split Code. This is a variation of the Long Code, but much shorter in length and it reduces the proof size significantly. Split Codes enable us to exploit the special structure of the ""outer PCP verifier"" constructed via Raz's Parallel Repetition Theorem [18]. Secondly, we make a novel use of the Split Codes over the domain GF(p) for a prime p. Working over non-boolean domain in fact makes our proof technically simpler than the proof of Guruswami at al [6]."
STOC	On the power of unique 2-prover 1-round games.	Subhash Khot	2002	"A 2-prover game is called unique if the answer of one prover uniquely determines the answer of the second prover and vice versa (we implicitly assume games to be one round games). The value of a 2-prover game is the maximum acceptance probability of the verifier over all the prover strategies. We make the following conjecture regarding the power of unique 2-prover games, which we call the Unique Games Conjecture: The Unique Games Conjecture: For arbitrarily small constants \zeta, \delta > 0, there exists a constant k = k(\zeta,\delta) such that it is NP-hard to determine whether a unique 2-prover game with answers from a domain of size k has value at least 1-\zeta or at most \delta.We show that a positive resolution of this conjecture would imply the following hardness results: (1) For any 1/2 0, it is NP-hard to distinguish between the instances of the problem 2-Linear-Equations mod 2 where either there exists an assignment that satisfies 1-\epsilon fraction of equations or no assignment can satisfy more than 1-\epsilon^t fraction of equations. As a corollary of this result, it is NP-hard to approximate the Min-2CNF-deletion problem within any constant factor. (2) For the constraint satisfaction problem where every constraint is the predicate Not-all-equal(a,b,c) with a,b,c being ternary variables, it is NP-hard to distinguish between the instances where either there exists an assignment that satisfies 1-\epsilon fraction of the constraints or no assignment satisfies more than 8/9 + \epsilon fraction of the constraints for an arbitrarily small constant \epsilon > 0. This problem is relavant for showing hardness of coloring 3-colorable 3-uniform hypergraphs. We also show that a variation of the Unique Games Conjecture implies that for arbitrarily small constant \delta > 0, it is hard to find an independent set of size (\delta n) in a graph that is guaranteed to have an independent set of size \Omega(n).The main idea in all the above results is to use the 2-prover game given by the Unique Games Conjecture as an ""outer verifier"" and build new probabilistically checkable proof systems (PCPs) on top of it. The uniqueness property plays a crucial role in the analysis of these PCPs.In light of such interesting consequences, we think it is an important open problem to prove (or disprove) the Unique Games Conjecture. We also present a semi-definite programming based algorithm for finding reasonable prover strategies for a unique 2-prover game. Given a unique 2-prover game with value 1-\zeta and answers from a domain of size k, this algorithm finds prover strategies that make the verifier accept with probability 1-O(k^2 \zeta^{1/5} \sqrt{\log(1/\zeta)}). This result shows that the domain size k = k(\zeta, \delta) must be sufficiently large if the Unique Games Conjecture is true."
STOC	Lower bounds & competitive algorithms for online scheduling of unit-size tasks to related machines.	Spyros C. Kontogiannis	2002	In this paper we study the problem of assigning unit-size tasks to related machines when only limited online information is provided to each task. This is a general framework whose special cases are the classical multiple-choice games for the assignment of unit-size tasks to identical machines. The latter case was the subject of intensive research for the last decade. The problem is intriguing in the sense that the natural extensions of the greedy oblivious schedulers, which are known to achieve near-optimal performance in the case of identical machines, are proved to perform quite poorly in the case of the related machines.(MATH) In this work we present a rather surprising lower bound stating that any oblivious scheduler that assigns an arbitrary number of tasks to $n$ related machines would need $\Omega\left(\frac{\log n}{\l2 n}\right)$ polls of machine loads per task, in order to achieve a constant competitive ratio versus the optimum offline assignment of the same input sequence to these machines. On the other hand, we prove that the missing information for an oblivious scheduler to perform almost optimally, is the amount of tasks to be inserted into the system. In particular, we provide an oblivious scheduler that only uses $\O(\l2 n)$ polls, along with the additional information of the size of the input sequence, in order to achieve a constant competitive ratio vs. the optimum offline assignment. The philosophy of this scheduler is based on an interesting exploitation of the slowfit concept ([1, 5, 3]; for a survey see [6, 9, 16]) for the assignment of the tasks to the related machines despite the restrictions on the provided online information, in combination with a layered induction argument for bounding the tails of the number of tasks passing from slower to faster machines. We finally use this oblivious scheduler as the core of an adaptive scheduler that does not demand the knowledge of the input sequence and yet achieves almost the same performance.
STOC	On the composition of authenticated byzantine agreement.	Yehuda Lindell,Anna Lysyanskaya,Tal Rabin	2002	A fundamental problem of distributed computing is that of simulating a secure broadcast channel, within the setting of a point-to-point network. This problem is known as Byzantine Agreement (or Generals) and has been the focus of much research. Lamport et al. [1982] showed that in order to achieve Byzantine Agreement in the plain model, more than two thirds of the participating parties must be honest. They further showed that by augmenting the network with a public-key infrastructure for digital signatures, it is possible to obtain protocols that are secure for any number of corrupted parties. The problem in this augmented model is called &ldquo;authenticated Byzantine Agreement&rdquo;.In this article, we consider the question of concurrent, parallel and sequential composition of authenticated Byzantine Agreement protocols with a single common setup. We present surprising impossibility results showing that:(1) Authenticated Byzantine Agreement protocols that remain secure under parallel or concurrent composition (even for just two executions) and tolerate a third or more corrupted parties, do not exist.(2) Deterministic authenticated Byzantine Agreement protocols that run for r rounds and tolerate a third or more corrupted parties, can remain secure for at most 2r &minus; 1 sequential executions.In contrast, we present randomized protocols for authenticated Byzantine Agreement that remain secure under sequential composition, for any polynomial number of executions. We exhibit two such protocols. In the first protocol, an honest majority is required. In the second protocol, any number of parties may be corrupted; however, the complexity of the protocol is in the order of 2n &middot; n&excl; for n parties. In order to have this polynomial in the security parameter k (used for the signature scheme in the protocol), this requires the overall number of parties to be limited to O(log k/log log k). The above results are achieved due to a new protocol for authenticated Byzantine Generals for three parties that can tolerate any number of faulty parties and composes sequentially.Finally, we show that when the model is further augmented so that in each session, all the participating parties receive a common session identifier that is unique to that session, then any polynomial number of authenticated Byzantine agreement protocols can be concurrently executed, while tolerating any number of corrupted parties.
STOC	Girth and euclidean distortion.	Nathan Linial,Avner Magen,Assaf Naor	2002	(MATH) In this paper we partially prove a conjecture that was raised by Linial, London and Rabinovich in \cite{llr}. Let $G$ be a $k$-regular graph, $k \ge 3$, with girth $g$. We show that every embedding $f : G \to \ell_2$ has distortion $\Omega (\sqrt{g})$. The original conjecture which remains open is that the Euclidean distortion is bounded below by $\Omega(g)$. Two proofs are given, one based on semi-definite programming, and the other on Markov Type, a concept that considers random walks on metrics.
STOC	Expanders from symmetric codes.	Roy Meshulam,Avi Wigderson	2002	Expanders from symmetric codes.
STOC	Improved cryptographic hash functions with worst-case/average-case connection.	Daniele Micciancio	2002	"We define a new family of collision resistant hash functions whose security is based on the worst case hardness of approximating the covering radius of a lattice within a factor O(t n^2 log n), where t is a value between 1 and sqrt(n) that depends on the solution of the closest vector problem in certain ""almost perfect"" lattices. Using standard transference theorems from the geometry of numbers, our result immediately gives a connection between the worst-case and average-case complexity of the shortest vector problem with connection factor O(t n^3 log n)."
STOC	The Glauber dynamics on colourings of a graph with high girth and maximum degree.	Michael Molloy	2002	We prove that the Glauber dynamics on the C-colorings of a graph G on n vertices with girth g and maximum degree $\Delta$ mixes rapidly if (i) $C=q\Delta$ and $q>q^*$, where $q^*=1.4890\ldots$ is the root of $(1-{\rm e}^{-1/q})^2+q{\rm e}^{-1/q}=1$; and (ii) $\Delta\geq D\log n$ and $g\geq D\log\Delta$ for some constant D=D(q). This improves the bound of roughly $1.763\Delta$ obtained by Dyer and Frieze [ Proceedings of the 32nd Annual Symposium on Foundations of Computer Science, 2001] for the same class of graphs. Our bound on this class of graphs is lower than the bound of $11\Delta/6\approx1.833\Delta$ obtained by Vigoda [J. Math. Phys., 41 (2000), pp. 1555--1569] for general graphs.
STOC	Models and thresholds for random constraint satisfaction problems.	Michael Molloy	2002	We introduce a class of models for random Constraint Satisfaction Problems. This class includes and generalizes many previously studied models. We characterize those models from our class which exhibit thresholds for satisfiability in the sense that the limiting probability of satisfiability changes significantly as the number of constraints increases. We also discuss models which exhibit sharp thresholds in the sense that the limiting probability jumps from 0 to 1 suddenly.
STOC	On communication over an entanglement-assisted quantum channel.	Ashwin Nayak,Julia Salzman	2002	"Shared entanglement is a resource available to parties communicating over a quantum channel, much akin to public coins in classical communication protocols: the two parties may be given some number of quantum bits jointly prepared in a fixed superposition, prior to communicating with each other. The quantum channel is then said to be ""entanglement-assisted.""Shared randomness does not help in the transmission of information from one party to another. Moreover, it does not significantly reduce the classical complexity of computing functions vis-a-vis private-coin protocols. On the other hand, prior entanglement leads to startling phenomena such as ""quantum teleportation"" and ""superdense coding."" The problem of characterising the power of prior entanglement has baffled many researchers, especially in the setting of bounded-error protocols. It is open whether it leads to more than a factor of two savings (using superdense coding) or more than an additive~O(\log n) savings (when used to create shared randomness). Few lower bounds are known for communication problems in this setting, and are all derived using sophisticated information-theoretic techniques.In this paper, we focus on the most basic problem in the setting of communication over an entanglement-assisted quantum channel, that of communicating classical bits from one party to another. We derive optimal bounds on the number of quantum bits required for this task, for any given probability of error."
STOC	Hardness amplification within NP.	"Ryan O'Donnell"	2002	Hardness amplification within NP.
STOC	The Joy of Theory.	Christos H. Papadimitriou	2002	"This talk is meant to be a celebration of theoreticians, thier achievements, and thier unique style, drawing to a large extent on examples from this volume.Theoretical Computer Science has largely succeeded in its core mission, that is, improving a rigorous and productive foundational understanding of the power and limitations of the von Neumann computer and its software. And in the past few years it has strived to extend its reach to the Internet and the worldwide web, the central computational artifact of our times.But theoreticians have achieved much more than this. Our community has identified P vs. NP, arguably the deepest and most important mathematical question of our time -- and it is leading the assault on it. In addition we are developing ""algorithmic mirrors"" through which other sciences (notably Physics and Biology, with Economics and other Social Sciences soon to join) rediscover, fruitfully, themselves. And we have furthered and influenced crucially Combinatorics and Logic, the important mathematical fields from which we have drawn methodologically. The newfound respectability and prestige of our parent field, Computer Science, owes much to these achievements.Theoreticians comprise a microcosm with wonderful characteristics: Great scientific, social, and intellectual openness; responsibility and mutual respect, but also healthy doses of irreverence, mistrust of the establishment, willingness to experiment, and self-critical spirit; and a strong sense of an international community that is remarkably cohesive and tightly knit while celebrating the diversity of its people, of their backgrounds, and of their scientific interests and approaches.We have also developed a fascinating, complex esthetic of our work based on mathematical elegance and depth, relevance and fashion, timeliness and competition -- but also on playfulness and humor. Our esthetic has served us well: Some of our most important results were derived by long chains of contributions, each seemingly guided to a large extent by such esthetic considerations. In fact, this esthetic extends delightfully to the exposition of our work, as evidenced by the unique genre of scientific prose known as ""FOCS/STOC abstract""."
STOC	On the complexity of matrix product.	Ran Raz	2002	Our main result is a lower bound of $\Omega(m^2 \log m)$ for the size of any arithmetic circuit for the product of two matrices, over the real or complex numbers, as long as the circuit does not use products with field elements of absolute value larger than 1 (where m &times; m is the size of each matrix). That is, our lower bound is superlinear in the number of inputs and is applied for circuits that use addition gates, product gates, and products with field elements of absolute value up to 1. We also prove size-depth tradeoffs for such circuits: We show that if a circuit, as above, is of depth d, then its size is $\Omega(m^{2+ 1/O(d)})$.
STOC	Resolution lower bounds for the weak pigeonhole principle.	Ran Raz	2002	We prove that any Resolution proof for the weak pigeon hole principle, with n holes and any number of pigeons, is of length \Omega(2^{n^{\epsilon}}), (for some constant \epsilon > 0). One corollary is that a certain propositional formulation of the statement NP \not \subset P/poly does not have short Resolution proofs.
STOC	The price of anarchy is independent of the network topology.	Tim Roughgarden	2002	We study the degradation in network performance caused by the selfish behavior of noncooperative network users. We consider a model of selfish routing in which the latency experienced by network traffic on an edge of the network is a function of the edge congestion, and network users are assumed to selfishly route traffic on minimum-latency paths. The quality of a routing of traffic is measured by the sum of travel times, also called the total latency. The outcome of selfish routing--a Nash equilibrium--does not in general minimize the total latency; hence, selfish behavior carries the cost of decreased network performance. We quantify this degradation in network performance via the price of anarchy, the worst-possible ratio between the total latency of a Nash equilibrium and of an optimal routing of the traffic. In this paper, we show that the price of anarchy is determined only by the simplest of networks. Specifically, we prove that under weak hypotheses on the class of allowable edge latency functions, the worst-case ratio between the total latency of a Nash equilibrium and of a minimum-latency routing for any multicommodity flow network is achieved by a single-commodity instance in a network of parallel links. In the special case where the class of allowable latency functions includes all of the constant functions, we prove that a network with only two parallel links suffices to achieve the worst-possible ratio. Our guarantee that simple networks always furnish worst-possible examples provides a powerful method for computing the price of anarchy with respect to an arbitrary class of latency functions. We apply this method to function classes that have been well studied in the literature, including degree-bounded polynomials and queuing delay functions. These are the first tight analyses of the price of anarchy for significant classes of latency functions outside the class of linear functions.
STOC	Algorithmic derandomization via complexity theory.	D. Sivakumar	2002	We point out how the methods of Nisan (1990, 1992), originally developed for derandomizing space-bounded computations, may be applied to obtain polynomial-time and NC derandomizations of several probabilistic algorithms. Our list includes the randomized rounding steps of linear and semi-definite programming relaxations of optimization problems, parallel derandomization of discrepancy-type problems, and the Johnson--Lindenstrauss lemma, to name a few.A fascinating aspect of this style of derandomization is the fact that we often carry out the derandomizations directly from the statements about the correctness of probabilistic algorithms, rather than carefully mimicking their proofs.
STOC	Space lower bounds for distance approximation in the data stream model.	Michael E. Saks,Xiaodong Sun	2002	"(MATH) We consider the problem of approximating the distance of two d-dimensional vectors x and y in the data stream model. In this model, the 2d coordinates are presented as a ""stream"" of data in some arbitrary order, where each data item includes the index and value of some coordinate and a bit that identifies the vector (x or y) to which it belongs. The goal is to minimize the amount of memory needed to approximate the distance. For the case of Lp-distance with p &egr; [1,2], there are good approximation algorithms that run in polylogarithmic space in d (here we assume that each coordinate is an integer with O(log d) bits). Here we prove that they do not exist for p&rho;2. In particular, we prove an optimal approximation-space tradeoff of approximating L&infty; distance of two vectors. We show that any randomized algorithm that approximates L&infty; distance of two length d vectors within factor of d&dgr; requires &omega;(d1&mdash;4&dgr;) space. As a consequence we show that for p&rho;2/(1&mdash;4&dgr;), any randomized algorithm that approximate Lp distance of two length d vectors within a factor d&dgr; requires &omega;(d 1&mdash; 2< \over p&mdash;4&dgr;) space.The lower bound follows from a lower bound on the two-party one-round communication complexity of this problem. This lower bound is proved using a combination of information theory and Fourier analysis."
STOC	"Reimer's inequality and tardos' conjecture."	Clifford D. Smyth	2002	"(MATH) Let f: {0,1}n &rarr; {0,1} be a boolean function. For &egr;&roe; 0 De(f) be the minimum depth of a decision tree for f that makes an error for &xie;&egr; fraction of the inputs &khar; &Egr; {0,1}n. We also make an appropriate definition of the approximate certificate complexity of f, C&egr;(f). In particular, D0(f) and C0(f) are the ordinary decision and certificate complexities of f. It is known that $D_0(f) \leq (C_0(f))^2$. Answering a question of Tardos from 1989, we show that for all $\Ge > 0$ there exists a $\Gd' > 0$ such that for all $0 \leq \Gd < \Gd'$, we have $D_\Ge(f) \leq K (C_\Gd(f))^2$ where $K = K(\Ge,\Gd) > 0$ is a constant independent of f. The algorithm used in the proof is modeled after those developed by R. Impagliazzo and S. Rudich for use in other problems."
STOC	Optimal rate-based scheduling on multiprocessors.	Anand Srinivasan,James H. Anderson	2002	"The PD2 Pfair/ERfair scheduling algorithm is the most efficient known algorithm for optimally scheduling periodic tasks on multiprocessors. In this paper, we prove that PD2 is also optimal for scheduling ""rate-based"" tasks whose processing steps may be highly jittered. The rate-based task model we consider generalizes the widely-studied sporadic task model."
STOC	Recognizing string graphs in NP.	Marcus Schaefer,Eric Sedgwick,Daniel Stefankovic	2002	A string graph is the intersection graph of a set of curves in the plane. Each curve is represented by a vertex, and an edge between two vertices means that the corresponding curves intersect. We show that string graphs can be recognized in NP. The recognition problem was not known to be decidable until very recently, when two independent papers established exponential upper bounds on the number of intersections needed to realize a string graph (Mutzel (Ed.), Graph Drawing 2001, Lecture Notes in Computer Science, Springer, Berlin; Proceedings of the 33rd Annual ACM Symposium on Theory of Computing (STOC-2001)). These results implied that the recognition problem lies in NEXP. In the present paper we improve this by showing that the recognition problem for string graphs is in NP, and therefore NP-complete, since Kratochvíl showed that the recognition problem is NP-hard (J. Combin Theory, Ser. B 52). The result has consequences for the computational complexity of problems in graph drawing, and topological inference. We also show that the string graph problem is decidable for surfaces of arbitrary genus.
STOC	A new average case analysis for completion time scheduling.	Mark Scharbrodt,Thomas Schickinger,Angelika Steger	2002	We present a new average case analysis for the problem of scheduling n jobs on m machines so that the sum of job completion times is minimized. Our goal is to use the concept of competitive ratio---which is a typical worst case notion---also within an average case analysis. We show that the classic SEPT scheduling strategy with &Omega;(n) worst-case competitive ratio achieves an average of O(1) under several natural distributions, among them the exponential distribution. Our analysis technique allows to also roughly estimate the probability distribution of the competitive ratio. Thus, our result bridges the gap between worst case and average case performance guarantee.
STOC	Pseudo-random generators for all hardnesses.	Christopher Umans	2002	We construct the first pseudo-random generators with logarithmic seed length that convert s bits of hardness into s^{\Omega(1)} bits of 2-sided pseudo-randomness, for any s. This improves [ISW00] and gives a direct proof of the optimal hardness vs. randomness tradeoff in [SU01]. A key element in our construction is an augmentation of the standard low-degree extension encoding that exploits the field structure of the underlying space in a new way.
STOC	Proceedings on 34th Annual ACM Symposium on Theory of Computing, May 19-21, 2002, Montréal, Québec, Canada	John H. Reif	2002	Proceedings on 34th Annual ACM Symposium on Theory of Computing, May 19-21, 2002, Montréal, Québec, Canada
FOCS	Quantum Search of Spatial Regions.	Scott Aaronson,Andris Ambainis	2003	"Can Grover¡'s quantum search algorithm speed up search of a physical region ¿ for example a 2-D grid of size \sqrt n\times \sqrt n? The problem is that \sqrt n time seems tobe needed for each query, just to move amplitude across the grid. Here we show that this problem can be surmounted, refuting a claim to the contrary by Benio. In particular, we show how to search a d-dimensional hypercube in time 0(\sqrt n ) for d \geqslant 3, or 0(\sqrt {n\log ^3 n)} for d = 2. More generally, we introduce a model of quantum query complexity on graphs, motivated by fundamental physical limits on information storage, particularly the holographic principle from black hole thermodynamics. Our results in this model include almost-tight upper and lower bounds for many search tasks; a generalized algorithm that works for any graph with good expansion properties, not just hypercubes; and relationships among several notions of `locality¿ for unitary matrices acting on graphs. As an application of our results, we give an 0(\sqrt {n)}-qubit communication protocol for the disjointness problem, which improves an upper bound of H¿yer and de Wolf and matches a lower bound of Razborov."
FOCS	Proving Hard-Core Predicates Using List Decoding.	Adi Akavia,Shafi Goldwasser,Shmuel Safra	2003	We introduce a unifying framework for proving that predicate P is hard-core for a one-way function f, and apply it to a broad family of functions and predicates, reproving old results in an entirely different way as well as showing new hard-core predicates for well known one-way function cadidates.Our framework extends the list-coding method of Goldreich and Levin for showing hard-core predicates. Namely, a predicate will correspond to some error correcting code, predicting a predicate will correspond to access to a corrupted codeword, and the task of inverting one-way functions will correspond to the task of list decoding a corrupted codeword.A characteristic of the error correcting codes which emerge and are addressed by our framework, is that codewords can be approximated by a small number of heavy coefficients in their Fourier representation. Moreover, as long as corrupted words are close enough to legal codewords, they will share a heavy Fourier coefficient. We list decodes, by devising a learning algorithm applied to corrupted codewords for learning heavy Fourier coefficients.For codes defined over {0, 1}n domain, a learning algorithm by Kushilevitz and Mansour already exists. For codes defined over ZN, which are the codes which emerge for predicates based on number theoretic one-way functions such as the RSA and Exponentiation modulo primes, we develop a new learning algorithm. This latter algorithm may be of independent interest outside the realm of hard-core predicates.
FOCS	On the Maximum Satisfiability of Random Formulas.	Dimitris Achlioptas,Assaf Naor,Yuval Peres	2003	Maximum satisfiability is a canonical NP-complete problem that appears empirically hard for random instances. At the same time, it is rapidly becoming a canonical problem for statistical physics. In both of these realms, evaluating new ideas relies crucially on knowing the maximum number of clauses one can typically satisfy in a random k-CNF formula. In this paperwe give asymptotically tight estimates for this quantity.Let us say that a k-CNF formula is p-satisfiable if there exists a truth assignment satisfying 1 - 2^{ - k}+ p2^{ - k} fraction of all clauses (every k-CNF is 0-satisfiable). LetFk (n, m) denote a random k-CNF formula on n variables formed by selecting uniformly, independently and with replacement m out of all (2n)k possible k-clauses. Finally, let t(p) = 2^k In 2/(p + (1 - p) In (1 - p)).It is easy to prove that for every k ¿ 2 and p \in (0,1), if r ¿ t(p) then the probability that Fk(n,m = rn) is p-satisfiable tends to 0 as n tends to infinity. We prove that there exists a sequence \delta _k\to 0 such that if r \leqslant (1 - \delta _k )t(p) then the probability that Fk(n,m = rn) is p-satisfiable tends to 1 as n tends to infinity. The sequence \delta _k tends to 0 exponentially fast in k. Indeed, even for moderate values of k, e.g. k = 10, our result gives very tight bounds for the fraction of satisfiable clauses in a random k-CNF. In particular, for k > 2 it improves upon all previously known such bound.
FOCS	More on Average Case vs Approximation Complexity.	Michael Alekhnovich	2003	"We consider the problem to determine the maximal number of satisfiable equations in a linear system chosen at random. We make several plausible conjectures about the average case hardness of this problem for some natural distributions on the instances, and relate them to several interesting questions in the theory of approximation algorithms and in cryptography.Namely we show that our conjectures imply the following facts:Feige's hypothesis about the hardness of refuting a random 3CNF is true, which in turn implies inapproximability within a constant for several combinatorial problems, for which no NP-hardness of approximation is known.It is hard to approximate the NEAREST CODEWORD within factor n^{1 - \varepsilon}.It is hard to estimate the rigidity of a matrix. More exactly, it is hard to distinguish between matrices of low rigidity and random ones.There exists a secure public-key (probabilistic) cryptosystem, based on the intractability of decoding of random binary codes.Our conjectures are strong in that they assume cryptographic hardness: no polynomial algorithm can solve the problem on any non-negligible fraction of inputs. Nevertheless, to the best of our knowledge no efficient algorithms are currently known that refute any of our hardness conjectures."
FOCS	Linear Upper Bounds for Random Walk on Small Density Random 3-CNF.	Michael Alekhnovich,Eli Ben-Sasson	2003	We analyze the efficiency of the random walk algorithm on random 3-CNF instances, and prove linear upper bounds on the running time of this algorithm for small clause density,less than 1.63. Our upper bound matches the observed running time to within a multiplicative factor. This is the first sub-exponential upper bound on the running time of a local improvement algorithm on random instances.Our proof introduces a simple, yet powerful tool for analyzing such algorithms, which may be of further use. This object, called a terminator, is a weighted satisfying assignment. We show that any CNF having a good (small weight) terminator, is assured to be solved quickly by the random walk algorithm. This raises the natural question of the terminator threshold which is the maximal clause density for which such assignments exist (with high probability).We use the analysis of the pure literal heuristic presented by Broder, Frieze and Upfal [12, 22] and show that for small clause densities good terminators exist. Thus we show that the Pure Literal threshold (\approx 1.63) is a lower bound on the terminator threshold. (We conjecture the terminator threshold to be in fact higher).One nice property of terminators is that they can be found efficiently, via linear programming. This makes tractable the future investigation of the terminator threshold, and also provides an efficiently computable certificate for short running time of the simple random-walk heuristic.
FOCS	Switch Scheduling via Randomized Edge Coloring.	Gagan Aggarwal,Rajeev Motwani,Devavrat Shah,An Zhu	2003	The essence of an Internet router is an n × n switch which routes packets from input to output ports. Such a switch can be viewed as a bipartite graph with the input and output ports as the two vertex sets. Packets arriving at input port i and destined for output port j can be modeled as an edge from i to j. Current switch scheduling algorithms view the routing of packets at each time step as a selection of a bipartite matching. We take the view that the switch scheduling problem across a sequence of time-steps is an instance of the edge coloring problem for a bipartite multigraph. Implementation considerations lead us to seek edge coloring algorithms for bipartite multigraphs that are fast, decentralized, and online. We present a randomized algorithm which has the desired properties, and uses only a near-optimal \Delta+ 0(\Delta) colors on dense bipartite graphs arising in the context of switch scheduling. This algorithm extends to nonbipartite graphs as well. It leads to a novel switch scheduling algorithm which, for stochastic online edge arrivals, is stable, i.e., the queue length at each input port is bounded at all times. We note that this is the first decentralized switch scheduling algorithm that is also guaranteed to be stable.
FOCS	A Lattice Problem in Quantum NP.	Dorit Aharonov,Oded Regev	2003	"We consider coGapSVP_{\sqrt n } a gap version of the shortest vector in a lattice problem. This problem is known to be in AM \cap coNP but is not known to be in NP or in MA. We prove that it lies inside QMA, the quantum analogue of NP. This is the first non-trivial upper bound on the quantum complexity of a lattice problem.The proof relies on two novel ideas. First, we give a new characterization of QMA, called QMA+ formulation allows us to circumvent a problem which arises commonly in the context of QMA: the prover might use entanglement between different copies of the same state in order to cheat. The second idea involves using estimations of autocorrelation functions for verification. We make the important observation that autocorrelation functions are positive definite functions and using properties of such functions we severely restrict the prover's possibility to cheat. We hope that these ideas will lead to further developments in the field."
FOCS	Polynomial Degree vs. Quantum Query Complexity.	Andris Ambainis	2003	The degree of a polynomial representing (or approximating) a function f is a lower bound for the quantum query complexity of f. This observation has been a source of many lower bounds on quantum algorithms. It has been an open problem whether this lower bound is tight.We exhibit a function with polynomial degree M and quantum query complexity (M1.321...). This is the first superlinear separation between polynomial degree and quantum query complexity. The lower bound is shown by a new, more general version of quantum adversary method.
FOCS	Stability and Efficiency of a Random Local Load Balancing Protocol.	Aris Anagnostopoulos,Adam Kirsch,Eli Upfal	2003	We study the long term (steady state) performance of a simple, randomized, local load balancing technique. We assume a system of n processors connected by an arbitrary network topology. Jobs are placed in the processors by a deterministic or randomized adversary. The adversary knows the current and past load distribution in the network and can use this information to place the new tasks in the processors. The adversary can put a number of new jobs in each processor, in each step, as long as the (expected) total number of new jobs arriving at a given step is bounded by \lambda n A node can execute one job per step, and also participate in one load balancing operation in which it can move tasks to a direct neighbor in the network. In the protocol we analyze here, a node equalizes its load with a random neighbor in the graph.We first study the stability of a system running our load balancing protocol. Clearly, if \lambda > 1 the system cannot be stable. We show that for any \lambda
FOCS	I/O-Efficient Strong Connectivity and Depth-First Search for Directed Planar Graphs.	Lars Arge,Norbert Zeh	2003	We present the first I/O-efficient algorithms for the following fundamental problems on directed planar graphs: finding the strongly connected components, finding a simple-path 23-separator, and computing a depth-first spanning (DFS) tree. Our algorithms for the first two problems perform O(sort(N)) I/Os, where N = V + E and sort(N) = THgr;((N/B)log M/B(N/B)) is the number of I/Os required to sort N elements. The DFS-algorithm performs O(sort(N) log(N/M)) I/Os, where M is the number of elements that fit into main memory.
FOCS	Locally Testable Cyclic Codes.	László Babai,Amir Shpilka,Daniel Stefankovic	2003	"Cyclic linear codes of block length n over a finite field \mathbb{F}_qare the linear subspace of \mathbb{F}_{_q }^n that are invariant under a cyclic shift of their coordinates. A family of codes is good if all the codes in the family have constant rate and constant normalized distance (distance divided by block length). It is a long-standing open problem whether there exists a good family of cyclic linear codes (cf. [MS, p. 270]).A code C is r-testable if there exist a randomized algorithm which, given a word x \in \mathbb{F}_q^n, adaptively selects r positions, checks the entries of x in the selected positions, and makes a decision (accept or reject x) based on the positions selected and the numbers found, such that(i) if x \in C then x is surely accepted;if dist(x,C) \geqslant \varepsilon n then x is probably rejected.(""dist"" refers to Hamming distane.)A family of codes is locally testable if all members of the family are r-testable for some some constant r. This concept arose from holographic proofs/PCPs. Goldreich and Sudan [GS] asked whether there exist good, locally testable families of codes.In this paper we address the intersection of the two questions stated."
FOCS	"Algorithms and Complexity Results for 	SAT and Bayesian Inference."	Fahiem Bacchus,Shannon Dalmao,Toniann Pitassi	2003#"Bayesian inference is an important problem with numerous applications in probabilistic reasoning. Counting satisfying assignments is a closely related problem of fundamental theoretical importance. In this paper, we show that plain old DPLL equipped with memoization (an algorithm we call #DPLLCache) can solve both of these problems with time complexity that is at least as good as state-of-the-art exact algorithms, and that it can also achieve the best known time-space tradeoff. We then proceed to show that there are instances where #DPLLCache can achieve an exponential speedup over existing algorithms."
FOCS	Lower Bounds for Non-Black-Box Zero Knowledge.	Boaz Barak,Yehuda Lindell,Salil P. Vadhan	2003	We show new lower bounds and impossibility results for general (possibly non-black-box) zero-knowledge proofs and arguments. Our main results are that, under reasonable complexity assumptions:1. There does not exist a constant-round zero-knowledge strong proof (or argument) of knowledge (as defined by Goldreich (2001)) for a nontrivial language.2. There does not exist a two-round zero-knowledge proof system with perfect completeness for an NP-complete language.The previous impossibility result for two-round zero knowledge, by Goldreich and Oren (J. Cryptology, 1994) was only for the case of auxiliary-input zero-knowledge proofs and arguments.3. There does not exist a constant-round public-coin proof system for a nontrivial language that is resettable zero knowledge. This result also extends to bounded resettable zero knowledge.In contrast, we show that under reasonable assumptions, there does exist such a (computationally sound) argument system that is bounded-resettable zero knowledge.The complexity assumptions we use are not commonly used in cryptography. However, in all cases, we show that assumptions like ours are necessary for the above results.Most previously known lower bounds, such as those of Goldreich and Krawczyk (SIAM J. Computing, 1996), were only for black-box zero knowledge. However, a result of Barak (FOCS 2001) shows that many (or even most) of these black-box lower bounds do not extend to the case of general zero knowledge.
FOCS	Average Case and Smoothed Competitive Analysis of the Multi-Level Feedback Algorithm.	Luca Becchetti,Stefano Leonardi,Alberto Marchetti-Spaccamela,Guido Schäfer,Tjark Vredeveld	2003	Average Case and Smoothed Competitive Analysis of the Multi-Level Feedback Algorithm.
FOCS	Separating the Power of Monotone Span Programs over Different Fields.	Amos Beimel,Enav Weinreb	2003	Monotone span programs are a linear-algebraic model of computation. They are equivalent to linear secret sharing schemes and have various applications in cryptography and complexity. A fundamental question is how the choice of the field in which the algebraic operations areperformed effects the power of the span program. In this paper we prove that the power of monotone span programs over finite fields of different characteristics is incomparable; we show a super-polynomial separation between any two fields with different characteristics, answering an open problem of Pudlák and Sgall 1998. Using this result we prove a super-polynomial lower bound for monotone span programs for a function in unifrom-NC2 (and therefore in P), answering an open problem of Babai, Wigderson, and Gál 1999. (All previous lower bounds for monotone span programs were for functions not known to be in P.) Finally, we show that quasi-linear schemes, a generalization of linear secret sharing schemes introduced in Beimel and Ishai 2001, are stronger than linear secret sharing schemes. In particular, this proves, without any assumptions, that non-linear secret sharing schemes are more efficient than linear secret sharing schemes.
FOCS	The Cost of Cache-Oblivious Searching.	Michael A. Bender,Gerth Stølting Brodal,Rolf Fagerberg,Dongdong Ge,Simai He,Haodong Hu,John Iacono,Alejandro López-Ortiz	2003	Tight bounds on the cost of cache-oblivious searching are proved. It is shown that no cache-oblivious search structure can guarantee that a search performs fewer than lg e logB N block transfers between any two levels of the memory hierarchy. This lower bound holds even if all of the block sizes are limited to be powers of 2. A modified version of the van Emde Boas layout is proposed, whose expected block transfers between any two levels of the memory hierarchy arbitrarily close to [lg e + O(lg lg B/ lgB)] logB N + O(1). This factor approaches lg e \approx 1.443 as B increases. The expectation is taken over the random placement of the first element of the structure in memory.As searching in the Disk Access Model (DAM) can be performed in logB N + 1 block transfers, this result shows a separation between the 2-level DAM and cache-oblivious memory-hierarchy models. By extending the DAM model to k levels, multilevel memory hierarchies can be modelled. It is shown that as k grows, the search costs of the optimal k-level DAM search structure and of the optimal cache-oblivious search structure rapidly converge. This demonstrates that for a multilevel memory hierarchy, a simple cache-oblivious structure almost replicates the performance of an optimal parameterizedk-level DAM structure.
FOCS	Symmetric Polynomials over Z and Simultaneous Communication Protocol.	Nayantara Bhatnagar,Parikshit Gopalan,Richard J. Lipton	2003	"We study the problem of representing symmetric Boolean functions as symmetric polynomials over Z""m. We prove an equivalence between representations of Boolean functions by symmetric polynomials and simultaneous communication protocols. We show that computing a function f on 0-1 inputs with a polynomial of degree d modulo pq is equivalent to a two player simultaneous protocol for computing f where one player is given the first @?log""pd@? digits of the weight in base p and the other is given the first @?log""qd@? digits of the weight in base q. This equivalence allows us to show degree lower bounds by using techniques from communication complexity. For example, we show lower bounds of @W(n) on symmetric polynomials weakly representing classes of Mod""r and Threshold functions. Previously the best known lower bound for such representations of any function modulo pq was @W(n^1^2) [D.A. Barrington, R. Beigel, S. Rudich, Representing Boolean functions as polynomials modulo composite numbers, Comput. Complexity 4 (1994) 367-382]. The equivalence also allows us to use results from number theory to prove upper bounds for Threshold-k functions. We show that proving bounds on the degree of symmetric polynomials strongly representing the Threshold-k function is equivalent to counting the number of solutions to certain Diophantine equations. We use this to show an upper bound of O(nk)^1^2^+^@? for Threshold-k assuming the abc-conjecture. We show the same bound unconditionally for k constant. Prior to this, non-trivial upper bounds were known only for the OR function [D.A. Barrington, R. Beigel, S. Rudich, Representing Boolean functions as polynomials modulo composite numbers, Comput. Complexity 4 (1994) 367-382]. We show an almost tight lower bound of @W(nk)^1^2, improving the previously known bound of @W(max(k,n)) [S.-C. Tsai, Lower bounds on representing Boolean functions as polynomials in Z""m, SIAM J. Discrete Math. 9 (1996) 55-62]."
FOCS	Instability of FIFO at Arbitrarily Low Rates in the Adversarial Queueing Model.	Rajat Bhattacharjee,Ashish Goel	2003	We study the stability of the commonly used packet forwarding protocol, FIFO (First In First Out), in the adversarial queueing model. We prove that FIFO can become unstable, i.e., lead to unbounded buffer-occupancies and queueing delays, at arbitrarily low injection rates. In order to demonstrate instability at rate ¿ we use a network of size polynomial in 1/¿.
FOCS	Machine Learning: My Favorite Results, Directions, and Open Problems.	Avrim Blum	2003	Machine Learning: My Favorite Results, Directions, and Open Problems.
FOCS	Approximation Algorithms for Orienteering and Discounted-Reward TSP.	Avrim Blum,Shuchi Chawla,David R. Karger,Terran Lane,Adam Meyerson,Maria Minkoff	2003	In this paper, we give the first constant-factor approximation algorithm for the rooted Orienteering problem, as well as a new problem that we call the Discounted-Reward traveling salesman problem (TSP), motivated by robot navigation. In both problems, we are given a graph with lengths on edges and rewards on nodes, and a start node $s$. In the Orienteering problem, the goal is to find a path starting at $s$ that maximizes the reward collected, subject to a hard limit on the total length of the path. In the Discounted-Reward TSP, instead of a length limit we are given a discount factor $\gamma$, and the goal is to maximize the total discounted reward collected, where the reward for a node reached at time $t$ is discounted by $\gamma^t$. This problem is motivated by an approximation to a planning problem in the Markov decision process (MDP) framework under the commonly employed infinite horizon discounted reward optimality criterion. The approximation arises from a need to deal with exponentially large state spaces that emerge when trying to model one-time events and nonrepeatable rewards (such as for package deliveries). We also consider tree and multiple-path variants of these problems and provide approximations for those as well. Although the unrooted Orienteering problem, where there is no fixed start node $s$, has been known to be approximable using algorithms for related problems such as $k$-TSP (in which the amount of reward to be collected is fixed and the total length is approximately minimized), ours is the first to approximate the rooted question, solving an open problem in [E. M. Arkin, J. S. B. Mitchell, and G. Narasimhan, Proceedings of the $14$th ACM Symposium on Computational Geometry, 1998, pp. 307-316] and [B. Awerbuch, Y. Azar, A. Blum, and S. Vempala, SIAM J. Comput., 28 (1998), pp. 254-262]. We complement our approximation result for Orienteering by showing that the problem is APX-hard.
FOCS	On Worst-Case to Average-Case Reductions for NP Problems.	Andrej Bogdanov,Luca Trevisan	2003	We show that if an NP-complete problem has a nonadaptive self-corrector with respect to any samplable distribution, then coNP is contained in NP/poly and the polynomial hierarchy collapses to the third level. Feigenbaum and Fortnow [SIAM J. Comput., 22 (1993), pp. 994-1005] show the same conclusion under the stronger assumption that an NP-complete problem has a nonadaptive random self-reduction. A self-corrector for a language L with respect to a distribution $\cal D$ is a worst-case to average-case reduction that transforms any given algorithm that correctly decides $L$ on most inputs (with respect to $\cal D$) into an algorithm of comparable efficiency that decides L correctly on every input. A random self-reduction is a special case of a self-corrector, where the reduction, given an input $x$, is restricted to only making oracle queries that are distributed according to $\cal D$. The result of Feigenbaum and Fortnow depends essentially on the property that the distribution of each query in a random self-reduction is independent of the input of the reduction. Our result implies that the average-case hardness of a problem in NP or the security of a one-way function cannot be based on the worst-case complexity of an NP-complete problem via nonadaptive reductions (unless the polynomial hierarchy collapses).
FOCS	On the Impossibility of Dimension Reduction in l.	Bo Brinkman,Moses Charikar	2003	"The Johnson--Lindenstrauss lemma shows that any n points in Euclidean space (i.e., &#x211D;n with distances measured under the &ell;2 norm) may be mapped down to O((log n)/&epsi;2) dimensions such that no pairwise distance is distorted by more than a (1 &plus; &epsi;) factor. Determining whether such dimension reduction is possible in &ell;1 has been an intriguing open question. We show strong lower bounds for general dimension reduction in &ell;1. We give an explicit family of n points in &ell;1 such that any embedding with constant distortion D requires n&Omega;(1/D2) dimensions. This proves that there is no analog of the Johnson--Lindenstrauss lemma for &ell;1; in fact, embedding with any constant distortion requires n&Omega;(1) dimensions. Further, embedding the points into &ell;1 with (1&plus;&epsi;) distortion requires n&half;&minus;O(&epsi; log(1/&epsi;)) dimensions. Our proof establishes this lower bound for shortest path metrics of series-parallel graphs. We make extensive use of linear programming and duality in devising our bounds. We expect that the tools and techniques we develop will be useful for future investigations of embeddings into &ell;1."
FOCS	Learning DNF from Random Walks.	"Nader H. Bshouty,Elchanan Mossel,Ryan O'Donnell,Rocco A. Servedio"	2003	We consider a model of learning Boolean functions from examples generated by a uniform random walk on {0, 1}n. We give a polynomial time algorithm for learning decision trees and DNF formulas in this model. This is the first efficient algorithm for learning these classes in a natural passive learning model where the learner has no influence overthe choice of examples used for learning.
FOCS	Towards a Dichotomy Theorem for the Counting Constraint Satisfaction Problem.	Andrei A. Bulatov,Víctor Dalmau	2003	"The Counting Constraint Satisfaction Problem (#CSP) over a .nite domain can be expressed as follows: given a first-order formula consisting of a conjunction of predicates, determine the number of satisfying assignments to the formula. #CSP can be parametrized by the set of allowed constraint predicates. In this paper we start a systematic study of subclasses of #CSP restricted in this way. The ultimate goal of this investigation is to distinguish those restricted subclasses of #CSP which are tractable, i.e. solvable in polynomial time, from those which are not. We show that the complexity of any restricted #CSP class on a finite domain can be deduced from the properties of polymorphisms of the allowed constraints, similar to that for thedecision CSP. Then we prove that if a subclass of the #CSP is tractable, then constraints allowed by the class satisfy some very restrictive condition: it has to have a Mal'tsev polymorphism, that is a ternary operation m(x, y, z) such that m(x, y, y) = m(y, y, x) = x. This condition uniformly explains all existing complexity results for particular cases of #CSP, and allows us to obtain new results and to conjecture a criterion distinguishing tractable counting CSPs. We also obtain a dichotomy theorem for the complexity of #CSP with a 3-element domain and give a new simpler proofs of the dichotomy results for the problem of counting graph homomorphisms."
FOCS	Paths, Trees, and Minimum Latency Tours.	Kamalika Chaudhuri,Brighten Godfrey,Satish Rao,Kunal Talwar	2003	We give improved approximation algorithms for a variety of latency minimization problems. In particular, we give a 3.591-approximation to the minimum latency problem, improving on previous algorithms by a multiplicative factor of 2. Our techniques also give similar improvements for related problems like k-traveling repairmen and its multiple depot variant. We also observe that standard techniques can be used to speed up the previous and this algorithm by a factor of \bar O(n).
FOCS	Rank Bounds and Integrality Gaps for Cutting Planes Procedures Joshua.	Josh Buresh-Oppenheim,Nicola Galesi,Shlomo Hoory,Avner Magen,Toniann Pitassi	2003	Rank Bounds and Integrality Gaps for Cutting Planes Procedures Joshua.
FOCS	On Levels in Arrangements of Curves, II: A Simple Inequality and Its Consequences.	Timothy M. Chan	2003	"We give a surprisingly short proof that in any planar arrangement of n curves where each pair intersects at most a fixed number (s) of times, the k-level has subquadratic(0(n^{2 - \frac{1}{{2s}}})) complexity. This answers one of the main open problems from the author's previous paper (FOCS'00), which provided a weaker bound for a restricted class of curves (graphs of degree-s polynomials) only. When combined with existing tools (cutting curves, sampling, etc.), the new idea generates a slew of improved k-level results for most of the curve families studied earlier, including a near-0(n^{{3 \mathord{\left/ {\vphantom {3 2}} \right. \kern-\nulldelimiterspace} 2}}) bound for parabolas."
FOCS	Clustering with Qualitative Information.	Moses Charikar,Venkatesan Guruswami,Anthony Wirth	2003	"We consider the problem of clustering a collection of elements based on pairwise judgments of similarity and dissimilarity. Bansal, Blum and Chawla [1] cast the problem thus: given a graph G whose edges are labeled ""+"" (similar) or ""-"" (dissimilar), partition the vertices into clusters so that the number of pairs correctly (resp. incorrectly) classified with respect to the input labeling is maximized (resp. minimized). Complete graphs, where the classifier labelsevery edge, and general graphs, where some edges are not labeled, are both worth studying. We answer several questions left open in [1] and provide a sound overview of clustering with qualitative information.We give a factor 4 approximation for minimization on complete graphs, and a factor O(log n) approximation for general graphs. For the maximization version, a PTAS for complete graphs is shown in [1]; we give a factor 0.7664 approximation for general graphs, noting that a PTAS is unlikely by proving APX-hardness. We also prove the APX-hardness of minimization on complete graphs."
FOCS	A Group-Theoretic Approach to Fast Matrix Multiplication.	Henry Cohn,Christopher Umans	2003	We develop a new, group-theoretic approach to bounding the exponent of matrix multiplication. There are two components to this approach: (1) identifying groups G that admit a certain type of embedding of matrix multiplication into the group algebra \mathbb{C}[G] and (2) controlling the dimensions of the irreducible representations of such groups. We present machinery and examples to support (1), including a proof that certain families of groups of order n^{2 + 0(1)} support n × n matrix multiplication, a necessary condition for the approach to yield exponent 2. Although we cannot yet completely achieve both (1) and (2), we hope that it may be possible, and we suggest potential routes to that result using the constructions in this paper.
FOCS	A Polynomial Algorithm for Recognizing Perfect Graphs.	Gérard Cornuéjols,Xinming Liu,Kristina Vuskovic	2003	We present a polynomial algorithm for recognizing whether a graph is perfect, thus settling a long standing open question. The algorithm uses a decomposition theorem of Conforti, Cornuéjols and Vu¡skovi¿. Another polynomial algorithm for recognizing perfect graphs, which does not use decomposition, was obtained simultaneously by Chudnovsky and Seymour. Both algorithms need a first phase developed jointly by Chudnovsky, Cornuéjols, Liu, Seymour and Vu¡skovi¿.
FOCS	Broadcasting Algorithms in Radio Networks with Unknown Topology.	Artur Czumaj,Wojciech Rytter	2003	"In this paper we present new randomized and deterministic algorithms for the classical problem of broadcasting in radio networks with unknown topology. We consider directed n-node radio networks with specified eccentricity D (maximum distance from the source node to any other node). In a seminal work on randomized broadcasting, Bar-Yehuda et al. presented an algorithm that for any n-node radio network with eccentricity D completes the broadcasting in O(D log n + log2 n) time, with high probability. This result is almost optimal, since as it has been shown by Kushilevitz and Mansour and Alon et al., every randomized algorithm requires \Omega(D log(n/D) + log2 n) expected time to complete broadcasting.Our first main result closes the gap between the lower and upper bound: we describe an optimal randomized broadcasting algorithm whose running time complexity is O(D log(n/D) + log2 n), with high probability. In particular, we obtain a randomized algorithm that completes broadcasting in any n-node radio network in time O(n), with high probability; the best previously existing algorithm achieved the running time O(n log n).The main source of our improvement is a better ""selecting sequence"" used by the algorithm that brings some stronger property and improves the broadcasting time. Two types of ""selecting sequence"" are considered: randomized and deterministic ones. The algorithm with a randomized sequence is easier (more intuitive) to analyze but both randomized and deterministic sequences give algorithms of the same asymptotic complexity.Next, we demonstrate how to apply our approach to deterministic broadcasting, and describe a deterministic oblivious algorithm that completes broadcasting in almost optimal time O(n log2 D), which improves upon best known algorithms in this case. The fastest previously known algorithm had the broadcasting time of O(n log n log D), it was non-oblivious and it was significantly more complicated; our algorithm can be seen as a natural extension of our randomized algorithm.Finally, we show how our randomized broadcasting algorithm can be used to improve the randomized complexity of the gossiping problem."
FOCS	An In-Place Sorting with O(n log n) Comparisons and O(n) Moves.	Gianni Franceschini,Viliam Geffert	2003	We present the first in-place algorithm for sorting an array of size n that performs, in the worst case, at most O(n log n) element comparisons and O(n) element transports.This solves a long-standing open problem, stated explicitly, e.g., in [J. I. Munro and V. Raman, Sorting with minimum data movement, J. Algorithms, 13, 374-93, 1992], of whether there exists a sorting algorithm that matches the asymptotic lower bounds on all computational resources simultaneously.
FOCS	On the Implementation of Huge Random Objects.	Oded Goldreich,Shafi Goldwasser,Asaf Nussboim	2003	"We initiate a general study of pseudo-random implementations of huge random objects, and apply it to a few areas in which random objects occur naturally. For example, a random object being considered may be a random connected graph, a random bounded-degree graph, or a random error-correcting code with good distance. A pseudo-random implementation of such type T objects must generate objects of type T that can not be distinguished from random ones, rather than objects that can not be distinguished from typeT objects (although they are not type T at all). We will model a type T object as a function, and access objects by queries into these functions. We investigate supporting both standard queries that only evaluates the primary function at locations of the user's choice (e.g., edge queries in a graph), and complex queries that may ask for the result of a computation on the primary function, where this computation is infeasible to perform with a polynomial number of standard queries (e.g., providing the next vertex along a Hamiltonian path in the graph)."
FOCS	On the (In)security of the Fiat-Shamir Paradigm.	Shafi Goldwasser,Yael Tauman Kalai	2003	"In 1986, Fiat and Shamir proposed a general method for transforming secure 3-round public-coin identification schemes into digital signature schemes. The idea of the transformation was to replace the random message of the veri.er in the identification scheme, with the value of some deterministic""hash"" function evaluated on various quantities in the protocol and on the message to be signed.The Fiat-Shamir methodology for producing digital signature schemes quickly gained popularity as it yields efficient and easy to implement digital signature schemes. The most important question however remained open: are the digital signatures produced by the Fiat-Shamir methodology secure?In this paper, we answer this question negatively. We show that there exist secure 3-round public-coin identification schemes for which the Fiat-Shamir transformation yields insecure digital signature schemes for any ""hash"" function used by the transformation. This is in contrast to the work of Pointcheval and Stern which proved that the Fiat-Shamir methodology always produces digital signatures secure against chosen message attack in the ""Random Oracle Model"" ¿ when the hash function is modelled by a random oracle.Among other things, we make new usage of Barak's technique for taking advantage of non black-box access to a program, this time in the context of digital signatures."
FOCS	The Complexity of Homomorphism and Constraint Satisfaction Problems Seen from the Other Side.	Martin Grohe	2003	We give a complexity theoretic classification of homomorphism problems for graphs and, more generally, relational structures obtained by restricting the left hand side structure in a homomorphism. For every class C of structures, let HOM(C,_) be the problem of deciding whether a given structure A \in C has a homomorphism to a given (arbitrary) structure B. We prove that, under some complexity theoretic assumption from parameterized complexity theory,HOM(C,_) is in polynomial time if, and only if, the cores of all structures in C have bounded tree-width (as long as the structures in C only contain relations of bounded arity).Due to a well known correspondence between homomorphism problems and constraint satisfaction problems, our classification carries over to the latter.
FOCS	Bounded Geometries, Fractals, and Low-Distortion Embeddings.	Anupam Gupta,Robert Krauthgamer,James R. Lee	2003	The doubling constant of a metric space (X, d) is the smallest value \lambda such that every ball in X can be covered by \lambda balls of half the radius. The doubling dimension of X is then defined as \dim (X) = \log _2 \lambda. A metric (or sequence of metrics) is called doubling precisely when its doubling dimension is bounded. This is a robust class of metric spaces which contains many families of metrics that occur in applied settings.We give tight bounds for embedding doubling metrics into (low-dimensional) normed spaces. We consider both general doubling metrics, as well as more restricted families such as those arising from trees, from graphs excluding a fixed minor, and from snowflaked metrics. Our techniques include decomposition theorems for doubling metrics, and an analysis of a fractal in the plane due to Laakso [21]. Finally, we discuss some applications and point out a centralopen question regarding dimensionality reduction in L2.
FOCS	Approximation Via Cost-Sharing: A Simple Approximation Algorithm for the Multicommodity Rent-or-Buy Problem.	Anupam Gupta,Amit Kumar,Martin Pál,Tim Roughgarden	2003	"We study the multicommodity rent-or-buy problem, a type of network design problem with economies of scale. In this problem, capacity on an edge can be rented, with cost incurred on a per-unit of capacity basis, or bought, which allows unlimited use after payment of a large fixed cost. Given a graph and a set of source-sink pairs, we seek a minimum-cost way of installing sufficient capacity on edges so that a prescribed amount of flow can be sent simultaneously from each source to the corresponding sink. The first constant-factor approximation algorithm for this problem was recently given by Kumar et al. (FOCS '02); however, this algorithm and its analysis are both quite complicated, and its performance guarantee is extremely large.In this paper, we give a conceptually simple 12-approximation algorithm for this problem. Our analysis of this algorithm makes crucial use of cost sharing, the task of allocating the cost of an object to many users of the object in a ""fair"" manner. While techniques from approximation algorithms have recently yielded new progress on cost sharing problems, our work is the first to show the converse ¿ that ideas from cost sharing can be fruitfully applied in the design and analysis of approximation algorithms."
FOCS	A Non-Markovian Coupling for Randomly Sampling Colorings.	Thomas P. Hayes,Eric Vigoda	2003	We study a simple Markov chain, known as the Glauber dynamics, for randomly sampling (proper) k-colorings of an input graph G on n vertices with maximum degree \Delta and girth g. We prove the Glauber dynamics is close to the uniform distribution after 0(n log n) steps whenever k > (1 + \varepsilon)\Delta for all \varepsilon > 0, assuming g ¿ 9 and \Delta= \Omega (\log n). The best previously known bounds were k > 11\Delta/6 for general graphs, and k > 1.489\Delta for graphs satisfying girth and maximum degree requirements.Our proof relies on the construction and analysis of a non-Markovian coupling. This appears to be the first application of a non-Markovian coupling to substantially improve upon known results.
FOCS	Breaking a Time-and-Space Barrier in Constructing Full-Text Indices.	Wing-Kai Hon,Kunihiko Sadakane,Wing-Kin Sung	2003	Suffix trees and suffix arrays are the most prominent full-text indices, and their construction algorithms are well studied. In the literature, the fastest algorithm runs in $O(n)$ time, while it requires $O(n\log n)$-bit working space, where $n$ denotes the length of the text. On the other hand, the most space-efficient algorithm requires $O(n)$-bit working space while it runs in $O(n\log n)$ time. It was open whether these indices can be constructed in both $o(n\log n)$ time and $o(n\log n)$-bit working space. This paper breaks the above time-and-space barrier under the unit-cost word RAM. We give an algorithm for constructing the suffix array, which takes $O(n)$ time and $O(n)$-bit working space, for texts with constant-size alphabets. Note that both the time and the space bounds are optimal. For constructing the suffix tree, our algorithm requires $O(n\log^{\epsilon}n)$ time and $O(n)$-bit working space for any $0<\epsilon<1$. Apart from that, our algorithm can also be adopted to build other existing full-text indices, such as compressed suffix tree, compressed suffix arrays, and FM-index. We also study the general case where the size of the alphabet $\Sigma$ is not constant. Our algorithm can construct a suffix array and a suffix tree using optimal $O(n\log|\Sigma|)$-bit working space while running in $O(n\log\log|\Sigma|)$ time and $O(n(\log^{\epsilon}n+\log|\Sigma|))$ time, respectively. These are the first algorithms that achieve $o(n\log n)$ time with optimal working space. Moreover, for the special case where $\log|\Sigma|=O((\log\log n)^{1-\epsilon})$, we can speed up our suffix array construction algorithm to the optimal $O(n)$.
FOCS	Logics for Reasoning about Cryptographic Constructions.	Russell Impagliazzo,Bruce M. Kapron	2003	We present two logical systems for reasoning about cryptographic constructions which are sound with respect to standard cryptographic definitions of security. Soundness of the first system is proved using techniques from non-standard models of arithmetic. Soundness of the second system is proved by an interpretation into the first system. We also present examples of how these systems may be used to formally prove the correctness of some elementary cryptographic constructions.
FOCS	Tight Lower Bounds for the Distinct Elements Problem.	Piotr Indyk,David P. Woodruff	2003	We prove strong lower bounds for the space complexity of (\varepsilon ,\delta )-approximating the number of distinct elements F0 in a data stream. Let m be the size of the universe from which the stream elements are drawn. We show that any one-pass streaming algorithm for (\varepsilon ,\delta )-approximating F0 must use \Omega (\frac{1}{{\varepsilon ^2 }}) space when \varepsilon= \Omega (m^{ - \frac{1}{{9 + k}}} ), for any k > 0, improving upon the known lower bound of \Omega (\frac{1}{\varepsilon }) for this range of \varepsilon. This lower bound is tight up to a factor of log log m for small \varepsilon and log (\frac{1}{\varepsilon }) for large \varepsilon. Our lower bound is derived from a reduction from the one-way communication complexity of approximating a boolean function in Euclidean space. The reduction makes use of a low-distortion embedding from an \iota _2 to an \iota _1 norm.
FOCS	A Lower Bound for the Bounded Round Quantum Communication Complexity of Set Disjointness.	Rahul Jain,Jaikumar Radhakrishnan,Pranab Sen	2003	We show lower bounds in the multi-party quantum communication complexity model. In this model, there are t parties where the ith party has input X_i\subseteq \left[ n \right]. These parties communicate with each other by transmitting qubits to determine with high probability the value of some function F of their combined input (X1, . . .,Xt). We consider the class of boolean valued functions whose value depends only on X_1\cap\cdots\cap X_t ; that is, for each F in this class there is an f_F :2^{\left[ n \right]}\to \{ 0,1\}, such that F(X_{1, \ldots ,} X_t ) = f_F (X_1 n \cdots nX_t ). We show that the t-party k-round communication complexity of F is \Omega (s_m (f_F )/(k^2 )), where s_m (f_F ) stands for the `monotone sensitivity of f_F¿ and is defined by s_m (f_F ) \triangleq \max _{S \subseteq \left[ n \right]} \left| {\{ i:f_F } \right.(S \cup \{i\} ) \ne f_F (S)\left. \}\right|.For two-party quantum communication protocols for the set disjointness problem, this implies that the two parties must exchange \Omega (n/k^2 ) qubits. An upper bound of O(n/k)can be derived from the O(\sqrt n) upper bound due to Aaronson and Ambainis [AA03]. For k = 1, our lower bound matches the \Omega(n) lower bound observed by Buhrman and de Wolf [BdW01] (based on a result of Nayak [Nay99]), and for 2 \leqslant k \ll n^{{1 \mathord{\left/ {\vphantom {1 4}} \right. \kern-\nulldelimiterspace} 4}}, improves the lower bound of \Omega (\sqrt n) shown by Razborov [Raz02]. For protocols with no restrictions on the number of rounds, we can conclude that the two parties must exchange \Omega (n^{{1 \mathord{\left/ {\vphantom {1 3}} \right. \kern-\nulldelimiterspace} 3}}) qubits. This, however, falls short of the optimal \Omega (\sqrt n) lower bound shown by Razborov [Raz02].Our result is obtained by adapting to the quantum setting the elegant information-theoretic arguments of Bar-Yossef, Jayram, Kumar and Sivakumar [BJKS02b]. Using this method we can show similar lower bounds for the L\infty function considered in [BJKS02b].
FOCS	Deterministic Extractors for Bit-Fixing Sources and Exposure-Resilient Cryptography.	Jesse Kamp,David Zuckerman	2003	We give an efficient deterministic algorithm which extracts \Omega (n^{2\gamma } ) almost-random bits from sources where n^{\frac{1}{2} + \gamma } of the n bits are uniformly random and the rest are fixed in advance. This improves on previous constructions which required that at least n/2 of the bits be random. Our construction also gives explicit adaptive exposure-resilient functions and in turn adaptive all-or-nothing transforms. For sources where instead of bits the values are chosen from [d], for d > 2, we give an algorithm which extracts a constant fraction of the randomness. We also give bounds on extracting randomness for sources where the fixed bits can depend on the random bits..
FOCS	Approximation Algorithms for Asymmetric TSP by Decomposing Directed Regular Multigraphs.	Haim Kaplan,Moshe Lewenstein,Nira Shafrir,Maxim Sviridenko	2003	"A directed multigraph is said to be d-regular if the indegree and outdegree of every vertex is exactly d. By Hall's theorem one can represent such a multigraph as a combinationof at most n2 cycle covers each taken with an appropriate multiplicity. We prove that if the d-regular multigraph does not contain more than \left\lfloor {{d \mathord{\left/ {\vphantom {d 2}} \right. \kern-\nulldelimiterspace} 2}} \right\rfloor copies of any 2-cycle then we can find a similar decomposition into 0(n2) pairs of cycle covers where each 2-cycle occurs in at most one component of each pair. Our proof is construtive and gives a polynomial algorithm to .nd such a decomposition. Since our applications only need one such a pair of cycle covers whose weight is at least the average weight of all pairs, we also give a simpler algorithm to extract a single such pair.This combinatorial theorem then comes handy in rounding a fractional solution of an LP relaxation of the maximum and minimum TSP problems. For maximum TSP, we obtain a tour whose weight is at least 2/3 of the weight of the longest tour, improving a previous 5/8 approximation. For minimum TSP we obtain a tour whose weight is at most 0.842log2n times the optimal, improving a previous 0.999log2n approximation. Utilizing a reduction from maximum TSP to the shortest superstring problem we obtain a 2.5-approximation algorithm for the latter problem which is again much simpler than the previous one. Other applications of the rounding procedure are approximation algorithms for maximum 3-cycle cover (factor 2/3, previously 3/5) and maximum asymmetric TSP with triangle inequality (factor 10/13, previously 3/4)."
FOCS	Gossip-Based Computation of Aggregate Information.	David Kempe,Alin Dobra,Johannes Gehrke	2003	"Over the last decade, we have seen a revolution in connectivity between computers, and a resulting paradigm shift from centralized to highly distributed systems. With massive scale also comes massive instability, as node and link failures become the norm rather than the exception. For such highly volatile systems, decentralized gossip-based protocols are emerging as an approach to maintaining simplicity and scalability while achieving fault-tolerant information dissemination.In this paper, we study the problem of computing aggregates with gossip-style protocols. Our first contribution is an analysis of simple gossip-based protocols for the computations of sums, averages, random samples, quantiles, and other aggregate functions, and we show that our protocols converge exponentially fast to the true answer when using uniform gossip.Our second contribution is the definition of a precise notion of the speed with which a node's data diffuses through the network. We show that this diffusion speed is at the heart of the approximation guarantees for all of the above problems. We analyze the diffusion speed of uniform gossip in the presence of node and link failures, as well as for flooding-based mechanisms. The latter expose interesting connections to random walks on graphs."
FOCS	Hardness of Approximating the Shortest Vector Problem in High Lp Norms.	Subhash Khot	2003	We show that for every \varepsilon > 0, there is a constant p(\varepsilon) such that for all integers p \geqslant p(\varepsilon), it is NP-hard to approximate the Shortest Vector Problem in Lp norm within factor p^{1 - \varepsilon } under randomized reductions. For large values of p, this improves the factor 2^{{1 \mathord{\left/ {\vphantom {1 p}} \right. \kern-\nulldelimiterspace} p}}- \delta hardness shown by Micciancio.
FOCS	The Value of Knowing a Demand Curve: Bounds on Regret for Online Posted-Price Auctions.	Robert D. Kleinberg,Frank Thomson Leighton	2003	The Value of Knowing a Demand Curve: Bounds on Regret for Online Posted-Price Auctions.
FOCS	Towards a Characterization of Truthful Combinatorial Auctions.	"Ron Lavi,Ahuva Mu'alem,Noam Nisan"	2003	"This paper analyzes incentive compatible (truthful) mechanisms over restricted domains of preferences, the leading example being combinatorial auctions. Our work generalizes the characterization of Roberts (1979) who showed that truthful mechanisms over unrestricted domains with at least 3 possible outcomes must be ""affine maximizers"". We show that truthful mechanisms for combinatorial auctions (and related restricted domains) must be ""almost affine maximizers"" if they also satisfy an additional requirement of ""independence of irrelevant alternatives"". This requirement is without loss of generality for unrestricted domains as well as for auctions between two players where all goods must be allocated. This implies unconditional results for these cases, including a new proof of Roberts' theorem. The computational implications of this characterization are severe, as reasonable ""almost affine maximizers"" are shown to be as computationally hard as exact optimization. This implies the near-helplessness of such truthful polynomial-time auctions in all cases where exact optimization is computationally intractable."
FOCS	General Composition and Universal Composability in Secure Multi-Party Computation.	Yehuda Lindell	2003	"Concurrent general composition relates to a setting where a secure protocol is run in a network concurrently with other, arbitrary protocols. Clearly, security in such a setting is what is desired, or even needed, in modern computer networks where many different protocols are executed concurrently. Canetti (FOCS 2001) introduced the notion of universal composability, and showed that security under this definition is sufficient for achieving concurrent generalcomposition. However, it is not known whether or not the opposite direction also holds.Our main result is a proof that security under concurrent general composition is equivalent to a relaxed variant of universal composability (where the only difference relates to the order of quantifiers in the definition). An important corollary of this theorem is that existing impossibilityresults for universal composability (or actually its relaxed variant) are inherent in any definition achieving security under concurrent general composition. In particular, there are large classes of two-party functionalities for which it is impossible to obtain protocols (in the plain model) thatremain secure under concurrent general composition. We stress that the impossibility results obtained are not ""blackbox"", and apply even to non-black-box simulation.Our main result also demonstrates that the definition of universal composability is somewhat ""minimal"", in that the composition guarantee provided by universal composability(almost) implies the definition itself. This indicates that the security definition of universal composability is not overly restrictive."
FOCS	The Ising Model on Trees: Boundary Conditions and Mixing Time.	Fabio Martinelli,Alistair Sinclair,Dror Weitz	2003	We give the first comprehensive analysis of the effect of boundary conditions on the mixing time of the Glauber dynamics for the Ising model. Specifically, we show that the mixing time on an n-vertex regular tree with (+) boundary remains 0(n log n) at all temperatures (in contrast to the free boundary case, where the mixing time is not bounded by any fixed polynomial at low temperatures). We also show that this bound continues to hold in the presence of an arbitrary external field. Our results are actually stronger, and provide tight bounds on the log-Sobolev constant and the spectral gap of the dynamics. In addition, our methods yield simpler proofs and stronger results for the mixing time in the regime where it is insensitive to the boundary condition. Our techniques also apply to a much wider class of models, including those with hard constraints like the antiferromagnetic Potts model at zero temperature (colorings) and the hard-core model (independent sets).
FOCS	Simulated Annealing in Convex Bodies and an 0*(n4) Volume Algorithm.	László Lovász,Santosh Vempala	2003	"We present a new algorithm for computing the volume of a convex body in \mathbb{R}^n. The main ingredient of the algorithm is a ""morphing"" technique that can be viewed as a variant of simulated annealing. Its complexity is 0*(n4), improving on the previous best algorithm by a factor of n."
FOCS	Logconcave Functions: Geometry and Efficient Sampling Algorithms	László Lovász,Santosh Vempala	2003	"The class of logconcave functions in \mathbb{R}^n is a common generalization of Gaussians and of indicator functions of convex sets. Motivated by the problem of sampling from a logconcave density function, we study their geometry and introduce an analysis technique for ""smoothing"" them out. This leads to efficient sampling algorithms with no assumptions on the local smoothness of the density function. After appropriate preprocessing, both the ball walk (with a Metropolis filter) and a generalization of hit-and-run produce a point from approximately the right distribution in time 0*(n4 and in amortized time 0*(n3 if many sample points are needed (where the asterisk indicates that dependence on the error parameter and factors of log n are not shown). The bounds are optimal in terms of a ""roundness"" parameter and match the best-known bounds for the special case of the uniform density over a convex set."
FOCS	Zero-Knowledge Sets.	Silvio Micali,Michael O. Rabin,Joe Kilian	2003	"We show how a polynomial-time prover can commit to an arbitrary finite set S of strings so that, later on, he can, for any string x, reveal with a proof whether x \in S or x \notin S, without revealing any knowledge beyond the verity of these membership assertions.Our method is non interactive. Given a public random string, the prover commits to a set by simply posting a short and easily computable message. After that, each time it wants to prove whether a given element is in the set, it simply posts another short and easily computable proof, whose correctness can be veri.ed by any one against the public random string.Our scheme is very ef.cient; no reasonable prior way to achieve our desiderata existed. Our new primitive immediately extends to providing zero-knowledge ""databases."""
FOCS	On Certain Connectivity Properties of the Internet Topology.	Milena Mihail,Christos H. Papadimitriou,Amin Saberi	2003	We show that random graphs in the preferential connectivity model have constant conductance, and hence have worst-case routing congestion that scales logarithmically with the number of nodes. Another immediate implication is constant spectral gap between the first and second eigenvalues of the random walk matrix associated with these graphs. We also show that the expected frugality (overpayment in the Vickrey-Clarke-Groves mechanism for shortest paths) of a random graph is bounded by a small constant.
FOCS	The Resolution Complexity of Random Constraint Satisfaction Problems.	Michael Molloy,Mohammad R. Salavatipour	2003	We consider random instances of constraint satisfaction problems where each variable has domain size $d$ and each constraint contains $t$ restrictions on $k$ variables. For each $(d,k,t)$ we determine whether the resolution complexity is a.s. constant, polynomial, or exponential in the number of variables. For a particular range of $(d,k,t)$, we determine a sharp threshold for resolution complexity where the resolution complexity drops from a.s. exponential to a.s. polynomial when the clause density passes a specific value.
FOCS	Always Good Turing: Asymptotically Optimal Probability Estimation.	Alon Orlitsky,Narayana P. Santhanam,Junan Zhang	2003	While deciphering the German Enigma code during World War II, I.J. Good and A.M. Turing considered the problem of estimating a probability distribution from a sample of data. THey derived a surprising and unintuitive formula that has since been used in a variety of applications and studied by a number of researchers. Borrowing an information-theoretic and machine-learning framework, we define the attenuation of a probability estimator as the largest possible ratio between the per-symbol probability assigned to an arbitrarily-long sequence by any distribution, and the corresponding probability assigned by the estimator. We show that some common estimators have infinite attenuation and that the attenuation of the Good-Turing estimator is low, yet large than one. We then derive an estimator whose attenuation is one, namely, as the length of any sequence increases, the per-symbol probability assigned by the estimator is at least the highest possible. Interestingly, some of the proofs use celebrated results by Hardy and Ramanujan on the number of partitions of an integer. To better understand the behavior of the estimator, we study the probability it assigns to several simple sequences. We show that some sequences this probability agrees with our intuition, while for others it is rather unexpected.
FOCS	On e-Biased Generators in NC0.	Elchanan Mossel,Amir Shpilka,Luca Trevisan	2003	Cryan and Miltersen [7] recently considered the question of whether there can be a pseudorandom generator in NC0, that is, a pseudorandom generator that maps n bits strings to m bits strings and such that every bit of the output depends on a constant number k of bits of the seed.They show that for k = 3, if m ¿ 4n + 1, there is a distinguisher; in fact, they show that in this case it is possible to break the generator with a linear test, that is, there is a subset of bits of the output whose XOR has a noticeable bias.They leave the question open for k ¿ 4. In fact they ask whether every NC0 generator can be broken by a statistical test that simply XORs some bits of the input. Equivalently, is it the case that no NC0 generator can sample an ¿-biased space with negligible ¿?We give a generator for k = 5 that maps n bits into cn bits, so that every bit of the output depends on 5 bits of the seed, and the XOR of every subset of the bits of the output has bias 2^{ - \Omega ({n \mathord{\left/ {\vphantom {n {c^4 )}}} \right. \kern-\nulldelimiterspace} {c^4 )}}} . For large values of k, we construct generators that map n bits to n^{\Omega (\sqrt {k)} } bits and such that every XOR of outputs has bias 2^{ - n^{\frac{1}{{2\sqrt k }}} }.We also present a polynomial-time distinguisher for k = 4,m ¿ 24n having constant distinguishing probability. For large values of k we show that a linear distinguisher with a constant distinguishing probability exists once m \geqslant \Omega (2^k n^{\left\lceil {{k \mathord{\left/{\vphantom {k 2}} \right.\kern-\nulldelimiterspace} 2}} \right\rceil } ).Finally, we consider a variant of the problem where each of the output bits is a degree k polynomial in the inputs. We show there exists a degree k = 2 pseudo random generator for which the XOR of every subset of the outputs has bias 2^{ - \Omega (n)} and which map n bits to \Omega (n^2 ) bits.
FOCS	Group Strategyproof Mechanisms via Primal-Dual Algorithms.	Martin Pál,Éva Tardos	2003	Group Strategyproof Mechanisms via Primal-Dual Algorithms.
FOCS	Proofs of the Parisi and Coppersmith-Sorkin Conjectures for the Finite Random Assignment Problem.	Chandra Nair,Balaji Prabhakar,Mayank Sharma	2003	"Suppose that there are n jobs and n machines and it costs cij to execute job i on machine j. The assignment problem concerns the determination of a one-to-one assignment of jobs onto machines so as to minimize the cost of executing all the jobs. The average case analysis of the classical random assignment problem has received a lot of interest in the recent literature, mainly due to the following pleasing conjecture of Parisi: The average value of the minimum-cost permutation in an n × n matrix with i.i.d. exp(1) entries equals \sum\nolimits_{i = 1}^n {\frac{1}{{i^2 }}}. Coppersmith and Sorkin (1999) have generalized Parisi's conjecture to the average value of the smallest k-assignment when there are n jobs and m machines. We prove both conjectures based on a common set of combinatorial and probabilistic arguments."
FOCS	Bounded-Concurrent Secure Two-Party Computation in a Constant Number of Rounds.	Rafael Pass,Alon Rosen	2003	We consider the problem of constructing a general protocol for secure two-party computation in a way that preserves security under concurrent composition. In our treatment,we focus on the case where an a-priori bound on the number of concurrent sessions is specified before the protocol is constructed (a.k.a. bounded concurrency). We make no set-up assumptions.Lindell (STOC 2003) has shown that any protocol for bounded-concurrent secure two-party computation, whose security is established via black-box simulation, must have round complexity that is strictly larger than the bound on the number of concurrent sessions. In this paper, we construct a (non black-box) protocol for realizing bounded-concurrent secure two-party computation in a constant number of rounds. The only previously known protocol for realizing the above task required more rounds than the pre-specified bound on the number of sessions (despite usage of non black-box simulation techniques).Our constructions rely on the existence of enhanced trap-door permutations, as well as on the existence of hash functions that are collision-resistant against subexponential sized circuits.
FOCS	Mixing.	Dana Randall	2003	"In this tutorial, we introduce the notion of a Markov chain and explore how it can be used to sample from a large set of configurations. Our primary focus is determining how quickly a Markov chain ""mixes,"" or converges to its stationary distribution, as this is the key factor in the running time. We provide an overview of several techniques used to establish good bounds on the mixing time. The applications are mostly chosen from statistical physics, although the methods are much more general."
FOCS	Solving Sparse, Symmetric, Diagonally-Dominant Linear Systems in Time 0(m).	Daniel A. Spielman,Shang-Hua Teng	2003	"We present a linear-system solver that, given an n-by-n symmetric positive semi-definite, diagonally dominant matrix A with m non-zero entries and an n-vector b, produces a vector \tilde x within relative distance \varepsilon of the solution to Ax = b in time 0(m^{1.31} \log ({n \mathord{\left/ {\vphantom {n \varepsilon }} \right. \kern-\nulldelimiterspace} \varepsilon })b^{0(1)}), where b is the log of the ratio of the largest to smallest non-zero entry of A. If the graph of A has genus m^{2\theta } or does not have a K_{m\theta} minor, then the exponent of m can be improved to the minimum of 1 + 5\theta and (9/8)(1 + \theta ). The key contribution of our work is an extension of Vaidya's techniques for constructing and analyzing combinatorial preconditioners."
FOCS	List-Decoding Using The XOR Lemma.	Luca Trevisan	2003	"We show that Yao's XOR Lemma, and its essentially equivalent rephrasing as a Direct Product Lemma, can be re-interpreted as a way of obtaining error-correcting codes with good list-decoding algorithms from error-correcting codes having weak unique-decoding algorithms. To get codes with good rate and efficient list decoding algorithms one needs a proof of the Direct Product Lemma that, respectively, is strongly derandomized, and uses very small advice.We show how to reduce advice in Impagliazzo's proof of the Direct Product Lemma for pairwise independent inputs, which leads to error-correcting codes with O(n2) encoding length, \bar 0(n^2 ) encoding time, and probabilistic \bar 0(n) list-decoding time. (Note that the decoding time is sub-linear in the length of the encoding.)Back to complexity theory, our advice-efficient proof of Impagliazzo's ""hard-core set"" results yields a (weak) uniform version of O'Donnell results on amplification of hardness in NP. We show that if there is a problem in NP that cannot be solved by BPP algorithms on more than a 1 - 1/(log n)c fraction of inputs, then there is a problem in NP that cannot be solved by BPP algorithms on more than a 3/4+1/(logn)c fraction of inputs, where c > 0 is an absolute constant."
FOCS	Performance Analysis of Dynamic Network Processes.	Eli Upfal	2003	This tutorial covers various approaches for modeling and analyzing dynamic processes in networks. Modeling the dynamic performance as a stochastic process, we apply tools from discrete and continues time Markov processes theory, renewal theory and queueing theory to analyze the long term, steady state, performance of the processes. Non-stochastic approaches include adversarial queueing theory, and game theory techniques.
FOCS	44th Symposium on Foundations of Computer Science (FOCS 2003), 11-14 October 2003, Cambridge, MA, USA, Proceedings		2003	44th Symposium on Foundations of Computer Science (FOCS 2003), 11-14 October 2003, Cambridge, MA, USA, Proceedings
SODA	The set-associative cache performance of search trees.	James D. Fix	2003	We consider the costs of access to data stored in search trees assuming that those memory accesses are managed with a cache. Our cache memory model is two-level, has a small degree of set-associativity, and uses LRU replacement, and we consider the number of cache misses that a set of accesses incurs. For standard tree access--searches and traversals---changing the degree of set-associativity has no effect on performance.To explain this, we develop general stochastic access models, an adaptation of the independent reference model (IRM), and analyze the expected number of cache hits and misses incurred by these types of access. The models and analyses are accurate: we are able to exactly predict the cache performance of tree data structures. In addition, we prove why set-associativity is of little or no benefit for these types of memory access and give examples where direct-mapping performs better than set-associativity.
SODA	Smaller explicit superconcentrators.	Noga Alon,Michael R. Capalbo	2003	We present an explicit construction of an infinite family of N-superconcentrators of density 44. The most economical previously known explicit graphs of this type have density around 60.
SODA	Labeling schemes for small distances in trees.	Stephen Alstrup,Philip Bille,Theis Rauhe	2003	We consider labeling schemes for trees, supporting various relationships between nodes at small distance. For instance, we show that given a tree T and an integer k we can assign labels to each node of T such that given the label of two nodes we can decide, from these two labels alone, if the distance between v and w is at most k and, if so, compute it. For trees with n nodes and $k\geq 2$, we give a lower bound on the maximum label length of $\log n + \Omega(\log \log n)$ bits, and for constant k, we give an upper bound of log n + O(log log n). Bounds for ancestor, sibling, connectivity, and bi- and triconnectivity labeling schemes are also presented.
SODA	Matching planar maps.	Helmut Alt,Alon Efrat,Günter Rote,Carola Wenk	2003	The subject of this paper are algorithms for measuring the similarity of patterns of line segments in the plane, a standard problem in, e.g., computer vision, geographic information systems, etc. More precisely, we define feasible distance measures that reflect how close a given pattern H is to some part of a larger pattern G. These distance measures are generalizations of the well-known Fréchet distance for curves. We first give an efficient algorithm for the case that H is a polygonal curve and G is a geometric graph. Then, slightly relaxing the definition of distance measure, we give an algorithm for the general case where both, H and G, are geometric graphs.
SODA	Optimal parallel selection.	Yijie Han	2003	We present an optimal parallel selection algorithm on the EREW PRAM. This algorithm runs in O(log n) time with n/log n processors. This complexity matches the known lower bound for parallel selection on the EREW PRAM model. We therefore close this problem which has been open for more than a decade.
SODA	Data migration to minimize the average completion time.	Yoo Ah Kim	2003	Data migration to minimize the average completion time.
SODA	Inplace 2D matching in compressed images.	Amihood Amir,Gad M. Landau,Dina Sokol	2003	The compressed matching problem is the problem of finding all occurrences of a pattern in a compressed text. In this paper we discuss the 2-dimensional compressed matching problem in Lempel-Ziv compressed images. Given a pattern P of (uncompressed) size m × m, and a text T of (uncompressed) size n × n, both in 2D-LZ compressed form, our algorithm finds all occurrences of P in T. The algorithm is strongly inplace, that is, the amount of extra space used is proportional to the best possible compression of a pattern of size m2. The best compression that the 2D-LZ technique can obtain for a file of size m2 is O(m). The time for performing the search is O(n2) and the preprocessing time is O(m3). Our algorithm is general in the sense that it can be used for any 2D compression which can be sequentially decompressed in small space.
SODA	Competitive queueing policies for QoS switches.	Nir Andelman,Yishay Mansour,An Zhu	2003	We consider packet scheduling in a network providing differentiated services, where each packet is assigned a value. We study various queueing models for supporting QoS (Quality of Service). In the nonpreemptive model, packets accepted to the queue will be transmitted eventually and cannot be dropped. The FIFO preemptive model allows packets accepted to the queue to be preempted (dropped) prior to their departure, while ensuring that transmitted packets are sent in the order of arrival. In the bounded delay model, packets must be transmitted before a certain deadline, otherwise it is lost (while transmission ordering is allowed to be arbitrary). In all models the goal of the buffer policy is to maximize the total value of the accepted packets.Let &alpha; be the ratio between the maximal and minimal value. For the non-preemptive model we derive a &Theta;(log &alpha) competitive ratio, both exhibiting a buffer policy and a general lower bound. For the interesting case of two distinct values, we give an 2&alpha;--1/&alpha; competitive buffer policy, which exactly matches the lower bound. We also analyze a RED-like policy and derive its competitive ratio, which is approximately 2&alpha;--0.5/&alpha; for two values and &Theta;(log &alpha;) for multiple values. In addition we improve the previous known lower and upper bounds of the Fixed Partition and Flexible Partition policies.For the FIFO preemptive model, we improve the general lower bound and show a tight bound for the special case of queue size 2. We prove that the bounded delay model with uniform delay 2 is equivalent to a modified FIFO preemptive model with queue size 2. We then give improved upper and lower bounds on the 2-uniform bounded delay model. We also give lower bound for the 2-variable bounded delay model, which matches the previously known upper bound.
SODA	Dynamic routing on networks with fixed-size buffers.	William Aiello,Rafail Ostrovsky,Eyal Kushilevitz,Adi Rosén	2003	The combination of the buffer size of routers deployed in the Internet and the Internet traffic itself leads routinely to routers dropping packets. Motivated by this, we initiate the rigorous study of dynamic store-and-forward routing on arbitrary networks in a model in which dropped packets must explicitly be taken into account. To avoid the uncertainties of traffic modeling, we consider arbitrary traffic on the network. We analyze and compare the effectiveness of several greedy, on-line, local-control protocols using a competitive analysis of the throughput. One goal of our approach is for the competitive results to continue to hold as a network grows without requiring the memory in the nodes to increase with the size of the network. Thus, in our model, we have link buffers of fixed size, B, which is independent of the size of the network, and B becomes a parameter of the model.Our results are in contrast to another adversarial traffic model known as Adversarial Queuing Theory (AQT), which studies the stability and growth rate of queues as a function of the network and traffic parameters. For example, in AQT the Furthest-To-Go (FTG) protocol is stable for all networks whereas Nearest-To-Go (NTG) can be unstable for some networks. Unlike AQT, in our setting NTG is preferable to FTG: we show that the NTG protocol is throughput-competitive on all networks whereas the FTG protocol has unbounded competitiveness whenever a network contains even small cycles.
SODA	Dynamic TCP acknowledgement: penalizing long delays.	Susanne Albers,Helge Bals	2003	"We study the problem of acknowledging a sequence of data packets that are sent across a TCP connection. Previous work on the problem has focused mostly on the objective function that minimizes the sum of the number of acknowledgments sent and on the delays incurred for all of the packets. Dooly, Goldman, and Scott presented a deterministic $2$-competitive online algorithm and showed that this is the best competitiveness of a deterministic strategy. Recently Karlin, Kenyon, and Randall developed a randomized online algorithm that achieves an optimal competitive ratio of $e/(e-1) \approx 1.58$.In this paper we investigate a new objective function that minimizes the sum of the number of acknowledgments sent and the maximum delay incurred for any of the packets. This function is especially interesting if a TCP connection is used for interactive data transfer between network nodes. The TCP acknowledgment problem with this new objective function is different in structure than the problem with the function considered previously. We develop a deterministic online algorithm that achieves a competitive ratio of $\pi^2/6 \approx 1.644$ and prove that no deterministic algorithm can have a smaller competitiveness. We also study a generalized objective function where delays are taken to the $p$th power for some positive integer $p$. Again we give tight upper and lower bounds on the best possible competitive ratio of deterministic online algorithms. The competitiveness is 1 plus an alternating sum of Riemann's zeta function and tends to 1.5 as $p\rightarrow \infty$. Finally, we consider randomized online algorithms and show that, for our first objective function, no randomized strategy can achieve a competitive ratio smaller than $3/(3 - 2/e)\approx 1.324$. For the generalized objective function we show a lower bound of $2/(2-1/e) \approx 1.225$."
SODA	Lower bounds for embedding edit distance into normed spaces.	Alexandr Andoni,Michel Deza,Anupam Gupta,Piotr Indyk,Sofya Raskhodnikova	2003	Lower bounds for embedding edit distance into normed spaces.
SODA	An approximate truthful mechanism for combinatorial auctions with single parameter agents.	Aaron Archer,Christos H. Papadimitriou,Kunal Talwar,Éva Tardos	2003	"Mechanism design seeks algorithms whose inputs are provided by selfish agents who would lie if advantageous. Incentive compatible mechanisms compel the agents to tell the truth by making it in their self-interest to do so. Often, as in combinatorial auctions, such mechanisms involve the solution of NP-hard problems. Unfortunately, approximation algorithms typically destroy incentive compatibility. Randomized rounding is a commonly used technique for designing approximation algorithms. We devise a version of randomized rounding that is incentive compatible, giving a truthful mechanism for combinatorial auctions with single parameter agents (e.g., ""single minded bidders"") that approximately maximizes the social value of the auction. We discuss two orthogonal notions of truthfulness for a randomized mechanism, truthfulness with high probability and in expectation, and give a mechanism that achieves both simultaneously.We consider combinatorial auctions where multiple copies of many different items are on sale, and each bidder i desires a subset Si. Given a set of bids, the problem of finding the allocation of items that maximizes total valuation is the well-known SETPACKING problem. This problem is NP-hard, but for the case of items with many identical copies the optimum can be approximated very well. To turn this approximation algorithm into a truthful auction mechanism we overcome two problems: we show how to make the allocation algorithm monotone, and give a method to compute the appropriate payments efficiently."
SODA	Faster approximation algorithms for the minimum latency problem.	Aaron Archer,David P. Williamson	2003	In this paper, we give a 9.28-approximation algorithm for the minimum latency problem that uses only O(n log n) calls to the prize-collecting Steiner tree (PCST) subroutine of Goemans and Williamson. A previous algorithm of Goemans and Kleinberg for the minimum latency problem requires an approximation algorithm for the k-MST problem which is called as a black box. Their algorithm can achieve a performance guarantee of 10.77 while making O(n2 log n) PCST calls (via a k-MST algorithm of Garg), or a performance guarantee of 7.18 + &epsilon; while using nO(1/&epsilon;) PCST calls (via a k-MST algorithm of Arora and Karakostas). In order to match our approximation ratio (i.e. setting &epsilon; = 2.10), the latter version requires O(n5 log2 n) PCST calls, so our running time bound is faster by a factor of &Theta;(n4 log n). Since PCST can be implemented to run in O(n2) time, the overall running time of our algorithm is O(n3 log n).The basic idea for our improvement is that we do not treat the k-MST algorithm as a black box. Thus we are able to take advantage of some situations in which the PCST subroutine delivers a k-MST with an improved performance guarantee.
SODA	Skip graphs.	James Aspnes,Gauri Shah	2003	Skip graphs are a novel distributed data structure, based on skip lists, that provide the full functionality of a balanced tree in a distributed system where elements are stored in separate nodes that may fail at any time. They are designed for use in searching peer-to-peer networks, and by providing the ability to perform queries based on key ordering, they improve on existing search tools that provide only hash table functionality. Unlike skip lists or other tree data structures, skip graphs are highly resilient, tolerating a large fraction of failed nodes without losing connectivity. In addition, constructing, inserting new elements into, searching a skip graph and detecting and repairing errors in the data structure introduced by node failures can be done using simple and straight-forward algorithms.
SODA	Approximation algorithm for embedding metrics into a two-dimensional space.	Mihai Badoiu	2003	In this paper, we present a polynomial-time approximation algorithm for computing an embedding of an arbitrary metric into a two-dimensional space. The algorithm finds an embedding whose additive distortion is at most c&epsilon;*, where &epsilon;* is the smallest additive distortion possible and c is an absolute constant. To our knowledge, this is the first result of this type, i.e., it gives an algorithm that finds (approximately) optimal embedding of a given distance matrix into a fixed d-dimensional space, where d < 1 is low, under any standard definition of embedding (see Related Work).
SODA	Smaller core-sets for balls.	Mihai Badoiu,Kenneth L. Clarkson	2003	Given a set of points P &sub; Rd and value ∊ > 0, an ∊-core-set S &sub; P has the property that the smallest ball containing S is an ∊-approximation of the smallest ball containing P. This paper shows that any point-set has an ∊-core-set of size [2/∊]. We also give a fast algorithm that finds this core-set. These results imply the existence of small core-sets for solving approximate k-center clustering and related problems. The sizes of these core-sets are considerably smaller than the previously known bounds, and imply faster algorithms; one such algorithm needs O(dn/∊ + (l/∊)5) time to compute an ∊-approximate minimum enclosing ball (1-center) of n points in d dimensions. A simple gradient-descent algorithm is also given, for computing the minimum enclosing ball in O(dn/∊2) time. This algorithm also implies slightly faster algorithms for computing approximately the smallest radius k-flat fitting a set of points.
SODA	Minimizing weighted flow time.	Nikhil Bansal,Kedar Dhamdhere	2003	"We consider the problem of minimizing weighted flow time on a single machine in the preemptive setting. Our main result is an O(log W) competitive online algorithm where the maximum to the minimum ratio of weights is W. More generally our algorithm achieves a competitive ratio of k if there are k weight classes. This gives the first O(1)-competitive algorithm for constant k. No O(1) competitive algorithm was known previously even for the special case of k = 2. These results settle a question posed by Chekuri et al [5] about the existence of a ""truly"" online algorithm with a non-trivial competitive ratio. We also give a ""semi-online"" algorithm with competitive ratio O(log n + log P), where P is ratio of the maximum to minimum job size. Our second result deals with the non-clairvoyant setting where the job sizes are unknown (but the weight of the jobs are known). We consider the resource augmentation model, and give a non-clairvoyant online algorithm, which if allowed a (1 + &epsilon;) speed-up, is (1 + l/&epsilon;) competitive against an optimal offline, clairvoyant algorithm."
SODA	Scheduling techniques for media-on-demand.	Amotz Bar-Noy,Richard E. Ladner,Tami Tamir	2003	"Broadcasting popular media to clients is the ultimate scalable solution for media-on-demand. Recently, it was shown that if clients can receive data at a rate faster than what they need for playback and if they can store later parts of the media in their buffers, then much higher scalability may be obtained. In the paper we focus on scheduling problems arising from these new systems for media-on-demand.For given amount of bandwidth, we improve the guaranteed start-up delay time for an uninterrupted playback. We achieve our results by introducing two techniques. In the first, the media is arranged on the channels such that clients gain from buffering later parts of the transmission before the actual start of the playback. In the second, segments of different media may be mixed together on the same channel. We introduce a simple class of recursive round-robin scheduling algorithms that implement our techniques.Our results improve the best known asymptotic results. Moreover, our scheduling algorithms outperform known results for ""practical"" values for number of media and number of broadcasting channels. For some specific small values, we present hand designed solutions that are better than those achieved by our algorithms."
SODA	Straight-skeleton based contour interpolation.	Gill Barequet,Michael T. Goodrich,Aya Levi-Steiner,Dvir Steiner	2003	"In this paper we present an efficient method for interpolating a piecewise-linear surface between two parallel slices, each consisting of an arbitrary number of (possibly nested) polygons that define 'material' and 'nonmaterial' regions. This problem has applications to medical imaging, geographic information systems, etc. Our method is fully automatic and is guaranteed to produce non-self-intersecting surfaces in all cases regardless of the number of contours in each slice, their complexity and geometry, and the depth of their hierarchy of nesting. The method is based on computing cells in the overlay of the slices, that form the symmetric difference between them. Then, the straight skeletons of the selected cells guide the triangulation of these cells. Finally, the resulting triangles are lifted up in space to form an interpolating surface. We provide some experimental results on various complex examples to show the good and robust performance of our algorithm."
SODA	Dynamic construction of Bluetooth scatternets of fixed degree and low diameter.	Lali Barrière,Pierre Fraigniaud,Lata Narayanan,Jaroslav Opatrny	2003	Bluetooth is a promising recent radio technology for ad hoc networking. Bluetooth networks are based on connecting together piconets, to form a scatternet. The structure of the scatternet, and the way the scatternet is built and maintained, are not part of the Bluetooth specifications, but have a tremendous impact on the performance of the network. We present an efficient distributed algorithm for Bluetooth scatternet construction. The resulting scatternet is scalable and our construction is dynamic in the sense that nodes can join and leave the network at their convenience. For fixed constant degree of nodes, the resulting diameter is polylogarithmic in the size of the network, and the connectivity of the masters is high. We also give a routing protocol adapted to the specific scatternet topology returned by our algorithm. This protocol does not require complicated path-discovery methods, but is based on a simple virtual labeling of the devices participating in the scatternet.
SODA	Multi-embedding and path approximation of metric spaces.	Yair Bartal,Manor Mendel	2003	"Metric embeddings have become a frequent tool in the design of algorithms. The applicability is often dependent on how high the embedding's distortion is. For example embedding into ultrametrics (or arbitrary trees) requires linear distortion. Using probabilistic metric embeddings, the bound reduces to O(log nlog logn). Yet, the lower bound is still logarithmic.We make a step further in the direction of bypassing this difficulty. We define ""multi-embeddings"" of metric spaces where a point is mapped onto a set of points, while keeping the target metric being of polynomial size and preserving the distortion of paths. The distortion obtained with such multi-embeddings into ultrametrics is at most O(log &Delta; log log &Delta;) where &delta; is the (normalized) diameter, and probabilistically O(log n log log log n). In particular, for expander graphs, we are able to obtain constant distortions embeddings into trees vs. the &Omega;(logn) lower bound for all previous notions of embeddings.We demonstrate the algorithmic application of the new embeddings by obtaining improvements for two well-known problems: group Steiner tree and metrical task systems."
SODA	Maintaining all-pairs approximate shortest paths under deletion of edges.	Surender Baswana,Ramesh Hariharan,Sandeep Sen	2003	We present a hierarchical scheme for efficiently maintaining all-pairs approximate shortest paths in undirected unweighted graphs under deletions of edges.An &alpha;-approximate shortest-path between two vertices is a path of length at-most &alpha; times the length of the shortest path. For maintaining &alpha;-approximate shortest paths for all pairs of vertices separated by distance &le; d in a graph of n vertices, we present the first o(nd) update time algorithm based on our hierarchical scheme. In particular, the update time per edge deletion achieved by our algorithm is &Otilde;(min{&radic;nd,(nd)2/3}) for 3-approximate shortest-paths, and &Otilde;(min{&radic;nd,(nd)4/7}) for 7-approximate shortest-paths. For graphs with &theta;(n2) edges, we achieve even further improvement in update time : &Otilde;(&radic;nd) for 3-approximate shortest-paths, and &Otilde;(3&radic;nd2) for 5-approximate shortest-paths.For maintaining all-pairs approximate shortest-paths, weimprove the previous &Otilde;(n3/2)bound on the update time per edge deletion for approximation factor &ge; 3. In particular, update time achieved by our algorithm is &Otilde;(n10/9) for 3-approximate shortest-paths, &Otilde;(n14/13) for 5-approximate shortest-paths, and &Otilde;(n28/27) for 7-approximate shortest-paths.All our algorithms achieve optimal query time and are simple to implement.
SODA	Optimizing misdirection.	Piotr Berman,Piotr Krysta	2003	"In this paper we consider the following problem. Given a (d + 1)-claw free graph G = (V, E, w) where w : V &rarr; R+, maximize w(A) where A is an independent set in G. Our focus is to minimize the approximation ratio (optimum/obtained) in polynomial time that does not depend on d. Our approach is to apply local improvements of size 2, using a ""misdirected"" criterion, i.e. w&alpha;(A) rather than w(A). We find the optimal value of &alpha; for every d, and the resulting ratio is roughly 0.667d for d = 3, 0.651d for d = 4 and 0.646d for d > 4."
SODA	Möbius-invariant natural neighbor interpolation.	Marshall W. Bern,David Eppstein	2003	Möbius-invariant natural neighbor interpolation.
SODA	Computing homotopic shortest paths in the plane.	Sergei Bespamyatnikh	2003	We address the problem of computing homotopic shortest paths in the presence of obstacles in the plane. Problems on homotopy of paths received attention very recently [Cabello et al., in: Proc. 18th Annu. ACM Sympos. Comput. Geom., 2002, pp. 160-169; Efrat et al., in: Proc. 10th Annu. European Sympos. Algorithms, 2002, pp. 411-423]. We present two output-sensitive algorithms, for simple paths and non-simple paths. The algorithm for simple paths improves the previous algorithm [Efrat et al., in: Proc. 10th Annu. European Sympos. Algorithms, 2002, pp. 411-423]. The algorithm for non-simple paths achieves O(log2n) time per output vertex which is an improvement by a factor of O(n/log2n) of the previous algorithm [Hershberger, Snoeyink, Comput. Geom. Theory Appl. 4 (1994) 63-98], where n is the number of obstacles. The running time has an overhead O(n2+ε) for any positive constant ε. In the case k < n2+ε, where k is the total size of the input and output, we improve the running to O((n + k + (nk)2/3) logO(1) n).
SODA	Compact representations of separable graphs.	Daniel K. Blandford,Guy E. Blelloch,Ian A. Kash	2003	"We consider the problem of representing graphs compactly while supporting queries efficiently. In particular we describe a data structure for representing n-vertex unlabeled graphs that satisfy an O(nc)-separator theorem, c < 1. The structure uses O(n) bits, and supports adjacency and degree queries in constant time, and neighbor listing in constant time per neighbor. This generalizes previous results for graphs with constant genus, such as planar graphs.We present experimental results using many ""real world"" graphs including 3-dimensional finite element meshes, link graphs of the web, internet router graphs, VLSI circuits, and street map graphs. Compared to adjacency lists, our approach reduces space usage by almost an order of magnitude, while supporting depthfirst traversal in about the same running time."
SODA	A new approximation algorithm for the asymmetric TSP with triangle inequality.	Markus Bläser	2003	We present a polynomial time factor 0.999 &cdot; log n approximation algorithm for the asymmetric traveling salesperson problem with triangle inequality.
SODA	Space-efficient finger search on degree-balanced search trees.	Guy E. Blelloch,Bruce M. Maggs,Shan Leung Maverick Woo	2003	"We show how to support the finger search operation on degree-balanced search trees in a space-efficient manner that retains a worst-case time bound of O(log d), where d is the difference in rank between successive search targets. While most existing tree-based designs allocate linear extra storage in the nodes (e.g., for side links and parent pointers), our design maintains a compact auxiliary data structure called the ""hand"" during the lifetime of the tree and imposes no other storage requirement within the tree.The hand requires O(log n) space for an n-node tree and has a relatively simple structure. It can be updated synchronously during insertions and deletions with time proportional to the number of structural changes in the tree. The auxiliary nature of the hand also makes it possible to introduce finger searches into any existing implementation without modifying the underlying data representation (e.g., any implementation of Red-Black trees can be used). Together these factors make finger searches more appealing in practice.Our design also yields a simple yet optimal in-order walk algorithm with worst-case O(1) work per increment (again without any extra storage requirement in the nodes), and we believe our algorithm can be used in database applications when the overall performance is very sensitive to retrieval latency."
SODA	Online learning in online auctions.	Avrim Blum,Vijay Kumar,Atri Rudra,Felix Wu	2003	We consider the problem of revenue maximization in online auctions, that is, auctions in which bids are received and dealt with one-by-one. In this paper, we demonstrate that results from online learning can be usefully applied in this context, and we derive a new auction for digital goods that achieves a constant competitive ratio with respect to the optimal (offline) fixed price revenue. This substantially improves upon the best previously known competitive ratio for this problem of O(exp(√log log h)). We also apply our techniques to the related problem of designing online posted price mechanisms, in which the seller declares a price for each of a series of buyers, and each buyer either accepts or rejects the good at that price. Despite the relative lack of information in this setting, we show that online learning techniques can be used to obtain results for online posted price mechanisms which are similar to those obtained for online auctions.
SODA	On the combinatorial complexity of euclidean Voronoi cells and convex hulls of d-dimensional spheres.	Jean-Daniel Boissonnat,Menelaos I. Karavelas	2003	In this paper we show an equivalence relationship between additively weighted Voronoi cells in Rd, power diagrams in Rd and convex hulls of spheres in Rd. An immediate consequence of this equivalence relationship is a tight bound on the complexity of: (1) a single additively weighted Voronoi cell in dimension d; (2) the convex hull of a set of d-dimensional spheres. In particular, given a set of n spheres in dimension d, we show that the worst case complexity of both a single additively weighted Voronoi cell and the convex hull of the set of spheres is &Theta;(n[d/2]). The equivalence between additively weighted Voronoi cells and convex hulls of spheres permits us to compute a single additively weighted Voronoi cel1 in dimension d in worst case optimal time O(n log n+n[d/2]).
SODA	Directed scale-free graphs.	Béla Bollobás,Christian Borgs,Jennifer T. Chayes,Oliver Riordan	2003	We introduce a model for directed scale-free graphs that grow with preferential attachment depending in a natural way on the in- and out-degrees. We show that the resulting in- and out-degree distributions are power laws with different exponents, reproducing observed properties of the worldwide web. We also derive exponents for the distribution of in- (out-) degrees among vertices with fixed out- (in-) degree. We conclude by suggesting a corresponding model with hidden variables.
SODA	Sparse distance preservers and additive spanners.	Béla Bollobás,Don Coppersmith,Michael Elkin	2003	"For an unweighted graph $G = (V,E)$, $G' = (V,E')$ is a subgraph if $E' \subseteq E$, and $G'' = (V'',E'',\omega)$ is a Steiner graph if $V \subseteq V''$, and for any pair of vertices $u,w \in V$, the distance between them in $G''$ (denoted $d_{G''}(u,w)$) is at least the distance between them in $G$ (denoted $d_G(u,w)$).In this paper we introduce the notion of distance preserver. A subgraph (resp., Steiner graph) $G'$ of a graph $G$ is a subgraph (resp., Steiner) $D$-preserver of $G$ if for every pair of vertices $u,w \in V$ with $d_G(u,w) \ge D$, $d_{G'}(u,w) = d_G(u,w)$. We show that any graph (resp., digraph) has a subgraph $D$-preserver with at most $O(n^2/D)$ edges (resp., arcs), and there are graphs and digraphs for which any undirected Steiner $D$-preserver contains $\Omega(n^2/D)$ edges. However, we show that if one allows a directed Steiner (diSteiner) $D$-preserver, then these bounds can be improved. Specifically, we show that for any graph or digraph there exists a diSteiner $D$-preserver with $O({{n^2 \cdot \log D} \over {D \cdot \log n}})$ arcs, and that this result is tight up to a constant factor.We also study $D$-preserving distance labeling schemes, that are labeling schemes that guarantee precise calculation of distances between pairs of vertices that are at a distance of at least $D$ one from another. We show that there exists a $D$-preserving labeling scheme with labels of size $O({{n} \over {D}} \log^2 n)$, and that labels of size $\Omega({{n} \over {D}} \log D)$ are required for any $D$-preserving labeling scheme."
SODA	Lower bounds for external memory dictionaries.	Gerth Stølting Brodal,Rolf Fagerberg	2003	We study trade-offs between the update time and the query time for comparison based external memory dictionaries. The main contributions of this paper are two lower bound trade offs between the I/O complexity of member queries and insertions: If N < M insertions perform at most &delta; &middot; N/B I/Os, then (1) there exists a query requiring N/(M. &middot;~O(&delta;)) I/Os, and (2) there exists a query requiring &Omega;(log&delta;log2N ~ I/Os when &delta; is O(B/log3 N) and N is at least M2. For both lower bound we describe data structures which give matching upper bounds for a wide range of parameters, thereby showing the lower bounds to be tight within these ranges.
SODA	Quantum property testing.	Harry Buhrman,Lance Fortnow,Ilan Newman,Hein Röhrig	2003	A language $L$ has a property tester if there exists a probabilistic algorithm that given an input $x$ queries only a small number of bits of $x$ and distinguishes the cases as to whether $x$ is in $L$ and $x$ has large Hamming distance from all $y$ in $L$. We define a similar notion of quantum property testing and show that there exist languages with good quantum property testers but no good classical testers. We also show there exist languages which require a large number of queries even for quantumly testing.
SODA	Algorithms for k-colouring and finding maximal independent sets.	Jesper Makholm Byskov	2003	Algorithms for k-colouring and finding maximal independent sets.
SODA	Embedding k-outerplanar graphs into l1.	Chandra Chekuri,Anupam Gupta,Ilan Newman,Yuri Rabinovich,Alistair Sinclair	2003	We show that the shortest-path metric of any $k$-outerplanar graph, for any fixed $k$, can be approximated by a probability distribution over tree metrics with constant distortion and hence also embedded into $\ell_1$ with constant distortion. These graphs play a central role in polynomial time approximation schemes for many NP-hard optimization problems on general planar graphs and include the family of weighted $k\times n$ planar grids. This result implies a constant upper bound on the ratio between the sparsest cut and the maximum concurrent flow in multicommodity networks for $k$-outerplanar graphs, thus extending a theorem of Okamura and Seymour [J. Combin. Theory Ser. B, 31 (1981), pp. 75-81] for outerplanar graphs, and a result of Gupta et al. [Combinatorica, 24 (2004), pp. 233-269] for treewidth-2 graphs. In addition, we obtain improved approximation ratios for $k$-outerplanar graphs on various problems for which approximation algorithms are based on probabilistic tree embeddings. We conjecture that these embeddings for $k$-outerplanar graphs may serve as building blocks for $\ell_1$ embeddings of more general metrics.
SODA	Edge disjoint paths revisited.	Chandra Chekuri,Sanjeev Khanna	2003	The approximability of the maximum edge disjoint paths problem (EDP) in directed graphs was seemingly settled by the &Omega;(m1/2-&epsilon;)-hardness result of Guruswami et al. [10] and the O(&radic;m) approximation achievable via both the natural LP relaxation [19] and the greedy algorithm [11, 12]. Here m is the number of edges in the graph. However, we observe that the hardness of approximation shown in [10] applies to sparse graphs and hence when expressed as a function of n, the number of vertices, only an &Omega;(n1/2-&epsilon;)-hardness follows. On the other hand, the O(&radic;m)-approximation algorithms do not guarantee a sub-linear (in terms of n) approximation algorithm for dense graphs. We note that a similar gap exists in the known results on the integrality gap of the natural LP relaxation: an &Omega;(&radic;n) lower bound and an O(&radic;m) upper bound. Motivated by this discrepancy in the upper and lower bounds we study algorithms for the EDP in directed and undirected graphs obtaining improved approximation ratios. We show that the greedy algorithm has an approximation ratio of O(min(n2/3, &radic;m)) in undirected graphs and a ratio of O(min(n4/5, &radic;m)) in directed graphs. For ayclic graphs we give an O(&radic;n log n) approximation via LP rounding. These are the first sub-linear approximation ratios for EDP. Our results also extend to EDP with weights and to the unsplittable flow problem with uniform edge capacities.
SODA	Graded conforming Delaunay tetrahedralization with bounded radius-edge ratio.	Siu-Wing Cheng,Sheung-Hung Poon	2003	We propose an algorithm to compute a conforming Delaunay mesh of a polyhedral domain. Arbitrarily small input angles are allowed. The output mesh is graded and has bounded radius-edge ratio everywhere.
SODA	Efficient sequences of trials.	Edith Cohen,Amos Fiat,Haim Kaplan	2003	We introduce a problem called sequential trial optimization, a generalization of the well studied set cover problem with a new objective function. We give a simple algorithm that achieves a constant factor approximation to this problem. Sequential trial optimization naturally arises in heterogenous search environments such as peer to peer networks.
SODA	Multidimensional matching and fast search in suffix trees.	Richard Cole,Moshe Lewenstein	2003	We show how to construct a suffix tree of a text string t in linear time, after sorting the characters in the text, so that a search for pattern p take time O(p + log t), independent of the alphabet size, thereby matching the asymptotic performance of suffix arrays. Using these suffix trees or suffix arrays we then give linear time algorithms for pattern matching in any fixed dimension.
SODA	The cover time of sparse random graphs.	Colin Cooper,Alan M. Frieze	2003	We study the cover time of a random walk on graphs G &isin; Gn, p when p = c log n/n, c < 1. We prove that whpthe cover time is asymptotic to c log (c/c--1) n log n.
SODA	Random MAX SAT, random MAX CUT, and their phase transitions.	Don Coppersmith,David Gamarnik,Mohammad Taghi Hajiaghayi,Gregory B. Sorkin	2003	"With random inputs, certain decision problems undergo a &ldquo;phase transition.&rdquo; We prove similar behavior in an optimization context. Given a conjunctive normal form (CNF) formula F on n variables and with m k-variable clauses, denote by max F the maximum number of clauses satisfiable by a single assignment of the variables. (Thus the decision problem k-SAT is to determine if max F is equal to m.) With the formula F chosen at random, the expectation of max F is trivially bounded by (3&#x002F;4)m &les; &Eopf; max F &les; m. We prove that for random formulas with m = &lfloor;cn&rfloor; clauses: for constants c < 1, &Eopf; max F is &lfloor;cn&rfloor; - &Theta;(1&#x002F;n); for large c, it approaches ** equation here ** and in the &ldquo;window&rdquo; c = 1 + &Theta;(n-1&#x002F;3), it is cn - &Theta;(1). Our full results are more detailed, but this already shows that the optimization problem MAX 2-SAT undergoes a phase transition just as the 2-SAT decision problem does, and at the same critical value c = 1. Most of our results are established without reference to the analogous propositions for decision 2-SAT, and can be used to reproduce them. We consider &ldquo;online&rdquo; versions of MAX 2-SAT, and show that for one version the obvious greedy algorithm is optimal; all other natural questions remain open. We can extend only our simplest MAX 2-SAT results to MAX k-SAT, but we conjecture a &ldquo;MAX k-SAT limiting function conjecture&rdquo; analogous to the folklore &ldquo;satisfiability threshold conjecture,&rdquo; but open even for k = 2. Neither conjecture immediately implies the other, but it is natural to further conjecture a connection between them. We also prove analogous results for random MAX CUT. &copy; 2004 Wiley Periodicals, Inc. Random Struct. Alg., 2004"
SODA	Random walks on the vertices of transportation polytopes with constant number of sources.	Mary Cryan,Martin E. Dyer,Haiko Müller,Leen Stougie	2003	We consider the problem of uniformly sampling a vertex of a transportation polytope with m sources and n destinations, where m is a constant. We analyse a natural random walk on the edge-vertex graph of the polytope. The analysis makes use of the multicommodity flow technique of Sinclair [20] together with ideas developed by Morris and Sinclair [15, 16] for the knapsack problem, and Cryan et al. [2] for contingency tables, to establish that the random walk approaches the uniform distribution in time nO(m2).
SODA	Chain decompositions and independent trees in 4-connected graphs.	Sean Curran,Orlando Lee,Xingxing Yu	2003	"This work was motivated by the study of a multitree approach to reliability in distributed networks and by the study of non-separating paths and cycles in highly connected graphs. We first give a result on ""non-separating chains"" in 4-connected graphs. This result is then used to obtain a ""non-separating chain decomposition"" of a 4-connected graph G, and an O(&verbar;V(G)&verbar;2&verbar;E(G)&verbar;) algorithm for constructing such a decomposition. As an application of this decomposition, we show how to produce four ""independent spanning trees"" in a 4-connected graph in O(&verbar;V(G)&verbar;3) time."
SODA	Sublinear-time approximation of Euclidean minimum spanning tree.	Artur Czumaj,Funda Ergün,Lance Fortnow,Avner Magen,Ilan Newman,Ronitt Rubinfeld,Christian Sohler	2003	We consider the problem of finding the weight of a Euclidean minimum spanning tree for a set of n points in ℝd. We focus on the situation when the input point set is supported by certain basic (and commonly used) geometric data structures that can provide efficient access to the input in a structured way. We present an algorithm that estimates with high probability the weight of a Euclidean minimum spanning tree of a set of points to within 1 + &epsilon; using only &Otilde;(&radic; poly(1/&epsilon;)) queries for constant d. The algorithm assumes that the input is supported by a minimal bounding cube enclosing it, by orthogonal range queries, and by cone approximate nearest neighbors queries.
SODA	Quantum algorithms for some hidden shift problems.	Wim van Dam,Sean Hallgren,Lawrence Ip	2003	Almost all of the most successful quantum algorithms discovered to date exploit the ability of the Fourier transform to recover subgroup structures of functions, especially periodicity. The fact that Fourier transforms can also be used to capture shift structure has received far less attention in the context of quantum computation. In this paper, we present three examples of &ldquo;unknown shift&rdquo; problems that can be solved efficiently on a quantum computer using the quantum Fourier transform. For one of these problems, the shifted Legendre symbol problem, we give evidence that the problem is hard to solve classically, by showing a reduction from breaking algebraically homomorphic cryptosystems. We also define the hidden coset problem, which generalizes the hidden shift problem and the hidden subgroup problem. This framework provides a unified way of viewing the ability of the Fourier transform to capture subgroup and shift structure.
SODA	Perturbations and vertex removal in a 3D delaunay triangulation.	Olivier Devillers,Monique Teillaud	2003	Though Delaunay triangulations are very well known geometric data structures, the problem of the robust removal of a vertex in a three-dimensional Delaunay triangulation is still a problem in practice.We propose a simple method that allows to remove any vertex even when the points are in very degenerate configurations. The solution is available in CGAL.
SODA	Certifying and repairing solutions to large LPs how good are LP-solvers?	Marcel Dhiflaoui,Stefan Funke,Carsten Kwappik,Kurt Mehlhorn,Michael Seel,Elmar Schömer,Ralph Schulte,Dennis Weber	2003	State-of-the-art linear programming (LP) solvers give solutions without any warranty. Solutions are not guaranteed to be optimal or even close to optimal. Of course, it is generally believed that the solvers produce optimal or at least close to optimal solutions.We have implemented a system LPex which allows us to check this belief. More precisely, given an LP and a basis B, it determines whether the basis is primal feasible and/or dual feasible. It can also find the optimum starting from an arbitrary basis (or from scratch). It uses exact arithmetic to guarantee correctness of the results. The system is efficient enough to be applied to medium- to large-scale LPs. We present results from the netlib benchmark suite.
SODA	Who cares about permanents?	Persi Diaconis	2003	Who cares about permanents?
SODA	Non-independent randomized rounding.	Benjamin Doerr	2003	We investigate an extension of the randomized rounding technique introduced by Raghavan and Thompson. Whereas their approach only requires that each variable is rounded with probabilities given by its fractional part, we also impose this condition on several sums of variables. Thus in particular our roundings are not independent.We show that such non-independent randomized roundings exist if and only if the hypergraph corresponding to these dependencies is totally unimodular.
SODA	Pass efficient algorithms for approximating large matrices.	Petros Drineas,Ravi Kannan	2003	Pass efficient algorithms for approximating large matrices.
SODA	Fast distributed algorithms for (weakly) connected dominating sets and linear-size skeletons.	Devdatt P. Dubhashi,Alessandro Mei,Alessandro Panconesi,Jaikumar Radhakrishnan,Aravind Srinivasan	2003	"Motivated by routing issues in ad hoc networks, we present polylogarithmic-time distributed algorithms for two problems. Given a network, we first show how to compute connected and weakly connected dominating sets whose size is at most O(log@D) times the optimum, @D being the maximum degree of the input network. This is best-possible if NP@?DTIME[n^O^(^l^o^g^l^o^g^n^)] and if the processors are required to run in polynomial-time. We then show how to construct dominating sets that have the above properties, as well as the ''low stretch'' property that any two adjacent nodes in the network have their dominators at a distance of at most O(logn) in the output network. (Given a dominating set S, a dominator of a vertex u is any v@?S such that the distance between u and v is at most one.) We also show our time bounds to be essentially optimal."
SODA	An approximation algorithm for cutting out convex polygons.	Adrian Dumitrescu	2003	We provide an O(logn)-approximation algorithm for the following problem. Given a convex n-gon P, drawn on a convex piece of paper, cut P out of the piece of paper in the cheapest possible way. No polynomial-time approximation algorithm was known for this problem posed in 1985.
SODA	A combinatorial algorithm for computing a maximum independent set in a t-perfect graph.	Friedrich Eisenbrand,Stefan Funke,Naveen Garg,Jochen Könemann	2003	We present a combinatorial polynomial time algorithm to compute a maximum stable set of a t-perfect graph. The algorithm rests on an &epsilon;-approximation algorithm for general set covering and packing problems and is combinatorial in the sense that it does not use an explicit linear programming algorithm or methods from linear algebra or convex geometry. Instead our algorithm is based on basic arithmetic operations and comparisons of rational numbers which are of polynomial binary encoding size in the input.
SODA	Sublogarithmic approximation for telephone multicast: path out of jungle.	Michael Elkin,Guy Kortsarz	2003	Sublogarithmic approximation for telephone multicast: path out of jungle.
SODA	Dynamic generators of topologically embedded graphs.	David Eppstein	2003	We provide a data structure for maintaining an embedding of a graph on a surface (represented combinatorially by a permutation of edges around each vertex) and computing generators of the fundamental group of the surface, in amortized time O(log n + log g(log log g)3) per update on a surface of genus g; we can also test orientability of the surface in the same time, and maintain the minimum and maximum spanning tree of the graph in time O(log n + log4 g) per update. Our data structure allows edge insertion and deletion as well as the dual operations; these operations may implicitly change the genus of the embedding surface. We apply similar ideas to improve the constant factor in a separator theorem for low-genus graphs, and to find in linear time a tree-decomposition of low-genus low-diameter graphs.
SODA	Comparing top k lists.	Ronald Fagin,Ravi Kumar,D. Sivakumar	2003	"Motivated by several applications, we introduce various distance measures between ""top k lists."" Some of these distance measures are metrics, while others are not. For each of these latter distance measures, we show that they are ""almost"" a metric in the following two seemingly unrelated aspects:(i) they satisfy a relaxed version of the polygonal (hence, triangle) inequality, and(ii) there is a metric with positive constant multiples that bound our measure above and below.This is not a coincidence---we show that these two notions of almost being a metric are the same. Based on the second notion, we define two distance measures to be equivalent if they are bounded above and below by constant multiples of each other. We thereby identify a large and robust equivalence class of distance measures.Besides the applications to the task of identifying good notions of (dis)similarity between two top k lists, our results imply polynomial-time constant-factor approximation algorithms for the rank aggregation problem with respect to a large class of distance measures."
SODA	The k-traveling repairman problem.	Jittat Fakcharoenphol,Chris Harrelson,Satish Rao	2003	We consider the k-traveling repairman problem, a generalization of the metric traveling repairman problem, also known as the minimum latency problem, to multiple repairmen. We give an 8.497&alpha;-approximation algorithm for this generalization, where &alpha; denotes the best achievable approximation factor for the problem of finding the least cost rooted tree spanning i vertices (i-MST) problem. This can be compared with the best known approximation algorithm for the case k = 1, which is 3.59&alpha;. We are aware of no previous work on the approximability of the present problem.In addition, we give a simple proof of the 3.59&alpha;approximation result which can be extended to the case of multiple repairmen.
SODA	An improved approximation algorithm for the 0-extension problem.	Jittat Fakcharoenphol,Chris Harrelson,Satish Rao,Kunal Talwar	2003	Given a graph G = (V, E), a set of terminals T &sube; V, and a metric D on T, the 0-extension problem is to assign vertices in V to terminals, so that the sum, over all edges e, of the distance (under D) between the terminals to which the end points of e are assigned, is minimized. This problem was first studied by Karzanov. Calinescu, Karloff and Rabani gave an O(logk) approximation algorithm based on a linear programming relaxation for the problem, where k is the number of terminals. We improve on this bound, and give an O(log k/log log k) approximation algorithm for the problem.
SODA	A spectral technique for random satisfiable 3CNF formulas.	Abraham Flaxman	2003	"Let I be a random 3CNF formula generated by choosing a truth assignment &phis; for variables x1, xn uniformly at random and including every clause with i literals set true by &phis; with probability pi, independently. We show that for any constants 0 &le; &eta;2,&eta;3 &le; 1 there is a constant dmin so that for all d &ge; dmin a spectral algorithm similar to the graph coloring algorithm of Alon and Kahale will find a satisfying assignment with high probability for p1 = d-n2, p2 = &eta;2d-n2, and p3 = &eta;3d-n2. Appropriately setting the &eta;i's yields natural distributions on satisfiable 3CNFs, not-all-equal-sat 3CNFs, and exactly-one-sat 3CNFs. &copy; 2008 Wiley Periodicals, Inc. Random Struct. Alg., 2008"
SODA	Approximately optimal control of fluid networks.	Lisa Fleischer,Jay Sethuraman	2003	We give an approximation algorithm for the optimal control problem in fluid networks. Such problems arise as fluid relaxations of multiclass queueing networks, and are used to find approximate solutions to complex job shop scheduling problems. In a network with linear flow costs and linear, per-unit-time holding costs, our algorithm finds a drainage of the network, that for given constants &epsilon; > 0 and &delta; > 0 has total cost (1 + &epsilon;)OPT + &delta;, where OPT is the cost of the minimum cost drainage. The complexity of our algorithm is polynomial in the size of the input network, 1/&epsilon; and log 1/&delta;. The fluid relaxation is a continuous problem. While the problem is known to have a piecewise constant solution, it is not known to have a polynomially-sized solution. We introduce a natural discretization of polynomial size and prove that this discretization produces a solution with low cost. This is the first polynomial time algorithm with a provable approximation guarantee for fluid relaxations.
SODA	Minimum cost flows over time without intermediate storage.	Lisa Fleischer,Martin Skutella	2003	Flows over time (also called dynamic flows) generalize standard network flows by introducing an element of time. They naturally model problems where travel and transmission are not instantaneous. Solving these problems raises issues that do not arise in standard network flows. One issue is the question of storage of flow at intermediate nodes. In most applications (such as, e.g., traffic routing, evacuation planning, telecommunications etc.), intermediate storage is limited, undesired, or prohibited.The minimum cost flow over time problem is NP-hard. In this paper we 1) prove that the minimum cost flow over time never requires storage; 2) provide the first approximation scheme for minimum cost flows over time that does not require storage; 3) provide the first approximation scheme for minimum cost flows over time that meets hard cost constraints, while approximating only makespan.Our approach is based on a condensed variant of time- expanded networks. It also yields fast approximation schemes with simple solutions for the quickest multicommodity flow problem.Finally, using completely different techniques, we describe a very simple capacity scaling FPAS for the minimum cost flow over time problem when costs are proportional to transit times. The algorithm builds upon our observation about the structure of optimal solutions to this problem: they are universally quickest flows. Again, the FPAS does not use intermediate node storage. In contrast to the preceding algorithms that use a time-expanded network, this FPAS runs directly on the original network.
SODA	Dominating sets in planar graphs: branch-width and exponential speed-up.	Fedor V. Fomin,Dimitrios M. Thilikos	2003	We introduce a new approach to design parameterized algorithms on planar graphs which builds on the seminal results of Robertson and Seymour on graph minors. Graph minors provide a list of powerful theoretical results and tools. However, the widespread opinion in the graph algorithms community about this theory is that it is of mainly theoretical importance. In this paper we show how deep min-max and duality theorems from graph minors can be used to obtain exponential speed-up to many known practical algorithms for different domination problems. Our use of branch-width instead of the usual tree-width allows us to obtain much faster algorithms. By using this approach, we show that the k-dominating set problem on planar graphs can be solved in time O(215.13 \sqrt k + n3).
SODA	Implicit dictionaries supporting searches and amortized updates in O(log n log log n) time.	Gianni Franceschini,Roberto Grossi	2003	We describe a new implicit data structure for maintaining n data values in the first n locations of an array. No information other than n and the data is to be retained, and the only operations which we may perform on the data values (other than reads and writes) are comparisons. Our structure supports searches in O(log n log log n) time in the worst case, and insertions and deletions in O(log n log log n) amortized time. The best known bound for these operations in main memory is O(log 2 n/log log n) in the worst case.
SODA	Perfect matchings in random graphs with prescribed minimal degree.	Alan M. Frieze,Boris Pittel	2003	Perfect matchings in random graphs with prescribed minimal degree.
SODA	Better performance bounds for finding the smallest k-edge connected spanning subgraph of a multigraph.	Harold N. Gabow	2003	Khuller and Raghavachari [12] present an approximation algorithm (the KR algorithm) for finding the smallest k-edge connected spanning subgraph (k-ECSS) of an undirected multigraph. They prove the KR algorithm has approximation ratio < 1.85. We prove the KR algorithm has approximation ratio &le; 1 + &radic;1/e < 1.61; for odd k this requires a minor modification of the algorithm. This is the bestknown performance bound for the smallest k-ECSS problem for arbitrary k. Our analysis also gives the best-known performance bound for any fixed value of k &le; 3, e.g., for even k the approximation ratio is &le; 1 + (1 -- 1/k)k/2. Our analysis is based on a laminar family of sets (similar to families used in related contexts) which gives a better accounting of edges added in previous iterations of the algorithm. We also present a polynomial time implementation of the KR algorithm on multigraphs, running in the time for O(nm) maximum flow computations, where n (m) is the number of vertices (edges, not counting parallel copies). This complements the implementation of [12] which uses time O((kn)2) and is efficient for small k.
SODA	Computing strongly connected components in a linear number of symbolic steps.	Raffaella Gentilini,Carla Piazza,Alberto Policriti	2003	"We present an algorithm that computes in a linear number of symbolic steps (O(&verbar;V&verbar;)) the strongly connected components (sccs) of a graph G = &lang;V, E&rang; represented by an Ordered Binary Decision Diagram (OBDD). This result matches the complexity of the (celebrated) Tarjan's algorithm operating on explicit data structures. To date, the best algorithm for the above problem works in &Theta;(&verbar;V&verbar;log&verbar;V&verbar;) symbolic steps ([BGS00])."
SODA	The flow complex: a data structure for geometric modeling.	Joachim Giesen,Matthias John	2003	We study a special case of the critical point (Morse) theory of distance functions namely, the gradient flow associated with the distance function to a finite point set in R^3. The fixed points of this flow are exactly the critical points of the distance function. Our main result is a mathematical characterization and algorithms to compute the stable manifolds, i.e., the inflow regions, of the fixed points. It turns out that the stable manifolds form a polyhedral complex that shares many properties with the Delaunay triangulation of the same point set. We call the latter complex the flow complex of the point set. The flow complex is suited for geometric modeling tasks like surface reconstruction.
SODA	Approximation of functions over redundant dictionaries using coherence.	Anna C. Gilbert,S. Muthukrishnan,Martin Strauss	2003	One of the central problems of modern mathematical approximation theory is to approximate functions, or signals, concisely, with elements from a large candidate set called a dictionary. Formally, we are given a signal A &isin; RN and a dictionary D = {&phi;i}i&isin;I of unit vectors that span RN. A representation R of B terms for input A &isin; RN is a linear combination of dictionary elements, R = &sigma;i&isin;A &alpha;i&phi;i, for &phi;i &isin; D and some A, &verbar;A&verbar; &ge; B. Typically, B ⪡ N, so that R is a concise approximation to signal A. The error of the representation indicates by how well it approximates A, and is given by ∥A - R∥2 = &radic;&Sigma;t|A[t - R[t]|2. The problem is to find the best B-term representation, i.e., find a R that minimizes ∥A - R∥2. A dictionary may be redundant in the sense that there is more than one possible exact representation for A, i.e., &verbar;D&verbar; > N = dim(RN). Redundant dictionaries are used because, both theoretically and in practice, for important classes of signals, as the size of a dictionary increases, the error and the conciseness of the approximations improve.We present the first known efficient algorithm for finding a provably approximate representation for an input signal over redundant dictionaries. We identify and focus on redundant dictionaries with small coherence (ie., vectors are nearly orthogonal). We present an algorithm that preprocesses any such dictionary in time and space polynomial in &verbar;D&verbar;, and obtains an 1 + &epsilon; approximate representation of the given signal in time nearly linear in signal size N and polylogarithmic in &verbar;D&verbar;; by contrast, most algorithms in the literature require &Omega;(&verbar;D&verbar;)time, and, yet, provide no provable bounds. The technical crux of our result is our proof that two commonly used local search techniques, when combined appropriately, gives a provably near-optimal signal representation over redundant dictionaries with small coherence. Our result immediately applies to several specific redundant dictionaries considered by the domain experts thus far. In addition, we present new redundant dictionaries which have small coherence (and therefore are amenable to our algorithms) and yet have significantly large sizes, thereby adding to the redundant dictionary construction literature.Work with redundant dictionaries forms the emerging field of highly nonlinear approximation theory. We have presented algorithmic results for some of the most basic problems in this area, but other mathematical and algorithmic questions remain to be explored.
SODA	Simultaneous optimization for concave costs: single sink aggregation or single source buy-at-bulk.	Ashish Goel,Deborah Estrin	2003	We consider the problem of finding efficient trees to send information from k sources to a single sink in a network where information can be aggregated at intermediate nodes in the tree. Specifically, we assume that if information from j sources is traveling over a link, the total information that needs to be transmitted is f(j). One natural and important (though not necessarily comprehensive) class of functions is those which are concave, non-decreasing, and satisfy f(0) = 0. Our goal is to find a tree which is a good approximation simultaneously to the optimum trees for all such functions. This problem is motivated by aggregation in sensor networks, as well as by buy-at-bulk network design.We present a randomized tree construction algorithm that guarantees E[maxfCf/C*(f)] 1 + log k, where Cf is a random variable denoting the cost of the tree for function f and C* (f) is the cost of the optimum tree for function f. To the best of our knowledge, this is the first result regarding simultaneous optimization for concave costs. We also show how to derandomize this result to obtain a deterministic algorithm that guarantees maxf/C*(f) = O(log k). Both these results are much stronger than merely obtaining a guarantee on maxfE[Cf/C* (f)]. A guarantee on maxfE[Cf/C* (f)] can be obtained using existing techniques, but this does not capture simultaneous optimization since no one tree is guaranteed to be a good approximation for all f simultaneously.While our analysis is quite involved, the algorithm itself is very simple and may well find practical use. We also hope that our techniques will prove useful for other problems where one needs simultaneous optimization for concave costs.
SODA	Competitiveness via consensus.	Andrew V. Goldberg,Jason D. Hartline	2003	We introduce the following consensus estimate problem. Several processors hold private and possibly different lower bounds on a value. The processors do not communicate with each other, but can observe a shared source of random numbers. The goal is to come up with a consensus lower bound on the value that is as high as possible. We give a solution to the consensus estimate problem and show how it is useful in the context of mechanism design. The consensus problem is natural and may have other applications. Based on our consensus estimate technique, we introduce Consensus Revenue Estimate (CORE) auctions. This is a class of competitive revenue-maximizing auctions that is interesting for several reasons. One auction from this class achieves a better competitive ratio than any previously known auction. Another one uses only two random bits, whereas the previously known competitive auctions on n bidders use n random bits. Furthermore, a parameterized CORE auction performs better than the previous auctions in the context of mass-market goods, such as digital goods.
SODA	An improved approximation algorithm for the partial latin square extension problem.	Carla P. Gomes,Rommel G. Regis,David B. Shmoys	2003	The problem of completing partial latin squares arises in a number of applications, including conflict-free wavelength routing in wide-area optical networks, statistical designs, and error-correcting codes. A partial latin square is an n by n array such that each cell is either empty or contains exactly one of the colors 1, ..., n, and each color occurs at most once in any row or column. In this paper, we consider the problem of finding an extension of a given partial latin square with the maximum number of colored cells. Approximation algorithms for this problem were introduced by Kumar, Russell, and Sundaram, who gave a 2-approximation algorithm for this problem that is based on a 3-dimensional assignment formulation. We introduce a packing linear programming relaxation for this problem, and show that a natural randomized rounding algorithm yields an e/(e -- 1)-approximation algorithm.
SODA	High-order entropy-compressed text indexes.	Roberto Grossi,Ankur Gupta,Jeffrey Scott Vitter	2003	We present a novel implementation of compressed suffix arrays exhibiting new tradeoffs between search time and space occupancy for a given text (or sequence) of n symbols over an alphabet &sigma;, where each symbol is encoded by lg&verbar;&sigma;&verbar; bits. We show that compressed suffix arrays use just nHh + &sigma; bits, while retaining full text indexing functionalities, such as searching any pattern sequence of length m in O(m lg &verbar;&sigma;&verbar; + polylog(n)) time. The term Hh &le; lg &verbar;&sigma;&verbar; denotes the hth-order empirical entropy of the text, which means that our index is nearly optimal in space apart from lower-order terms, achieving asymptotically the empirical entropy of the text (with a multiplicative constant 1). If the text is highly compressible so that Hn = o(1) and the alphabet size is small, we obtain a text index with o(m) search time that requires only o(n) bits. Further results and tradeoffs are reported in the paper.
SODA	Zonotopes as bounding volumes.	Leonidas J. Guibas,An Nguyen,Li Zhang	2003	Zonotopes are centrally symmetric polytopes with a very special structure: they are Minkowski sums of line segments. In this paper we propose to use zonotopes as bounding volumes for geometry in collision detection and other applications where the spatial relationship between two pieces of geometry is important. We show how to construct optimal, or approximately optimal zonotopes enclosing given set of points or other geometry. We also show how zonotopes can be used for efficient collision testing, based on their representation via their defining line segments --- without ever building their explicit description as polytopes. This implicit representation adds flexibility, power, and economy to the use of zonotopes as bounding volumes.
SODA	Improved results for directed multicut.	Anupam Gupta	2003	We give a simple algorithm for the Minimum Directed Multicut problem, and show that it gives an O(&radic;n)-approximation. This improves on the previous approximation guarantee of O(&radic;n log k) of Cheriyan, Karloff and Rabani [1], which was obtained by a more sophisticated algorithm.
SODA	Counting inversions in lists.	Anupam Gupta,Francis Zane	2003	In a recent paper, Ajtai et al. [1] give a streaming algorithm to count the number of inversions in a stream L&epsilon;[m]n using two passes and O(&epsilon;&minus;1-&radic;n log n(log m + log n)) space. Here, we present a simple randomized streaming algorithm for the same problem that uses one pass and O(&epsilon;&minus;3 log2 n log m) space. Our algorithm is based on estimating quantiles of the items already seen in the stream, and using that to estimate the number of inversions involving each element.
SODA	Embeddings and non-approximability of geometric problems.	Venkatesan Guruswami,Piotr Indyk	2003	Embeddings and non-approximability of geometric problems.
SODA	Unconditional proof of tightness of Johnson bound.	Venkatesan Guruswami,Igor Shparlinski	2003	Unconditional proof of tightness of Johnson bound.
SODA	Integrality ratio for group Steiner trees and directed steiner trees.	Eran Halperin,Guy Kortsarz,Robert Krauthgamer,Aravind Srinivasan,Nan Wang	2003	We present an &Omega;(log2k) lower bound on the integrality ratio of the flow-based relaxation for the Group Steiner Tree problem, where k denotes the number of groups; this holds even for input graphs that are Hierarchically Well-Separated Trees, introduced by Bartal [Symp. Foundations of Computer Science, pp. 184--193, 1996], in which case this lower bound is tight. This relaxation appears to be the only one that have been studied for the problem, as well as for its generalization, the Directed Steiner Tree problem. For the latter problem, our results imply an &Omega;(log2n/(log logn)2) integrality ratio, where n is the number of vertices in the graph. For both problems, this is the first known lower bound on the integrality ratio that is superlogarithmic in the input size. We also show algorithmically that the integrality ratio for Group Steiner Tree is much better for certain families of instances, which helps pinpoint the types of instances that appear to be most difficult to approximate.
SODA	Binary space partitions for 3D subdivisions.	John Hershberger,Subhash Suri	2003	We consider the following question: Given a subdivision of space into n convex polyhedral cells, what is the worst-case complexity of a binary space partition (BSP) for the subdivision? We show that if the subdivision is rectangular and axis-aligned, then the worstcase complexity of an axis-aligned BSP is &Omega;(n4/3) and O(n&alpha; log2 n), where &alpha; = 1 + log2(4/3 ) = 1.4150375 .... By contrast, it is known that the BSP of a collection of n rectangular cells not forming a subdivision has worstcase complexity &Theta;(n3/2). We also show that the worstcase complexity of a BSP for a general convex polyhedral subdivision of total complexity O(n) is &Omega;(n3/2).
SODA	Directed graphs requiring large numbers of shortcuts.	William Hesse	2003	A conjecture by Thorup is that the diameter of a directed graph with n vertices and m edges can be reduced to (log n)O(1) by adding O(m) edges [3]. We give a counterexample to this conjecture. We construct a graph G requiring the addition of &Omega;(mn 1/17) edges to reduce its diameter below &Theta;(n1/17). By extending the construction to higher dimensions, we construct graphs with n1+&epsilon; edges that require the addition of &Omega;(n2--&epsilon;) edges to reduce their diameter. These constructions yield time-space tradeoffs in lower bounds for transitive closure queries in a certain computational model.
SODA	Better algorithms for high-dimensional proximity problems via asymmetric embeddings.	Piotr Indyk	2003	"In this paper we give several results based on randomized embeddings of l2 into l&infin;(or ""l&infin;-like"") spaces. Our first result is a (1 + &epsilon;)-distortion asymmetric embedding of n points in l2 into l&infin; with polylog(n) dimension, for any 1 + &epsilon;. This gives the first known O(1)- approximate nearest neighbor algorithm with fast query time and almost polynomial space for a product of Euclidean norms, a common generalization of both l2 and l&infin; norms. Our embedding also clarifies the relative complexity of approximate nearest neighbor in l2 and l&infin; spaces.Our second result in a (1 + &epsilon;)-approximate algorithm for the diameter of n points in ld2, running in time &Otilde;(dn1+l/(1+&epsilon;)2); the algorithm is fully dynamic. This improves several previous algorithms for this problem (see Table 1 for more information)."
SODA	Algorithms for power savings.	Sandy Irani,Sandeep K. Shukla,Rajesh K. Gupta	2003	This paper examines two different mechanisms for saving power in battery-operated embedded systems. The first is that the system can be placed in a sleep state if it is idle. However, a fixed amount of energy is required to bring the system back into an active state in which it can resume work. The second way in which power savings can be achieved is by varying the speed at which jobs are run. We utilize a power consumption curve P(s). which indicates the power consumption level given a particular speed. We assume that P(s) and P(s)/s are convex. The problem is to schedule arriving jobs in a way that minimizes total energy use and so that each job is completed after its arrival time and before its deadline. Although each problem has been considered separately, this is the first theoretical analysis of systems which can use both mechanisms. We give an off line algorithm which is within a factor of three of the optimal algorithm. We also give an online algorithm with a constant competitive ratio.
SODA	Packing Steiner trees.	Kamal Jain,Mohammad Mahdian,Mohammad R. Salavatipour	2003	The Steiner packing problem is to find the maximum number of edge-disjoint subgraphs of a given graph G that connect a given set of required points S. This problem is motivated by practical applications in VLSI- layout and broadcasting, as well as theoretical reasons. In this paper, we study this problem and present an algorithm with an asymptotic approximation factor of &verbar;S&verbar;/4. This gives a sufficient condition for the existence of k edge-disjoint Steiner trees in a graph in terms of the edge-connectivity of the graph. We will show that this condition is the best possible if the number of terminals is 3. At the end, we consider the fractional version of this problem, and observe that it can be reduced to the minimum Steiner tree problem via the ellipsoid algorithm.
SODA	A 5/4-approximation algorithm for minimum 2-edge-connectivity.	Raja Jothi,Balaji Raghavachari,Subramanian Varadarajan	2003	A 5/4-approximation algorithm is presented for the minimum cardinality 2-edge-connected spanning subgraph problem in undirected graphs. This improves the previous best approximation ratio of 4/3. It is shown that our ratio is tight with respect to current lower bounds, and any further improvement is possible only if new lower bounds are discovered.
SODA	Selection with monotone comparison cost.	Sampath Kannan,Sanjeev Khanna	2003	"We consider the problem of selecting the rth-smallest element from a list of n elements under a model where the comparisons may have different costs depending on the elements being compared. This model was introduced by [3] and is realistic in the context of comparisons between complex objects. An important special case of this general cost model is one where the comparison costs are monotone in the sizes of the elements being compared. This monotone cost model covers most ""natural"" cost models that arise and the selection problem turns out to be the most challenging one among the usual problems for comparison-based algorithms. We present an O(log2 n)-competitive algorithm for selection under the monotone cost model. This is in contrast to an &Omega;(n) lower bound that is known for arbitrary comparison costs. We also consider selection under a special case of monotone costs --- the min model where the cost of comparing two elements is the minimum of the sizes. We give a randomized O(1)-competitive algorithm for the min model."
SODA	Root comparison techniques applied to computing the additively weighted Voronoi diagram.	Menelaos I. Karavelas,Ioannis Z. Emiris	2003	This work examines algebraic techniques for comparing quadratic algebraic numbers, thus yielding methods for deciding key predicates in various geometric constructions. Our motivation and main application concerns a dynamic algorithm for computing the additively weighted Voronoi diagram in the plane. We propose effficient, exact, and complete methods, which are crucial for a fast and robust implementation of these predicates and the overall algorithm. Our first contribution is to minimize, on the one hand, the algebraic degree of the computed quantities, thus optimizing precision and, on the other hand, the total number of arithmetic operations. We focus on the hardest predicate, which involves quadratic polynomials, and detail the corresponding algorithms, which are based on polynomial Sturm sequences; ancillary tools include geometric invariants, multivariate resultants, and polynomial factorization. Our last contribution is a general and efficient implementation, which has been extensively tested in order to demonstrate the practical performance of our methods and the improvements achieved over existing approaches.
SODA	On the complexity of distance-based evolutionary tree reconstruction.	Valerie King,Li Zhang,Yunhong Zhou	2003	We give the first tight lower bounds on the complexity of reconstructing k-ary evolutionary trees from additive distance data. We also consider the problem under DNA-based distance estimation assumptions, where the accuracy of distance data depends on the length of the sequence and the distance. We give the first o(n2) algorithm to reconstruct trees in this context, and prove a trade-off between the length of the DNA sequences and the number of distance queries needed to reconstruct the tree. We introduce new computational models for understanding this problem, which simplify the development of algorithms. We prove lower bounds in these models which apply to the type of techniques currently in use.
SODA	A note on the set systems used for broadcast encryption.	Ravi Kumar,Alexander Russell	2003	An exclusive set system is a family of subsets of a universe with the property that every large subset may be written as the union of subsets from the family. We obtain new upper bounds on the size of such families, showing that in a universe of n elements, there is a system of 48k3 (nk)r/k In subsets with the property that every subset of the universe of size n -- r can be written as the union of k subsets in the system. Such sets systems form the combinatorial foundation of many broadcast encryption schemes.
SODA	Property testing of data dimensionality.	Robert Krauthgamer,Ori Sasson	2003	Data dimensionality is a crucial issue in a variety of settings, where it is desirable to determine whether a data set given in a high-dimensional space adheres to a low-dimensional structure. We study this problem in the framework of property testing: Given a query access to a data set S, we wish to determine whether S is low-dimensional, or whether it should be modified significantly in order to have the property. Allowing a constant probability of error, we aim at algorithms whose complexity does not depend on the size of S.We present algorithms for testing the low-dimensionality of a set of vectors and for testing whether a matrix is of low rank. We then address low-dimensionality in metric spaces. For vectors in the metric space l1, we show that low-dimensionality is not testable. For l2, we show that a data set can be tested for having a low-dimensional structure, but that the property of approximately having such a structure is not testable.
SODA	Approximating asymmetric maximum TSP.	Moshe Lewenstein,Maxim Sviridenko	2003	The asymmetric maximum travelling salesman problem, also known as the Taxicab Ripoff problem, is the problem of finding a maximally weighted tour in a complete asymmetric graph with non-negative weights. Interesting in its own right, this problem is also motivated by such problems such as the shortest superstring problem.We propose a polynomial time approximation algorithm for the problem with a 5/8 approximation guarantee. This (1) improves upon the approximation factors of previous results and (2) presents a simpler solution to the previously fairly involved algorithms. Our solution uses a simple LP formulation. Previous solutions where combinatorial. We make use of the LP in a novel manner and strengthen the Path-Coloring method originally proposed in [13].
SODA	Certifying algorithms for recognizing interval graphs and permutation graphs.	Dieter Kratsch,Ross M. McConnell,Kurt Mehlhorn,Jeremy Spinrad	2003	A certifying algorithm for a problem is an algorithm that provides a certificate with each answer that it produces. The certificate is a piece of evidence that proves that the answer has not been compromised by a bug in the implementation. We give linear-time certifying algorithms for recognition of interval graphs and permutation graphs, and for a few other related problems. Previous algorithms fail to provide supporting evidence when they claim that the input graph is not a member of the class. We show that our certificates of nonmembership can be authenticated in O(|V|) time.
SODA	The similarity metric.	Ming Li,Xin Chen,Xin Li,Bin Ma,Paul M. B. Vitányi	2003	"A new class of metrics appropriate for measuring effective similarity relations between sequences, say one type of similarity per metric, is studied. We propose a new ""normalized information distance"", based on the noncomputable notion of Kolmogorov complexity, and show that it minorizes every metric in the class (that is, it is universal in that it discovers all effective similarities). We demonstrate that it too is a metric and takes values in [0, 1]; hence it may be called the similarity metric. This is a theory foundation for a new general practical tool. We give two distinctive applications in widely divergent areas (the experiments by necessity use just computable approximations to the target notions). First, we computationally compare whole mitochondrial genomes and infer their evolutionary history. This results in a first completely automatic computed whole mitochondrial phylogeny tree. Secondly, we give fully automatically computed language tree of 52 different language based on translated versions of the ""Universal Declaration of Human Rights""."
SODA	Between O(nm) and O(n alpha).	Dieter Kratsch,Jeremy Spinrad	2003	This paper uses periodic matrix multiplication to improve the time complexities for a number of graph problems. The time for finding a clique cutset in a graph is reduced from O(nm) to O(n2.69), the time for finding an asteroidal triple is reduced to O(n2.82), and the time for finding a star cutset, a two-pair, and a dominating pair is reduced from O(nm) to O(n2.79).It is also shown that each of these problems is at least as hard as one of three basic graph problems for which the best known algorithms run in time O(nm) and O(n&alpha;).
SODA	Deterministic identity testing for multivariate polynomials.	Richard J. Lipton,Nisheeth K. Vishnoi	2003	"In this paper we present a simple deterministic algorithm for testing whether a multivariate polynomial f(x1, ..., xn) is identically zero, in time polynomial in m, n, log(d + 1) and H. Here m is the number of monomials in f, d is the maximum degree of a variable in f and 2H is the least upper bound on the magnitude of the largest coefficient in f. We assume that f has integer coefficients.The main feature of our algorithm is its conceptual simplicity. The proof uses Linnik's Theorem which is a deep fact about distribution of primes in an arithmetic progression."
SODA	Improved bounds on the average length of longest common subsequences.	George S. Lueker	2003	"It has long been known &lsqb;Chv&aacute;tal and Sankoff 1975&rsqb; that the average length of the longest common subsequence of two random strings of length n over an alphabet of size k is asymptotic to &gamma;kn for some constant &gamma;k depending on k. The value of these constants remains unknown, and a number of papers have proved upper and lower bounds on them. We discuss techniques, involving numerical calculations with recurrences on many variables, for determining lower and upper bounds on these constants. To our knowledge, the previous best-known lower and upper bounds for &gamma;2 were those of Dan&ccaron;&iacute;k and Paterson, approximately 0.773911 and 0.837623 &lsqb;Dan&ccaron;&iacute;k 1994; Dan&ccaron;&iacute;k and Paterson 1995&rsqb;. We improve these to 0.788071 and 0.826280. This upper bound is less than the &gamma;2 given by Steele's old conjecture (see Steele &lsqb;1997, page 3&rsqb;) that &gamma;2 &equals; 2/(1 + &sqrt;2)&approx; 0.828427. (As Steele points out, experimental evidence had already suggested that this conjectured value was too high.) Finally, we show that the upper bound technique described here could be used to produce, for any k, a sequence of upper bounds converging to &gamma;k, though the computation time grows very quickly as better bounds are guaranteed."
SODA	Fully-dynamic two dimensional orthogonal range and line segment intersection reporting in logarithmic time.	Christian Worm Mortensen	2003	We consider the two dimensional fully-dynamic orthogonal range reporting problem and the two dimensional fully-dynamic orthogonal line segment intersection reporting problem in the comparison model. We show that if n is the number of stored elements, then these problems can be solved in worst case time &Theta;(log n) plus time proportional to the size of the output pr. operation.
SODA	Data streams: algorithms and applications.	S. Muthukrishnan	2003	In the data stream scenario, input arrives very rapidly and there is limited memory to store the input. Algorithms have to work with one or few passes over the data, space less than linear in the input size or time significantly less than the input size. In the past few years, a new theory has emerged for reasoning about algorithms that work within these constraints on space, time, and number of passes. Some of the methods rely on metric embeddings, pseudo-random computations, sparse approximation theory and communication complexity. The applications for this scenario include IP network traffic analysis, mining text message streams and processing massive data sets in general. Researchers in Theoretical Computer Science, Databases, IP Networking and Computer Systems are working on the data stream challenges. This article is an overview and survey of data stream algorithmics and is an updated version of [1].
SODA	Rangesum histograms.	S. Muthukrishnan,Martin Strauss	2003	A rangesum query to an array A is a pair (l, r) of range endpoints, which should be answered by &Sigma;l&le;irA[i]. To compress A, we consider representing an array A lossily by a histogram, a function that is constant on each of a small number of buckets. We then answer range queries from H instead of from A, i.e., as &Sigma;l&le;irH[i]. An optimal rangesum histogram H for this purpose is one whose bucket boundaries and constant heights within buckets are chosen to minimize the expected square error, El, r[(&Sigma;l&le;irA[i]--&Sigma;l&le;irH[i].)2], assuming each rangesum query is equally likely. Rangesum histograms find many applications in database systems.In a degenerate variation, all rangesum queries are over ranges of size one, namely, individual points; histograms optimal for this special case are called pointwise optimal histograms. Pointwise optimal histogram is a classical notion in statistics and approximation theory, but rangesum optimal histogram appears to be novel in these areas. While optimal pointwise histograms can be constructed efficiently by simple dynamic progrmming, no efficient (even approximate) general rangesmn histogram construction algorithms were previously known. In practice, all commercial database systems use heuristically built histograms for pointwise and rangesum queries.We present the first general algorithms for approximate rangesum histograms. Given parameter B, we denote by (&alpha;, &beta;)-approximation an algorithm to produce a (&alpha;B)-bucket histogram with error at most &beta; times the error of the optimal B-bucket histogram. We give a (2, 1)-approximation with runtime O(N2B), a (2, 1+∊)-approximation with runtime N + (B log(N)/∊)O(1) (1), and a (1, 1 + ∊)-approximation with runtime O(B3N4/∊2). We also consider the problem of dynamic maintenance of rangesum histograms for data updated by additive changes, and we give a (2, 1 + ∊)-approximation that uses space (Blog(N)/∊)O(1) and time (Blog(N)/∊)O(1) for update and query operations. The bounds are nearly competitive with some of the best known bounds for constructing pointwise optimal histograms modulo small additional number of buckets used; however, rangesum histograms are substantially harder to construct because of the long range dependence between subproblems.
SODA	Inferring tree topologies using flow tests.	S. Muthukrishnan,Torsten Suel,Radek Vingralek	2003	Inferring tree topologies using flow tests.
SODA	Multirate rearrangeable clos networks and a generalized edge coloring problem on bipartite graphs.	Hung Q. Ngo,Van H. Vu	2003	Chung and Ross (SIAM J. Comput., 20, 1991) conjectured that the minimum number m(n, r) of middle-state switches for the symmetric 3-stage Clos network C(n, m(n, r), r) to be rearrangeable in the multirate enviroment is at most 2n -- 1. This problem is equivalent to a generalized version of the biparite graph edge coloring problem. The best bounds known so far on the function m(n, r) is 11n/9 &le; m(n, r) &le; 41n/16 + O(1), for n, r &ge; 2, derived by Du-Gao-Hwang-Kim (SIAM J. Comput., 28, 1999). In this paper, we make several contributions. Firstly, we give evidence to show that even a stronger result might hold. In particular, we give a coloring algorithm to show that m(n, r) &le; [(r + 1)n/2], which implies m(n, 2) &le; [3n/2] - stronger than the conjectured value of 2n -- 1. Secondly, we derive that m(2, r) = 3 by an elegant argument. Lastly, we improve both the best upper and lower bounds given above: [5n/4] &le; m(n, r) &le; 2n -- 1 + [(r -- 1)/2], where the upper bound is an improvement over 41n/16 when r is relatively small compared to n. We also conjecture that m(n, r) &le; [2n (1 -- 1/2(r)].
SODA	A faster and simpler fully dynamic transitive closure.	Liam Roditty	2003	We obtain a new fully dynamic algorithm for maintaining the transitive closure of a directed graph. Our algorithm maintains the transitive closure matrix in a total running time of O(mn &plus; (ins &plus; del) &middot; n2), where ins (del) is the number of insert (delete) operations performed. Here n is the number of vertices in the graph and m is the initial number of edges in the graph. Obviously, reachability queries can be answered in constant time. The algorithm uses only O(n2) time which is essentially optimal for maintaining the transitive closure matrix. Our algorithm can also support path queries. If v is reachable from u, the algorithm can produce a path from u to v in time proportional to the length of the path. The best previously known algorithm for the problem is due to Demetrescu and Italiano [2000]. Their algorithm has a total running time of O(n3 &plus; (ins &plus; del) &middot; n2). The query time is also constant. In addition, we also present a simple algorithm for directed acyclic graphs (DAGs) with a total running time of O(mn &plus; ins &middot; n2 &plus; del). Our algorithms are obtained by combining some new ideas with techniques of Italiano [1986, 1988], King [1999], King and Thorup [2001] and Frigioni et al. [2001]. We also note that our algorithms are extremely simple and can be easily implemented.
SODA	A (1+epsilon)-approximation algorithm for partitioning hypergraphs using a new algorithmic version of the Lovász Local Lemma.	Mohammad R. Salavatipour	2003	A (1+epsilon)-approximation algorithm for partitioning hypergraphs using a new algorithmic version of the Lovász Local Lemma.
SODA	Lower bounds for collusion-secure fingerprinting.	Chris Peikert,Abhi Shelat,Adam Smith	2003	"Collusion-secure fingerprinting codes are an important primitive used by many digital watermarking schemes [1, 10, 9]. Boneh and Shaw [3] define a model for these types of codes and present an explicit construction. Their code has length O(c3 log(l/&epsilon;)) and attains security against coalitions of size c with &epsilon; error. Boneh and Shaw also present a lower bound of &Omega; (c3log(1/c&epsilon;)) on the length of any collusion-secure code.We give new lower bounds on the length of collusion-secure codes by analyzing a weighted coinflipping strategy for the coalition. As an illustration of our methods, we give a simple proof that the Boneh-Shaw construction cannot be asymptotically improved. Next, we prove a general lower bound: no secure code can have length O(c21og(1/c&epsilon;)), which improves the previous known bound by a factor of c. In particular, we show that any secure code will have length &Omega;(c2 log(1/c&epsilon;)) as long as log(l/&epsilon;) &ge; K k log c, where K is a constant and k is the number of columns in the code (in some sense, a measure of the code's complexity). Finally, we describe a general paradigm for constructing fingerprinting codes which encompasses the construction of [3], and show that no secure code that follows this paradigm can have length O((c3/log c) log(1/c&epsilon;)) follows this (again, by showing a lower bound for large values of ln(1/&epsilon;)). This suggests that any attempts at improvement should be directed toward techniques that lie outside our paradigm."
SODA	Equitable colorings with constant number of colors.	Sriram V. Pemmaraju,Kittikorn Nakprasit,Alexandr V. Kostochka	2003	Equitable colorings with constant number of colors.
SODA	Online paging with arbitrary associativity.	Enoch Peserico	2003	"We tackle the problem of online paging on two level memories with arbitrary associativity (including victim caches, skewed caches etc.). We show that some important classes of paging algorithms are not competitive on a wide class of associativities (even with arbitrary resource augmentation) and that although some algorithms designed for full associativity are actually competitive on any two level memory, the myopic behavior of paging algorithms designed for full associativity will generally result in very poor performance at least for some ""associativity topologies"". At the same time we present a simple and yet powerful technique that allows us to overcome this shortcoming, generalizing algorithms designed for full associativity into practical algorithms which are efficient on two level memories with arbitrary associativity. We identify a simple topological parameter, pseudo associativity, which characterizes the competitive ratio achievble on any two level memory, giving a lower bound on the competitiveness achievable by any paging algorithm and matching it within a factor 4 with a novel algorithm."
SODA	On the performance of user equilibria in traffic networks.	Andreas S. Schulz,Nicolás E. Stier Moses	2003	On the performance of user equilibria in traffic networks.
SODA	Pursuit-evasion with imprecise target location.	Günter Rote	2003	We consider a game between two persons where one person tries to chase the other, but the pursuer only knows an approximation of the true position of the fleeing person. The two players have identical constraints on their speed. It turns out that the fugitive can increase his distance from the pursuer beyond any limit. However, when the speed constraints are given by a polyhedral metric, the pursuer can always remain within a constant distance of the other person.We apply this problem to buffer minimization in an online scheduling problem with conflicts.
SODA	Allocating vertex pi-guards in simple polygons via pseudo-triangulations.	Bettina Speckmann,Csaba D. Tóth	2003	We use the concept of pointed pseudo-triangulations to establish new upper and lower bounds on a well known problem from the area of art galleries: What is the worst case optimal number of vertex &pi;-guards that collectively monitor a simple polygon with n vertices?Our results are as follows:1. Any simple polygon with n vertices can be mon- itored by at most [n/2] general vertex &pi;-guards. This bound is tight up to an additive constant of 1.2. Any simple polygon with n vertices, k of which are convex, can be monitored by at most [(2n -- k)/3] edge-aligned vertex &pi;-guards. This is the first non- trivial upper bound for this problem and it is tight for the worst case families of polygons known so far.
SODA	Fault-tolerant facility location.	Chaitanya Swamy,David B. Shmoys	2003	We consider a fault-tolerant generalization of the classical uncapacitated facility location problem, where each client j has a requirement that rj distinct facilities serve it, instead of just one. We give a 2.076-approximation algorithm for this problem using LP rounding, which is currently the best-known performance guarantee. Our algorithm exploits primal and dual complementary slackness conditions and is based on clustered randomized rounding. A technical difficulty that we overcome is the presence of terms with negative coefficients in the dual objective function, which makes it difficult to bound the cost in terms of dual variables. For the case where all requirements are the same, we give a primal-dual 1.52-approximation algorithm. We also consider a fault-tolerant version of the k-median problem. In the metric k-median problem, we are given n points in a metric space. We must select k of these to be centers, and then assign each input point j to the selected center that is closest to it. In the fault-tolerant version we want j to be assigned to rj distinct centers. The goal is to select the k centers so as to minimize the sum of assignment costs. The primal-dual algorithm for fault-tolerant facility location with uniform requirements also yields a 4-approximation algorithm for the fault-tolerant k-median problem for this case. This the first constant-factor approximation algorithm for the uniform requirements case.
SODA	Quick and good facility location.	Mikkel Thorup	2003	"We consider the facility location problem with shortest path distances in a weighted graph. W.h.p., we get an approximation factor of 1.62 in O(n + m) time with n and m the number of nodes and edges. Also, as a kind of warm-up, for a metric with a constant-times distance oracle, we get the factor 1.62 deterministically in O(n2 log n) time.Our results build on a recent facility location algorithm of Jain, Mahdian, and Saberi (STOC'02) achieving an approximation factor of 1.61 in O(n3) time."
SODA	On AC implementations of fusion trees and atomic heaps.	Mikkel Thorup	2003	"Addressing a question of Fredman and Willard from STOC'90, we show that fusion trees cannot be implemented using the AC0 operations available through a standard programming language such as C. However, they can be implemented using AC0 operations on emerging multimedia processors such as the Pentium 4.A fusion node is a linear space representation of an integer set X of size O(&radic;W), where W &ge; log n is the word-length. The fusion node supports searches in X in constant time. Here, a search for y in X returns max{x &epsilon; X&verbar;x &le; y}. Using fusion nodes in a O(&radic;W)-degree fusion tree gave Fredman and Willard O(log n/log W) searching for general n, beating the comparison based lower-bound. However, the search routine uses multiplication which is not an AC0 operation.Fredman and Willard asked if multiplication instructions could be avoided. We show that the answer is ""no"" unless you have room for a multiplication table. More precisely, restricting ourselves to the AC0 operations available through C, we show that constant time look-ups or searches in sets of any non-constant size require space 2&Omega;(W). However, if we have that much space, i.e., 2&epsilon;W for some constant &epsilon; > 0, then we can tabulate multiplication of (&epsilon;W/2)-bit numbers, and then we get constant time multiplication of words using additions and shifts. Previous related lowerbounds all disallowed some common AC0 instructions in C such as shifts.We note that even on the weaker ""Practical RAM"" the above 2&Omega;(W) space lower-bound for constant look-ups was only known for sets of size &Omega;(W2) (Miltersen, ICALP'96). Our &Omega;(1) set size is best possible since sets of constant size can be searched directly in constant time.Contrasting the above result, we show that using the AC0 operations available on Intel's new Pentium 4, we can implement both fusion trees and Fredman and Willard's later atomic heaps from FOCS'90. Among the many consequences, we get linear time and space AC0 implementations of minimum spanning tree and undirected single source shortest paths. Also, we get optimal &Theta;(log n/log log n) implementations of dynamic rank and 1&frac12; dimensional range searching. Previous optimal solutions required either multiplication or the use of self-designed AC0 instructions not available on existing processors."
SODA	On the rectilinear crossing number of complete graphs.	Uli Wagner	2003	We prove a lower bound of 0.3288(n4) for the rectilinear crossing number cr(Kn>) of a complete graph on n vertices, or in other words, for the minimum number of convex quadrilaterals in any set of n points in general position in the Euclidean plane. As we see it, the main contribution of this paper is not so much the concrete numerical improvement over earlier bounds, as the novel method of proof, which is not based on bounding cr(Kn>) for some small n.
SODA	Wavelength assignment and generalized interval graph coloring.	Peter Winkler,Lisa Zhang	2003	In this paper we study wavelength assignment on an optical linesystem without wavelength conversion. Consider a set of undirected demands along the line. Each demand is carried on a wavelength and any two overlapping demands on the same fiber require distinct wavelengths. Suppose &mu; wavelengths are available in the system and each fiber can carry all &mu; wavelengths. We define &ell;(e), the load on link e, to be the smallest integer such that &ell;(e)&mu; is at least the number of demands passing through e. Hence, &ell;(e) is the minimum number of fibers required on e in order to support all demands.We present a polynomial-time wavelength assignment algorithm that guarantees each wavelength appears at most &ell;(e) times on each link e. (This generalizes the well-known fact that interval graphs are perfect.) In the presence of MOADMs (mesh optical add/drop multiplexers), devices that multiplex distinct wavelengths from different fibers into a new fiber, we only need to deploy &ell;(e) fibers per link. On the other hand, if each demand has to stay on a single fiber, as is the case without MOADMs, we show that some links may require more than &ell;(e) fibers. In fact, we show that it is NP-complete to decide if a set of demands can be carried on a given set of fibers, or if there exists a set of fibers with a given total length that can carry all the demands.
SODA	Browsing around a digital library.	Ian H. Witten	2003	Browsing around a digital library.
SODA	Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms, January 12-14, 2003, Baltimore, Maryland, USA.		2003	Proceedings of the Fourteenth Annual ACM-SIAM Symposium on Discrete Algorithms, January 12-14, 2003, Baltimore, Maryland, USA.
STOC	Constant factor approximation of vertex-cuts in planar graphs.	Eyal Amir,Robert Krauthgamer,Satish Rao	2003	We devise the first constant factor approximation algorithm for minimum quotient vertex-cuts in planar graphs. Our algorithm achieves approximation ratio 1+4/3(1+ε) with running time O(W• n3+2/ε), where W is the total weight of the vertices. The approximation ratio improves to 4/3(1+ε+o(1)) if there is an optimal quotient vertex-cut (A*,B*,C*) where the weight of C* is of low order compared to those of A* and B*; this holds, for example, when the input graph has uniform weights and costs. The ratio further improves to 1+ε+o(1) if, in addition, min[w(A*),w(B*)] ≤ 1/3 W.We use our algorithm for quotient vertex-cuts to achieve the first constant-factor pseudo-approximation for vertex separators in planar graphs.Our technical contribution is two-fold. First, we prove a structural theorem for planar graphs, showing the existence of a near-optimal quotient vertex-cut whose high-level structure is that of a bounded-depth tree. Second, we develop an algorithm that optimizes over such complex structures in running time that depends (exponentially) not on the size of the structure, but rather only on its depth. These techniques may be applicable in other problems.
STOC	The threshold for random k-SAT is 2 (ln 2 - O(k)).	Dimitris Achlioptas,Yuval Peres	2003	Let Fk(n,m) be a random k-SAT formula on n variables formed by selecting uniformly and independently m out of all possible k-clauses. It is well-known that for r ≥ 2k ln 2, Fk(n,rn) is unsatisfiable with probability 1-o(1). We prove that there exists a sequence tk = O(k) such that for r ≥ 2k ln 2 - tk, Fk(n,rn) is satisfiable with probability 1-o(1).Our technique yields an explicit lower bound for every k which for k > 3 improves upon all previously known bounds. For example, when k=10 our lower bound is 704.94 while the upper bound is 708.94.
STOC	A stochastic process on the hypercube with applications to peer-to-peer networks.	Micah Adler,Eran Halperin,Richard M. Karp,Vijay V. Vazirani	2003	Consider the following stochastic process executed on a graph G=(V,E) whose nodes are initially uncovered. In each step, pick a node at random and if it is uncovered, cover it. Otherwise, if it has an uncovered neighbor, cover a random uncovered neighbor. Else, do nothing. This can be viewed as a structured coupon collector process. We show that for a large family of graphs, O(n) steps suffice to cover all nodes of the graph with high probability, where n is the number of vertices. Among these graphs are d-regular graphs with d =Ω(log n log log n), random d-regular graphs with d =Ω(log n) and the k-dimensional hypercube where n=2k.This process arises naturally in answering a question on load balancing in peer-to-peer networks. We consider a distributed hash table in which keys are partitioned across a set of processors, and we assume that the number of processors grows dynamically, starting with a single processor. If at some stage there are n processors, the number of queries required to find a key is log2 n+O(1), the number of pointers maintained by each processor is log2 n+O(1), and moreover the worst ratio between the loads of processors is O(1), with high probability. To the best of our knowledge, this is the first analysis of a distributed hash table that achieves asymptotically optimal load balance, while still requiring only O(log n) pointers per processor and O(log n) queries for locating a key; previous methods required Ω(log2 n) pointers per processor and Ω(log n) queries for locating a key.
STOC	The online set cover problem.	Noga Alon,Baruch Awerbuch,Yossi Azar,Niv Buchbinder,Joseph Naor	2003	"Let $X=\{1,2,\ldots,n\}$ be a ground set of $n$ elements, and let ${\cal S}$ be a family of subsets of $X$, $|{\cal S}|=m$, with a positive cost $c_S$ associated with each $S\in{\cal S}$. Consider the following online version of the set cover problem, described as a game between an algorithm and an adversary. An adversary gives elements to the algorithm from $X$ one by one. Once a new element is given, the algorithm has to cover it by some set of ${\cal S}$ containing it. We assume that the elements of $X$ and the members of ${\cal S}$ are known in advance to the algorithm; however, the set $X'\subseteq X$ of elements given by the adversary is not known in advance to the algorithm. (In general, $X'$ may be a strict subset of $X$.) The objective is to minimize the total cost of the sets chosen by the algorithm. Let ${\cal C}$ denote the family of sets in ${\cal S}$ that the algorithm chooses. At the end of the game the adversary also produces (offline) a family of sets ${\cal C}_{OPT}$ that covers $X'$. The performance of the algorithm is the ratio between the cost of ${\cal C}$ and the cost of ${\cal C}_{OPT}$. The maximum ratio, taken over all input sequences, is the competitive ratio of the algorithm. We present an $O(\log m\log n)$ competitive deterministic algorithm for the problem and establish a nearly matching $\Omega\bigl(\frac{\log n\log m}{\log\log m+\log\log n}\bigr)$ lower bound for all interesting values of $m$ and $n$. The techniques used are motivated by similar techniques developed in computational learning theory for online prediction (e.g., the WINNOW algorithm) together with a novel way of converting a fractional solution into a deterministic online algorithm."
STOC	Testing subgraphs in directed graphs.	Noga Alon,Asaf Shapira	2003	"Let H be a fixed directed graph on h vertices, let G be a directed graph on n vertices and suppose that at least εn2 edges have to be deleted from it to make it H-free. We show that in this case G contains at least f(ε, H)nh copies of H. This is proved by establishing a directed version of Szemerédi's regularity lemma, and implies that for every H there is a one-sided error property tester whose query complexity is bounded by a function of ε only for testing the property PH of being H-free.As is common with applications of the undirected regularity lemma, here too the function 1/f(ε,H) is an extremely fast growing function in ε. We therefore further prove a precise characterization of all the digraphs H, for which f(ε,H) has a polynomial dependency on ε. This implies a characterization of all the digraphs H, for which the property of being H-free has a one-sided error property tester whose query complexity is polynomial in 1/ε. We further show that the same characterization also applies to two-sided error property testers as well. A special case of this result settles an open problem raised by the first author in (Alon, Proceedings of the 42nd IEEE FOCS, IEEE, New York, 2001, pp. 434-441). Interestingly, it turns out that if PH has a polynomial query complexity, then there is a two-sided ε-tester for PH that samples only O(1/ε) vertices, whereas any one-sided tester for PH makes at least (1/ε)d/2 queries, where d is the average degree of H. We also show that the complexity of deciding if for a given directed graph H, PH has a polynomial query complexity, is NP-complete, marking an interesting distinction from the case of undirected graphs.For some special cases of directed graphs H, we describe very efficient one-sided error property-testers for testing PH. As a consequence we conclude that when H is an undirected bipartite graph, we can give a one-sided error property tester with query complexity O((1/ε)h/2), improving the previously known upper bound O((1/ε)h2). The proofs combine combinatorial, graph theoretic and probabilistic arguments with results from additive number theory."
STOC	Adiabatic quantum state generation and statistical zero knowledge.	Dorit Aharonov,Amnon Ta-Shma	2003	"The design of new quantum algorithms has proven to be an extremely difficult task. This paper considers a different approach to the problem, by studying the problem of 'quantum state generation'.We first show that any problem in Statistical Zero Knowledge (including eg. discrete log, quadratic residuosity and gap closest vector in a lattice) can be reduced to an instance of the quantum state generation problem. Having shown the generality of the state generation problem, we set the foundations for a new paradigm for quantum state generation. We define 'Adiabatic State Generation' (ASG), which is based on Hamiltonians instead of unitary gates. We develop tools for ASG including a very general method for implementing Hamiltonians (The sparse Hamiltonian lemma), and ways to guarantee non negligible spectral gaps (The jagged adiabatic path lemma). We also prove that ASG is equivalent in power to state generation in the standard quantum model. After setting the foundations for ASG, we show how to apply our techniques to generate interesting superpositions related to Markov chains.The ASG approach to quantum algorithms provides intriguing links between quantum computation and many different areas: the analysis of spectral gaps and groundstates of Hamiltonians in physics, rapidly mixing Markov chains, statistical zero knowledge, and quantum random walks. We hope that these links will bring new insights and methods into quantum algorithms."
STOC	"The worst-case behavior of schnorr's algorithm approximating the shortest nonzero vector in a lattice."	Miklós Ajtai	2003	"Schnorr's algorithm for finding an approximation for the shortest nonzero vector in an n dimensional lattice depends on a parameter k. He proved that for a fixed k ≤ n his algorithm (block 2k-reduction) provides a lattice vector whose length is greater than the length of a shortest nonzero vector in the lattice by at most a factor of (4k2) n/k. (The time required by the algorithm depends on k.) We show that if k=o(n), this bound on the performance of Schnorr's algorithm cannot be improved (apart from a constant factor in the exponent), namely there is a lattice and a basis so that if they are given as an input to the algorithm then the resulting approximating factor of the output is at least k ε n/k. (For larger integers k if Schnorr's algorithm runs in polynomial time then we have already a polynomial time algorithm for finding the shortest nonzero vector.) We also solve an open problem formulated by Schnorr about the the Korkine-Zolotareff lattice constants αk. We show that his upper bound αk ≤ k1 + ln k is the best possible apart from a constant factor in the exponent. We prove a similar result about his upper bound βk≤ 4k2, where βk is another lattice constant with an important role in Schnorr's analysis of his algorithm."
STOC	Near-optimal network design with selfish agents.	Elliot Anshelevich,Anirban Dasgupta,Éva Tardos,Tom Wexler	2003	"We introduce a simple network design game that models how independent selfish agents can build or maintain a large network. In our game every agent has a specific connectivity requirement, i.e. each agent has a set of terminals and wants to build a network in which his terminals are connected. Possible edges in the network have costs and each agent's goal is to pay as little as possible. Determining whether or not a Nash equilibrium exists in this game is NP-complete. However, when the goal of each player is to connect a terminal to a common source, we prove that there is a Nash equilibrium as cheap as the optimal network, and give a polynomial time algorithm to find a (1+ε)-approximate Nash equilibrium that does not cost much more. For the general connection game we prove that there is a 3-approximate Nash equilibrium that is as cheap as the optimal network, and give an algorithm to find a (4.65+ε)-approximate Nash equilibrium that does not cost much more."
STOC	Cutting triangular cycles of lines in space.	Boris Aronov,Vladlen Koltun,Micha Sharir	2003	We show that n lines in 3-space can be cut into O(n2-1/69log16/69n) pieces, such that all depth cycles defined by triples of lines are eliminated. This partially resolves a long-standing open problem in computational geometry, motivated by hidden-surface removal in computer graphics.
STOC	Distinct distances in three and higher dimensions.	Boris Aronov,János Pach,Micha Sharir,Gábor Tardos	2003	Improving an old result of Clarkson, Edelsbrunner, Guibas, Sharir and Welzl, we show that the number of distinct distances determined by a set $P$ of $n$ points in three-dimensional space is $\Omega(n^{77/141-\varepsilon})=\Omega(n^{0.546})$, for any $\varepsilon>0$. Moreover, there always exists a point $p\in P$ from which there are at least so many distinct distances to the remaining elements of $P$. The same result holds for points on the three-dimensional sphere. As a consequence, we obtain analogous results in higher dimensions.
STOC	Reducing truth-telling online mechanisms to online optimization.	Baruch Awerbuch,Yossi Azar,Adam Meyerson	2003	"We describe a general technique for converting an online algorithm Β to a truthtelling mechanism. We require that the original online competitive algorithm has certain ""niceness"" properties in that actions on future requests are independent of the actual value of requests which were accepted (though these actions will of course depend upon the set of accepted requests). Under these conditions, we are able to give an online truthtelling mechanism (where the values of requests are given by bids which may not accurately represent the valuation of the requesters) such that our total profit is within O(ρ + log μ) of the optimum offline profit obtained by an omniscient algorithm (one which knows the true valuations of the users). Here ρ is the competitive ratio of Β for the optimization version of the problem, and μ is the ratio of the maximum to minimum valuation for a request. In general there is an Ω(log μ) lower bound on the ratio of worst-case profit for a truthtelling mechanism when compared to the profit obtained by an omniscient algorithm, so this result is in some sense best possible. In addition, we prove that our construction is resilient against many forms of ""cheating"" attempts, such as forming coalitions.We demonstrate applications of this result to several problems. We develop online truthtelling mechanisms for online routing and admission control of path or multicast requests, assuming large network capacities. Assuming the existance of an algorithm Β for the optimization version of the problem, our techniques provide truthtelling mechanisms for general combinatorial auctions. However, designing optimization algorithms may be difficult in general because of online or approximation lower bounds. For the cases described above, we are able to design optimization algorithms Β by amortizing the lost benefit from online computation (and from approximation hardness in the case of multicast) against the benefit obtained from accepted requests.We comment that our upper bounds on profit competitiveness imply, as an obvious corollary, similar bound on global efficiency, namely overall well-being of all the users. This contrasts with most other work on truthtelling mechanisms for general online resource allocation, where only efficiency is maximized, and competitiveness can be arbitrarily poor."
STOC	Optimal oblivious routing in polynomial time.	Yossi Azar,Edith Cohen,Amos Fiat,Haim Kaplan,Harald Räcke	2003	"A recent seminal result of Räcke is that for any undirected network there is an oblivious routing algorithm with a polylogarithmic competitive ratio with respect to congestion. Unfortunately, Räcke's construction is not polynomial time. We give a polynomial time construction that guarantees Räcke's bounds, and more generally gives the true optimal ratio for any (undirected or directed) network."
STOC	Management of multi-queue switches in QoS networks.	Yossi Azar,Yossi Richter	2003	The concept of Quality of Service (QoS) networks has gained growing attention recently, as the traffic volume in the Internet constantly increases, and QoS guarantees are essential to ensure proper operation of most communication based applications. A QoS switch serves m incoming queues by transmitting packets arriving at these queues through one output port, one packet per time unit. Each packet is marked with a value indicating its guaranteed quality of service. Since the queues have bounded capacity and the rate of arriving packets can be much higher than the transmission rate, packets can be lost due to insufficient queue space. The goal is to maximize the total value of transmitted packets. This problem encapsulates two dependent questions: admission control, namely which packets to discard in case of queue overflow, and scheduling, i.e. which queue to use for transmission in each time unit. We use competitive analysis to study online switch performance in QoS based networks. Specifically, we provide a novel generic technique that decouples the admission control and scheduling problems. Our technique transforms any single queue admission control strategy (preemptive or nonpreemptive) to a scheduling and admission control algorithm for our general m queues model, whose competitive ratio is at most twice the competitive ratio of the given admission control strategy. We use our technique to derive concrete algorithms for the general preemptive and nonpreemptive cases, as well as for the interesting special cases of the 2-value model and the unit value model. To the best of our knowledge this is the first result combining both scheduling and admission control decisions for arbitrary packets sequences in multi-queue switches. We also provide a 1.58-competitive randomized algorithm for the unit value case. This case is interesting by itself since most current networks (e.g. IP networks) only support a best-effort service in which all packets streams are treated equally.
STOC	Server scheduling in the L norm: a rising tide lifts all boat.	Nikhil Bansal,Kirk Pruhs	2003	Often server systems do not implement the best known algorithms for optimizing average Quality of Service (QoS) out of concern of that these algorithms may be insufficiently fair to individual jobs. The standard method for balancing average QoS and fairness is optimize the Lp metric, 1 < p < ∞. Thus we consider server scheduling strategies to optimize the Lp norms of the standard QoS measures, flow and stretch. We first show that there is no no(1)-competitive online algorithm for the Lp norms of either flow or stretch. We then show that the standard clairvoyant algorithms for optimizing average QoS, SJF and SRPT, are O(1+ε)-speed O(1/ε)-competitive for the Lp norms of flow and stretch. And that the standard nonclairvoyant algorithm for optimizing average QoS, SETF, is O(1+ε)-speed O(1/ε(2+2/p))-competitive for the Lp norms of flow. These results argue that these standard algorithms will not starve jobs until the system is near peak capacity. In contrast, we show that the Round Robin, or Processor Sharing algorithm, which is sometimes adopted because of its seeming fairness properties, is not O(1+ε)-speed no(1)-competitive for sufficiently small ε.
STOC	Sampling lower bounds via information theory.	Ziv Bar-Yossef	2003	"We present a novel technique, based on the Jensen-Shannon divergence from information theory, to prove lower bounds on the query complexity of sampling algorithms that approximate functions over arbitrary domain and range. Unlike previous methods, our technique does not use a reduction from a decision promise problem. As a result, it gives stronger bounds for functions that possess a large set of inputs, each two of which exhibit a gap in the function value.We demonstrate the technique with new query complexity lower bounds for three fundamental problems: (1) the ""election problem"", for which we obtain a quadratic improvement over previous bounds, (2) low rank matrix approximation, for which we prove the first lower bounds, showing that the algorithms given for this problem are almost optimal, and (3) matrix reconstruction.In addition, we introduce a new method for proving lower bounds on the expected query complexity of functions, using the Kullback-Leibler divergence. We demonstrate its use by a simple query complexity lower bound for the mean."
STOC	On metric ramsey-type phenomena.	Yair Bartal,Nathan Linial,Manor Mendel,Assaf Naor	2003	"This paper deals with Ramsey-type theorems for metric spaces. Such a theorem states that every n point metric space contains a large subspace which can be embedded with some fixed distortion in a metric space from some special class.Our main theorem states that for any ε>0, every n point metric space contains a subspace of size at least n1-ε which is embeddable in an ultrametric with O(log(1/ε)/ε distortion. This in particular provides a bound for embedding in Euclidean spaces. The bound on the distortion is tight up to the log(1/ε) factor even for embedding in arbitrary Euclidean spaces. This result can be viewed as a non-linear analog of Dvoretzky's theorem, a cornerstone of modern Banach space theory and convex geometry.Our main Ramsey-type theorem and techniques naturally extend to give theorems for classes of hierarchically well-separated trees which have algorithmic implications, and can be viewed as the solution of a natural clustering problem.We further include a comprehensive study of various other aspects of the metric Ramsey problem."
STOC	A sublinear algorithm for weakly approximating edit distance.	Tugkan Batu,Funda Ergün,Joe Kilian,Avner Magen,Sofya Raskhodnikova,Ronitt Rubinfeld,Rahul Sami	2003	"We show how to determine whether the edit distance between two given strings is small in sublinear time. Specifically, we present a test which, given two n-character strings A and B, runs in time o(n) and with high probability returns ""CLOSE"" if their edit distance is O(nΑ), and ""FAR"" if their edit distance is Ω(n), where Α is a fixed parameter less than 1. Our algorithm for testing the edit distance works by recursively subdividing the strings A and B into smaller substrings and looking for pairs of substrings in A, B with small edit distance. To do this, we query both strings at random places using a special technique for economizing on the samples which does not pick the samples independently and provides better query and overall complexity. As a result, our test runs in time Õ(nmax(Α/2, 2Α - 1\)) for any fixed Α < 1. Our algorithm thus provides a trade-off between accuracy and efficiency that is particularly useful when the input data is very large.We also show a lower bound of Ω(nΑ/2) on the query complexity of every algorithm that distinguishes pairs of strings with edit distance at most nΑ from those with edit distance at least n/6."
STOC	Random knapsack in expected polynomial time.	René Beier,Berthold Vöcking	2003	We present the first average-case analysis proving a polynomial upper bound on the expected running time of an exact algorithm for the 0/1 knapsack problem. In particular, we prove for various input distributions, that the number of Pareto-optimal knapsack fillings is polynomially bounded in the number of available items. An algorithm by Nemhauser and Ullmann can enumerate these solutions very efficiently so that a polynomial upper bound on the number of Pareto-optimal solutions implies an algorithm with expected polynomial running time.The random input model underlying our analysis is quite general and not restricted to a particular input distribution. We assume adversarial weights and randomly drawn profits (or vice versa). Our analysis covers general probability distributions with finite mean and, in its most general form, can even handle different probability distributions for the profits of different items. This feature enables us to study the effects of correlations between profits and weights. Our analysis confirms and explains practical studies showing that so-called strongly correlated instances are harder to solve than weakly correlated ones.
STOC	Some 3CNF properties are hard to test.	Eli Ben-Sasson,Prahladh Harsha,Sofya Raskhodnikova	2003	For a Boolean formula $\phi$ on n variables, the associated property $P_\phi$ is the collection of n-bit strings that satisfy $\phi$. We study the query complexity of tests that distinguish (with high probability) between strings in $P_\phi$ and strings that are far from $P_\phi$ in Hamming distance. We prove that there are 3CNF formulae (with O(n) clauses) such that testing for the associated property requires $\Omega(n)$ queries, even with adaptive tests. This contrasts with 2CNF formulae, whose associated properties are always testable with $O(\sqrt{n})$ queries [E. Fischer et al., Monotonicity testing over general poset domains, in Proceedings of the 34th Annual ACM Symposium on Theory of Computing, ACM, New York, 2002, pp. 474--483]. Notice that for every negative instance (i.e., an assignment that does not satisfy $\phi$) there are three bit queries that witness this fact. Nevertheless, finding such a short witness requires reading a constant fraction of the input, even when the input is very far from satisfying the formula that is associated with the property.A property is linear if its elements form a linear space. We provide sufficient conditions for linear properties to be hard to test, and in the course of the proof include the following observations which are of independent interest: In the context of testing for linear properties, adaptive two-sided error tests have no more power than nonadaptive one-sided error tests. Moreover, without loss of generality, any test for a linear property is a linear test. A linear test verifies that a portion of the input satisfies a set of linear constraints, which define the property, and rejects if and only if it finds a falsified constraint. A linear test is by definition nonadaptive and, when applied to linear properties, has a one-sided error. Random low density parity check codes (which are known to have linear distance and constant rate) are not locally testable. In fact, testing such a code of length n requires $\Omega(n)$ queries.
STOC	Randomness-efficient low degree tests and short PCPs via epsilon-biased sets.	Eli Ben-Sasson,Madhu Sudan,Salil P. Vadhan,Avi Wigderson	2003	We present the first explicit construction of Probabilistically Checkable Proofs (PCPs) and Locally Testable Codes (LTCs) of fixed constant query complexity which have almost-linear (= n * 2Õ(√log n)) size. Such objects were recently shown to exist (nonconstructively) by Goldreich and Sudan[17]. Previous explicit constructions required size n1 + Ω(ε) with 1/ε queries. The key to these constructions is a nearly optimal randomness-efficient version of the low degree test[32]. In a similar way we give a randomness-efficient version of the BLR linearity test[13] (which is used, for instance, in locally testing the Hadamard code). The derandomizations are obtained through ε-biased sets for vector spaces over finite fields. The analysis of the derandomized tests rely on alternative views of ε-biased sets --- as generating sets of Cayley expander graphs for the low degree test, and as defining linear error-correcting codes for the linearity test.
STOC	Modified log-sobolev inequalities, mixing and hypercontractivity.	Sergey Bobkov,Prasad Tetali	2003	"Motivated by (the rate of information loss or) the rate at which the entropy of an ergodic Markov chain relative to its stationary distribution decays to zero, we study modified versions of the standard logarithmic Sobolev inequality in the discrete setting of finite Markov chains and graphs. These inequalities turn out to be weaker than the standard log-Sobolev inequality, but stronger than the Poincare' (spectral gap) inequality. We also derive a hypercontractivity formulation equivalent to our main modified log-Sobolev inequality which might be of independent interest. Finally we show that, in contrast with the spectral gap, for bounded degree expander graphs various log-Sobolev-type constants go to zero with the size of the graph."
STOC	On the limits of cache-obliviousness.	Gerth Stølting Brodal,Rolf Fagerberg	2003	In this paper, we present lower bounds for permuting and sorting in the cache-oblivious model. We prove that (1) I/O optimal cache-oblivious comparison based sorting is not possible without a tall cache assumption, and (2) there does not exist an I/O optimal cache-oblivious algorithm for permuting, not even in the presence of a tall cache assumption.Our results for sorting show the existence of an inherent trade-off in the cache-oblivious model between the strength of the tall cache assumption and the overhead for the case M » B, and show that Funnelsort and recursive binary mergesort are optimal algorithms in the sense that they attain this trade-off.
STOC	OPT versus LOAD in dynamic storage allocation.	Adam L. Buchsbaum,Howard J. Karloff,Claire Kenyon,Nick Reingold,Mikkel Thorup	2003	Dynamic storage allocation is the problem of packing given axis-aligned rectangles into a horizontal strip of minimum height by sliding the rectangles vertically but not horizontally. Where L= is the maximum sum of heights of rectangles that intersect any vertical line and OPT is the minimum height of the enclosing strip, it is obvious that $\ensuremath{\text{\it OPT}}\ge \ensuremath{\text{\it LOAD}}$; previous work showed that $\ensuremath{\text{\it OPT}}\le 3\cdot LOAD. We continue the study of the relationship between OPT and LOAD, proving that OPT=L+O((hmax/L)1/7)L, where hmax is the maximum job height. Conversely, we prove that for any $\epsilon>0$, there exists a c>0 such that for all sufficiently large integers $h_{\max}$, there is a dynamic storage allocation instance with maximum job height $h_{\max}$, maximum load at most L, and $\ensuremath{\text{\it OPT}}\geq L+c(h_{\max}/L)^{1/2+\epsilon}L$, for infinitely many integers L. En route, we construct several new polynomial-time approximation algorithms for dynamic storage allocation, including a $(2+\epsilon)$-approximation algorithm for the general case and polynomial-time approximation schemes for several natural special cases.
STOC	Better streaming algorithms for clustering problems.	"Moses Charikar,Liadan O'Callaghan,Rina Panigrahy"	2003	We study clustering problems in the streaming model, where the goal is to cluster a set of points by making one pass (or a few passes) over the data using a small amount of storage space. Our main result is a randomized algorithm for the k--Median problem which produces a constant factor approximation in one pass using storage space O(k poly log n). This is a significant improvement of the previous best algorithm which yielded a 2O(1/ε) approximation using O(nε) space. Next we give a streaming algorithm for the k--Median problem with an arbitrary distance function. We also study algorithms for clustering problems with outliers in the streaming model. Here, we give bicriterion guarantees, producing constant factor approximations by increasing the allowed fraction of outliers slightly.
STOC	Sublinear geometric algorithms.	Bernard Chazelle,Ding Liu,Avner Magen	2003	We initiate an investigation of sublinear algorithms for geometric problems in two and three dimensions. We give optimal algorithms for intersection detection of convex polygons and polyhedra, point location in two-dimensional Delaunay triangulations and Voronoi diagrams, and ray shooting in convex polyhedra, all of which run in time O(√n), where n is the size of the input. We also provide sublinear solutions for the approximate evaluation of the volume of a convex polytope and the length of the shortest path between two points on the boundary.
STOC	Meet and merge: approximation algorithms for confluent flows.	Jiangzhuo Chen,Rajmohan Rajaraman,Ravi Sundaram	2003	In this paper, we investigate the problem of determining confluent flows with minimum congestion. A flow of a given commodity is said to be confluent if at any node all the flow of the commodity departs along a single edge. Confluent flows appear in a variety of application areas ranging from wireless communications to evacuations; in fact, most flows in the Internet are confluent since Internet routing is destination based. We consider the single-commodity confluent flow problem, in which we are given an n-node directed network G, a sink t and supplies at each node, and the goal is to find a confluent flow that routes all the supplies to the sink while minimizing the maximum edge congestion. Our main result is an approximation algorithm, based on randomized rounding, for the special case when all the supplies are uniform; the algorithm finds a confluent flow with edge (and node) congestion O(C^2log^3n), where C is the node congestion of a splittable flow with minimum node congestion; here the node congestion of a flow is the maximum, over all nodes other than t, of the congestion at a node. This implies an O@?(n) approximation algorithm for the problem with uniform supplies. Our result relies on the analysis of a natural probabilistic process defined on directed acyclic graphs, that may be of independent interest. For tree networks, we present an optimal polynomial-time algorithm for a multi-sink generalization of the above confluent flow problem. We show that it is NP-hard to approximate the congestion of the optimal confluent flow for general networks to within a factor of 32. We also establish a lower bound on the gap between confluent and splittable flows, and consider multi-commodity and fractional versions of confluent flow problems.
STOC	Exponential algorithmic speedup by a quantum walk.	Andrew M. Childs,Richard Cleve,Enrico Deotto,Edward Farhi,Sam Gutmann,Daniel A. Spielman	2003	We construct a black box graph traversal problem that can be solved exponentially faster on a quantum computer than on a classical computer. The quantum algorithm is based on a continuous time quantum walk, and thus employs a different technique from previous quantum algorithms based on quantum Fourier transforms. We show how to implement the quantum walk efficiently in our black box setting. We then show how this quantum walk solves our problem by rapidly traversing a graph. Finally, we prove that no classical algorithm can solve the problem in subexponential time.
STOC	Pricing network edges for heterogeneous selfish users.	Richard Cole,Yevgeniy Dodis,Tim Roughgarden	2003	We study the negative consequences of selfish behavior in a congested network and economic means of influencing such behavior. We consider a model of selfish routing in which the latency experienced by network traffic on an edge of the network is a function of the edge congestion, and network users are assumed to selfishly route traffic on minimum-latency paths. The quality of a routing of traffic is measured by the sum of travel times (the total latency).It is well known that the outcome of selfish routing (a Nash equilibrium) does not minimize the total latency. An ancient strategy for improving the selfish solution is the principle of marginal cost pricing, which asserts that on each edge of the network, each network user on the edge should pay a tax offsetting the congestion effects caused by its presence. By pricing network edges according to this principle, the inefficiency of selfish routing can always be eradicated.This result, while fundamental, assumes a very strong homogeneity property: all network users are assumed to trade off time and money in an identical way. The guarantee also ignores both the algorithmic aspects of edge pricing and the unfortunate possibility that an efficient routing of traffic might only be achieved with exorbitant taxes. Motivated by these shortcomings, we extend this classical work on edge pricing in several different directions and prove the following results.We prove that the edges of a single-commodity network can always be priced so that an optimal routing of traffic arises as a Nash equilibrium, even for very general heterogeneous populations of network users.When there are only finitely many different types of network users and all edge latency functions are convex, we show how to compute such edge prices efficiently.We prove that an easy-to-check mathematical condition on the population of heterogeneous network users is both necessary and sufficient for the existence of edge prices that induce an optimal routing while requiring only moderate taxes.
STOC	A fast algorithm for computing steiner edge connectivity.	Richard Cole,Ramesh Hariharan	2003	"Given an undirected graph or an Eulerian directed graph G and a subset S of its vertices, we show how to determine the edge connectivity C of the vertices in S in time O(C3 n log n+m). This algorithm is based on an efficient construction of tree packings which generalizes Edmonds' Theorem. These packings also yield a characterization of all minimal Steiner cuts of size C from which an efficient data structure for maintaining edge connectivity between vertices in S under edge insertion can be obtained. This data structure enables the efficient construction of a cactus tree for representing significant C-cuts among these vertices, called C-separations, in the same time bound. In turn, we use the cactus tree to give a fast implementation of an approximation algorithm for the Survivable Network Design problem due to Williamson, Goemans, Mihail and Vazirani."
STOC	Reconstructing curves in three (and higher) dimensional space from noisy data.	Don Coppersmith,Madhu Sudan	2003	"We consider the task of reconstructing a curve in constant dimensional space from noisy data. We consider curves of the form C = [(x,y1,•••,yc) | yj = pj(x)], where the pj's are polynomials of low degree. Given n points in (c+1)-dimensional space, such that t of these lie on some such unknown curve C while the other n-t are chosen randomly and independently, we give an efficient algorithm to recover the curve C and the identity of the good points. The success of our algorithm depends on the relation between n, t, c and the degree of the curve C, requiring t = Ω (n deg(C)) 1/(c+1). This generalizes, in the restricted setting of random errors, the work of Sudan (J. Complexity, 1997) and of Guruswami and Sudan (IEEE Trans. Inf. Th. 1999) that considered the case c=1."
STOC	Non-interactive and reusable non-malleable commitment schemes.	Ivan Damgård,Jens Groth	2003	We consider non-malleable (NM) and universally composable (UC) commitment schemes in the common reference string (CRS) model. We show how to construct non-interactive NM commitments that remain non-malleable even if the adversary has access to an arbitrary number of commitments from honest players - rather than one, as in several previous schemes. We show this is a strictly stronger security notion. Our construction is the first non-interactive scheme achieving this that can be based on the minimal assumption of existence of one-way functions. But it can also be instantiated in a very efficient version based on the strong RSA assumption. For UC commitments, we show that existence of a UC commitment scheme in the CRS model (interactive or not) implies key exchange and - for a uniform reference string - even implies oblivious transfer. This indicates that UC commitment is a strictly stronger primitive than NM. Finally, we show that our strong RSA based construction can be used to improve the most efficient known UC commitment scheme so it can work with a CRS of size independent of the number of players, without loss of efficiency.
STOC	A new approach to dynamic all pairs shortest paths.	Camil Demetrescu,Giuseppe F. Italiano	2003	We study novel combinatorial properties of graphs that allow us to devise a completely new approach to dynamic all pairs shortest paths problems. Our approach yields a fully dynamic algorithm for general directed graphs with non-negative real-valued edge weights that supports any sequence of operations in O(n2log3n) amortized time per update and unit worst-case time per distance query, where n is the number of vertices. We can also report shortest paths in optimal worst-case time. These bounds improve substantially over previous results and solve a long-standing open problem. Our algorithm is deterministic, uses simple data structures, and appears to be very fast in practice.
STOC	Alpha-shapes and flow shapes are homotopy equivalent.	Tamal K. Dey,Joachim Giesen,Matthias John	2003	In this paper we establish a topological similarity between two apparently different shape constructors from a set of points. Shape constructors are geometric structures that transform finite point sets into continuous shapes. Due to their immense practical importance in geometric modeling various shape constructors have been proposed recently. Understanding the relations among them often leads to new insights that are potentially helpful in applications. Here we discover a topological equivalence among two such geometric structures, namely α shapes and flow shapes. Both shapes found applications in surface reconstruction and molecular modelin.
STOC	Almost random graphs with simple hash functions.	Martin Dietzfelbinger,Philipp Woelfel	2003	"We describe a simple randomized construction for generating pairs of hash functions h1,h2 from a universe U to ranges V = [m] = (0,1,...,m-1) and W = [m] so that for every key set S ⊆ U with n = |S| ≤ m/(1 + ε) the (random) bipartite (multi)graph with node set V ∪ W and edge set (h1(x),h2(x))| x ∈ S exhibits a structure that is essentially random. The construction combines d-wise independent classes for d a relatively small constant with the well-known technique of random offsets. While keeping the space needed to store the description of h1 and h2 at O(nζ), for ζ < 1 fixed arbitrarily, we obtain a much smaller (constant) evaluation time than previous constructions of this kind, which involved Siegel's high-performance hash classes. The main new technique is the combined analysis of the graph structure and the inner structure of the hash functions, as well as a new way of looking at the cycle structure of random (multi)graphs. The construction may be applied to improve on Pagh and Rodler's ""cuckoo hashing"" (2001), to obtain a simpler and faster alternative to a recent construction of Ostlin and Pagh (2002/03) for simulating uniform hashing on a key set S, and to the simulation of shared memory on distributed memory machines. We also describe a novel way of implementing (approximate) d-wise independent hashing without using polynomials."
STOC	A new multilayered PCP and the hardness of hypergraph vertex cover.	Irit Dinur,Venkatesan Guruswami,Subhash Khot,Oded Regev	2003	Given a k-uniform hypergraph, the Ek-Vertex-Cover problem is to find the smallest subset of vertices that intersects every hyperedge. We present a new multilayered probabilistically checkable proof (PCP) construction that extends the Raz verifier. This enables us to prove that Ek-Vertex-Cover is NP-hard to approximate within a factor of $(k-1-\epsilon)$ for arbitrary constants $\epsilon>0$ and $k\ge 3$. The result is nearly tight as this problem can be easily approximated within factor k. Our construction makes use of the biased long-code and is analyzed using combinatorial properties of s-wise t-intersecting families of subsets.We also give a different proof that shows an inapproximability factor of $\lfloor \frac{k}{2} \rfloor -\eps$. In addition to being simpler, this proof also works for superconstant values of k up to (log N)1/c, where c > 1 is a fixed constant and N is the number of hyperedges.
STOC	Touring a sequence of polygons.	Moshe Dror,Alon Efrat,Anna Lubiw,Joseph S. B. Mitchell	2003	"Given a sequence of k polygons in the plane, a start point s, and a target point, t, we seek a shortest path that starts at s, visits in order each of the polygons, and ends at t. If the polygons are disjoint and convex, we give an algorithm running in time O(kn log (n/k)), where n is the total number of vertices specifying the polygons. We also extend our results to a case in which the convex polygons are arbitrarily intersecting and the subpath between any two consecutive polygons is constrained to lie within a simply connected region; the algorithm uses O(nk2 log n) time. Our methods are simple and allow shortest path queries from s to a query point t to be answered in time O(k log n + m), where m is the combinatorial path length. We show that for nonconvex polygons this ""touring polygons"" problem is NP-hard.The touring polygons problem is a strict generalization of some classic problems in computational geometry, including the safari problem, the zoo-keeper problem, and the watchman route problem in a simple polygon. Our new results give an order of magnitude improvement in the running times of the safari problem and the watchman route problem: We solve the safari problem in O(n2 log n) time and the watchman route problem (through a fixed point s) in time O(n3 log n), compared with the previous time bounds of O(n3) and O(n4), respectively."
STOC	Approximate counting by dynamic programming.	Martin E. Dyer	2003	"We give efficient algorithms to sample uniformly, and count approximately, the solutions to a zero-one knapsack problem. The algorithm is based on using dynamic programming to provide a deterministic relative approximation. Then ""dart throwing"" techniques are used to give arbitrary approximation ratios. We also indicate how further improvements can be obtained using randomized rounding. We extend the approach to several related problems: the m-constraint zero-one knapsack, the general integer knapsack (including its m-constraint version) and contingency tables with constantly many rows."
STOC	A tight bound on approximating arbitrary metrics by tree metrics.	Jittat Fakcharoenphol,Satish Rao,Kunal Talwar	2003	In this paper, we show that any n point metric space can be embedded into a distribution over dominating tree metrics such that the expected stretch of any edge is O(log n). This improves upon the result of Bartal who gave a bound of O(log n log log n). Moreover, our result is existentially tight; there exist metric spaces where any tree embedding must have distortion Ω(log n)-distortion. This problem lies at the heart of numerous approximation and online algorithms including ones for group Steiner tree, metric labeling, buy-at-bulk network design and metrical task system. Our result improves the performance guarantees for all of these problems.
STOC	A tight time lower bound for space-optimal implementations of multi-writer snapshots.	Panagiota Fatourou,Faith Ellen Fich,Eric Ruppert	2003	A snapshot object consists of a collection of m > 1 components, each capable of storing a value, shared by n processes in an asynchronous shared-memory distributed system. It supports two operations: a process can UPDATE any individual component or atomically SCAN the entire collection to obtain the values of all the components. It is possible to implement a snapshot object using m registers so that each operation takes O(mn) time.In a previous paper, we proved that m registers are necessary to implement a snapshot object with m < n-1 components. Here we prove that, for any such space-optimal implementation, Ω(mn) steps are required to perform a SCAN operation in the worst case, matching the upper bound. We also extend our space and time lower bounds to implementations that use single-writer registers in addition to the multi-writer registers. Specifically, we prove that at least m multi-writer registers are still needed, provided the SCANS do not read a large fraction of the single-writer registers. We also prove that any implementation that uses single-writer registers in addition to $m$ multi-writer registers uses Ω(√mn) steps in the worst case. Our proof yields insight into the structure of any implementation that uses only m multi-writer registers, showing that processes must access the multi-writer registers in a very constrained way.
STOC	Hidden translation and orbit coset in quantum computing.	Katalin Friedl,Gábor Ivanyos,Frédéric Magniez,Miklos Santha,Pranab Sen	2003	We give efficient quantum algorithms for the problems of Hidden Translation and Hidden Subgroup in a large class of non-abelian groups including solvable groups of constant exponent and of constant length derived series. Our algorithms are recursive. For the base case, we solve efficiently Hidden Translation in Z pn, whenever p is a fixed prime. For the induction step, we introduce the problem Orbit Coset generalizing both Hidden Translation and Hidden Subgroup, and prove a powerful self-reducibility result: Orbit Coset in a finite group G is reducible to Orbit Coset in G/N and subgroups of N, for any solvable normal subgroup N of G.
STOC	"A proof of Alon's second eigenvalue conjecture."	Joel Friedman	2003	"A d-regular graph has largest or first (adjacency matrix) eigenvalue λ1 = d. In this paper we show the following conjecture of Alon. Fix an integer d > 2 and a real ε > 0. Then for sufficiently large n we have that ""most"" d-regular graphs on n vertices have all their eigenvalues except λ1 = d bounded above by 2√d-1 + ε. Our methods, being trace methods, also bound those eigenvalues below by -2√d-1 - ε."
STOC	Lower bounds on the amount of randomness in private computation.	Anna Gál,Adi Rosén	2003	"We consider the amount of randomness necessary in information-theoretic private protocols. We prove that at least Ω(log n) random bits are necessary for the t-private computation of the function xor by n players, for any t ≥ 2. In view of the upper bound of O(t2log(n/t))[19], this bound is tight, up to constant factors, for any fixed t. For a class of protocols obeying certain restrictions, we give stronger lower bounds of Ω(t log (n/t)). We note that all known randomness efficient private protocols designed specifically for xor belong to this class. All our lower bounds hold for the ""trusted dealer"" model as well, and the Ω(t log (n/t)) lower bound for restricted protocols is tight, up to constant factors, for any t ≥ 2 in this model.In comparison, the previous lower bounds on the amount of randomness required by t-private computation of explicit functions did not grow with n for constant values of t, and our results improve the previous lower bounds for xor for any 2 ≤ t = o(log n). Our results also show that already for t = 2, Ω(log n) random bits are necessary, while it is known that for the case of t = 1 a single random bit is sufficient for privately computing xor for any number of players.Our proofs use novel techniques by which we extract random variables from a t-private protocol, and then use the t-privacy property of the protocol to prove properties of these random variables. These properties in turn imply that the number of random bits used by the players is large."
STOC	Well-separated pair decomposition for the unit-disk graph metric and its applications.	Jie Gao,Li Zhang	2003	We extend the classic notion of well-separated pair decomposition [P. B. Callahan and S. R. Kosaraju, J. ACM, 42 (1975), pp. 67--90] to the unit-disk graph metric: the shortest path distance metric induced by the intersection graph of unit disks. We show that for the unit-disk graph metric of n points in the plane and for any constant $c\geq 1$, there exists a c-well-separated pair decomposition with O(n log n) pairs, and the decomposition can be computed in O(n log n) time. We also show that for the unit-ball graph metric in k dimensions where $k\geq 3$, there exists a c-well-separated pair decomposition with O(n2-2/k) pairs, and the bound is tight in the worst case. We present the application of the well-separated pair decomposition in obtaining efficient algorithms for approximating the diameter, closest pair, nearest neighbor, center, median, and stretch factor, all under the unit-disk graph metric.
STOC	Lower bounds on the efficiency of encryption and digital signature schemes.	Rosario Gennaro,Yael Gertner,Jonathan Katz	2003	"A central focus of modern cryptography is to investigate the weakest possible assumptions under which various cryptographic algorithms exist. Typically, a proof that a ""weak"" primitive (e.g., a one-way function) implies the existence of a ""strong"" algorithm (e.g., a private-key encryption scheme) proceeds by giving an explicit construction of the latter from the former. In addition to showing the existence of such a construction, an equally important research direction is to explore the efficiency of such constructions.Among the most fundamental cryptographic algorithms are digital signature schemes and schemes for public- or private-key encryption. Here, we show the first lower bounds on the efficiency of any encryption or signature construction based on black-box access to one-way or trapdoor one-way permutations. If S is the assumed security of the permutation π (i.e., no adversary of size S can invert π on a fraction larger than 1/S of its inputs), our results show that:Any public-key encryption scheme for m-bit messages must query π at least Ω(m log S) times.Any private-key encryption scheme for m-bit messages (with k-bit keys) must query π at least Ω(m-k/log S) times.Any signature verification algorithm for m-bit messages must query π at least Ω(m log S) times.Our bounds match known upper bounds for the case of encryption.We prove our results in an extension of the Impagliazzo-Rudich model. That is, we show that any black-box construction beating our lower bounds would imply the unconditional existence of a one-way function."
STOC	Work-competitive scheduling for cooperative computing with dynamic groups.	Chryssis Georgiou,Alexander Russell,Alexander A. Shvartsman	2003	The problem of cooperatively performing a set of t tasks in a decentralized computing environment subject to failures is one of the fundamental problems in distributed computing. The setting with partitionable networks is especially challenging, as algorithmic solutions must accommodate the possibility that groups of processors become disconnected (and, perhaps, reconnected) during the computation. The efficiency of task-performing algorithms is often assessed in terms of work: the total number of tasks, counting multiplicities, performed by all of the processors during the computation. In general, the scenario where the processors are partitioned into g disconnected components causes any task-performing algorithm to have work $\Omega(t\cdot g)$ even if each group of processors performs no more than the optimal number of $\Theta(t)$ tasks. Given that such pessimistic lower bounds apply to any scheduling algorithm, we pursue a competitive analysis. Specifically, this paper studies a simple randomized scheduling algorithm for p asynchronous processors, connected by a dynamically changing communication medium, to complete t known tasks. The performance of this algorithm is compared against that of an omniscient off-line algorithm with full knowledge of the future changes in the communication medium. The paper describes a notion of computation width, which associates a natural number with a history of changes in the communication medium, and shows both upper and lower bounds on work-competitiveness in terms of this quantity. Specifically, it is shown that the simple randomized algorithm obtains the competitive ratio $(1+\mathbf{cw}/e)$, where $\mathbf{cw}$ is the computation width and $e$ is the base of the natural logarithm ($e=2.7182\ldots$); this competitive ratio is then shown to be tight.
STOC	On the fractal behavior of TCP.	Anna C. Gilbert,Howard J. Karloff	2003	We propose a natural, mathematically tractable model of TCP which captures both its additive-increase, multiplicative-decrease behavior and its feedback mechanism. Neither a fluid nor a mean-field model, our model does not explicitly model the loss process; the losses are entirely determined by the rates of the sources at the time of buffer overflow. The system involves two sources competing to send packets into one recipient buffer of size B, from which bytes are drained at the rate of d per step. We prove that for many choices of the pairs (B,d), the long term behavior of the system is fractal. We conjecture that this fact continues to hold for all B > d and d > 2.
STOC	Simpler and better approximation algorithms for network design.	Anupam Gupta,Amit Kumar,Tim Roughgarden	2003	We give simple and easy-to-analyze randomized approximation algorithms for several well-studied NP-hard network design problems. Our algorithms improve over the previously best known approximation ratios. Our main results are the following.We give a randomized 3.55-approximation algorithm for the connected facility location problem. The algorithm requires three lines to state, one page to analyze, and improves the best-known performance guarantee for the problem.We give a 5.55-approximation algorithm for virtual private network design. Previously, constant-factor approximation algorithms were known only for special cases of this problem.We give a simple constant-factor approximation algorithm for the single-sink buy-at-bulk network design problem. Our performance guarantee improves over what was previously known, and is an order of magnitude improvement over previous combinatorial approximation algorithms for the problem.
STOC	Linear time encodable and list decodable codes.	Venkatesan Guruswami,Piotr Indyk	2003	We present the first construction of error-correcting codes which can be (list) decoded from a noise fraction arbitrarily close to 1 in linear time. Specifically, we present an explicit construction of codes which can be encoded in linear time as well as list decoded in linear time from a fraction (1-ε) of errors for arbitrary ε > 0. The rate and alphabet size of the construction are constants that depend only on ε. Our construction involves devising a new combinatorial approach to list decoding, in contrast to all previous approaches which relied on the power of decoding algorithms for algebraic codes like Reed-Solomon codes.Our result implies that it is possible to have, and in fact explicitly specifies, a coding scheme for arbitrarily large noise thresholds with only constant redundancy in the encoding and constant amount of work (at both the sending and receiving ends) for each bit of information to be communicated. Such a result was known for certain probabilistic error models, and here we show that this is possible under the stronger adversarial noise model as well.
STOC	"Classical deterministic complexity of Edmonds' Problem and quantum entanglement."	Leonid Gurvits	2003	"Generalizing a decision problem for bipartite perfect matching, J. Edmonds introduced in [14] the problem (now known as the Edmonds Problem) of deciding if a given linear subspace of M(N) contains a nonsingular matrix, where M(N) stands for the linear space of complex NxN matrices. This problem led to many fundamental developments in matroid theory etc.Classical matching theory can be defined in terms of matrices with nonnegative entries. The notion of Positive operator, central in Quantum Theory, is a natural generalization of matrices with nonnegative entries. (Here operator refers to maps from matrices to matrices.) First, we reformulate the Edmonds Problem in terms of of completely positive operators, or equivalently, in terms of bipartite density matrices. It turns out that one of the most important cases when Edmonds' problem can be solved in polynomial deterministic time, i.e. an intersection of two geometric matroids, corresponds to unentangled (aka separable) bipartite density matrices. We introduce a very general class (or promise) of linear subspaces of M(N) on which there exists a polynomial deterministic time algorithm to solve Edmonds' problem. The algorithm is a thoroughgoing generalization of algorithms in [23], [26], and its analysis benefits from an operator analog of permanents, so called Quantum Permanents. Finally, we prove that the weak membership problem for the convex set of separable normalized bipartite density matrices is NP-HARD."
STOC	Polylogarithmic inapproximability.	Eran Halperin,Robert Krauthgamer	2003	We provide the first hardness result of a polylogarithmic approximation ratio for a natural NP-hard optimization problem. We show that for every fixed ε>0, the GROUP-STEINER-TREE problem admits no efficient log2-ε k approximation, where k denotes the number of groups (or, alternatively, the input size), unless NP has quasi polynomial Las-Vegas algorithms. This hardness result holds even for input graphs which are Hierarchically Well-Separated Trees, introduced by Bartal [FOCS, 1996]. For these trees (and also for general trees), our bound is nearly tight with the log-squared approximation currently known. Our results imply that for every fixed ε>0, the DIRECTED-STEINER TREE problem admits no log2-ε n--approximation, where n is the number of vertices in the graph, under the same complexity assumption.
STOC	Randomly coloring graphs of girth at least five.	Thomas P. Hayes	2003	We improve rapid mixing results for the simple Glauber dynamics designed to generate a random k-coloring of a bounded-degree graph.Let G be a graph with maximum degree Δ = Ω(log n), and girth ≥ 5. We prove that if k > Α Δ, where Α ≈ 1.763 then Glauber dynamics has mixing time O(n log n). If girth(G) ≥ 6 and k > Β Δ, where Β ≈ 1.489 then Glauber dynamics has mixing time O(n log n). This improves a recent result of Molloy, who proved the same conclusion under the stronger assumptions that Δ=Ω(log n) and girth Ω(log Δ). Our work suggests that rapid mixing results for high girth and degree graphs may extend to general graphs.Analogous results hold for random graphs of average degree up to n¼, compared with polylog(n), which was the best previously known.Some of our proofs rely on a new Chernoff-Hoeffding type bound, which only requires the random variables to be well-behaved with high probability. This tail inequality may be of independent interest.
STOC	On the sample size of k-restricted min-wise independent permutations and other k-wise distributions.	Toshiya Itoh,Yoshinori Takei,Jun Tarui	2003	An explicit study of min-wise independent permutation families, together with their variants --- k-restricted, approximate, etc. --- was initiated by Broder, et al[4]. In this paper, we give a lower bound for the size of k-restricted min-wise independent permutation family. A family F of permutations on [0,n-1]=(0,1,...,n-1) is said to be k-restricted min-wise independent if for any subset X ⊆ [0,n-1] with |X| ≤ k and any x ∈ X, Pr[min(π(X))=π(x)] = 1/|X|, when π is randomly chosen from F according to a probability distribution D on the family F. For the minimum size of a family of k-restricted min-wise independent permutations, upper bounds of O(nk) for any fixed k have been shown for uniform and biased probability distributions on F. We show that if a family F of permutations on [0,n-1] is k-restricted min-wise independent, then |F| ≥ m(n-1,k-1), where m(n,d) = ∑i=0d/2(ni) if d is even; m(n,d)= ∑i=0(d-1)/2(ni) + (n-1(d-1)/2) otherwise. The lower bound for the size of F still holds when we allow an arbitrary probability distribution on F. Our proof technique is based on linear algebra methods, and can be regarded as a generalization of the result by Alon, Babai, and Itai[1], i.e., if random variables X1,X2,...,Xn: Ω → (0,1) are k-wise independent and Pr[Xi=1] = pi is neither 0 nor 1, then |Ω| ≥ m(n,k). By applying our proof technique, we also derive lower bounds for the sample size of the related notions, e.g., k-wise symmetrically independent distributions, k-rankwise independent permutation families, etc.
STOC	Cell-probe lower bounds for the partial match problem.	T. S. Jayram,Subhash Khot,Ravi Kumar,Yuval Rabani	2003	Given a database of n points in {0, 1)d, the partial match problem is: In response to a query x in {0,1,*}d, is there a database point y such that for every i whenever xi ≠ *, we have xi = yi. In this paper we show randomized lower bounds in the cell-probe model for this well-studied problem (Analysis of associative retrieval algorithms, Ph.D. Thesis, Stanford University, 1974; The Art of Computer Programming; Sorting and Searching, Addison-Wesley, Reading, MA, 1973; SIAM J. Comput. 5(1) (1976) 19; J. Comput. System Sci. 57(1) (1998) 37; Proceedings of the 31st Annual ACM Symposium on Theory of Computing, 1999; Proceedings of the 29th International Colloquium on Algorithms, Logic, and Programming, 1999).Our lower bounds follow from a near-optimal asymmetric communication complexity lower bound for this problem. Specifically, we show that either Alice has to send Ω(d/log n) bits or Bob has to send Ω(n1-o(1)) bits. When applied to the cell-probe model, it means that if the number of cells is restricted to be poly(n,d) where each cell is of size poly(log n,d), then Ω(d/log2 n) probes are needed. This is an exponential improvement over the previously known lower bounds for this problem obtained by Miltersen et al. (1998) and Borodin et al. (1999).Our lower bound also leads to new and improved lower bounds for related problems including a lower bound for the l∞ c-nearest neighbor problem for c < 3 and an improved communication complexity lower bound for the exact nearest neighbor problem.
STOC	Two applications of information complexity.	T. S. Jayram,Ravi Kumar,D. Sivakumar	2003	We show the following new lower bounds in two concrete complexity models:<ol>(1) In the two-party communication complexity model, we show that the tribes function on n inputs[6] has two-sided error randomized complexity Ω(n), while its nondeterminstic complexity and co-nondeterministic complexity are both Θ(√n). This separation between randomized and nondeterministic complexity is the best possible and it settles an open problem in Kushilevitz and Nisan[17], which was also posed by Beame and Lawry[5].(2) In the Boolean decision tree model, we show that the recursive majority-of-three function on 3h inputs has randomized complexity Ω((7/3)h). The deterministic complexity of this function is Θ(3h), and the nondeterministic complexity is Θ(2h). Our lower bound on the randomized complexity is a substantial improvement over any lower bound for this problem that can be obtained via the techniques of Saks and Wigderson [23], Heiman and Wigderson[14], and Heiman, Newman, and Wigderson[13]. Recursive majority is an important function for which a class of natural algorithms known as directional algorithms does not achieve the best randomized decision tree upper bound.</ol.These lower bounds are obtained using generalizations of information complexity, which quantifies the minimum amount of information that will have to be revealed about the inputs by every correct algorithm in a given model of computation.
STOC	Derandomizing polynomial identity tests means proving circuit lower bounds.	Valentine Kabanets,Russell Impagliazzo	2003	We show that derandomizing Polynomial Identity Testing is essentially equivalent to proving arithmetic circuit lower bounds for NEXP. More precisely, we prove that if one can test in polynomial time (or even nondeterministic subexponential time, infinitely often) whether a given arithmetic circuit over integers computes an identically zero polynomial, then either (i) NEXP ⊄ P/poly or (ii) Permanent is not computable by polynomial-size arithmetic circuits. We also prove a (partial) converse: If Permanent requires superpolynomial-size arithmetic circuits, then one can test in subexponential time whether a given arithmetic circuit of polynomially bounded degree computes an identically zero polynomial.Since Polynomial Identity Testing is a coRP problem, we obtain the following corollary: If RP = P (or even coRP ⊆ ∩ε > 0 NTIME(2nε), infinitely often), then NEXP is not computable by polynomial-size arithmetic circuits. Thus establishing that RP = coRP or BPP = P would require proving superpolynomial lower bounds for Boolean or arithmetic circuits. We also show that any derandomization of RNC would yield new circuit lower bounds for a language in NEXP.We also prove unconditionally that NEXPRP does not have polynomial-size Boolean or arithmetic circuits. Finally, we show that NEXP ⊄ P/poly if both BPP = P and low-degree testing is in P; here low-degree testing is the problem of checking whether a given Boolean circuit computes a function that is close to some low-degree polynomial over a finite field.
STOC	Boosting in the presence of noise.	Adam Kalai,Rocco A. Servedio	2003	"Boosting algorithms are procedures that ''boost'' low-accuracy weak learning algorithms to achieve arbitrarily high accuracy. Over the past decade boosting has been widely used in practice and has become a major research topic in computational learning theory. In this paper we study boosting in the presence of random classification noise, giving both positive and negative results. We show that a modified version of a boosting algorithm due to Mansour and McAllester (J. Comput. System Sci. 64(1) (2002) 103) can achieve accuracy arbitrarily close to the noise rate. We also give a matching lower bound by showing that no efficient black-box boosting algorithm can boost accuracy beyond the noise rate (assuming that one-way functions exist). Finally, we consider a variant of the standard scenario for boosting in which the ''weak learner'' satisfies a slightly stronger condition than the usual weak learning guarantee. We give an efficient algorithm in this framework which can boost to arbitrarily high accuracy in the presence of classification noise."
STOC	Dynamic rectangular intersection with priorities.	Haim Kaplan,Eyal Molad,Robert Endre Tarjan	2003	We present efficient data structures to maintain dynamic set of rectangles, each with priority assigned to it, such that we can efficiently find the rectangle of maximum priority containing a query point. Our data structures support insertions and deletions of rectangles. In one dimension, when rectangles are intervals, our most efficient data structure supports queries and insertions in O(log n) time, deletions in O(log n loglog n) time and requires linear space. When intervals are guaranteed to be nonoverlapping (but one can be nested within the other) we obtain a simpler data structure that supports all operations in O(log n) time.
STOC	Exponential lower bound for 2-query locally decodable codes via a quantum argument.	Iordanis Kerenidis,Ronald de Wolf	2003	"A locally decodable code (LDC) encodes n-bit strings x in m-bit codewords C(x) in such a way that one can recover any bit xi from a corrupted codeword by querying only a few bits of that word. We use a quantum argument to prove that LDCs with 2 classical queries require exponential length: m = 2Ω(n). Previously, this was known only for linear codes (Goldreich et al., in: Proceedings of 17th IEEE Conference on Computation Complexity, 2002, pp. 175-183). The proof proceeds by showing that a 2-query LDC can be decoded with a single quantum query, when defined in an appropriate sense. It goes on to establish an exponential lower bound on any 'l-query locally quantum-decodable code'. We extend our lower bounds to non-binary alphabets and also somewhat improve the polynomial lower bounds by Katz and Trevisan for LDCs with more than 2 queries. Furthermore, we show that q quantum queries allow more succinct LDCs than the best known LDCs with q classical queries. Finally, we give new classical lower bounds and quantum upper bounds for the setting of private information retrieval. In particular, we exhibit a quantum 2-server private information retrieval (PIR) scheme with O(n3/10) qubits of communication, beating the O(n1/3) bits of communication of the best known classical 2-server PIR."
STOC	Generating random regular graphs.	Jeong Han Kim,Van H. Vu	2003	"Random regular graphs play a central role in combinatorics and theoretical computer science. In this paper, we analyze a simple algorithm introduced by Steger and Wormald [10] and prove that it produces an asymptotically uniform random regular graph in a polynomial time. Precisely, for fixed d and n with d = O(n1/3&#x2212;&#x03b5;), it is shown that the algorithm generates an asymptotically uniform random d-regular graph on n vertices in time O(nd2). This confirms a conjecture of Wormald. The key ingredient in the proof is a recently developed concentration inequality by the second author. The algorithm works for relatively large d in practical (quadratic) time and can be used to derive many properties of uniform random regular graphs."
STOC	Quantum time-space tradeoffs for sorting.	Hartmut Klauck	2003	We investigate the complexity of sorting in the model of sequential quantum circuits. While it is known that in general a quantum algorithm based on comparisons alone cannot outperform classical sorting algorithms by more than a constant factor in time complexity, this is wrong in a space bounded setting. We observe that for all storage bounds n/log ≥ S ≥ log3n, one can devise a quantum algorithm that sorts n numbers (using comparisons only) in time T=O(n3/2 log3/2 n/√S). We then show the following lower bound on the time-space tradeoff for sorting n numbers from a polynomial size range in a general sorting algorithm (not necessarily based on comparisons): TS=Ω(n3/2). Hence for small values of S the upper bound is almost tight. Classically the time-space tradeoff for sorting is TS=Θ(n2).
STOC	Consistent load balancing via spread minimization.	Robert D. Kleinberg,Frank Thomson Leighton	2003	Consistent load balancing via spread minimization.
STOC	"Primal-dual meets local search: approximating MST's with nonuniform degree bounds."	Jochen Könemann,R. Ravi	2003	"We present a new bicriteria approximation algorithm for the degree-bounded minimum-cost spanning tree problem: Given an undirected graph with nonnegative edge weights and degree bounds Bv > 1 for all vertices v, find a spanning tree T of minimum total edge-cost such that the maximum degree of each node v in T is at most Bv. Our algorithm finds a tree in which the degree of each node v is O(Bv + log n) and the total edge-cost is at most a constant times the cost of any tree that obeys all degree constraints.Our previous algorithm[9] with similar guarantees worked only in the case of uniform degree bounds (i.e. Bv=B for all vertices v). While the new algorithm is based on ideas from Lagrangean relaxation as is our previous work, it does not rely on computing a solution to a linear program. Instead it uses a repeated application of Kruskal's MST algorithm interleaved with a combinatorial update of approximate Lagrangean node-multipliers maintained by the algorithm. These updates cause subsequent repetitions of the spanning tree algorithm to run for longer and longer times, leading to overall progress and a proof of the performance guarantee."
STOC	Short path queries in planar graphs in constant time.	Lukasz Kowalik,Maciej Kurowski	2003	We present a new algorithm for answering short path queries in planar graphs. For any fixed constant k and a given unweighted planar graph G=(V,E) one can build in O(|V|) time a data structure, which allows to check in O(1) time whether two given vertices are distant by at most k in G and if so a shortest path between them is returned. This significantly improves the previous result of D. Eppstein [5] where after a linear preprocessing the queries are answered in O(log |V|) time. Our approach can be applied to compute the girth of a planar graph and a corresponding shortest cycle in O(|V|) time provided that the constant bound on the girth is known.Our results can be easily generalized to other wide classes of graphs~--~for instance we can take graphs embeddable in a surface of bounded genus or graphs of bounded tree-width.
STOC	The intrinsic dimensionality of graphs.	Robert Krauthgamer,James R. Lee	2003	"We resolve the following conjecture raised by Levin together with Linial, London, and Rabinovich [Combinatorica, 1995]. For a graph G, let dim(G) be the smallest d such that G occurs as a (not necessarily induced) subgraph of &#x2124;&#x221e; d , the infinite graph with vertex set &#x2124; d and an edge (u, v) whenever &#x2225;u &#x2212; v&#x2225;&#x221e; = 1. The growth rate of G, denoted &#x03c1; G , is the minimum &#x03c1; such that every ball of radius r > 1 in G contains at most r &#x03c1; vertices. By simple volume arguments, dim(G) = &#x03a9;(&#x03c1; G ). Levin conjectured that this lower bound is tight, i.e., that dim(G) = O(&#x03c1; G ) for every graph G. Previously, it was unknown whether dim(G) could be bounded above by any function of &#x03c1; G . We show that a weaker form of Levin&#x2019;s conjecture holds by proving that dim(G) = O(&#x03c1; G log &#x03c1; G ) for any graph G. We disprove, however, the specific bound of the conjecture and show that our upper bound is tight by exhibiting graphs for which dim(G) = &#x03a9;(&#x03c1; G log &#x03c1; G ). For several special families of graphs (e.g., planar graphs), we salvage the strong form, showing that dim(G) = O(&#x03c1; G ). Our results extend to a variant of the conjecture for finite-dimensional Euclidean spaces posed by Linial and independently by Benjamini and Schramm."
STOC	Bounded-concurrent secure two-party computation without setup assumptions.	Yehuda Lindell	2003	"In this paper we study the feasibility of obtaining protocols for general two-party computation that remain secure under concurrent composition. (A general protocol can be used for obtaining secure computation of any functionality.) We consider a scenario where no trusted setup is assumed (and so, for example, there is no common reference string available to the parties); we call this the ""plain model"". We present both negative and positive results for this model. Specifically, we show that a general two-party protocol that remains secure for m concurrent executions and can be proven via black-box simulation, must have more than m rounds of communication. An important corollary of this result is that there do not exist protocols for black-box secure general two-party computation for the case of unbounded concurrency (where any polynomial number of concurrent executions may be run). On the positive side, we show that under general cryptographic assumptions, there exist secure protocols for general two-party computation in the model of bounded concurrent composition (in this model the number of concurrent executions is fixed and the protocol design may depend on this number). Our protocol has O(m) rounds of communication, where m is the bound on the number of concurrent executions, and uses both black-box and non black-box techniques. We note that this protocol constitutes the first feasibility result for general two-party computation without setup assumptions for any model of concurrency."
STOC	Extractors: optimal up to constant factors.	Chi-Jen Lu,Omer Reingold,Salil P. Vadhan,Avi Wigderson	2003	"This paper provides the first explicit construction of extractors which are simultaneously optimal up to constant factors in both seed length and output length. More precisely, for every n,k, our extractor uses a random seed of length O(log n) to transform any random source on n bits with (min-)entropy k, into a distribution on (1-α)k bits that is ε-close to uniform. Here α and ε can be taken to be any positive constants. (In fact, ε can be almost polynomially small.Our improvements are obtained via three new techniques, each of which may be of independent interest. The first is a general construction of mergers [22] from locally decodable error-correcting codes. The second introduces new condensers that have constant seed length (and retain a constant fraction of the min-entropy in the random source). The third is a way to augment the ""win-win repeated condensing"" paradigm of [17] with error reduction techniques like [15] so that the our constant seed-length condensers can be used without error accumulation."
STOC	Evolving sets and mixin.	Ben Morris,Yuval Peres	2003	We show that a new probabilistic technique, recently introduced by the first author, yields the sharpest bounds obtained to date on mixing times in terms of isoperimetric properties of the state space (also known as conductance bounds or Cheeger inequalities). We prove that the bounds for mixing time in total variation obtained by Lovasz and Kannan, can be refined to apply to the maximum relative deviation |pn(x,y)/π(y)-1| of the distribution at time n from the stationary distribution π. Our approach also yields a direct link between isoperimetric inequalities and heat kernel bounds; previously, this link rested on analytic estimates known as Nash inequalities.
STOC	Learning juntas.	"Elchanan Mossel,Ryan O'Donnell,Rocco A. Servedio"	2003	We consider a fundamental problem in computational learning theory: learning an arbitrary Boolean function which depends on an unknown set of k out of n Boolean variables. We give an algorithm for learning such functions from uniform random examples which runs in time roughly (nk)ω/(ω + 1), where ω < 2.376 is the matrix multiplication exponent. We thus obtain the first polynomial factor improvement on the naive nk time bound which can be achieved via exhaustive search. Our algorithm and analysis exploit new structural properties of Boolean functions.
STOC	New degree bounds for polynomial threshold functions.	"Ryan O'Donnell,Rocco A. Servedio"	2003	We give new upper and lower bounds on the degree of real multivariate polynomials which sign-represent Boolean functions. Our upper bounds for Boolean formulas yield the first known subexponential time learning algorithms for formulas of superconstant depth. Our lower bounds for constant-depth circuits and intersections of halfspaces are the first new degree lower bounds since 1968, improving results of Minsky and Papert. The lower bounds are proved constructively; we give explicit dual solutions to the necessary linear programs.
STOC	Uniform hashing in constant time and linear space.	Anna Östlin,Rasmus Pagh	2003	Many algorithms and data structures employing hashing have been analyzed under the uniform hashing assumption, i.e., the assumption that hash functions behave like truly random functions. Starting with the discovery of universal hash functions, many researchers have studied to what extent this theoretical ideal can be realized by hash functions that do not take up too much space and can be evaluated quickly. In this paper we present an almost ideal solution to this problem: A hash function that, on any set of n inputs, behaves like a truly random function with high probability, can be evaluated in constant time on a RAM, and can be stored in O(n) words, which is optimal. For many hashing schemes this is the first hash function that makes their uniform hashing analysis come true, with high probability, without incurring overhead in time or space.
STOC	Approximation algorithms for hierarchical location problems.	C. Greg Plaxton	2003	"We formulate and (approximately) solve hierarchical versions of two prototypical problems in discrete location theory, namely, the metric uncapacitated k-median and facility location problems. Our work yields new insights into hierarchical clustering, a widely used technique in data analysis. For example, we show that every metric space admits a hierarchical clustering that is within a constant factor of optimal at every level of granularity with respect to the average (squared) distance objective. A key building block of our hierarchical facility location algorithm is a constant-factor approximation algorithm for an ''incremental'' variant of the facility location problem; the latter algorithm may be of independent interest."
STOC	On average distortion of embedding metrics into the line and into L1.	Yuri Rabinovich	2003	We introduce and study the notion of the average distortion of a nonexpanding embedding of one metric space into another. Less sensitive than the multiplicative metric distortion, the average distortion captures well the global picture, and, overall, is a quite interesting new measure of metric proximity, related to the concentration of measure phenomenon. We establish close mutual relations between the MinCut- MaxFlow gap in a uniform-demand multicommodity flow, and the average distortion of embedding the suitable (dual) metric into l1. These relations are exploited to show that the shortest-path metrics of special (e.g., planar, bounded treewidth, etc.) graphs embed into l1 with constant average distortion. The main result of the paper claims that this remains true even if l1 is replaced with the line. This result is further sharpened for graphs of a bounded treewidth.
STOC	New lattice based cryptographic constructions.	Oded Regev	2003	"We introduce the use of Fourier analysis on lattices as an integral part of a lattice-based construction. The tools we develop provide an elegant description of certain Gaussian distributions around lattice points. Our results include two cryptographic constructions that are based on the worst-case hardness of the unique shortest vector problem. The main result is a new public key cryptosystem whose security guarantee is considerably stronger than previous results (O(n1.5) instead of O(n7)). This provides the first alternative to Ajtai and Dwork's original 1996 cryptosystem. Our second result is a family of collision resistant hash functions with an improved security guarantee in terms of the unique shortest vector problem. Surprisingly, both results are derived from one theorem that presents two indistinguishable distributions on the segment [0, 1). It seems that this theorem can have further applications; as an example, we use it to solve an open problem in quantum computation related to the dihedral hidden subgroup problem."
STOC	The computational complexity of some julia sets.	Robert Rettinger,Klaus Weihrauch	2003	Although numerous computer programs have been written to compute sets of points which claim to approximate Julia sets, no reliable high precision pictures of non-trivial Julia sets are currently known. Usually, no error estimates are added and even those algorithms which work reliably in theory, become unreliable in practice due to rounding errors and the use of fixed length floating point numbers.In this paper we prove the existence of polynomial time algorithms to approximate the Julia sets of complex functions f(z)=z2+c for |c|<1/4. We will give a strict computable error estimation w.r.t. the Hausdorff metric dH which means that the set is recursive [10]. Although these and many more Julia sets J are proven to be recursive [12] and furthermore recursive compact subsets of the Euclidean plane are known to have a computable Turing machine time complexity [10], hardly anything is known about the computational complexity of non-trivial examples. The algorithms given in this paper compute the Julia sets locally in time O(k2• M(k)) (where M(k) is a time bound for multiplication of two k-bit integers). Roughly speaking, the local time complexity is the number of Turing machine steps to decide for a single point whether it belongs to a grid Kk⊆ (2-k• Z)2 such that dH(Kk,J)≤ 2-k.
STOC	Time-space tradeoff lower bounds for integer multiplication and graphs of arithmetic functions.	Martin Sauerhoff,Philipp Woelfel	2003	We prove exponential size lower bounds for nondeterministic and randomized read-k BPs as well as a time-space tradeoff lower bound for unrestricted, deterministic multi-way BPs computing the middle bit of integer multiplication. The lower bound for randomized read-k BPs is superpolynomial as long as the error probability is superpolynomially small. For polynomially small error, we have a polynomial upper bound on the size of approximating read once BPs for this function. The lower bounds follow from a more general result for the graphs of universal hash classes that is applicable to the graphs of arithmetic functions such as integer multiplication, convolution, and finite field multiplication.
STOC	On the power of quantum fingerprinting.	Andrew Chi-Chih Ya	2003	"In the simultaneous message model, two parties holding n-bit integers x,y send messages to a third party, the referee, enabling him to compute a boolean function f(x,y). Buhrman et al [3] proved the remarkable result that, when f is the equality function, the referee can solve this problem by comparing short ""quantum fingerprints"" sent by the two parties, i.e., there exists a quantum protocol using only O(log n) bits. This is in contrast to the well-known classical case for which Ω(n1/2) bits are provably necessary for the same problem even with randomization. In this paper we show that short quantum fingerprints can be used to solve the problem for a much larger class of functions. Let R<??par line>,pub(f) denote the number of bits needed in the classical case, assuming in addition a common sequence of random bits is known to all parties (the public coin model). We prove that, if R<??par line>,pub(f)=O(1), then there exists a quantum protocol for f using only O(log n) bits. As an application we show that O(log n) quantum bits suffice for the bounded Hamming distance function, defined by f(x,y)=1 if and only if x and y have a constant Hamming distance d or less."
STOC	Optimal probabilistic fingerprint codes.	Gábor Tardos	2003	We construct binary codes for fingerprinting digital documents. Our codes for n users that are &epsi;-secure against c pirates have length O(c2log(n/&epsi;)). This improves the codes proposed by Boneh and Shaw &lsqb;1998&rsqb; whose length is approximately the square of this length. The improvement carries over to works using the Boneh--Shaw code as a primitive, for example, to the dynamic traitor tracing scheme of Tassa &lsqb;2005&rsqb;. By proving matching lower bounds we establish that the length of our codes is best within a constant factor for reasonable error probabilities. This lower bound generalizes the bound found independently by Peikert et al. &lsqb;2003&rsqb; that applies to a limited class of codes. Our results also imply that randomized fingerprint codes over a binary alphabet are as powerful as over an arbitrary alphabet and the equal strength of two distinct models for fingerprinting.
STOC	Space efficient dynamic stabbing with fast queries.	Mikkel Thorup	2003	In dynamic stabbing, we operate on a dynamic set of intervals. A stabbing query asks for an interval containing a given point. This basic problem encodes problems such as method look-up in object oriented programming languages and classification in IP firewalls. For such application, very fast, say constant, query time is extremely important, small space is very important, and fast updates are good but the least important. Previous solutions traded space and update time for fast queries. We show here that space needs not be sacrificed. We get the same trade-off between update time and query time but using only the space necessary for locating a query point among the interval end-points. All our bounds are optimal or near-optimal.
STOC	Integer priority queues with decrease key in constant time and the single source shortest paths problem.	Mikkel Thorup	2003	We consider Fibonacci heap style integer priority queues supporting find-rain, insert, and decrease key operations in constant time. We present a deterministic linear space solution that with n integer keys supports delete in O(log log n) time. If the integers are in the range [0,N), we can also support delete in O(log log N) time.Even for the special case of monotone priority queues, where the minimum has to be non-decreasing, the best previous bounds on delete were O((log n)1/(3-ε)) and O((log N)1/(4-ε)). These previous bounds used both randomization and amortization. Our new bounds are deterministic, worst-case, with no restriction to monotonicity, and exponentially faster.As a classical application, for a directed graph with n nodes and m edges with non-negative integer weights, we get single source shortest paths in O(m + n log log n) time, or O(m + n log log C) if C is the maximal edge weight. The latter solves an open problem of Ahuja, Mehlhorn, Orlin, and Tarjan from 1990.
STOC	Approximation schemes for clustering problems.	Wenceslas Fernandez de la Vega,Marek Karpinski,Claire Kenyon,Yuval Rabani	2003	Let k be a fixed integer. We consider the problem of partitioning an input set of points endowed with a distance function into k clusters. We give polynomial time approximation schemes for the following three clustering problems: Metric k-Clustering, l 22 k-Clustering, and l22 k-Median. In the k-Clustering problem, the objective is to minimize the sum of all intra-cluster distances. In the k-Median problem, the goal is to minimize the sum of distances from points in a cluster to the (best choice of) cluster center. In metric instances, the input distance function is a metric. In l 22 instances, the points are in R d and the distance between two points x,y is measured by x&minus;y 22 (notice that (R d, &sdot; 22 is not a metric space). For the first two problems, our results are the first polynomial time approximation schemes. For the third problem, the running time of our algorithms is a vast improvement over previous work.
STOC	Proceedings of the 35th Annual ACM Symposium on Theory of Computing, June 9-11, 2003, San Diego, CA, USA		2003	Proceedings of the 35th Annual ACM Symposium on Theory of Computing, June 9-11, 2003, San Diego, CA, USA
FOCS	Learnability and Automatizability.	Michael Alekhnovich,Mark Braverman,Vitaly Feldman,Adam R. Klivans,Toniann Pitassi	2004	We consider the complexity of properly learning concept classes, i.e. when the learner must output a hypothesis of the same form as the unknown concept. We present the following new upper and lower bounds on well-known concept classes: We show that unless NP = RP, there is no polynomial-time PA Clearning algorithm for DNF formulae where the hypothesis is an OR-of-thresholds. Note that as special cases, we show that neither DNF nor OR-of-thresholds are properly learnable unless NP = RP. Previous hardness results have required strong restrictions on the size of the output DNF formula. We also prove that it is NP-hard to learn the intersection of \ell\geqslant 2 halfspaces by the intersection of k halfspaces for any constant k ¿ 0. Previous work held for the case when k = \ell. Assuming that NP ¿ DTIME(2^{n^\varepsilon} ) for a certain constant ¿
FOCS	On the Streaming Model Augmented with a Sorting Primitive.	Gagan Aggarwal,Mayur Datar,Sridhar Rajagopalan,Matthias Ruhl	2004	"The need to deal with massive data sets in many practical applications has led to a growing interest in computational models appropriate for large inputs. The most important quality of a realistic model is that it can be efficiently implemented across a wide range of platforms and operating systems. In this paper, we study the computational model that results if the streaming model is augmented with a sorting primitive. We argue that this model is highly practical, and that a wide range of important problems can be efficiently solved in this (relatively weak) model. Examples are undirected connectivity, minimum spanning trees, and red-blue line segment intersection, among others. This suggests that using more powerful, harder to implement models may not always be justified. Our main technical contribution is to show a hardness result for the ""streaming and sorting"" model, which demonstrates that the main limitation of this model is that it can only access one data stream at a time. Since our model is strong enough to solve ""pointer chasing"" problems, the communication complexity based techniques commonly used in showing lower bounds for the streaming model cannot be adapted to our model. We therefore have to employ new techniques to obtain these results. Finally, we compare our model to a popular restriction of external memory algorithms that access their data mostly sequentially."
FOCS	Adiabatic Quantum Computation is Equivalent to Standard Quantum Computation.	Dorit Aharonov,Wim van Dam,Julia Kempe,Zeph Landau,Seth Lloyd,Oded Regev	2004	Adiabatic quantum computation has recently attracted attention in the physics and computer science communities, but its computational power was unknown. We describe an efficient adiabatic simulation of any given quantum algorithm, which implies that the adiabatic computation model and the conventional quantum computation model are polynomially equivalent. Our result can be extended to the physically realistic setting of particles arranged on a two-dimensional grid with nearest neighbor interactions. The equivalence between the models allows stating the main open problems in quantum computation using well-studied mathematical objects such as eigenvectors and spectral gaps of sparse matrices.
FOCS	Lattice Problems in NP cap coNP.	Dorit Aharonov,Oded Regev	2004	Lattice Problems in NP cap coNP.
FOCS	Quantum Walk Algorithm for Element Distinctness.	Andris Ambainis	2004	We use quantum walks to construct a new quantum algorithm for element distinctness and its generalization. For element distinctness (the problem of finding two equal items among $N$ given items), we get an $O(N^{2/3})$ query quantum algorithm. This improves the previous $O(N^{3/4})$ quantum algorithm of Buhrman et al. [SIAM J. Comput., 34 (2005), pp. 1324-1330] and matches the lower bound of Aaronson and Shi [J. ACM, 51 (2004), pp. 595-605]. We also give an $O(N^{k/(k+1)})$ query quantum algorithm for the generalization of element distinctness in which we have to find $k$ equal items among $N$ items.
FOCS	Hardness of Buy-at-Bulk Network Design.	Matthew Andrews	2004	We consider the Buy-at-Bulk network design problem in which we wish to design a network for carrying multicommodity demands from a set of source nodes to a set of destination nodes. The key feature of the problem is that the cost of capacity on each edge is concave and hence exhibits economies of scale. If the cost of capacity per unit length can be different on different edges then we say that the problem is non-uniform. The problem is uniform otherwise. We show that for any constant ¿, if NP ¿ZIPTIME(n^polylog n) then there is no 0(\log ^{\frac{1}{2} - \gamma } N)-approximation algorithm for non-uniform Buy-at-Bulk network design and there is no 0(\log ^{\frac{1}{4} - \gamma } N)-approximation algorithm for the uniform problem.
FOCS	The Price of Stability for Network Design with Fair Cost Allocation.	Elliot Anshelevich,Anirban Dasgupta,Jon M. Kleinberg,Éva Tardos,Tom Wexler,Tim Roughgarden	2004	Network design is a fundamental problem for which it is important to understand the effects of strategic behavior. Given a collection of self-interested agents who want to form a network connecting certain endpoints, the set of stable solutions&mdash;the Nash equilibria&mdash;may look quite different from the centrally enforced optimum. We study the quality of the best Nash equilibrium, and refer to the ratio of its cost to the optimum network cost as the price of stability. The best Nash equilibrium solution has a natural meaning of stability in this context&mdash;it is the optimal solution that can be proposed from which no user will defect. We consider the price of stability for network design with respect to one of the most widely studied protocols for network cost allocation, in which the cost of each edge is divided equally between users whose connections make use of it; this fair-division scheme can be derived from the Shapley value and has a number of basic economic motivations. We show that the price of stability for network design with respect to this fair cost allocation is $O(\log k)$, where $k$ is the number of users, and that a good Nash equilibrium can be achieved via best-response dynamics in which users iteratively defect from a starting solution. This establishes that the fair cost allocation protocol is in fact a useful mechanism for inducing strategic behavior to form near-optimal equilibria. We discuss connections to the class of potential games defined by Monderer and Shapley, and extend our results to cases in which users are seeking to balance network design costs with latencies in the constructed network, with stronger results when the network has only delays and no construction costs. We also present bounds on the convergence time of best-response dynamics, and discuss extensions to a weighted game.
FOCS	Cryptography in NC.	Benny Applebaum,Yuval Ishai,Eyal Kushilevitz	2004	"We study the parallel time-complexity of basic cryptographic primitives such as one-way functions (OWFs) and pseudorandom generators (PRGs). Specifically, we study the possibility of computing instances of these primitives by NC¿ circuits, in which each output bit depends on a constant number of input bits. Despite previous efforts in this direction, there has been no significant theoretical evidence supporting this possibility, which was posed as an open question in several previous works. We essentially settle this question by providing overwhelming positive evidence for the possibility of cryptography in NC¿ Our main result is that every ""moderatelyeasy"" OWF (resp., PRG), say computable in NC¹, can be compiled into a corresponding OWF (resp., low-stretch PRG) in NC_4^0 i.e. whose output bits each depend on at most 4 input bits. The existence of OWF and PRG in NC¹ is a relatively mild assumption, implied by most number-theoretic or algebraic intractability assumptions commonly used in cryptography. Hence, the existence of OWF and PRG in NC¿ follows from a variety of standard assumptions. A similar compiler can also be obtained for other cryptographic primitives such as one-way permutations, encryption, commitment, and collision-resistant hashing. The above results leave a small gap between the possibility of cryptography in NC_4^0and the known impossibility of implementing even OWF in NC_2^0 We partially close this gap by providing evidence for the existence of OWF in NC_3^0. resolving an open question posed by Mossel et al. [25], as well as a PRG for logspace in NC¿. Our results make use of the machinery of randomizing polynomials [19], which was originally motivated by questions in the domain of information-theoretic secure multiparty computation."
FOCS	0(sqrt (log n)) Approximation to SPARSEST CUT in Õ(n) Time.	Sanjeev Arora,Elad Hazan,Satyen Kale	2004	0(sqrt (log n)) Approximation to SPARSEST CUT in Õ(n) Time.
FOCS	Optimal Power-Down Strategies.	John Augustine,Sandy Irani,Chaitanya Swamy	2004	We consider the problem of selecting threshold times to transition a device to low-power sleep states during an idle period. The two-state case, in which there is a single active and a single sleep state, is a continuous version of the ski-rental problem. We consider a generalized version in which there is more than one sleep state, each with its own power-consumption rate and transition costs. We give an algorithm that, given a system, produces a deterministic strategy whose competitive ratio is arbitrarily close to optimal. We also give an algorithm to produce the optimal online strategy given a system and a probability distribution that generates the length of the idle period. We also give a simple algorithm that achieves a competitive ratio of $3 + 2\sqrt{2} \approx 5.828$ for any system.
FOCS	Dynamic Speed Scaling to Manage Energy and Temperature.	Nikhil Bansal,Tracy Kimbrel,Kirk Pruhs	2004	We first consider online speed scaling algorithms to minimize the energy used subject to the constraint that every job finishes by its deadline. We assume that the power required to run at speed s is P(s) = s^¿. We provide a tight ¿^¿ bound on the competitive ratio of the previously proposed Optimal Available algorithm. This improves the bestknown competitive ratio by a factor of 2^¿. We then introduce competitive ratio is at most 2({\alpha\mathord{\left/ {\vphantom {\alpha{(\alpha- 1)^\alpha}}} \right. \kern-\nulldelimiterspace} {(\alpha- 1)^\alpha}}\varepsilon ^\alpha. This competitive ratio is significantly better and is approximately 2\varepsilon ^{\alpha+ 1} for large ¿. Our result is essentially tight for large ¿.In particular, as ¿ approaches infinity, we show that any algorithm must have competitive ratio \varepsilon ^\alpha (up to lower order terms). We then turn to the problem of dynamic speed scaling to minimize the maximum temperature that the device ever reaches, again subject to the constraint that all jobs finish by their deadlines. We assume that the device cools according to Fourierýs law. We show how to solve this problem in polynomial time, within any error bound, using the Ellipsoid algorithm.
FOCS	Approximating Edit Distance Efficiently.	Ziv Bar-Yossef,T. S. Jayram,Robert Krauthgamer,Ravi Kumar	2004	"Edit distance has been extensively studied for the past several years. Nevertheless, no linear-time algorithm is known to compute the edit distance between two strings, or even to approximate it to within a modest factor. Furthermore, for various natural algorithmic problems such as low-distortion embeddings into normed spaces, approximate nearest-neighbor schemes, and sketching algorithms, known results for the edit distance are rather weak. We develop algorithms that solve gap versions of the edit distance problem: given two strings of length n with the promise that their edit distance is either at most k or greater than \ell, decide which of the two holds. We present two sketching algorithms for gap versions of edit distance. Our first algorithm solves the k vs.(kn)^{{2 \mathord{\left/ {\vphantom {2 3}} \right. \kern-\nulldelimiterspace} 3}} gap problem, using a constant size sketch. A more involved algorithm solves the stronger k vs. \ell gap problem, where \ell can be as small as O(k²) ¿ still with a constant sketch ¿ but works only for strings that are mildly ""non-repetitive"". Finally, we develop an n^{{3 \mathord{\left/ {\vphantom {3 7}} \right. \kern-\nulldelimiterspace} 7}}-approximation quasi-linear time algorithm for edit distance, improving the previous best factor of n^{{3 \mathord{\left/ {\vphantom {3 4}} \right. \kern-\nulldelimiterspace} 4}} [5]; if the input strings are assumed to be non-repetitive, then the approximation factor can be strengthened to n^{{1 \mathord{\left/ {\vphantom {1 3}} \right. \kern-\nulldelimiterspace} 3}}."
FOCS	Universally Composable Protocols with Relaxed Set-Up Assumptions.	Boaz Barak,Ran Canetti,Jesper Buus Nielsen,Rafael Pass	2004	"A desirable goal for cryptographic protocols is to guarantee security when the protocol is composed with other protocol instances. Universally Composable (UC) protocols provide this guarantee in a strong sense: A protocol remains secure even when composed concurrently with an unbounded number of instances of arbitrary protocols. However, UC protocols for carrying out general tasks are known to exist only if a majority of the participants are honest, or in the common reference string (CRS) model where all parties are assumed to have access to a common string that is drawn from some pre-defined distribution. Furthermore, carrying out many interesting tasks in a UC manner and without honest majority or set-up assumptions is impossible, even if ideally authenticated communication is provided. A natural question is thus whether there exist more relaxed set-up assumptions than the CRS model that still allow for UC protocols. We answer this question in the affirmative: we propose alternative and relaxed set-up assumptions and show that they suffice for reproducing the general feasibility results for UC protocols in the CRS model. These alternative assumptions have the flavor of a ""public-key infrastructure"": parties have registered public keys, no single registration authority needs to be fully trusted, and no single piece of information has to be globally trusted and available. In addition, unlike known protocols in the CRS model, the proposed protocols guarantee some basic level of security even if the set-up assumption is violated."
FOCS	Extracting Randomness Using Few Independent Sources.	Boaz Barak,Russell Impagliazzo,Avi Wigderson	2004	In this work we give the first deterministic extractors from a constant number of weak sources whose entropy rate is less than 1/2. Specifically, for every $\delta >0$ we give an explicit construction for extracting randomness from a constant (depending polynomially on $1/\delta$) number of distributions over $\bits^n$, each having min-entropy $\delta n$. These extractors output $n$ bits that are $2^{-n}$ close to uniform. This construction uses several results from additive number theory, and in particular a recent result of Bourgain et al. We also consider the related problem of constructing randomness dispersers. For any constant output length $m$, our dispersers use a constant number of identical distributions, each with requires min-entropy $\Omega(\log n)$, and outputs every possible $m$-bit string with positive probability. The main tool we use is a variant of the &ldquo;stepping-up lemma&rdquo; of Erdo&dblac;s and Hajnal used in establishing a lower bound on the Ramsey number for hypergraphs.
FOCS	Constructing Expander Graphs by 2-Lifts and Discrepancy vs. Spectral Gap.	Yonatan Bilu,Nathan Linial	2004	"We present a new explicit construction for expander graphs with nearly optimal spectral gap. The construction is based on a series of 2-lift operations. Let G be a graph on n vertices. A 2-lift of G is a graph H on 2n vertices, with a covering map ¿ : H ¿ G. It is not hard to see that all eigenvalues of G are also eigenvalues of H. In addition, H has n ""new"" eigenvalues. We conjecture that every d-regular graph has a 2-lift such that all new eigenvalues are in the range \left[ { - 2\sqrt {d - 1} ,2\sqrt {d - 1} } \right] (If true, this is tight, e.g. by the Alon-Boppana bound). Here we show that every graph of maximal degree d has a2-lift such that all ""new"" eigenvalues are in the range \left[ { - c\sqrt {d\log ^3 d} ,c\sqrt {d\log ^3 d} } \right] for some constant c. This leads to a polynomial time algorithm for constructing arbitrarily large d-regular graphs, with second eigenvalue 0(\sqrt {d\log ^3 d}). The proof uses the following lemma (Lemma 3.6): Let A be a real symmetric matrix with zeros on the diagonal. Let d be such that the ¿¿ norm of each row in A is at most d. Suppose that \frac{{\left| {xAy} \right|}}{{\left\| x \right\|\left\| y \right\|}} \leqslant \alpha for every x,y \in \{ 0,1\} ^nwith ¿ x,y ¿= 0. Then the spectral radius of A is 0(\alpha (\log ({d \mathord{\left/ {\vphantom {d {\alpha ) + 1))}}} \right. \kern-\nulldelimiterspace} {\alpha ) + 1))}}. An interesting consequence of this lemma is a converse to the Expander Mixing Lemma."
FOCS	Learning with Errors in Answers to Membership Queries.	Laurence Bisht,Nader H. Bshouty,Lawrance Khoury	2004	We study the learning models defined in [D. Angluin, M. Krikis, R.H. Sloan, G. Turan, Malicious omissions and errors in answering to membership queries, Machine Learning 28 (2-3) (1997) 211-255]: Learning with equivalence and limited membership queries and learning with equivalence and malicious membership queries. We show that if a class of concepts that is closed under projection is learnable in polynomial time using equivalence and (standard) membership queries then it is learnable in polynomial time in the above models. This closes the open problems in [D. Angluin, M. Krikis, R.H. Sloan, G. Turan, Malicious omissions and errors in answering to membership queries, Machine Learning 28 (2-3) (1997) 211-255]. Our algorithm can also handle errors in the equivalence queries.
FOCS	Edge-Disjoint Paths in Planar Graphs.	Chandra Chekuri,Sanjeev Khanna,F. Bruce Shepherd	2004	We study the maximum edge-disjoint paths problem (MEDP). We are given a graph G = (V,E) and a set T = {s1t1, s2t2, . . . , sktk} of pairs of vertices: the objective is to find the maximum number of pairs in T that can be connected via edge-disjoint paths. Our main result is a poly-logarithmic approximation for MEDP on undirected planar graphs if a congestion of 2 is allowed, that is, we allow up to 2 paths to share an edge. Prior to our work, for any constant congestion, only a polynomial-factor approximation was known for planar graphs although much stronger results are known for some special cases such as grids and grid-like graphs. We note that the natural multi-commodity flow relaxation of the problem has an integrality gap of \Omega (\sqrt {\left| V \right|} ) even on planar graphs when no congestion is allowed. Our starting point is the same relaxation and our result implies that the integrality gap shrinks to a poly-logarithmic factor once 2 paths are allowed per edge. Our result also extends to the unsplittable flow problem and the maximum integer multicommodity flow problem. A set X ¿ V is well-linked if for each S ¿ V , |¿(S)| ¿ min-{|S ¿ X|, |(V - S) ¿ X|}. The heart of our approach is to show that in any undirected planar graph, given any matching M on a well-linked set X, we can route ¿(|M|) pairs in M with a congestion of 2. Moreover, all pairs in M can be routed with constant congestion for a sufficiently large constant. This results also yields a different proof of a theorem of Klein, Plotkin, and Rao that shows an O(1) maxflow-mincut gap for uniform multicommodity flow instances in planar graphs. The framework developed in this paper applies to general graphs as well. If a certain graph theoretic conjecture is true, it will yield poly-logarithmic integrality gap for MEDP with constant congestion.
FOCS	On the List and Bounded Distance Decodibility of the Reed-Solomon Codes (Extended Abstract).	Qi Cheng,Daqing Wan	2004	"For an error-correcting code and a distance bound, the list decoding problem is to compute all the codewords within a given distance to a received message. The bounded distance decoding problem is to find one codeword if there is at least one codeword within the given distance, or to out-put the empty set if there is not. Obviously the bounded distance decoding problem is not as hard as the list decoding problem. For a Reed-Solomon code [n, k]q, a simple counting argument shows that for any integer 0 0. We show that the discrete logarithm problem over f_q h can be efficiently reduced by a randomized algorithm to the bounded distance decoding problem of the Reed-Solomon code [q, g - h]_q with radius q - g. These results show that the decoding problems for the Reed-Solomon code are at least as hard as the discrete logarithm problem over finite fields. The main tools to obtain these results are an interesting connection between the problem of list-decoding of Reed-Solomon code and the problem of discrete logarithm over finite fields, and a generalization of Katz's theorem on representations of elements in an extension finite field by products of distinct linear factors."
FOCS	Algebras with Polynomial Identities and Computing the Determinant.	Steve Chien,Alistair Sinclair	2004	In 1991, Nisan proved an exponential lower bound on the size of an algebraic branching program (ABP) that computes the determinant of a matrix in the noncommutative &ldquo;free algebra&rdquo; setting, in which there are no nontrivial relationships between the matrix entries. By contrast, when the matrix entries commute there are polynomial size ABPs for the determinant. This paper extends Nisan&rsquo;s result to a much wider class of noncommutative algebras, including all nontrivial matrix algebras over any field of characteristic 0, group algebras of all nonabelian finite groups over algebraically closed fields of characteristic 0, the quaternion algebra, and the Clifford algebras. As a result, we obtain more compelling evidence for the essential role played by commutativity in the efficient computation of the determinant. The key to our approach is a characterization of noncommutative algebras by means of the polynomial identities that they satisfy. Extending Nisan&rsquo;s lower bound framework, we find that any reduction in complexity compared to the free algebra must arise from the ability of the identities to reduce the rank of certain naturally associated matrices. Using results from the theory of algebras with polynomial identities, we are able to show that none of the identities of the above classes of algebras is able to achieve such a rank reduction.
FOCS	An Optimal Randomised Cell Probe Lower Bound for Approximate Nearest Neighbour Searching.	Amit Chakrabarti,Oded Regev	2004	We consider the approximate nearest neighbour search problem on the Hamming Cube {0, 1}^d. We show that a randomised cell probe algorithm that uses polynomial storage and word size d^{0(1)} requires a worst case query time \Omega ({{\log \log d} \mathord{\left/ {\vphantom {{\log \log d} {\log \log \log d}}} \right. \kern-\nulldelimiterspace} {\log \log \log d}}). The approximation factor may be as loose as 2^{\log ^{1 - n} d} for any fixed. n > 0. This generalises an earlier result [5] on the deterministic complexity of the same problem and, more importantly, fills a major gap the study of this problem since all earlier lower bounds either did not allow randomisation [5, 18] or did not allow approximation [4, 2, 15]. We also give a cell probe algorithm which proves that our lower bound is optimal. Our proof uses a lower bound on the round complexity of the related communication problem. We show, additionally, that considerations of bit complexity alone cannot prove any nontrivial cell probe lower bound for the problem. This shows that the Richness Technique [20] used in lot of recent research around this problem would not have helped here. Our proof is based on information theoretic techniques for communication complexity, a theme that has been prominent in recent research [6, 1, 23, 14]. In particular, we make heavy use of the round elimination and message compression ideas in the recent work of Sen [23] and Jain, Radhakrishnan, and Sen [14], and also introduce a new technique which we call message switching.
FOCS	Machine Minimization for Scheduling Jobs with Interval Constraints.	Julia Chuzhoy,Sudipto Guha,Sanjeev Khanna,Joseph Naor	2004	The problem of scheduling jobs with interval constraints is a well-studied classical scheduling problem. The input to the problem is a collection of n jobs where each job has a set of intervals on which it can be scheduled. The goal is to minimize the total number of machines needed to schedule all jobs subject to these interval constraints. In the continuous version, the allowed intervals associated with a job form a continuous time segment, described by a release date and a deadline. In the discrete version of the problem, the set of allowed intervals for a job is given explicitly. So far, only an 0(\frac{{\log n}}{{\log \log n}})-approximation is known for either version of the problem, obtained by a randomized rounding of a natural linear programming relaxation of the problem. In fact, we show here that this analysis is tight for both versions of the problem by providing a matching lower bound on the integrality gap of the linear program. Moreover, even when all jobs can be scheduled on a single machine, the discrete case has recently been shown to be ¿(log log n)-hard to approximate. In this paper we provide improved approximation factors for the number of machines needed to schedule all jobs in the continuous version of the problem. Our main result is an O(1)-approximation algorithm when the optimal number of machines needed is bounded by a fixed constant. Thus, our results separate the approximability of the continuous and the discrete cases of the problem. For general instances, we strengthen the natural linear programming relaxation in a recursive manner by forbidding certain configurations which cannot arise in an integral feasible solution. This yields an O(OPT)-approximation, where OPT denotes the number of machines needed by an optimal solution. Combined with earlier results, our work implies an 0(\sqrt {\frac{{\log n}}{{\log \log n}}} )-approximation for any value of OPT.
FOCS	The Hardness of Metric Labeling.	Julia Chuzhoy,Joseph Naor	2004	The Metric Labeling problem is an elegant and powerful mathematical model capturing a wide range of classification problems. The input to the problem consists of a set of labels and a weighted graph. Additionally, a metric distance function on the labels is defined, and for each label and each vertex, an assignment cost is given. The goal is to find a minimum-cost assignment of the vertices to the labels. The cost of the solution consists of two parts: the assignment costs of the vertices and the separation costs of the edges (each edge pays its weight times the distance between the two labels to which its endpoints are assigned). Due to the simple structure and variety of the applications, the problem and its special cases (with various distance functions on the labels) have recently received much attention. Metric Labeling has a known logarithmic approximation, and it has been an open question for several years whether a constant approximation exists. We refute this possibility and show that no constant approximation can be obtained for the problem unless P=NP, and we also show that the problem is \Omega (\sqrt {\log n} )-hard to approximate, unless NP has quasi-polynomial time algorithms.
FOCS	On the Integrality Ratio for Asymmetric TSP.	Moses Charikar,Michel X. Goemans,Howard J. Karloff	2004	We improve the lower bound on the integrality ratio of the Held-Karp bound for asymmetric TSP (with triangle inequality) from 4/3 to 2.
FOCS	"Maximizing Quadratic Programs: Extending Grothendieck's Inequality."	Moses Charikar,Anthony Wirth	2004	"This paper considers the following type of quadratic programming problem. Given an arbitrary matrix A, whose diagonal elements are zero, find x ¿ {-1, 1}^n such that x^TAx is maximized. Our approximation algorithm for this problem uses the canonical semidefinite relaxation and returns a solution whose ratio to the optimum is in ¿(1/log n). This quadratic programming problem can be seen as an extension to that of maximizing x^TAy (where y's components are also ±1). Grothendieck's inequality states that the ratio of the optimum value of the latter problem to the optimum of its canonical semidefinite relaxation is bounded below by a constant. The study of this type of quadratic program arose from a desire to approximate the maximum correlation in correlation clustering. Nothing substantive was known about this problem; we present an ¿(1/log n) approximation, based on our quadratic programming algorithm. We can also guarantee that our quadratic programming algorithm returns a solution to the MAXCUT problem that has a significant advantage over a random assignment."
FOCS	The Exact Satisfiability Threshold for a Potentially Intractible Random Constraint Satisfaction Problem.	Harold S. Connamacher,Michael Molloy	2004	We determine the exact threshold of satisfiability for random instances of a particular NP-hard constraint satisfaction problem. The problem appears to share many of the threshold characteristics of random k-SAT for k ¿ 3; for example, we prove the problem almost surely has high resolution complexity.We also prove the analogue of the (2 + p)-SATconjecture for a class of problems that includes this problem and XOR-SAT.
FOCS	Spectral Analysis of Random Graphs with Skewed Degree Distributions.	Anirban Dasgupta,John E. Hopcroft,Frank McSherry	2004	"We extend spectral methods to random graphs with skewed degree distributions through a degree based normalization closely connected to the normalized Laplacian. The normalization is based on intuition drawn from perturbation theory of random matrices, and has the effect of boosting the expectation of the random adjacency matrix without increasing the variances of its entries, leading to better perturbation bounds. The primary implication of this result lies in the realm of spectral analysis of random graphs with skewed degree distributions, such as the ubiquitous ""power law graphs"". Recently Mihail and Papadimitriou [22] argued that for randomly generated graphs satisfying a power law degree distribution, spectral analysis of the adjacency matrix will simply produce the neighborhoods of the high degree nodes as its eigenvectors, and thus miss any embedded structure. We present a generalization of their model, incorporating latent structure, and prove that after applying our transformation, spectral analysis succeeds in recovering the latent structure with high probability."
FOCS	Approximating the Stochastic Knapsack Problem: The Benefit of Adaptivity.	Brian C. Dean,Michel X. Goemans,Jan Vondrák	2004	"We consider a stochastic variant of the NP-hard 0/1 knapsack problem in which item values are deterministic and item sizes are independent random variables with known, arbitrary distributions. Items are placed in the knapsack sequentially, and the act of placing an item in the knapsack instantiates its size. Our goal is to compute a solution ""policy"" that maximizes the expected value of items placed in the knapsack, and we consider both non-adaptive policies (that designate a priori a fixed sequence of items to insert) and adaptive policies (that can make dynamic choices based on the instantiated sizes of items placed in the knapsack thus far). We show that adaptivity provides only a constant-factor improvement by demonstrating a greedy non-adaptive algorithm that approximates the optimal adaptive policy within a factor of 7. We also design an adaptive polynomial-time algorithm which approximates the optimal adaptive policy within a factor of 5 + ¿, for any constant ¿ > 0."
FOCS	Dynamic Optimality -- Almost.	Erik D. Demaine,Dion Harmon,John Iacono,Mihai Patrascu	2004	We present an O(lg lg n)-competitive online binary search tree, improving upon the best previous (trivial) competitive ratio of O(lg n). This is the first major progress on Sleator and Tarjanýs dynamic optimality conjecture of 1985 that O(1)-competitive binary search trees exist.
FOCS	Assignment Testers: Towards a Combinatorial Proof of the PCP-Theorem.	Irit Dinur,Omer Reingold	2004	In this work we look back into the proof of the PCP (probabilistically checkable proofs) theorem, with the goal of finding new proofs that are &ldquo;more combinatorial&rdquo; and arguably simpler. For that we introduce the notion of an assignment tester, which is a strengthening of the standard PCP verifier, in the following sense. Given a statement and an alleged proof for it, while the PCP verifier checks correctness of the statement, the assignment tester checks correctness of the statement and the proof. This notion enables composition that is truly modular; i.e., one can compose two assignment testers without any assumptions on how they are constructed. A related notion called PCPs of proximity was independently introduced in [E. Ben-Sasson et al., Proceedings of the 36th Annual ACM Symposium on Theory of Computing, Chicago, IL, 2004, ACM, New York, 2004, pp. 1-10]. We provide a toolkit of (nontrivial) generic transformations on assignment testers. These transformations may be interesting in their own right, and allow us to present the following two main results: 1. A new proof of the PCP theorem. This proof relies on a rather weak assignment tester given as a &ldquo;black box.&rdquo; From this, we construct combinatorially the full PCP. An important component of this proof is a new combinatorial aggregation technique (i.e., a new transformation that allows the verifier to read fewer, though possibly longer, &ldquo;pieces&rdquo; of the proof). An implementation of the black-box tester can be obtained from the algebraic proof techniques that already appear in [L. Babai et al., Proceedings of the 23rd ACM Symposium on Theory of Computing, New Orleans, LA, 1991, ACM, New York, 1991, pp. 21-31; U. Feige et al., J. ACM, 43 (1996), pp. 268-292]. 2. Our second construction is a &ldquo;standalone&rdquo; combinatorial construction showing $NP \subseteq PCP[polylog, 1]$. This implies, for example, that approximating max-SAT is quasi-NP-hard. This construction relies on a transformation that makes an assignment tester &ldquo;oblivious,&rdquo; so that the proof locations read are independent of the statement that is being proven. This eliminates, in a rather surprising manner, the need for aggregation in a crucial point in the proof.
FOCS	On the (Im)possibility of Cryptography with Imperfect Randomness.	Yevgeniy Dodis,Shien Jin Ong,Manoj Prabhakaran,Amit Sahai	2004	We investigate the feasibility of a variety of cryptographic tasks with imperfect randomness. The kind of imperfect randomness we consider are entropy sources, such as those considered by Santha and Vazirani, Chor and Goldreich, and Zuckerman. We show the following: Certain cryptographic tasks like bit commitment, encryption, secret sharing, zero-knowledge, noninteractive zero-knowledge, and secure two-party computation for any non-trivial function are impossible to realize if parties have access to entropy sources with slightly less-than-perfect entropy, i.e., sources with imperfect randomness. These results are unconditional and do not rely on any unproven assumption. On the other hand, based on stronger variants of standard assumptions, secure signature schemes are possible with imperfect entropy sources. As another positive result, we show (without any unproven assumption) that interactive proofs can be made sound with respect to imperfect entropy sources.
FOCS	Randomly Coloring Constant Degree Graphs.	Martin E. Dyer,Alan M. Frieze,Thomas P. Hayes,Eric Vigoda	2004	We study a simple Markov chain, known as the Glauber dynamics, for generating a random k-coloring of a n-vertex graph with maximum degree ¿. We prove that the dynamics converges to a random coloring after 0(n log n) steps assuming k ¿ k_0 for some absolute constnat k_0, and either: (i) {k \mathord{\left/ {\vphantom {k \Delta }} \right. \kern-\nulldelimiterspace} \Delta } > ¿* ¿ 1.763 and the girth g ¿ 5, or (ii) {k \mathord{\left/ {\vphantom {k \Delta }} \right. \kern-\nulldelimiterspace} \Delta } > β* ¿ 1.489 and the girth g ¿ 6. Previous results on this problem applied when k = ¿(log n), or when k > 11¿/6 for general graphs.
FOCS	Tolls for Heterogeneous Selfish Users in Multicommodity Networks and Generalized Congestion Games.	Lisa Fleischer,Kamal Jain,Mohammad Mahdian	2004	We prove the existence of tolls to induce multicommodity, heterogeneous network users that independently choose routes minimizing their own linear function of tolls versus latency to collectively form the traffic pattern of a minimum average latency flow. This generalizes both the previous known results of the existence of tolls for multicommodity, homogeneous users [1] and for single commodity, heterogeneous users [3]. Unlike previous proofs for single commodity users in general graphs, our proof is constructive - it does not rely on a fixed point theorem - and results in a simple polynomial-sized linear program to compute tolls when the number of different types of users is bounded by a polynomial. We show that our proof gives a complete characterization of flows that are enforceable by tolls. In particular, tolls exist to induce any traffic pattern that is the result of minimizing an arbitrary function from \mathbb{R}^{E(G)} to the reals that is nondecreasing in each of its arguments. Thus, tolls exist to induce flows with minimum average weighted latency, minimum maximum latency, and other natural objectives. We give an exponential bound on tolls that is independent of the number of network users and the number of commodities. We use this to show that multicommodity tolls also exist when users are not from discrete classes, but instead define a general function that trades off latency versus toll preference. Finally, we show that our result extends to very general frameworks. In particular, we show that tolls exist to induce the Nash equilibrium of general nonatomic congestion games to be system optimal. In particular, tolls exist even when 1) latencies depend on user type; 2) latency functions are nonseparable functions of traffic on edges; 3) the latency of a set S is an arbitrary function of the latencies of the resources contained in S.Our exponential bound on size of tolls also holds in this case; and we give an example of a congestion game that shows this is tight: it requires tolls that are exponential in the size of the game.
FOCS	Hierarchy Theorems for Probabilistic Polynomial Time.	Lance Fortnow,Rahul Santhanam	2004	"We show a hierarchy for probabilistic time with one bit of advice, specifically we show that for all real numbers 1 ¿ ¿ 0, there is a language L computable on average in BPP but not on average in BPTIME(n^(d)). We build on Barak's techniques by using a different translation argument and by a careful application of the fact that there is a PSPACE-complete problem L such that worst-case probablistic algorithms for L take only slightly more time thane average-case algorithms."
FOCS	No Sorting? Better Searching!	Gianni Franceschini,Roberto Grossi	2004	Questions about order versus disorder in systems and models have been fascinating scientists over the years. In computer science, order is intimately related to sorting, commonly meant as the task of arranging keys in increasing or decreasing order with respect to an underlying total order relation. The sorted organization is amenable for searching a set of n keys, since each search requires &Theta;(log n) comparisons in the worst case, which is optimal if the cost of a single comparison can be considered a constant. Nevertheless, we prove that disorder implicitly provides more information than order does. For the general case of searching an array of multidimensional keys whose comparison cost is proportional to their length (and hence which cannot be considered a constant), we demonstrate that &ldquo;suitable&rdquo; disorder gives better bounds than those derivable by using the natural lexicographic order. We start from previous work done by Andersson et al. [2001], who proved that &Theta;(k log log n/log log(4 &plus; klog log n/log n) &plus; k &plus; log n) character comparisons (or probes) comprise the tight complexity for searching a plain sorted array of n keys, each of length k, arranged in lexicographic order. We describe a novel permutation of the n keys that is different from the sorted order. When keys are kept &ldquo;unsorted&rdquo; in the array according to this permutation, the complexity of searching drops to &Theta;(k &plus; log n) character comparisons (or probes) in the worst case, which is optimal among all possible permutations, up to a constant factor. Consequently, disorder carries more information than does order; this fact was not observable before, since the latter two bounds are &Theta;(log n) when k &equals; O(1). More implications are discussed in the article, including searching in the bit-probe model.
FOCS	Deterministic Extractors for Bit-Fixing Sources by Obtaining an Independent Seed.	Ariel Gabizon,Ran Raz,Ronen Shaltiel	2004	An $(n,k)$-bit-fixing source is a distribution $X$ over $\{0,1\}^n$ such that there is a subset of $k$ variables in $X_1,\ldots,X_n$ which are uniformly distributed and independent of each other, and the remaining $n-k$ variables are fixed. A deterministic bit-fixing source extractor is a function $E:\{0,1\}^n \rightarrow \{0,1\}^m$ which on an arbitrary $(n,k)$-bit-fixing source outputs $m$ bits that are statistically close to uniform. Recently, Kamp and Zuckerman [Proceedings of the 44th Annual IEEE Symposium on Foundations of Computer Science, 2003, pp. 92-101] gave a construction of a deterministic bit-fixing source extractor that extracts $\Omega(k^2/n)$ bits and requires $k>\sqrt{n}$. In this paper we give constructions of deterministic bit-fixing source extractors that extract $(1-o(1))k$ bits whenever $k>(\log n)^c$ for some universal constant $c>0$. Thus, our constructions extract almost all the randomness from bit-fixing sources and work even when $k$ is small. For $k \gg \sqrt{n}$ the extracted bits have statistical distance $2^{-n^{\Omega(1)}}$ from uniform, and for $k \le \sqrt{n}$ the extracted bits have statistical distance $k^{-\Omega(1)}$ from uniform. Our technique gives a general method to transform deterministic bit-fixing source extractors that extract few bits into extractors which extract almost all the bits.
FOCS	trong Spatial Mixing for Lattice Graphs with Fewer Colours.	Leslie Ann Goldberg,Russell A. Martin,Mike Paterson	2004	trong Spatial Mixing for Lattice Graphs with Fewer Colours.
FOCS	An Edge in Time Saves Nine: LP Rounding Approximation Algorithms for Stochastic Network Design.	Anupam Gupta,R. Ravi,Amitabh Sinha	2004	Real-world networks often need to be designed under uncertainty, with only partial information and predictions of demand available at the outset of the design process. The field of stochastic optimization deals with such problems where the forecasts are specified in terms of probability distributions of future data. In this paper, we broaden the set of models as well as the techniques being considered for approximating stochastic optimization problems. For example, we look at stochastic models where the cost of the elements is correlated to the set of realized demands, and risk-averse models where upper bounds are placed on the amount spent in each of the stages. These generalized models require new techniques, and our solutions are based on a novel combination of the primal-dual method truncated based on optimal LP relaxation values, followed by a tree-rounding stage. We use these to give constant-factor approximation algorithms for the stochastic Steiner tree and single sink network design problems in these generalized models.
FOCS	An Approximate Max-Steiner-Tree-Packing Min-Steiner-Cut Theorem.	Lap Chi Lau	2004	"Given an undirected multigraph G and a subset of vertices S &#x2286; V (G), the STEINER TREE PACKING problem is to find a largest collection of edge-disjoint trees that each connects S. This problem and its generalizations have attracted considerable attention from researchers in different areas because of their wide applicability. This problem was shown to be APX-hard (no polynomial time approximation scheme unless P=NP). In fact, prior to this paper, not even an approximation algorithm with asymptotic ratio o(n) was known despite several attempts. In this work, we present the first polynomial time constant factor approximation algorithm for the STEINER TREE PACKING problem. The main theorem is an approximate min-max relation between the maximum number of edge-disjoint trees that each connects S (S-trees) and the minimum size of an edge-cut that disconnects some pair of vertices in S (S-cut). Specifically, we prove that if every S-cut in G has at least 26k edges, then G has at least k edge-disjoint S-trees; this answers Kriesells conjecture affirmatively up to a constant multiple."
FOCS	On the Power of Discrete and of Lexicographic Helly-Type Theorems.	Nir Halman	2004	Hellyýs theorem says that if every d + 1 elements of a given finite set of convex objects in \mathbb{R}^d have a common point, then there is a point common to all of the objects in the set. We define three new types of Helly theorems: discrete Helly theorems - where the common point should belong to an a-priori given set, lexicographic Helly theorems - where the common point should not be lexicographically greater than a given point, and lexicographic-discrete Helly theorems. We show the relations between these new Helly theorems and their corresponding (standard) Helly theorems.We obtain several new discrete and lexicographic Helly numbers. Using these new types of Helly theorems we get linear time solutions for various optimization problems. For this, we define a new framework, DLP-type (Discrete Linear Programming type), and provide new algorithms that solve in randomized linear time fixed-dimensional DLP-type problems.We show that the complexity of the DLP-type class stands somewhere between Linear Programming (LP) and Integer Programming (IP). Finally, we use our results in order to solve in randomized linear time problems such as the discrete p-center on the real line, the discrete weighted 1-center problem in \mathbb{R}^dwith \iota _\infty norm, the standard (continuous) problem of finding a line transversal for a totally separable set of planar convex objects, a discrete version of the problem of finding a line transversal for a set of axis-parallel planar rectangles, and the (planar) lexicographic rectilinear p-center problem for p = 1, 2, 3. These are the first known linear time algorithms for these problems.
FOCS	A Polynomial Time Algorithm for Computing the Arrow-Debreu Market Equilibrium for Linear Utilities.	Kamal Jain	2004	We provide the first polynomial time exact algorithm for computing an Arrow-Debreu market equilibrium for the case of linear utilities. Our algorithm is based on solving a convex program using the ellipsoid algorithm and simultaneous diophantine approximation. As a side result, we prove that the set of assignments at equilibria is convex and the equilibria prices themselves are log-convex. Our convex program is explicit and intuitive, which allows maximizing a concave function over the set of equilibria. On the practical side, Ye developed an interior point algorithm [31] to find an equilibrium based on our convex program. We also derive separate combinatorial characterizations of equilibrium for Arrow-Debreu and Fisher cases. Our convex program can be extended for many non-linear utilities (section 8 and [4, 24]) and production models [21]. Our paper also makes a powerful theorem (theorem 6.4.1 in [19]) even more powerful (theorems 12 and 13) in the area of Geometric Algorithms and Combinatorial Optimization. The main idea in this generalization is to allow ellipsoids not to contain the whole convex region but a part of it. This theorem is of independent interest.
FOCS	Testing Low-Degree Polynomials over Prime Fields.	Charanjit S. Jutla,Anindya C. Patthak,Atri Rudra,David Zuckerman	2004	We present an efficient randomized algorithm to test if a given function f : &Fopf; <stack>pn</stack> &rarr; &Fopf;p (where p is a prime) is a low-degree polynomial. This gives a local test for Generalized Reed-Muller codes over prime fields. For a given integer t and a given real ε > 0, the algorithm queries f at O($ O({{1}\over{\epsilon}}+t.p^{{2t \over p-1}+1}) $) points to determine whether f can be described by a polynomial of degree at most t. If f is indeed a polynomial of degree at most t, our algorithm always accepts, and if f has a relative distance at least ε from every degree t polynomial, then our algorithm rejects f with probability at least $ {1\over 2} $. Our result is almost optimal since any such algorithm must query f on at least $ \Omega ( {1 \over \epsilon} + p^ {t+1 \over p-1})$ points. &copy; 2009 Wiley Periodicals, Inc. Random Struct. Alg., 2009 A preliminary version of this paper appeared in 45th Symposium on Foundations of Computer Science, 2004. Most of this work was done while the author (Patthak) was at the University of Texas at Austin. This work was done while the author (Rudra) was at the University of Texas at Austin.
FOCS	Edge Pricing of Multicommodity Networks for Heterogeneous Selfish Users.	George Karakostas,Stavros G. Kolliopoulos	2004	We examine how the selfish behavior of heterogeneous users in a network can be regulated through economic disincentives, i.e., through the introduction of appropriate taxation. One wants to impose taxes on the edges so that any traffic equalibrium reached by the selfish users who are conscious of both the travel latencies and the taxes will minimize the social cost, i.e., will minimize the total latency. We generalize previous results of Cole, Dodis and Roughgarden that held for a single origin-destination pair to the multicommodity setting. Our approach, which could be of independent interest, is based on the formulation of traffic equilibria as a nonlinear complementarity problem by Aashtiani and Magnanti [1]. We extend this formulation so that each of its solutions will give us a set of taxes that forces the network users to conform, at equilibrium, to a certain prescribed routing. We use the special nature of the prescribed minimum-latency flow in order to reduce the difficult nonlinear complementary formulation to a pair of primal-dual linear programs. LP duality is then enough to derive our results.
FOCS	Testing Polynomials over General Fields.	Tali Kaufman,Dana Ron	2004	In this work we fill the knowledge gap concerning testing polynomials over finite fields. As previous works show, when the cardinality of the field, $q$, is sufficiently larger than the degree bound, $d$, then the number of queries sufficient for testing is polynomial or even linear in $d$. On the other hand, when $q=2$ then the number of queries, both sufficient and necessary, grows exponentially with $d$. Here we study the intermediate case where $2 < q = O(d)$ and show a smooth transition between the two extremes. Specifically, let $p$ be the characteristic of the field (so that $p$ is prime and $q = p^s$ for some integer $s \geq 1$). Then the number of queries performed by the test grows like $\ell\cdot q^{2\ell+1}$, where $\ell = \big\lceil \frac{d+1}{q-q/p}\big\rceil $. Furthermore, $q^{\Omega(\ell)}$ queries are necessary when $q = O(d)$. The test itself provides a unifying view of the tests for these two extremes: it considers random affine subspaces of dimension $\ell$ and verifies that the function restricted to the selected subspaces is a polynomial of degree at most $d$. Viewed in the context of coding theory, our result shows that Reed-Muller codes over general fields (usually referred to as generalized Reed-Muller (GRM) codes) are locally testable. In the course of our analysis we provide a characterization of small-weight words that span the code. Such a characterization was previously known only when the field size is a prime or is sufficiently large, in which case the minimum-weight words span the code.
FOCS	Hardness of Approximating the Shortest Vector Problem in Lattices.	Subhash Khot	2004	Let p > 1 be any fixed real. We show that assuming NP &nsube; RP, there is no polynomial time algorithm that approximates the Shortest Vector Problem (SVP) in &ell;p norm within a constant factor. Under the stronger assumption NP &nsube; RTIME(2poly(log n)), we show that there is no polynomial-time algorithm with approximation ratio 2(log n)1/2&minus;&epsi; where n is the dimension of the lattice and &epsi; > 0 is an arbitrarily small constant.We first give a new (randomized) reduction from Closest Vector Problem (CVP) to SVP that achieves some constant factor hardness. The reduction is based on BCH Codes. Its advantage is that the SVP instances produced by the reduction behave well under the augmented tensor product, a new variant of tensor product that we introduce. This enables us to boost the hardness factor to 2(log n)1/2-&epsi;.
FOCS	Ruling Out PTAS for Graph Min-Bisection, Densest Subgraph and Bipartite Clique.	Subhash Khot	2004	Assuming that NP ¿ ¿_¿ > 0 BPTIME(2^n^¿), we show that GraphMin-Bisection, Densest Subgraph and Bipartite Clique have no PTAS. We give a reduction from the Minimum Distance of Code Problem (MDC). Starting with an instance of MDC, we build a Quasi-random PCP that suffices to prove the desired inapproximability results. In a Quasi-random PCP, the query pattern of the verifier looks random in some precise sense. Among the several new techniques introduced, we give a way of certifying that a given polynomial belongs to a given subspace of polynomials. As is important for our purpose, the certificate itself happens to be another polynomial and it can be checked by reading a constant number of its values.
FOCS	Optimal Inapproximability Results for Max-Cut and Other 2-Variable CSPs?	"Subhash Khot,Guy Kindler,Elchanan Mossel,Ryan O'Donnell"	2004	In this paper we show a reduction from the Unique Games problem to the problem of approximating MAX-CUT to within a factor of $\alpha_{\text{\tiny{GW}}} + \epsilon$ for all $\epsilon > 0$; here $\alpha_{\text{\tiny{GW}}} \approx .878567$ denotes the approximation ratio achieved by the algorithm of Goemans and Williamson in [J. Assoc. Comput. Mach., 42 (1995), pp. 1115-1145]. This implies that if the Unique Games Conjecture of Khot in [Proceedings of the 34th Annual ACM Symposium on Theory of Computing, 2002, pp. 767-775] holds, then the Goemans-Williamson approximation algorithm is optimal. Our result indicates that the geometric nature of the Goemans-Williamson algorithm might be intrinsic to the MAX-CUT problem. Our reduction relies on a theorem we call Majority Is Stablest. This was introduced as a conjecture in the original version of this paper, and was subsequently confirmed in [E. Mossel, R. O&rsquo;Donnell, and K. Oleszkiewicz, Proceedings of the 46th Annual IEEE Symposium on Foundations of Computer Science, 2005, pp. 21-30]. A stronger version of this conjecture called Plurality Is Stablest is still open, although [E. Mossel, R. O&rsquo;Donnell, and K. Oleszkiewicz, Proceedings of the 46th Annual IEEE Symposium on Foundations of Computer Science, 2005, pp. 21-30] contains a proof of an asymptotic version of it. Our techniques extend to several other two-variable constraint satisfaction problems. In particular, subject to the Unique Games Conjecture, we show tight or nearly tight hardness results for MAX-2SAT, MAX-$q$-CUT, and MAX-2LIN($q$). For MAX-2SAT we show approximation hardness up to a factor of roughly $.943$. This nearly matches the $.940$ approximation algorithm of Lewin, Livnat, and Zwick in [Proceedings of the 9th Annual Conference on Integer Programming and Combinatorial Optimization, Springer-Verlag, Berlin, 2002, pp. 67-82]. Furthermore, we show that our .943... factor is actually tight for a slightly restricted version of MAX-2SAT. For MAX-$q$-CUT we show a hardness factor which asymptotically (for large $q$) matches the approximation factor achieved by Frieze and Jerrum [Improved approximation algorithms for MAX k-CUT and MAX BISECTION, in Integer Programming and Combinatorial Optimization, Springer-Verlag, Berlin, pp. 1-13], namely $1 - 1/q + 2({\rm ln}\,q)/q^2$. For MAX-2LIN($q$) we show hardness of distinguishing between instances which are $(1-\epsilon)$-satisfiable and those which are not even, roughly, $(q^{-\epsilon/2})$-satisfiable. These parameters almost match those achieved by the recent algorithm of Charikar, Makarychev, and Makarychev [Proceedings of the 38th Annual ACM Symposium on Theory of Computing, 2006, pp. 205-214]. The hardness result holds even for instances in which all equations are of the form $x_i - x_j = c$. At a more qualitative level, this result also implies that $1-\epsilon$ vs. &egr; hardness for MAX-2LIN($q$) is equivalent to the Unique Games Conjecture.
FOCS	Quantum and Classical Strong Direct Product Theorems and Optimal Time-Space Tradeoffs.	Hartmut Klauck,Robert Spalek,Ronald de Wolf	2004	A strong direct product theorem says that if we want to compute k independent instances of a function, using less than k times the resources needed for one instance, then our overall success probability will be exponentially small in k. We established such theorems for the classical as well as quantum query complexity of the OR function. This implies slightly weaker direct product results for all total functions. We prove a similar result for quantum communication protocols computing k instances of the disjointness function. These results imply a time-space tradeoff T²S = ¿(N³) for sorting N items on a quantum computer, which is optimal up to polylog factors. They also give several tight time-space and communication-space tradeoffs for the problems of Boolean matrix-vector multiplication and matrix multiplication.
FOCS	Triangulation and Embedding Using Small Sets of Beacons.	Jon M. Kleinberg,Aleksandrs Slivkins,Tom Wexler	2004	Concurrent with recent theoretical interest in the problem of metric embedding, a growing body of research in the networking community has studied the distance matrix defined by node-to-node latencies in the Internet, resulting in a number of recent approaches that approximately embed this distance matrix into low-dimensional Euclidean space. There is a fundamental distinction, however, between the theoretical approaches to the embedding problem and this recent Internet-related work: in addition to computational limitations, Internet measurement algorithms operate under the constraint that it is only feasible to measure a linear (or near-linear) number of node pairs, and typically in a highly structured way. Indeed, the most common framework for Internet measurements of this type is a beacon-based approach: one chooses uniformly at random a constant number of nodes (ýbeaconsý) in the network, each node measures its distance to all beacons, and one then has access to only these measurements for the remainder of the algorithm. Moreover, beacon-based algorithms are often designed not for embedding but for the more basic problem of triangulation, in which one uses the triangle inequality to infer the distances that have not been measured. Here we give algorithms with provable performance guarantees for beacon-based triangulation and embedding. We show that in addition to multiplicative error in the distances, performance guarantees for beacon-based algorithms typically must include a notion of slack ¿ a certain fraction of all distances may be arbitrarily distorted. For metrics of bounded doubling dimension (which have been proposed as a reasonable abstraction of Internet latencies), we show that triangulation-based reconstruction with a constant number of beacons can achieve multiplicative error 1 + ¿ on a 1 - ¿ fraction of distances, for arbitrarily small constants ¿ and ¿. For this same class of metrics, we give a beacon-based embedding algorithm that achieves constant distortion on a 1- ¿ fraction of distances; this provides some theoretical justification for the success of the recent Global Network Positioning algorithm of Ng and Zhang, and it forms an interesting contrast with lower bounds showing that it is not possible to embed all distances in a doubling metric with constant distortion. We also give results for other classes of metrics, as well as distributed algorithms that require only a sparse set of distances but do not place too much measurement load on any one node.
FOCS	A Simple Linear Time (1+ ) -Approximation Algorithm for k-Means Clustering in Any Dimensions.	Amit Kumar,Yogish Sabharwal,Sandeep Sen	2004	We present the first linear time (1+¿)-approximation algorithm for the k-means problem for fixed k and ¿. Our algorithm runs in O(nd) time, which is linear in the size of the input. Another feature of our algorithm is its simplicity ¿ the only technique involved is random sampling.
FOCS	Private Codes or Succinct Random Codes That Are (Almost) Perfect.	Michael Langberg	2004	"Coding theory adresses the design and analysis of codes that enable communication over noisy channels. Two types of channels that have been extensively considered are the binary symmetric channel and the adversarial channel. In a binary symmetric channel each bit of the sent message is flipped independently with some probability p, implying that the noise imposed by the channel is random in nature where the amount of noise is determined by p. In an adversarial channel the message is treated as a whole, and the noise may be an arbitray (and malicious) function of the message being sent, as long as it does not effect more than a certain fraction (say p) of the bits transmitted. Roughly speaking, any code designed for an adversarial channel can be used on a corresponding binary symmetric channel successsfully, whereas the contrary is not necessarily true. In this work we will present a construction that transforms the best codes for binary symmetric channels into ""codes"" for corresponding adversarial channels. The ""codes"" we present assume that the sender and the receiver of the message have a joint secret random string (which is not known to the channel). These codes are referred to as private codes. Intuitively, this private randomness allows a reduction between the random and adversarial channels. Such a reduction is simple once the size of the joint random string ¿(n log n) (here the codes are a subset of {0, 1}^(n)). In this work we present private codes in which the size of the joint random string is 0(log n). Moreover, we show that our result is tight. Namely, to design private codes that allow communication over adversarial channels that meet the bounds achievable when communicating over binary symmetric channels, an amount of ¿(log n) shared random bits are required. To the best of our knowledge, no prior results of this nature have been presented in the past. As part of our proof we established a connection between list decodable codes and private codes which complements a recent result of Guruswami (CCC'03) on list decoding with side information."
FOCS	Measured Descent: A New Embedding Method for Finite Metrics.	Robert Krauthgamer,James R. Lee,Manor Mendel,Assaf Naor	2004	"We devise a new embedding technique, which we call measured descent, based on decomposing a metric space locally, at varying speeds, according to the density of some probability measure. This provides a refined and unified framework for the two primary methods of constructing Fr¡äechet embeddings for finite metrics, due to J. Bourgain and S. Rao. We prove that any n-point metric space (X, d) embeds in Hilbert space with distortion 0(\sqrt {\log \alpha \chi\cdot \log n}, where \alpha \chiis a geometric estimate on the decomposability of X. An an immediate corollary, we obtain an 0(\sqrt {\log \lambda \chi\cdot \log n} distortion embedding, where \lambda \chi is the doubling constant of X. Since \lambda \chi\leqslant n, this result recovers Bourgain's theorem, but when the metric X is, in a sense, ""low-dimensional,"" improved bounds are achieved. Our embeddings are volume-respecting for subsets of arbitrary size. One consequence is the existence of (k, O(log n)) volume-respecting embeddings for all 1 \leqslant k \leqslant n, which is the best possible, and answers positively a question posed by U. Feige. Our techniques are also used to answer positively a question of Y. Rabinovich, showing that any weighted n-point planar graph embeds in \ell _\infty ^{0(\log n)} with O(1) distortion. The O(log n) bound on the dimension is optimal, and improves upon the previously known bound of O(log² n)."
FOCS	Random Edge Can Be Exponential on Abstract Cubes.	Jirí Matousek,Tibor Szabó	2004	We prove that RANDOM EDGE, the simplex algorithm that always chooses a random improving edge to proceed on, can take a mildly exponential number of steps in the model of abstract objective functions (introduced by Wiliamson Hoke [27] and by Kalai [16] under different names). We define an abstract objective function on the n-dimensional cube for which the algorithm, started at a random vertex, needs at least exp(const · n^1/3) steps with high probability. The best previous lower bound was quadratic. So in order for RANDOM EDGE to succeed in polynomial time, geometry must help.
FOCS	Worst-Case to Average-Case Reductions Based on Gaussian Measures.	Daniele Micciancio,Oded Regev	2004	We show that finding small solutions to random modular linear equations is at least as hard as approximating several lattice problems in the worst case within a factor almost linear in the dimension of the lattice. The lattice problems we consider are the shortest vector problem, the shortest independent vectors problem, the covering radius problem, and the guaranteed distance decoding problem (a variant of the well-known closest vector problem). The approximation factor we obtain is $n \log^{O(1)} n$ for all four problems. This greatly improves on all previous work on the subject starting from Ajtai&rsquo;s seminal paper [Generating hard instances of lattice problems, in Complexity of Computations and Proofs, Quad. Mat. 13, Dept. Math., Seconda Univ. Napoli, Caserta, Italy, 2004, pp. 1-32] up to the strongest previously known results by Micciancio [SIAM J. Comput., 34 (2004), pp. 118-169]. Our results also bring us closer to the limit where the problems are no longer known to be in NP intersect coNP. Our main tools are Gaussian measures on lattices and the high-dimensional Fourier transform. We start by defining a new lattice parameter which determines the amount of Gaussian noise that one has to add to a lattice in order to get close to a uniform distribution. In addition to yielding quantitatively much stronger results, the use of this parameter allows us to simplify many of the complications in previous work. Our technical contributions are twofold. First, we show tight connections between this new parameter and existing lattice parameters. One such important connection is between this parameter and the length of the shortest set of linearly independent vectors. Second, we prove that the distribution that one obtains after adding Gaussian noise to the lattice has the following interesting property: the distribution of the noise vector when conditioning on the final value behaves in many respects like the original Gaussian noise vector. In particular, its moments remain essentially unchanged.
FOCS	Quantum Weak Coin-Flipping with Bias of 0.192.	Carlos Mochon	2004	We present a family of protocols for flipping a coin over a telephone in a quantum mechanical setting. The family contains protocols with n + 2 messages for all n > 1, and asymptotically achieves a bias of 0.192. The case n = 2 is equivalent to the protocol of Spekkens and Rudolph with bias 0.207, which was the best known protocol. The case n = 3 achieves a bias of 0.199, and n = 8 achieves a bias of 0.193. The analysis of the protocols uses Kitaevýs description of coin-flipping as a semidefinite program. We construct an analytical solution to the dual problem which provides an upper bound on the amount that a party can cheat.
FOCS	Shuffling by Semi-Random Transpositions.	Elchanan Mossel,Yuval Peres,Alistair Sinclair	2004	"In the cyclic-to-random shuffle, we are given n cards arranged in a circle. At step k, we exchange the kýth card along the circle with a uniformly chosen random card. The problem of determining the mixing time of the cyclicto- random shuffle was raised by Aldous and Diaconis in 1986. Recently, Mironov used this shuffle as a model for the cryptographic system known as RC4, and proved an upper bound of O(n log n) for the mixing time. We prove a matching lower bound, thus establishing that the mixing time is indeed of order ¿(n log n). We also prove an upper bound of O(n log n) for the mixing time of any ""semi-random transposition shuffle"", i.e., any shuffle in which a random card is exchanged with another card chosen according to an arbitrary (deterministic or random) rule. To prove our lower bound, we exhibit an explicit complex-valued test function which typically takes very different values for permutations arising from few iterations of the cyclic-to-random-shuffle and for uniform random permutations. Perhaps surprisingly, the proof hinges on the fact that the function e^z - 1 has nonzero fixed points in the complex plane. A key insight from our work is the importance of complex analysis tools for uncovering structure in nonreversible Markov chains."
FOCS	Maximum Matchings via Gaussian Elimination.	Marcin Mucha,Piotr Sankowski	2004	We present randomized algorithms for finding maximum matchings in general and bipartite graphs. Both algorithms have running time O(n^\omega), where \omega is the exponent of the best known matrix multiplication algorithm. Since \omega
FOCS	Multilinear-NC neq Multilinear-NC.	Ran Raz	2004	Multilinear-NC neq Multilinear-NC.
FOCS	Dynamic Approximate All-Pairs Shortest Paths in Undirected Graphs.	Liam Roditty,Uri Zwick	2004	We obtain three new dynamic algorithms for the approximate all-pairs shortest paths problem in unweighted undirected graphs: 1. For any fixed ¿ > 0, a decremental algorithm with an expected total running time of Õ(mn), where m is the number of edges and n is the number of vertices in the initial graph. Each distance query is answered in 0(1) worst-case time, and the stretch of the returned distances is at most 1 + ¿ The algorithm uses ¿(n²) space. 2. For any fixed integer k ¿ 1, a decremental algorithm with an expected total running time of Õ(mn). Each query is answered in 0(1) worst-case time, and the stretch of the returned distances is at most 2k - 1. This algorithm uses, however, only 0(m + n^{1 + {1 \mathord{\left/ {\vphantom {1 k}} \right. \kern-\nulldelimiterspace} k}} ) space. It is obtained by dynamizing techniques of Thorup and Zwick. In addition to being more space efficient, this algorithm is also one of the building blocks used to obtain the first algorithm. 3. For any fixed ¿, ¿ > 0 and every t \leqslant m^{{1 \mathord{\left/ {\vphantom {1 {2 - \delta }}} \right. \kern-\nulldelimiterspace} {2 - \delta }}}, a fully dynamic algorithm with an expected amortized update time of Õ(mn/t) and worst-case query time of 0(t). The stretch of the returned distances is at most 1 + ¿. All algorithms can also be made to work on undirected graphs with small integer edge weights. If the largest edge weight is b, then all bounds on the running times are multiplied by b.
FOCS	Dynamic Transitive Closure via Dynamic Matrix Inverse (Extended Abstract).	Piotr Sankowski	2004	We consider dynamic evaluation of algebraic functions such as computing determinant, matrix adjoint, matrix inverse and solving linear system of equations. We show that in the dynamic setup the above problems can be solved faster than evaluating everything from scratch. In the case when rows and columns of the matrix can change we show an algorithm that achieves O(n²) arithmetic operations per update and O(1) arithmetic operations per query. Next, we describe two algorithms, with different tradeoffs, for updating the inverse and determinant when single entries of the matrix are changed. The fastest update for the first tradeoff is 0(n^{1.575} ) arithmetic operations per update and O(n^{0.575} ) arithmetic operations per query. The second tradeoff gives O(n^{1.495} ) arithmetic operations per update and O(n^{1.495} ) arithmetic operations per query. We also consider the case when some number of columns or rows can change. We use dynamic determinant computations to solve the following problems in the dynamic setup: computing the number of spanning trees in a graph and testing if an edge in a graph is contained in some perfect matching. These are the first dynamic algorithms for these problems. Next, with the use of dynamic matrix inverse, we solve fully dynamic transitive closure in general directed graphs. The bounds on arithmetic operations for dynamic matrix inverse translate directly to time bounds for dynamic transitive closure. Thus we obtain the first known algorithm with O(n²) worstcase update time and constant query time and two algorithms for transitive closure in general digraphs with subquadratic update and query times. Our algorithms for transitive closure are randomized with one-sided error. We also consider for the first time the case when the edges incident with a part of vertices of the graph can be changed.
FOCS	Exponentially Many Steps for Finding a Nash Equilibrium in a Bimatrix Game.	Rahul Savani,Bernhard von Stengel	2004	"The Lemke-Howson algorithm is the classical algorithm for the problem NASH of finding one Nash equilibrium of a bimatrix game. It provides a constructive and elementary proof of existence of an equilibrium, by a typical ""directed parity argument"", which puts NASH into the complexity class PPAD. This paper presents a class of bimatrix games for which the Lemke-Howson algorithm takes, even in the best case, exponential time in the dimension d of the game, requiring \Omega ((\theta ^{{3 \mathord{\left/ {\vphantom {3 4}} \right. \kern-\nulldelimiterspace} 4}} )^d ) many steps, where ¿ is the Golden Ratio. The ""parity argument"" for NASH is thus explicitly shown to be inefficient. The games are constructed using pairs of dual cyclic polytopes with 2d suitably labeled facets in d-space."
FOCS	Stochastic Optimization is (Almost) as easy as Deterministic Optimization.	David B. Shmoys,Chaitanya Swamy	2004	"Stochastic optimization problems attempt to model uncertainty in the data by assuming that (part of) the input is specified in terms of a probability distribution. We consider the well-studied paradigm of 2-stage models with recourse: first, given only distributional information about (some of) the data one commits on initial actions, and then once the actual data is realized (according to the distribution), further (recourse) actions can be taken. We give the first approximation algorithms for 2-stage discrete stochastic optimization problems with recourse for which the underlying random data is given by a ""black box"" and no restrictions are placed on the costs in the two stages, based on an FPRAS for the LP relaxation of the stochastic problem (which has exponentially many variables and constraints). Among the range of applications we consider are stochastic versions of the set cover, vertex cover, facility location, multicut (on trees), and multicommodity flow problems."
FOCS	Quantum Speed-Up of Markov Chain Based Algorithms.	Mario Szegedy	2004	We develop a generic metho d for quantizing classical algorithms based on random walks. We show that under certain conditions, the quantum version gives rise to a quadratic speed-up. This is the case, in particular,when the Markov chain is ergodic and its transition matrix is symmetric. This generalizes the celebrated result ofGrover [G96] and a number of more recent results, including the element distinctness result of Ambainis [Amb03] and the result of Ambainis, Kempe and Rivosh [AKR] that computes properties of quantum walks on the d-dimensional torus.Among the consequences is a faster search for multiple marked items. We show that the quantum escape time, just like its classical version, depends on the spectral properties of the transition matrix with the marked rows and columns deleted.
FOCS	An Unconditional Study of Computational Zero Knowledge.	Salil P. Vadhan	2004	We prove a number of general theorems about ZK, the class of problems possessing (computational) zero-knowledge proofs. Our results are unconditional, in contrast to most previous works on ZK, which rely on the assumption that one-way functions exist. We establish several new characterizations of ZK and use these characterizations to prove results such as the following: 1. Honest-verifier ZK equals general ZK. 2. Public-coin ZK equals private-coin ZK. 3. ZK is closed under union. 4. ZK with imperfect completeness equals ZK with perfect completeness. 5. Any problem in ${\bf ZK} \cap {\bf NP}$ can be proven in computational zero knowledge by a ${\bf BPP}^{{\bf NP}}$ prover. 6. ZK with black-box simulators equals ZK with general, non-black-box simulators. The above equalities refer to the resulting class of problems (and do not necessarily preserve other efficiency measures such as round complexity). Our approach is to combine the conditional techniques previously used in the study of ZK with the unconditional techniques developed in the study of SZK, the class of problems possessing statistical zero-knowledge proofs. To enable this combination, we prove that every problem in ZK can be decomposed into a problem in SZK together with a set of instances from which a one-way function can be constructed.
FOCS	Holographic Algorithms (Extended Abstract).	Leslie G. Valiant	2004	"We introduce a new notion of efficient reduction among computational problems. Classical reductions involve gadgets that map local solutions of one problem to local solutions of another in one-to-one, or possibly many-to-one or one-to-many, fashion. Our proposed reductions allow for gadgets with many-to-many correspondences. Their objective is to preserve the sum of the local solutions. Such reductions provide a method of translating a combinatorial problem to a family of finite systems of polynomial equations with integer coefficients such that the number of solutions of the combinatorial problem can be counted in polynomial time if some system in the family has a solution over the complex numbers. We can derive polynomial time algorithms in this way for ten problems for which only exponential time algorithms were known before. General questions about complexity classes are also formulated. If the method is applied to a #P-complete problem then we obtain families of polynomial systems such that the solvability of any one member would imply P^(#P) = NC2."
FOCS	45th Symposium on Foundations of Computer Science (FOCS 2004), 17-19 October 2004, Rome, Italy, Proceedings		2004	45th Symposium on Foundations of Computer Science (FOCS 2004), 17-19 October 2004, Rome, Italy, Proceedings
SODA	Routing and scheduling in multihop wireless networks with time-varying channels.	Matthew Andrews,Lisa Zhang	2004	We study routing and scheduling in multihop wireless networks. When data is transmitted from its source node to its destination node it may go through other wireless nodes as intermediate hops. The data transmission is node constrained, i.e. every node can transmit data to at most one neighboring node per time step. The transmission rates are time varying as a result of the changing wireless channel conditions.In this paper we assume that the data arrivals and transmission rates are governed by an adversary. The power of the adversary is limited by an admissibility condition which forbids the adversary from overloading any wireless node a priori. The node constrained transmission and the time-varying nature of the transmission rates make our model different from and harder than the standard adversarial queueing model which relates to wireline networks.For the case in which the adversary specifies the paths that the data must follow, we design scheduling algorithms that ensure network stability. These algorithms try to give priority to data that is closest to its source node. However, at each time step only a subset of the data queued at a node is eligible for scheduling. One of our algorithms is fully distributed.For the case in which the adversary does not dictate the data paths, we show how to route the data so that the admissibility condition is satisfied. We can then schedule data along the chosen paths using our stable scheduling algorithms. We conclude by discussing the performance of distributed load balancing algorithms for combined routing and scheduling.
SODA	LAND: stretch (1 + epsilon) locality-aware networks for DHTs.	Ittai Abraham,Dahlia Malkhi,Oren Dobzinski	2004	LAND: stretch (1 + epsilon) locality-aware networks for DHTs.
SODA	A general approach to online network optimization problems.	Noga Alon,Baruch Awerbuch,Yossi Azar,Niv Buchbinder,Joseph Naor	2004	We study a wide range of online graph and network optimization problems, focusing on problems that arise in the study of connectivity and cuts in graphs. In a general online network design problem, we have a communication network known to the algorithm in advance. What is not known in advance are the bandwidth or cut demands between nodes in the network. Our results include an O(log m log n) competitive randomized algorithm for the online non-metric facility location and for a generalization of the problem called themulticast problem. In the non-metric facility location m is the number of facilities and n is the number of clients. The competitive ratio is nearly tight. We also present anO(log2 n log k) competitive randomized algorithm for the on-line group Steiner problem in trees and an O(log3 n log k)competitive randomized algorithm for the problem in general graphs, where n is the number of vertices in the graph and k is the number of groups. Finally, we design a deterministic O(log3 n log log n) competitive algorithm for the online multi-cut problem. Our algorithms are based on a unified framework for designing online algorithms for problems involving connectivity and cuts. We first present a general O(log m)-deterministic algorithm for generating fractional solution that satisfies the online connectivity or cut demands, where m is the number of edges in the graph.
SODA	Dynamizing static algorithms, with applications to dynamic trees and history independence.	Umut A. Acar,Guy E. Blelloch,Robert Harper,Jorge L. Vittes,Shan Leung Maverick Woo	2004	We describe a machine model for automatically dynamizing static algorithms and apply it to history-independent data structures. Static programs expressed in this model are dynamized automatically by keeping track of dependences between code and data in the form of a dynamic dependence graph. To study the performance of such automatically dynamized algorithms we present an analysis technique based on trace stability. As an example of the use of the model, we dynamize the Parallel Tree Contraction Algorithm of Miller and Reif to obtain a history-independent data structure for the dynamic trees problem of Sleator and Tarjan.
SODA	Exponential bounds for DPLL below the satisfiability threshold.	Dimitris Achlioptas,Paul Beame,Michael Molloy	2004	For each k &le; 4, we give &tau;k > 0 such that a random k-CNF formula F with n variables and &lfloor;rkn&rfloor; clauses is satisfiable with high probability, but ORDERED-DLL takes exponential time on F with uniformly positive probability. Using results of [2], this can be strengthened to a high probability result for certain natural backtracking schemes and extended to many other DPLL algorithms.
SODA	On the number of rectangular partitions.	Eyal Ackerman,Gill Barequet,Ron Y. Pinter	2004	How many ways can a rectangle be partitioned into smaller ones? We study two variants of this problem: when the partitions are constrained to lie on n given points (no two of which are corectilinear), and when there are no such constraints and all we require is that the number of (non-intersecting) segments is n. In the first case, when the order (permutation) of the points conforms with a certain property, the number of partitions is the (n + 1)st Baxter number, B(n + 1); the number of permutations conforming with the property is the (n - 1)st Schr&ouml;der number; and the number of guillotine partitions is the nth Schr&ouml;der number. In the second case, it is known [22] that the number of partitions and the number of guillotine partitions correspond to the Baxter and Schr&ouml;der numbers, respectively. Our contribution is a bijection between permutations and partitions. Our results provide interesting and new geometric interpretations to both Baxter and Schr&ouml;der numbers and suggest insights regarding the intricacies of the interrelations.
SODA	A characterization of easily testable induced subgraphs.	Noga Alon,Asaf Shapira	2004	Let H be a fixed graph on h vertices. We say that a graph G is induced H-free if it does not contain any induced copy of H. Let G be a graph on n vertices and suppose that at least εn2 edges have to be added to or removed from it in order to make it induced H-free. It was shown in [5] that in this case G contains at least f(ε, h)nh induced copies of H, where 1/f(ε, h) is an extremely fast growing function in 1/ε, that is independent of n. As a consequence, it follows that for every H, testing induced H-freeness with one-sided error has query complexity independent of n. A natural question, raised by the first author in [1], is to decide for which graphs H the function 1/f(ε, H) can be bounded from above by a polynomial in 1/ε. An equivalent question is for which graphs H, can one design a one-sided error property tester for testing induced H-freeness, whose query complexity is polynomial in 1/ε. We settle this question almost completely by showing that, quite surprisingly, for any graph other than the paths of lengths 1,2 and 3, the cycle of length 4, and their complements, no such property tester exists. We further show that a similar result also applies to the case of directed graphs, thus answering a question raised by the authors in [9]. We finally show that the same results hold even in the case of two-sided error property testers. The proofs combine combinatorial, graph theoretic and probabilistic arguments with results from additive number theory.
SODA	Efficient algorithms for bichromatic separability.	Pankaj K. Agarwal,Boris Aronov,Vladlen Koltun	2004	A closed solid body separates one point set from another if it contains the former and the closure of its complement contains the latter. We present a near-linear algorithm for deciding whether two sets of n points in 3-space can be separated by a prism, near-quadratic algorithms for separating by a slab or a wedge, and a near-cubic algorithm for separating by a double-wedge. The latter three algorithms improve the previous best known results by an order of magnitude, while the prism separability algorithm constitutes an improvement of two orders of magnitude.
SODA	Point containment in the integer hull of a polyhedron.	Ernst Althaus,Friedrich Eisenbrand,Stefan Funke,Kurt Mehlhorn	2004	We show that the point containment problem in the integer hull of a polyhedron, which is defined by m inequalities, with coefficients of at most &phis; bits can be solved in time O(m + &phis;) in the two-dimensional case and in expected time O(m + &phis;2 log m) in any fixed dimension. This improves on the algorithm which is based on the equivalence of separation and optimization in the general case and on a direct algorithm (SODA 97) for the two-dimensional case.
SODA	Computing maximally separated sets in the plane and independent sets in the intersection graph of unit disks.	Pankaj K. Agarwal,Mark H. Overmars,Micha Sharir	2004	Let S be a set of n points in R2. Given an integer 1 &le; k &le; n, we wish to find a maximally separated subset I &sube; S of size k; this is a subset for which the minimum among the (k2) pairwise distances between its points is as large as possible. The decision problem associated with this problem is to determine whether there exists I &sube; S, |I| = k, so that all (k2) pairwise distances in I are at least 2, say. This problem can also be formulated in terms of disk-intersection graphs: Let D be the set of unit disks centered at the points of S. The disk-intersection graph G of D connects pairs of disks by an edge if they have nonempty intersection. I is then the set of centers of disks that form an independent set in the graph G. This problem is known to be NP-Complete if k is part of the input.In this paper we first present a linear-time approximation algorithm for any constant k. Next we give O(n4/3polylog(n)) exact algorithms for the cases k = 3 and k = 4. We also present a simpler nO(&radic;k)-time algorithm (as compared with the recent algorithm in [5]) for arbitrary values of k.
SODA	Bipartite roots of graphs.	Lap Chi Lau	2004	Graph H is a root of graph G if there exists a natural number k such that xy &isin; E(G) &harr; dH(x, y) &le; k where dH(x, y) is the length of a shortest path in H from x to y. In such a case, H is a k-th root of G and we write G = Hk and call G the k-th power of H. Motwani and Sudan proved that it is NP-complete to recognize squares of graphs and believed it is also NP-complete to recognize squares of bipartite graphs. In this paper, we show, rather surprisingly, that squares of bipartite graphs can be recognized in polynomial time. Also, we show that counting the number of different bipartite square roots of a graph can be done in polynomial time although this number could be exponential in the size of the input graph. Furthermore, we can generate all bipartite roots of a graph G in time O(max{&Delta;(G) &middot; M, r(G)}) where &Delta;(G) is the maximum degree of G, M is the time complexity to do matrix multiplication, and r(G) is the number of different bipartite square roots of G. By using the tools developed, we are able to give a new and simpler linear time algorithm to recognize squares of trees and a new algorithmic proof that tree square roots, when they exist, are unique up to isomorphism. Finally, we prove the NP-completeness of recognition of cubes of bipartite graphs.
SODA	Complexities for generalized models of self-assembly.	Gagan Aggarwal,Michael H. Goldwasser,Ming-Yang Kao,Robert T. Schweller	2004	"In this paper, we extend Rothemund and Winfree's examination of the tile complexity of tile self-assembly [6]. They provided a lower bound of &Omega;(log N/log log N) on the tile complexity of assembling an N &times; N square for almost all N. Adleman et al. [1] gave a construction which achieves this bound. We consider whether the tile complexity for self-assembly can be reduced through several natural generalizations of the model. One of our results is a tile set of size O(&radic;log N) which assembles an N &times; N square in a model which allows flexible glue strength between non-equal glues (This was independently discovered in [3]). This result is matched by a lower bound dictated by Kolmogorov complexity. For three other generalizations, we show that the &Omega;(log N/log log N) lower bound applies to N &times; N squares. At the same time, we demonstrate that there are some other shapes for which these generalizations allow reduced tile sets. Specifically, for thin rectangles with length N and width k, we provide a tighter lower bound of &Omega;(N(1/k)/k) for the standard model, yet we also give a construction which achieves O(log N/log log N) complexity in a model in which the temperature of the tile system is adjusted during assembly. We also investigate the problem of verifying whether a given tile system uniquely assembles into a given shape, and show that this problem is NP-hard."
SODA	Fault-tolerant gathering algorithms for autonomous mobile robots.	Noa Agmon,David Peleg	2004	This paper studies fault tolerant algorithms for the problem of gathering N autonomous mobile robots. A gathering algorithm, executed independently by each robot, must ensure that all robots are gathered at one point within finite time. It is first observed that most existing algorithms fail to operate correctly in a setting allowing crash failures. Subsequently, an algorithm tolerant against one crash-faulty robot in a system of three or more robots is presented. It is then shown that in an asynchronous environment it is impossible to perform a successful gathering in a 3-robot system with one Byzantine failure. Finally, in a fully synchronous system, an algorithm is provided for gathering N &ge; 3 robots with at most a single faulty robot, and a more general gathering algorithm is given in an N-robot system with up to f faults, where N &ge; 3 f +1.
SODA	On colorings of squares of outerplanar graphs.	Geir Agnarsson,Magnús M. Halldórsson	2004	We investigate the clique number, the chromatic number and the inductiveness (or the degeneracy) of the square G2 of an outerplanar graph G, and bound as a function of the maximum degree &Delta; of G. Our main result is a tight bound of &Delta; for the inductiveness of the square of any outerplanar graph G, when &Delta; &ge; &tau;. This implies that a greedy algorithm yields an optimal coloring of such square graphs, and leads to an exact linear time algorithm that holds for any &Delta;. We then derive optimal upper bounds on the three parameters for outerplanar graphs of smaller degree &Delta; < &tau;, and in the case of chordal outerplanar graphs, classify exactly which graphs have parameters exceeding the absolute minimum. A co-product of the study is a characterization of all strongly simplicial elimination orderings of an arbitrary power of a tree.
SODA	Approximate classification via earthmover metrics.	Aaron Archer,Jittat Fakcharoenphol,Chris Harrelson,Robert Krauthgamer,Kunal Talwar,Éva Tardos	2004	"Given a metric space (X, d), a natural distance measure on probability distributions over X is the earthmover metric. We use randomized rounding of earthmover metrics to devise new approximation algorithms for two well-known classification problems, namely, metric labeling and 0-extension.Our first result is for the 0-extension problem. We show that if the terminal metric is decomposable with parameter &alpha; (e.g., planar metrics are decomposable with &alpha; = O(1)), then the earthmover based linear program (for 0-extension) can be rounded to within an O(&alpha;) factor.Our second result is an O(log n)-approximation for metric labeling, using probabilistic tree embeddings in a way very different from the O(log k)-approximation of Kleinberg and Tardos. (Here, n is the number of nodes, and k is the number of labels.) The key element is rounding the earthmover based linear program (for metric labeling) without increasing the solution's cost, when the input graph is a tree. This rounding method also provides an alternate proof to a result stated in Chekuri et al., that the earthmover based linear program is integral when the input graph is a tree.Our simple and constructive rounding techniques contribute to the understanding of earthmover metrics and may be of independent interest."
SODA	The hyperring: a low-congestion deterministic data structure for distributed environments.	Baruch Awerbuch,Christian Scheideler	2004	"In this paper we study the problem of designing searchable concurrent data structures with performance guarantees that can be used in a distributed environment where data elements are stored in a dynamically changing set of nodes. Searchable data structures are data structures that provide three basic operations: INSERT, DELETE, and SEARCH. In addition to searching for an exact match, we demand that for a data structure to be called ""searchable"", Search also has to be able to search for the closest successor or predecessor of a data item. Such a property has a tremendous advantage over just exact match, because it would allow to implement many data base applications.We are interested in finding a searchable concurrent data structure that has (1) a low degree, (2) requires a small amount of work for INSERT and DELETE operations, and (3) is able to handle concurrent search requests with low congestion and dilation.We present the first deterministic concurrent data structure, called Hyperring, that can fulfill all of these objectives in a polylogarithmic way. In fact, the Hyperring has a degree of O(log n), requires O(log3 n) work for INSERT and DELETE operations, and can handle concurrent search requests to random destinations, one request per node, with congestion and dilation O(log n) w.h.p.Most of the previous solutions for distributed environments are not searchable (in our sense) but only provide exact lookup, and those that are searchable do not have proofs about the congestion caused by concurrent search requests."
SODA	On the diameter of the symmetric group: polynomial bounds.	László Babai,Robert Beals,Ákos Seress	2004	"We address the long-standing conjecture that all permutations have polynomially bounded word length in terms of any set of generators of the symmetric group. The best available bound on the maximum required word length is exponential in n log n. Polynomial bounds on the word length have previously been established for very special classes of generating sets only.In this paper we give a polynomial bound on the word length under the sole condition that one of the generators fix at least 67% of the domain. Words of the length claimed can be found in Las Vegas polynomial time.The proof involves a Markov chain mixing estimate which permits us, apparently for the first time, to break the ""element order bottleneck.""As a corollary, we obtain the following average-case result: for a 1 -- &delta; fraction of the pairs of generators for the symmetric group, the word length is polynomially bounded. It is known that for almost all pairs of generators, the word length is less than exp(&radic;n ln n(1 + o(1)))."
SODA	Simultaneous diophantine approximation with excluded primes.	László Babai,Daniel Stefankovic	2004	Simultaneous diophantine approximation with excluded primes.
SODA	Fast approximate pattern matching with few indels via embeddings.	Mihai Badoiu,Piotr Indyk	2004	Fast approximate pattern matching with few indels via embeddings.
SODA	Almost-Delaunay simplices: nearest neighbor relations for imprecise points.	Deepak Bandyopadhyay,Jack Snoeyink	2004	Delaunay tessellations and Voronoi diagrams capture proximity relationships among sets of points in any dimension. When point coordinates are not known exactly, as in the case of 3D points representing protein atom coordinates, the Delaunay tessellation may not be robust; small perturbations in the coordinates may cause the Delaunay simplices to change. In this paper, we define the almost-Delaunay simplices, derive some of their properties, and give algorithms for computing them, especially for neighbor analysis in three dimensions. We sketch applications in proteins that will be described more fully in a companion paper in biology. http://www.cs.unc.edu/&sim;debug/papers/AlmDel.
SODA	On minimizing the total flow time on multiple machines.	Nikhil Bansal	2004	We consider the problem of minimizing the total flow time on multiple machines with preemption, where the flow time of a job is the time spent since it arrives until it finishes. Our main result is a quasi-polynomial time approximation scheme for a constant number of machines (m). The result also extends to total weighted flow time where either the job weights or the job sizes are polynomially bounded by the number of jobs (n). We also show that the dependence on m cannot be substantially improved. In particular, obtaining an O(1) approximation for the weighted case (even when all weights and sizes are polynomially bounded by n) by an algorithm with running time npolylog(n,m) would imply that NP &sub; DTIME(npolylog(n)).
SODA	New approximability and inapproximability results for 2-dimensional Bin Packing.	Nikhil Bansal,Maxim Sviridenko	2004	We study the 2-dimensional generalization of the classical Bin Packing problem: Given a collection of rectangles of specified size (width, height), the goal is to pack these into minimum number of square bins of unit size. A long history of results exists for this problem and its special cases [3, 14, 10, 18, 9, 1, 15]. Currently, the best known approximation algorithm achieves a guarantee of 1.69 in the asymptotic case (i.e. when the optimum uses a large number of bins) [1]. However, an important open question has been whether 2-dimensional bin packing is essentially similar to the 1-dimensional case in that it admits an asymptotic polynomial time approximation scheme (APTAS) [8, 13] or not? We answer the question in the negative and show that the problem is APX hard in the asymptotic case. On the other hand, we give an asymptotic PTAS for the special case when all the rectangles to be packed are squares (or more generally hypercubes). This improves upon the previous best known guarantee of 1.454 for d = 2 [9] and 2 - (2/3)d for d > 2 [15], and settles the approximability for this special case.
SODA	Windows scheduling as a restricted version of Bin Packing.	Amotz Bar-Noy,Richard E. Ladner,Tami Tamir	2004	"Given is a sequence of n positive integers w1;w2....,wn that are associated with the items 1, 2....n respectively. In the windows scheduling problem, the goal is to schedule all the items (equal length information pages) on broadcasting channels such that the gap between two consecutive appearances of page i on any of the channels is at most wi slots (a slot is the transmission time of one page). In the unit fractions bin packing problem, the goal is to pack all the items in bins of unit size where the size (width) of item i is 1/wi. The optimization objective is to minimize the number of channels or bins. In the off-line setting the sequence is known in advance whereas in the on-line setting the items arrive in order and assignment decisions are irrevocable. Since a page requires at least 1=wi of the channel's bandwidth, it follows that windows scheduling without migration (all broadcasts of a page must be from the same channel) is a restricted version of unit fractions bin packing.Let H = [&Sigma;ni = 1 (1/wi)] be the obvious bandwidth lower bound on the required number of bins (channels). Previously an H + O(ln H) off-line algorithm for the windows scheduling problem was known. This paper presents an H + 1 off-line algorithm to the unit fractions bin packing problem. In the on-line setting, this paper presents an H + O(&radic;H) algorithm to both problems where the one for the unit fractions bin packing problem is simpler. On the other hand, this paper shows that already for the unit fractions bin packing problem, any on-line algorithm must use at least H + &Omega; (ln H) bins."
SODA	Dimension reduction for ultrametrics.	Yair Bartal,Manor Mendel	2004	We prove that an ultrametric on n points can be embedded in ldp with distortion at most 1 + ε, and d = O(ε-2 log n). This bound matches the best known bound for the special case of an equilateral space.
SODA	Randomized -server algorithms for growth-rate bounded graphs.	Yair Bartal,Manor Mendel	2004	The k-server problem is a fundamental online problem where k mobile servers should be scheduled to answer a sequence of requests for points in a metric space as to minimize the total movement cost. While the deterministic competitive ratio is at least k, randomized k-server algorithms have the potential of reaching o(k) competitive ratios. This goal may be approached by using probabilistic metric approximation techniques. This paper gives the first results in this direction obtaining o(k) competitive ratio for a natural class of metric spaces, including d-dimensional grids, and wide range of k. Prior to this work no result of this type was known beyond results for specific metric spaces.
SODA	Lyndon words with a fixed standard right factor.	Frédérique Bassino,Julien Clément,Cyril Nicaud	2004	Lyndon words with a fixed standard right factor.
SODA	Approximate distance oracles for unweighted graphs in Õ(n) time.	Surender Baswana,Sandeep Sen	2004	Let G(V, E) be an undirected weighted graph with |V| = n, |E| = m. Recently Thorup and Zwick introduced a remarkable data-structure that stores all pairs approximate distance information implicitly in o(n2) space, and yet answers any approximate distance query in constant time. They named this data-structure approximate distance oracle because of this feature. Given an integer k < 1, a (2k-1)-approximate distance oracle requires O(kn1+1/k) space and answers a (2k-1)-approximate distance query in O(k) time. Thorup and Zwick showed that a (2k - 1)-approximate distance oracle can be computed in O(kmn1/k) time, and posed the following question : Can (2k - 1)-approximate distance oracle be computed in &Otilde;(n2) time?In this paper, we answer their question in affirmative for unweighted graphs. We present an algorithm that computes (2k -1)-approximate distance oracle for a given unweighted graph in &Otilde;(n2) time. One of the new ideas used in the improved algorithm also leads to the first linear time algorithm for computing an optimal size (2, 1)-spanner of an unweighted graph.
SODA	Reconstructing strings from random traces.	Tugkan Batu,Sampath Kannan,Sanjeev Khanna,Andrew McGregor	2004	We are given a collection of m random subsequences (traces) of a string t of length n where each trace is obtained by deleting each bit in the string with probability q. Our goal is to exactly reconstruct the string t from these observed traces. We initiate here a study of deletion rates for which we can successfully reconstruct the original string using a small number of samples. We investigate a simple reconstruction algorithm called Bitwise Majority Alignment that uses majority voting (with suitable shifts) to determine each bit of the original string. We show that for random strings t, we can reconstruct the original string (w.h.p.) for q = O(1/ log n) using only O(log n) samples. For arbitrary strings t, we show that a simple modification of Bitwise Majority Alignment reconstructs a string that has identical structure to the original string (w.h.p.) for q = O(1/n1/2+ε) using O(1) samples. In this case, using O(n log n) samples, we can reconstruct the original string exactly. Our setting can be viewed as the study of an idealized biological evolutionary process where the only possible mutations are random deletions. Our goal is to understand at what mutation rates, a small number of observed samples can be correctly aligned to reconstruct the parent string.In the process of establishing these results, we show that Bitwise Majority Alignment has an interesting self-correcting property whereby local distortions in the traces do not generate errors in the reconstruction and eventually get corrected.
SODA	Computing equilibria for congestion games with (im)perfect information.	René Beier,Artur Czumaj,Piotr Krysta,Berthold Vöcking	2004	"We study algorithmic questions concerning a basic microeconomic congestion game in which there is a single provider that offers a service to a set of potential customers. Each customer has a particular demand of service and the behavior of the customers is determined by utility functions that are non-increasing in the congestion. Customers decide whether to join or leave the service based on the experienced congestion and the offered prices. Following standard game theory, we assume each customer behaves in the most rational way. If the prices of service are fixed, then such a customer behavior leads to a pure, not necessarily unique Nash equilibrium among the customers. In order to evaluate marketing strategies, the service provider is interested in estimating its revenue under the best and worst customer equilibria. We study the complexity of this problem under different models of information available to the provider.&bull;We first consider the classical model in which the provider has perfect knowledge of the behavior of all customers. We present a complete characterization of the complexity of computing optimal pricing strategies and of computing best and worst equilibria. Basically, we show that most of these problems are inapproximable in the worst case but admit an ""average-case FPAS."" Our average case analysis covers general distributions for customer demands and utility thresholds. We generalize our analysis to robust equilibria in which players change their strategies only when this promises a significant utility improvement.&bull;We extend our analysis to a more realistic model in which the provider has incomplete information. Following the game theoretic framework of Bayesian games introduced by Harsanyi, we assume that the provider is aware of probability distributions describing the behavior of the customers and aims at estimating its expected revenue under best and worst equilibria. Somewhat counterintuitive, we obtain an FPRAS for the equilibria problem in the model with imperfect information although the problem with perfect information is inapproximable under the worst case measures. In particular, the worst case complexity of the considered stochastic equilibria problems increases with the precision of the available knowledge."
SODA	Probabilistic analysis of knapsack core algorithms.	René Beier,Berthold Vöcking	2004	We study the average-case performance of algorithms for the binary knapsack problem. Our focus lies on the analysis of so-called core algorithms, the predominant algorithmic concept used in practice. These algorithms start with the computation of an optimal fractional solution that has only one fractional item and then they exchange items until an optimal integral solution is found. The idea is that in many cases the optimal integral solution should be close to the fractional one such that only a few items need to be exchanged. Despite the well known hardness of the knapsack problem on worst-case instances, practical studies show that knapsack core algorithms can solve large scale instances very efficiently. For example, they exhibit almost linear running time on purely random inputs.In this paper, we present the first theoretical result on the running time of core algorithms that comes close to the results observed in practical experiments. We prove an upper bound of O(npolylog(n)) on the expected running time of a core algorithm on instances with n items whose profits and weights are drawn independently, uniformly at random. A previous analysis on the average-case complexity of the knapsack problem proves a running time of O(n4), but for a different kind of algorithms. The previously best known upper bound on the running time of core algorithms is polynomial as well. The degree of this polynomial, however, is at least a large three digit number. In addition to uniformly random instances, we investigate harder instances in which profits and weights are pairwise correlated. For this kind of instances, we can prove a tradeoff describing how the degree of correlation influences the running time.
SODA	Improved bounds on sorting with length-weighted reversals.	Michael A. Bender,Dongdong Ge,Simai He,Haodong Hu,Ron Y. Pinter,Steven Skiena,Firas Swidan	2004	We study the problem of sorting integer sequences and permutations by length-weighted reversals. We consider a wide class of cost functions, namely f(l) = l&alpha; for all &alpha; &ge; 0, where l is the length of the reversed subsequence. We present tight or nearly tight upper and lower bounds on the worst-case cost of sorting by reversals. Then we develop algorithms to approximate the optimal cost to sort a given input. Furthermore, we give polynomial-time algorithms to determine the optimal reversal sequence for a restricted but interesting class of sequences and cost functions. Our results have direct application in computational biology to the field of comparative genomics.
SODA	Two tricks to triangulate chordal probe graphs in polynomial time.	Anne Berry,Martin Charles Golumbic,Marina Lipshteyn	2004	A graph G = (V,E) is chordal probe if its vertices can be partitioned into two sets P (probes) and N (non-probes) where N is a stable set and such that G can be extended to a chordal graph by adding edges between non-probes. The study of chordal probe graphs was originally motivated as a generalization of the interval probe graphs which occur in applications involving physical mapping of DNA. However, chordal probe graphs also have their own computational biology application as a special case of constructing phylogenies, tree structures which model genetic mutations.We give several characterizations of chordal probe graphs, first in the case of a fixed given partition of the vertices into probes and non-probes, and second in the more general case where no partition is given. In both of these cases, our results are obtained by characterizing superclasses, namely, N-triangulatable graphs and cyclebicolorable graphs, which are first introduced here. We give polynomial time recognition algorithms for each class. The complexity is O (|P||E|), given a partition of the vertices into probes and non-probes, thus also providing a interesting tractible subcase of the chordal graph sandwich problem. If no partition is given in advance, the complexity of our recognition algorithm is O(|V|2|E|).
SODA	Torpid mixing of simulated tempering on the Potts model.	Nayantara Bhatnagar,Dana Randall	2004	Simulated tempering and swapping are two families of sampling algorithms in which a parameter representing temperature varies during the simulation. The hope is that this will overcome bottlenecks that cause sampling algorithms to be slow at low temperatures. Madras and Zheng demonstrate that the swapping and tempering algorithms allow efficient sampling from the low-temperature mean-field Ising model, a model of magnetism, and a class of symmetric bimodal distributions [10]. Local Markov chains fail on these distributions due to the existence of bad cuts in the state space.Bad cuts also arise in the q-state Potts model, another fundamental model for magnetism that generalizes the Ising model. Glauber (local) dynamics and the Swendsen-Wang algorithm have been shown to be prohibitively slow for sampling from the Potts model at some temperatures [1, 2, 6]. It is reasonable to ask whether tempering or swapping can overcome the bottlenecks that cause these algorithms to converge slowly on the Potts model.We answer this in the negative, and give the first example demonstrating that tempering can mix slowly. We show this for the 3-state ferromagnetic Potts model on the complete graph, known as the mean-field model. The slow convergence is caused by a first-order (discontinuous) phase transition in the underlying system. Using this insight, we define a variant of the swapping algorithm that samples efficiently from a class of bimodal distributions, including the mean-field Potts model.
SODA	Compact representations of ordered sets.	Daniel K. Blandford,Guy E. Blelloch	2004	We consider the problem of efficiently representing sets S of size n from an ordered universe U = {0,...,m-1}. Given any ordered dictionary structure (or comparison-based ordered set structure) D that uses O(n) pointers, we demonstrate a simple blocking technique that produces an ordered set structure supporting the same operations in the same time bounds but with O(n log m+n/n) bits. This is within a constant factor of the information-theoretic lower bound. We assume the unit cost RAM model with word size &Omega;(log |U|) and a table of size O(m&alpha; log2 m) bits, for some constant &alpha; > 0. The time bound for our operations contains a factor of 1/&alpha;.We present experimental results for the STL (C++ Standard Template Library) implementation of Red-Black trees, and for an implementation of Treaps. We compare the implementations with blocking and without blocking. The blocking variants use a factor of between 1.5 and 10 less space depending on the density of the set.
SODA	Approximate budget balanced mechanisms with low communication costs for the multicast cost-sharing problem.	Markus Bläser	2004	Approximate budget balanced mechanisms with low communication costs for the multicast cost-sharing problem.
SODA	A new algorithm for normal dominance constraints.	Manuel Bodirsky,Denys Duchier,Joachim Niehren,Sebastian Miele	2004	Dominance constraints are logical descriptions of trees. Efficient algorithms for the subclass of normal dominance constraints were recently proposed. We present a new and simpler graph algorithm solving these constraints more efficiently, in quadratic time per solved form. It also applies to weakly normal dominance constraints as needed for an application to computational linguistics. Subquadratic running time can be achieved employing decremental graph biconnectivity algorithms.
SODA	Competitive analysis of organization networks or multicast acknowledgement: how much to wait?	Carlos Brito,Elias Koutsoupias,Shailesh Vaya	2004	We study, from the competitive analysis perspective, the trade off between communication cost and delay cost (or simply the send-or-wait dilemma) on a hierarchy (rooted tree). The problem is an abstraction of the message aggregation problem on communication networks and the organizational problem in network hierarchies. We consider the most natural variant of the problem, the distributed asynchronous regime, and give tight (within an additive constant) upper and lower bounds of the competitive ratio.We also consider the centralized version of the problem, where we combine the natural rent-to-buy strategy with prediction techniques to achieve the first constant competitive ratio algorithm for any non-trivial class of network topologies.
SODA	The list partition problem for graphs.	Kathie Cameron,Elaine M. Eschen,Chính T. Hoàng,R. Sritharan	2004	We consider the problem of partitioning the vertex-set of a graph into at most k parts A1, A2,..., Ak, where it may be specified that Ai induce a stable set, a clique, or an arbitrary subgraph, and pairs Ai, Aj (i &ne; j) be completely non-adjacent, completely adjacent, or arbitrarily adjacent. This problem is generalized to the list version which specifies for each vertex a list of parts in which the vertex is allowed to be placed. Many well-known graph problems can be formulated as list partition problems: e.g. 3-colourability, clique cutset, stable cutset, homogeneous set, skew partition, and 2-clique cutset. We classify, with the exception of two polynomially equivalent problems, each list partition problem with k = 4 as either solvable in polynomial time or NP-complete. In doing so, we provide polynomial-time algorithms for many problems whose polynomial-time solvability was open, including the list 2-clique cutset problem. This also allows us to classify each list generalized 2-clique cutset problem and list generalized skew partition problem as solvable in polynomial time or NP-complete.
SODA	A deterministic near-linear time algorithm for finding minimum cuts in planar graphs.	Parinya Chalermsook,Jittat Fakcharoenphol,Danupon Nanongkai	2004	We present a simple deterministic O(n log2 n)-time divide-and-conquer algorithm for finding minimum cuts in planar graphs. This can be compared to a randomized algorithm for general graphs by Karger that runs in time O(m log3 n) and also a deterministic algorithm for general graphs by Nagamochi and Ibaraki that runs in time O(mn + n2 log n). We use shortest paths in the dual graphs to partition the problem, and use the relationship between minimum cuts in primal graphs and shortest paths in dual graphs to find minimum cuts that cross the partitions efficiently.
SODA	An optimal randomized algorithm for maximum Tukey depth.	Timothy M. Chan	2004	"We present the first optimal algorithm to compute the maximum Tukey depth (also known as location or halfspace depth) for a non-degenerate point set in the plane. The algorithm is randomized and requires O(n log n) expected time for n data points. In a higher fiexed dimension d &ge; 3, the expected time bound is O(nd-1), which is probably optimal as well. The result is obtained using an interesting variant of the author's randomized optimization technique, capable of solving ""implicit"" linear-programming-type problems; some other applications of this technique are briefly mentioned."
SODA	Non-migratory online deadline scheduling on multiprocessors.	Ho-Leung Chan,Tak Wah Lam,Kar-Keung To	2004	In this paper we consider multiprocessor scheduling with hard deadlines and investigate the cost of eliminating migration in the online setting. Let I be any set of jobs that can be completed by some migratory offline schedule on m processors. We show that I can also be completed by a non-migratory online schedule using m speed-5.828 processors (i.e., processors of 5.828 times faster). This result supplements the previous results that I can also be completed by a non-migratory offline schedule using 6m unit-speed processors [8] or a migratory online schedule using m speed-2 processors [13]. Our result is based on a simple conservative scheduling algorithm called PARK which commits a processor to a job only when the processor has zero commitment before its deadline. A careful analysis of PARK further shows that the processor speed can be reduced arbitrarily close to 1 by exploiting more processors (say, using 16m speed-1.8 processors). PARK also finds application in overloaded systems; it gives the first online non-migratory algorithm that can exploit moderately faster processors to match the performance of any migratory offline algorithm.
SODA	Quantitative stochastic parity games.	Krishnendu Chatterjee,Marcin Jurdzinski,Thomas A. Henzinger	2004	We study perfect-information stochastic parity games. These are two-player nonterminating games which are played on a graph with turn-based probabilistic transitions. A play results in an infinite path and the conflicting goals of the two players are &omega;-regular path properties, formalized as parity winning conditions. The qualitative solution of such a game amounts to computing the set of vertices from which a player has a strategy to win with probability 1 (or with positive probability). The quantitative solution amounts to computing the value of the game in every vertex, i.e., the highest probability with which a player can guarantee satisfaction of his own objective in a play that starts from the vertex.For the important special case of one-player stochastic parity games (parity Markov decision processes) we give polynomial-time algorithms both for the qualitative and the quantitative solution. The running time of the qualitative solution is O(d &middot; m3/2) for graphs with m edges and d priorities. The quantitative solution is based on a linear-programming formulation.For the two-player case, we establish the existence of optimal pure memoryless strategies. This has several important ramifications. First, it implies that the values of the games are rational. This is in contrast to the concurrent stochastic parity games of de Alfaro et al.; there, values are in general algebraic numbers, optimal strategies do not exist, and ε-optimal strategies have to be mixed and with infinite memory. Second, the existence of optimal pure memoryless strategies together with the polynomial-time solution forone-player case implies that the quantitative two-player stochastic parity game problem is in NP &cap; co-NP. This generalizes a result of Condon for stochastic games with reachability objectives. It also constitutes an exponential improvement over the best previous algorithm, which is based on a doubly exponential procedure of de Alfaro and Majumdar for concurrent stochastic parity games and provides only ε-approximations of the values.
SODA	Who says you have to look at the input? The brave new world of sublinear computing.	Bernard Chazelle	2004	Who says you have to look at the input? The brave new world of sublinear computing.
SODA	The Bloomier filter: an efficient data structure for static support lookup tables.	Bernard Chazelle,Joe Kilian,Ronitt Rubinfeld,Ayellet Tal	2004	We introduce the Bloomier filter, a data structure for compactly encoding a function with static support in order to support approximate evaluation queries. Our construction generalizes the classical Bloom filter, an ingenious hashing scheme heavily used in networks and databases, whose main attribute---space efficiency---is achieved at the expense of a tiny false-positive rate. Whereas Bloom filters can handle only set membership queries, our Bloomier filters can deal with arbitrary functions. We give several designs varying in simplicity and optimality, and we provide lower bounds to prove the (near) optimality of our constructions.
SODA	Invadable self-assembly: combining robustness with efficiency.	Ho-Lin Chen,Qi Cheng,Ashish Goel,Ming-Deh A. Huang,Pablo Moisset de Espanés	2004	DNA self-assembly is emerging as a key paradigm for nano-technology, nano-computation, and several related disciplines. In nature, DNA self-assembly is often equipped with explicit mechanisms for both error prevention and error correction. For artificial self-assembly, these problems are even more important since we are interested in assembling large systems with great precision. So far, theoretical studies of DNA self-assembly have primarily focused on the efficiency of the assembly process in terms of the program size and the running time. In this paper, we perform a preliminary study of algorithms for DNA self-assembly that are both robust and efficient.Strand invasion is an important error-correction mechanism observed in several natural self-assembling systems. We first define invadable self-assemblies as self-assembling systems which can effectively use the strand invasion mechanism for error-correction. We then show that O(log2 n/ log log n) tiles are sufficient to assemble an n &times; n square in this model. The running time of our system is &Otilde; (n). We obtain our result by growing a counter which simulates Chinese remaindering. The running time and the program size of our invadable system are within polylogarithmic factors of known lower bounds for general systems, i.e. the efficiency penalty for obtaining robustness is small in our model. We also show how to simulate an arbitrary Turing machine using an invadable self-assembly system.
SODA	Constructing finite field extensions with large order elements.	Qi Cheng	2004	In this paper, we present an algorithm that, given a fixed prime power $q$ and a positive integer $N$, finds an integer $n \in [N, 2qN]$ and an element $\alpha \in \mbox{\bf F}_{q^n}$ of order greater than $ 5.8^{n / \log_q n}$, in time polynomial in $N$. We present another algorithm that finds an integer $n \in [N, N+O(N^{0.77})]$ and an element $\alpha \in \mbox{\bf F}_{q^n}$ of order at least $ 5.8^{\sqrt{n}}$, in time polynomial in $N$. Our result is inspired by the recent AKS primality testing algorithm [M. Agrawal, N. Kayal, and N. Saxena, Ann. of Math. (2), 160 (2004), pp. 781-793] and the subsequent improvements [P. Berrizbeitia, Math. Comp., 74 (2005), pp. 2043-2059, Q. Cheng, in Proceedings of the 23rd Annual International Cryptology Conference (CRYPTO 2003), D. Boneh, ed., Lecture Notes in Comput. Sci. 2729, Springer-Verlag, Berlin, 2003, pp. 338-348, D. J. Bernstein, Math. Comp., 76 (2007), pp. 389-403].
SODA	On finding a guard that sees most and a shop that sells most.	Otfried Cheong,Alon Efrat,Sariel Har-Peled	2004	We present a near-quadratic time algorithm that computes a point inside a simple polygon P having approximately the largest visibility polygon inside P, and near-linear time algorithm for finding the point that will have approximately the largest Voronoi region when added to an n-point set. We apply the same technique to find the translation that approximately maximizes the area of intersection of two polygonal regions in near-quadratic time.
SODA	A determinant-based algorithm for counting perfect matchings in a general graph.	Steve Chien	2004	"We present a simple estimator for the number of perfect matchings in a general (non-bipartite) graph. Our estimator requires O(ε-23n/2) trials to obtain a (1 &plusmn; ε)-approximation of the correct value with high probability on a graph with 2n vertices in the worst case, and only a polynomial number (O(ε-2n&omega;(n)) of trials on random graphs, where &omega;(n) is any function tending to infinity.Our algorithm is based on the following idea: For any graph G, construct its associated Tutte matrix T, and derive a random matrix B from it by replacing each variable in T with &plusmn;1 uniformly at random; then output det B. This estimator is a natural generalization of the Godsil--Gutman estimator for matchings in a bipartite graph, and our analysis of its performance on random graphs borrows generously from Frieze and Jerrum's analysis of a similar estimator for bipartite graphs."
SODA	The wake-up problem in multi-hop radio networks.	Marek Chrobak,Leszek Gasieniec,Dariusz R. Kowalski	2004	We study the problem of waking up a collection of n processors connected by a multi-hop ad-hoc ratio network with unknown topology, no access to a global clock, and no collision detection mechanism available. Each node in the network wakes-up spontaneously, or it is activated by receiving a wake-up signal from another node. All active nodes transmit the wake-up signals according to a given protocol Q. The running time of is the number of steps counted from the first spontaneous wake-up, until all nodes become activated.We provide two protocols for this problem. The first one is a deterministic protocol with running time O(n5/3Log n). Our protocol is based on a novel concept of a rotation-tolerant selector to which we refer as a synchronizer. The second protocol is randomized, and its expected running time is O(Dlog2n), where D is the diameter of the network.Subsequently we show how to employ our wake-up protocols to solve two other communication primitives: leader election and clock synchronization.
SODA	Efficient estimation algorithms for neighborhood variance and other moments.	Edith Cohen,Haim Kaplan	2004	The neighborhood variance problem is as follows. Given a (directed or undirected) graph with values associated with each node, compute a data structure that for any given node v and r &ge; 0, would quickly produce an estimate of the variance of all values of nodes that lie within distance r from v. The problem can be generalized to other moment functions and to arbitrary distance-dependent decay.These problems are motivated by applications where the relevance of a measurement observed (or data present) at a certain location decreases with its distance, and thus the aggregate value varies by location. The centralized version of the problem is motivated by applications to query processing on graphical databases. The distributed version of the problem falls in a model we recently introduced for spatially decaying aggregation and is motivated by sensor or p2p networks.We present novel algorithms for the centralized and distributed versions of the problem. Our algorithms are nearly optimal, the centralized version requires &Otilde;(m) time and the distributed version requires polylogarithmic communication per node or edge (depending on assumptions).
SODA	An improved data stream algorithm for frequency moments.	Don Coppersmith,Ravi Kumar	2004	We present a simple, one-pass, &Otilde;(&radic;n)-space data stream algorithm for approximating the third frequency moment. This is the first improvement to the &Otilde;(n2/3)-space data stream algorithm of Alon, Matias, and Szegedy [AMS99]. the current known lower bound for this problem is &Omega;(n1/3) [BJKS02a].Our algorithm can also be generalized to an &Otilde;(n1-1/(k-1))-space data stream algorithm for approximating the k-th frequency moment. Besides improving the &Otilde;(n1--1/k)-space upper bound [AMS99], our algorithm beats the &Omega;(n1--1/k)-sampling lower bound [BKS01] for this problem.Our method suggests a unified perspective of space-efficient data stream algorithms for all frequency moments.
SODA	Approximation schemes for multidimensional packing.	José R. Correa,Claire Kenyon	2004	We consider a classic multidimensional generalization of the bin packing problem, namely, packing d-dimensional rectangles into the minimum number of unit cubes. Our two results are: an asymptotic polynomial time approximation scheme for packing d-dimensional cubes into the minimum number of unit cubes and a polynomial time algorithm for packing rectangles into at most OPT bins whose sides have length (1 + ε), where OPT denotes the minimum number of unit bins required to pack the rectangles. Both algorithms also achieve the best possible additive constant term. For cubes, this settles the approximability of the problem and represents a significant improvement over the previous best known asymptotic approximation factor of 2 - (2/3)d + ε. For rectangles, this contrasts with the currently best known approximation factor of 1.691....
SODA	Approximation schemes for minimum 2-edge-connected and biconnected subgraphs in planar graphs.	Artur Czumaj,Michelangelo Grigni,Papa Sissokho,Hairong Zhao	2004	Given an undirected graph, finding either a minimum 2-edge-connected spanning subgraph or a minimum 2-vertex-connected (biconnected) spanning subgraph is MaxSNP-hard. We show that for planar graphs, both problems have a polynomial time approximation scheme (PTAS) with running time nO(1/ε), where n is the graph size and ε is the relative error allowed.When the planar graph has edge costs, we approximately solve the analogous min-cost subgraph problems in time nO(&gamma;/ε), where &gamma; is the ratio of the total edge cost to the optimum solution cost.
SODA	An exact subexponential-time lattice algorithm for Asian options.	Tian-Shyr Dai,Yuh-Dauh Lyuu	2004	Asian options are path-dependent derivatives. How to price them efficiently and accurately has been a long-standing research and practical problem. Asian options can be priced on the lattice. But only exponential-time algorithms are currently known if such options are to be priced on a lattice without approximation. Although efficient approximation methods are available, most of them lack accuracy guarantees. This paper proposes a novel lattice for pricing Asian options. The resulting exact pricing algorithm runs in subexponential time. This is the first exact lattice algorithm to break the exponential-time barrier. Because this lattice converges to the continuous-time stock price process, the proposed algorithm is guaranteed to converge to the desired continuous-time option value.
SODA	Models of greedy algorithms for graph problems.	Sashka Davis,Russell Impagliazzo	2004	"Borodin, Nielsen, and Rackoff ([5]) gave a model of greedy-like algorithms for scheduling problems and [1] extended their work to facility location and set cover problems. We generalize their notion to include other optimization problems, and apply the generalized framework to graph problems. Our goal is to define an abstract model that captures the intrinsic power and limitations of greedy algorithms for various graph optimization problems. We prove bounds on the approximation ratio achievable by such algorithms for basic graph problems such as shortest path, vertex cover, and others. Shortest path is an example of a problem where no algorithm in the FIXED priority model can achieve any approximation ratio (even one dependent on the graph size), but for which the well-known Dijkstra's algorithm shows that an ADAPTIVE priority algorithm can be optimal. We also prove that the approximation ratio for vertex cover achievable by ADAPTIVE priority algorithms is exactly 2. Here, a new lower bound matches the known upper bounds ([8])."
SODA	Subexponential parameterized algorithms on graphs of bounded-genus and -minor-free graphs.	Erik D. Demaine,Fedor V. Fomin,Mohammad Taghi Hajiaghayi,Dimitrios M. Thilikos	2004	"We introduce a new framework for designing fixed-parameter algorithms with subexponential running time---2O(&radic;k)nO(1). Our results apply to a broad family of graph problems, called bidimensional problems, which includes many domination and covering problems such as vertex cover, feedback vertex set, minimum maximal matching, dominating set, edge dominating set, clique-transversal set, and many others restricted to bounded-genus graphs. Furthermore, it is fairly straightforward to prove that a problem is bidimensional. In particular, our framework includes as special cases all previously known problems to have such subexponential algorithms. Previously, these algorithms applied to planar graphs, single-crossing-minor-free graphs, and map graphs; we extend these results to apply to bounded-genus graphs as well. In a parallel development of combinatorial results, we establish an upper bound on the treewidth (or branchwidth) of a bounded-genus graph that excludes some planar graph H as a minor. This bound depends linearly on the size |V (H)| of the excluded graph H and the genus g(G) of the graph G, and applies and extends the graphminors work of Robertson & Seymour.Building on these results, we develop subexponential fixedparameter algorithms for dominating set, vertex cover, and set cover in any class of graphs excluding a fixed graph H as a minor. In particular, this general category of graphs includes planar graphs, bounded-genus graphs, single-crossing-minor-free graphs, and any class of graphs that is closed under taking minors. Specifically, the running time is 2O(&radic;k)nh, where h is a constant depending only on H, which is polynomial for k = O(log2n). We introduce a general approach for developing algorithms on H-minor-free graphs, based on structural results about H-minor-free graphs at the heart of Robertson & Seymour's graph-minors work. We believe this approach opens the way to further development for problems on H-minor-free graphs."
SODA	Equivalence of local treewidth and linear local treewidth and its algorithmic applications.	Erik D. Demaine,Mohammad Taghi Hajiaghayi	2004	We solve an open problem posed by Eppstein in 1995 [14, 15] and re-enforced by Grohe [16, 17] concerning locally bounded treewidth in minor-closed families of graphs. A graph has bounded local treewidth if the subgraph induced by vertices within distance r of any vertex has treewidth bounded by a function of r (not n). Eppstein characterized minor-closed families of graphs with bounded local treewidth as precisely minor-closed families that minor-exclude an apex graph, where an apex graph has one vertex whose removal leaves a planar graph. In particular, Eppstein showed that all apex-minor-free graphs have bounded local treewidth, but his bound is doubly exponential in r, leaving open whether a tighter bound could be obtained. We improve this doubly exponential bound to a linear bound, which is optimal. In particular, any minor-closed graph family with bounded local treewidth has linear local treewidth. Our bound generalizes previously known linear bounds for special classes of graphs proved by several authors. As a consequence of our result, we obtain substantially faster polynomial-time approximation schemes for a broad class of problems in apex-minor-free graphs, improving the running time from 222O(1/ε) nO(1) to 2O(1/ε)nO(1).
SODA	Retroactive data structures.	Erik D. Demaine,John Iacono,Stefan Langerman	2004	We introduce a new data structuring paradigm in which operations can be performed on a data structure not only in the present but also in the past. In this new paradigm, called retroactive data structures, the historical sequence of operations performed on the data structure is not fixed. The data structure allows arbitrary insertion and deletion of operations at arbitrary times, subject only to consistency requirements. We initiate the study of retroactive data structures by formally defining the model and its variants. We prove that, unlike persistence, efficient retroactivity is not always achievable, so we go on to present several specific retroactive data structures.
SODA	Interpolation search for non-independent data.	Erik D. Demaine,Thouis R. Jones,Mihai Patrascu	2004	"We define a deterministic metric of ""well-behaved data"" that enables searching along the lines of interpolation search. Specifically, define &Delta; to be the ratio of distances between the farthest and nearest pair of adjacent elements. We develop a data structure that stores a dynamic set of n integers subject to insertions, deletions, and predecessor/successor queries in O(lg &Delta;) time per operation. This result generalizes interpolation search and interpolation search trees smoothly to nonrandom (in particular, non-independent) input data. In this sense, we capture the amount of ""pseudorandomness"" required for effective interpolation search."
SODA	Experimental analysis of dynamic all pairs shortest path algorithms.	Camil Demetrescu,Stefano Emiliozzi,Giuseppe F. Italiano	2004	We present the results of an extensive computational study on dynamic algorithms for all pairs shortest path problems. We describe our implementations of the recent dynamic algorithms of King [18] and of Demetrescu and Italiano [7], and compare them to the dynamic algorithm of Ramalingam and Reps [25] and to static algorithms on random, real-world and hard instances. Our experimental data suggest that some of the dynamic algorithms and their algorithmic techniques can be really of practical value in many situations.
SODA	Matrix rounding and approximation.	Benjamin Doerr	2004	Matrix rounding and approximation.
SODA	A maiden analysis of Longest Wait First.	Jeff Edmonds,Kirk Pruhs	2004	We consider server scheduling strategies to minimize average flow time in a multicast pull system where data items have uniform size. The algorithm Longest Wait First (LWF) always services the page where the aggregate waiting times of the outstanding requests for that page is maximized. We provide the first non-trivial analysis of the worst case performance of LWF. On the negative side, we show that LWF is not s-speed O(1)-competitive for s < 1+&radic;5/2. On the positive side, we show that LWF is 6-speed O(1)-competitive.
SODA	A faster distributed protocol for constructing a minimum spanning tree.	Michael Elkin	2004	"This paper studies the problem of constructing a minimum-weight spanning tree (MST) in a distributed network. This is one of the most important problems in the area of distributed computing. There is a long line of gradually improving protocols for this problem, and the state of the art today is a protocol with running time O(&and;(G) + &radic;n log* n) due to Kutten and Peleg [KP95], where &and;(G) denotes the diameter of the graph G. Peleg and Rubinovich [PR99] have shown that (&radic;n) time is required for constructing MST even on graphs of small diameter, and claimed that their result ""establishes the asymptotic near-optimality"" of the protocol of [KP95].In this paper we refine this claim, and devise a protocol that constructs the MST in &Otilde;(&mu;(G = w + &radic;n) rounds, where &mu;(G,&mu;) is the MST-radius of the graph. The ratio between the diameter and the MST-radius may be as large as &Theta;(n), and, consequently, on some inputs our protocol is faster than the protocol of [KP95] by a factor of (&radic;n). Also, on every input, the running time of our protocol is never greater than twice the running time of the protocol of [KP95].As part of our protocol for constructing an MST, we develop a protocol for constructing neighborhood covers with a drastically improved running time. The latter result may be of independent interest."
SODA	Frugality in path auctions.	Edith Elkind,Amit Sahai,Kenneth Steiglitz	2004	We consider the problem of picking (buying) an inexpensive s -- t path in a graph where edges are owned by independent (selfish) agents, and the cost of an edge is known to its owner only. We study the problem of finding frugal mechanisms for this task, i.e. we investigate the payments the buyer must make in order to buy a path.First, we show that any mechanism with (weakly) dominant strategies (or, equivalently, any truthful mechanism) for the agents can force the buyer to make very large payments. Namely, for every such mechanism, the buyer can be forced to pay c(P) + 1/2k(c(Q) -- c(P)), where c(P) is the cost of the shortest path, c(Q) is the cost of the second-shortest path, and k is the number of edges in P. This extends the previous work of Archer and Tardos [1], who showed a similar lower bound for a subclass of truthful mechanisms called min-function mechanisms. Our lower bounds have no such limitations on the mechanism.Motivated by this lower bound, we study mechanisms for this problem providing Bayes-Nash equilibrium strategies for the agents. In this class, we identify the optimal mechanism with regard to total payment. We then demonstrate a separation in terms of average overpayments between the classical VCG mechanism and the optimal mechanism showing that under various natural distributions of edge costs, the optimal mechanism pays at most logarithmic factor more than the actual cost, whereas VCG pays &radic;k times the actual cost. On the other hand, we also show that the optimal mechanism does incur at least a constant factor overpayment in natural distributions of edge costs. Since our mechanism is optimal, this gives a lower bound on all mechanisms with Bayes--Nash equilibria.
SODA	Approximating Minimum Max-Stretch spanning Trees on unweighted graphs.	Yuval Emek,David Peleg	2004	Given a graph G and a spanning tree T of G, we say that T is a tree t-spanner of G if the distance between every pair of vertices in T is at most t times their distance in G. The problem of finding a tree t-spanner minimizing t is referred to as the Minimum Max-Stretch spanning Tree (MMST) problem. This paper concerns the MMST problem on unweighted graphs. The problem is known to be NP-hard, and the paper presents an O(log n) approximation algorithm for it.
SODA	Quasiconvex analysis of backtracking algorithms.	David Eppstein	2004	We consider a class of multivariate recurrences frequently arising in the worst case analysis of Davis-Putnam-style exponential time backtracking algorithms for NP-hard problems. We describe a technique for proving asymptotic upper bounds on these recurrences, by using a suitable weight function to reduce the problem to that of solving univariate linear recurrences; show how to use quasiconvex programming to determine the weight function yielding the smallest upper bound; and prove that the resulting upper bounds are within a polynomial factor of the true asymptotics of the recurrence. We develop and implement a multiple-gradient descent algorithm for the resulting quasiconvex programs, using a real-number arithmetic package for guaranteed accuracy of the computed worst case time bounds.
SODA	Testing bipartiteness of geometric intersection graphs.	David Eppstein	2004	"We show how to test the bipartiteness of an intersection graph of n line segments or simple polygons in the plane, or of balls in Rd, in time O(n log n). More generally we find subquadratic algorithms for connectivity and bipartiteness testing of intersection graphs of a broad class of geometric objects. For unit balls in Rd, connectivity testing has equivalent randomized complexity to construction of Euclidean minimum spanning trees, and for line segments in the plane connectivity testing has the same lower bounds as Hopcroft's problem; therefore, for these problems, connectivity is unlikely to be solved as efficiently as bipartiteness. For line segments or planar disks, testing k-colorability of intersection graphs for k > 2 is NP-complete."
SODA	Optimal online bounded space multidimensional packing.	Leah Epstein,Rob van Stee	2004	We solve an open problem in the literature by providing an online algorithm for multidimensional bin packing that uses only bounded space. To achieve this, we introduce a new technique for classifying the items to be packed. We show that our algorithm is optimal among bounded space algorithms for any dimension d > 1. Its asymptotic performance ratio is (II&infin;)d, where II&infin; &asymp; 1:691 is the asymptotic performance ratio of the one-dimensional algorithm HARMONIC. A modified version of this algorithm for the case where all items are hypercubes is also shown to be optimal. Its asymptotic performance ratio is sublinear in d.Additionally, for the special case of packing squares in two-dimensional bins, we present a new unbounded space online algorithm with asymptotic performance ratio of at most 2.271. We also present an approximation algorithm for the offline problem with approximation ratio of 16/11.
SODA	Structural and algorithmic aspects of massive social networks.	Stephen Eubank,V. S. Anil Kumar,Madhav V. Marathe,Aravind Srinivasan,Nan Wang	2004	We study the algorithmic and structural properties of very large, realistic social contact networks. We consider the social network for the city of Portland, Oregon, USA, developed as a part of the TRANSIMS/EpiSims project at the Los Alamos National Laboratory. The most expressive social contact network is a bipartite graph, with two types of nodes: people and locations; edges represent people visiting locations on a typical day. Three types of results are presented. (i) Our empirical results show that many basic characteristics of the dataset are well-modeled by a random graph approach suggested by Fan Chung Graham and Lincoln Lu (the CL-model), with a power-law degree distribution. (ii) We obtain fast approximation algorithms for computing basic structural properties such as clustering coefficients and shortest paths distribution. We also study the dominating set problem for such networks; this problem arose in connection with optimal sensor-placement for disease-detection. We present a fast approximation algorithm for computing near-optimal dominating sets. (iii) Given the close approximations provided by the CL-model to our original dataset and the large data-volume, we investigate fast methods for generating such random graphs. We present methods that can generate such a random network in near-linear time, and show that these variants asymptotically share many key features of the CL-model, and also match the Portland social network.The structural results have been used to study the impact of policy decisions for controlling large-scale epidemics in urban environments.
SODA	Optimally scheduling video-on-demand to minimize delay when server and receiver bandwidth may differ.	William S. Evans,David G. Kirkpatrick	2004	We establish tight bounds on the intrinsic cost (either minimizing delay d for fixed server and receiver bandwidths, or minimizing server bandwidth for fixed delay and receiver bandwidth) of broadcasting a movie of length m over a channel of bandwidth S in such a way that a receiver (with bandwidth R), starting at an arbitrary time t, can download the movie so that it can begin playback after a delay of at most d time units.Our bounds are realized by a simple abstract protocol that partitions the movie into a fixed number of segments, partitions the server bandwidth into an equivalent number of equal bandwidth subchannels, and broadcasts each segment repeatedly on its flown subchannel. This protocol can be implemented as a concrete discrete protocol in which movie information is packaged into discrete fixed length packets using only a modest overhead (measured in terms of increased delay or server bandwidth).Our primary contribution is a lower bound on the required delay that applies in a very general model of communication. This lower bound matches the behaviour of our abstract protocol in the limit as the number of segments approaches infinity. We are also able to relate its behaviour to arbitrary protocols that have a fixed number of segments.
SODA	Output-sensitive construction of the union of triangles.	Eti Ezra,Micha Sharir	2004	We present an efficient algorithm for the following problem: Given a collection T = {&Delta;1.....,&Delta;n} of n triangles in the plane, such that there exists a subset S &sub; T (unknown to us), of &cup;&Delta; &isin; S &Delta; = &cup;&Delta;&Delta;&isin;T&Delta; n triangles, such that &zeta; &laquo; construct efficiently the union of the triangles in T. We show that this problem can be solved in subquadratic time. In our solution, we use the approximate Disjoint-Cover (DC) algorithm, presented as a heuristics in [9]. We present a detailed implementation of this method, which combines a variety of techniques related to range-searching in two dimensions. We provide a rigorous analysis of its performance in the above setting, showing that it does indeed run in subquadratic time (for a reasonable range of &zeta;).
SODA	Minimizing the stabbing number of matchings, trees, and triangulations.	Sándor P. Fekete,Marco E. Lübbecke,Henk Meijer	2004	"The (axis-parallel) stabbing number of a given set of line segments is the maximum number of segments that can be intersected by any one (axis-parallel) line. We investigate problems of finding perfect matchings, spanning trees, or triangulations of minimum stabbing number for a given set of points. The complexity of these problems has been a long-standing open problem; in fact, it is one of the original 30 outstanding open problems in computational geometry on the list by Demaine, Mitchell, and O'Rourke.We show that minimum stabbing problems are NP-complete. We also show that an iterated rounding technique is applicable for matchings and spanning trees of minimum stabbing number by showing that there is a polynomially solvable LP-relaxation that has fractional solutions with at least one heavy edge. This suggests constant-factor approximations. Our approach uses polyhedral methods that are related to another open problem (from a combinatorial optimization list), in combination with geometric properties. We also demonstrate that the resulting techniques are practical for actually solving problems with up to several hundred points optimally or near-optimally."
SODA	Compression boosting in optimal linear time using the Burrows-Wheeler Transform.	Paolo Ferragina,Giovanni Manzini	2004	"In this paper we provide the first compression booster that turns a zeroth order compressor into a more effiective k-th order compressor without any loss in time efficiency. More precisely, let A be an algorithm that compresses a string s within &lambda;|s|H*0(s)+&mu; bits of storage in O(T (|s|)) time, where H*0(s) is the zeroth order entropy of the string s. Our booster improves A by compressing s within &lambda;|s|H*0(S) + log2 |s| + gk bits still using O(T (|s|)) time, where H*k(s) is the k-th order entropy of s.The idea of a ""compression booster"" has been very recently introduced by Giancarlo and Sciortino in [7]. They combined the Burrows-Wheeler Transform [3] with dynamic programming and achieved our same compression bound but with running time O(T (|s|)) + &Omega;(|s|2). We start from the same premises of [7], but instead of using dynamic programming we design a linear time optimization algorithm based on novel structural properties of the Burrows-Wheeler Transform."
SODA	The number of bit comparisons used by Quicksort: an average-case analysis.	James Allen Fill,Svante Janson	2004	"The analyses of many algorithms and data structures (such as digital search trees) for searching and sorting are based on the representation of the keys involved as bit strings and so count the number of bit comparisons. On the other hand, the standard analyses of many other algorithms (such as Quicksort) are performed in terms of the number of key comparisons. We introduce the prospect of a fair comparison between algorithms of the two types by providing an averagecase analysis of the number of bit comparisons required by Quicksort. Counting bit comparisons rather than key comparisons introduces an extra logarithmic factor to the asymptotic average total. We also provide a new algorithm, ""BitsQuick"", that reduces this factor to constant order by eliminating needless bit comparisons."
SODA	A fast approximation scheme for fractional covering problems with variable upper bounds.	Lisa Fleischer	2004	We present the first combinatorial approximation scheme for mixed positive packing and covering linear programs that yields a pure approximation guarantee. Our algorithm returns solutions that simultaneously satisfy general positive covering constraints and packing constraints that are variable upper bounds. The returned solution has positive linear objective function value at most 1 + ε times the optimal value.Our approximation scheme is based on Lagrangian-relaxation methods. Previous such approximation schemes for mixed packing and covering problems does not simultaneously satisfy packing and covering constraints exactly. We show how to exactly satisfy general positive covering constraints simultaneously with variable upper bounds.A natural set of problems that our work addresses are linear programs for various network design problems: generalized Steiner network, vertex connectivity, directed connectivity, capacitated network design, group Steiner forest. These are all NP-hard problems for which there are approximation algorithms that round the solution to the corresponding linear program. Solving the linear program is often the computational bottleneck in these problems, and thus a fast approximation scheme for the LP relaxation means faster approximation algorithms.For the special case of survivable network design, we introduce a new modification of the push-relabel maximum flow algorithm that allows us to perform each iteration in amortized O(m + n log n) time, instead of one maximum flow per iteration that is implied by the straight forward adaptation of our general algorithm. (m is the number of edges and n is the number of vertices in the network.) In conjunction with an observation that reduces the number of iterations to {log n for f0} constraint matrices, the modification allows us to obtain an algorithm that is faster than existing exact or approximate algorithms by a factor of at least O(m) and by a factor of O(m log n) if the number of demand pairs is &Omega;(n).
SODA	Proximity Mergesort: optimal in-place sorting in the cache-oblivious model.	Gianni Franceschini	2004	An algorithm performs its operations in-place if it uses O(1) extra locations of main memory besides those containing the input entries. An algorithm is cache-oblivious if it is not conscious of any parameter of the memory hierarchy (M, the size of cache memory, and B, the size of the minimal contiguous block of information that can be transferred between the cache and the main memory). Hence, it cannot directly exploit these parameters to reach the optimality. In the cache-oblivious model the complexity is measured with two criteria: the work complexity, which is the standard complexity in the RAM model, and the cache complexity, which is the total number of block transfers (cache misses) incurred during the computation.The contribution of this paper is twofold. We present the first sorting algorithm that is optimal in both work and cache complexity in the cache-oblivious model and that operates in-place. Furthermore, we introduce a new approach to the sorting problem in the cache-oblivious model.
SODA	Special edges, and approximating the smallest directed -edge connected spanning subgraph.	Harold N. Gabow	2004	"We give two approximation algorithms for finding the smallest k-edge connected spanning subgraph of a digraph. For multidigraphs we achieve performance ratio 2 - 1/3k. This is the first known ratio strictly less than 2. For simple digraphs the best known approximation algorithm is due to Cheriyan and Thurimella. We improve their analysis of the number of ""special edges"" of a simple digraph. This improves the performance ratio of their algorithm for simple digraphs from 1 + 4/&radic;k to slightly more than 1 + &radic;2/k, for k &ge; 15. Our analysis of the number of special edges is tight for k &ge; 15. For 5 < k < 15 our improved approximation ratio is 1 + 5/k."
SODA	Finding a long directed cycle.	Harold N. Gabow,Shuxin Nie	2004	Consider a digraph with n vertices. For any fixed value k, we present linear- and almost-linear-time algorithms to find a cycle of length &ge; k, if one exists. We also find a cycle that has length &ge; log n/log log n in polynomial time, if one exists. Under an appropriate complexity assumption it is known to be impossible to improve this guarantee by more than a log log n factor. Our approach is based on depth-first search.
SODA	Slow mixing of Glauber dynamics for the hard-core model on the hypercube.	David Galvin,Prasad Tetali	2004	For &lambda; > 0, let &pi;&lambda; be the probability measure on the independent sets of the hypercube {0,1}d in which I is chosen with probability proportional to &lambda;|I|. We study the Glauber dynamics, or single-site-update Markov chain, whose stationary distribution is &pi;&lambda;, and show that for values of &lambda; tending to 0 as d grows, the convergence to stationarity is exponentially slow in the volume of the cube. The proof combines a conductance argument with combinatorial enumeration methods.
SODA	Linear phase transition in random linear constraint satisfaction problems.	David Gamarnik	2004	"Our model is a generalized linear programming relaxation of a much studied random K-SAT problem. Specifically, a set of linear constraints C on K variables is fixed. From a pool of n variables, K variables are chosen uniformly at random and a constraint is chosen from C also uniformly at random. This procedure is repeated m times independently. We are interested in whether the resulting linear programming problem is feasible. We prove that the feasibility property experiences a linear phase transition, when n &larr; &infin; and m = cn for a constant c. Namely, there exists a critical value c* such that, when c < c*, the problem is feasible or is asymptotically almost feasible, as n &larr; &infin;, but, when c > c*, the ""distance"" to feasibility is at least a positive constant independent of n. Our result is obtained using the combination of a powerful local weak convergence method developed in Aldous [Ald92], [Ald01], Aldous and Steele [AS03], Steele [Ste02] and martingale techniques. By exploiting a linear programming duality, our theorem implies some results for maximum weight matchings in sparse random graphs G(n, &lfloor;cn&rfloor;) on n nodes with cn edges, where edges are equipped with randomly generated weights."
SODA	On contract-and-refine transformations between phylogenetic trees.	Ganeshkumar Ganapathy,Vijaya Ramachandran,Tandy Warnow	2004	The inference of evolutionary trees using approaches which attempt to solve the maximum parsimony (MP) and maximum likelihood (ML) optimization problems is a standard part of much of biological data analysis. However, both problems are hard to solve: MP provably NP-hard, and ML even harder in practice. Consequently, hill-climbing heuristics are used to analyze datasets for phylogeny reconstruction. Two primary topological transformations have been used in the most popular heuristics: TBR (tree-bisection-and-reconnection) and ECR (edge-contractions-and-refinements). While most of the popular heuristics exclusively use TBR moves to explore tree space, some recent methods have used ECR in conjunction with TBR and found significant improvements in the speed and accuracy with which they can analyze datasets. In this paper we analyze ECR moves in detail, and provide results on the diameter of the tree space, the neighborhood intersection with TBR, structural analysis of the ECR operation, and an efficient method for sampling uniformly from the 2-ECR neighborhood of a tree. Our results should lead to a better understanding of the impact of ECR moves on the performance of heuristic searches.
SODA	Optimal routing in Chord.	Prasanna Ganesan,Gurmeet Singh Manku	2004	We propose optimal routing algorithms for Chord [1], a popular topology for routing in peer-to-peer networks. Chord is an undirected graph on 2b nodes arranged in a circle, with edges connecting pairs of nodes that are 2k positions apart for any k &ge; 0. The standard Chord routing algorithm uses edges in only one direction. Our algorithms exploit the bidirectionality of edges for optimality. At the heart of the new protocols lie algorithms for writing a positive integer d as the difference of two non-negative integers d&prime; and d&Prime; such that the total number of 1-bits in the binary representation of d&prime; and d&Prime; is minimized. Given that Chord is a variant of the hypercube, the optimal routes possess a surprising combinatorial structure.
SODA	Fair and efficient router congestion control.	Xiaojie Gao,Kamal Jain,Leonard J. Schulman	2004	"Congestion is a natural phenomenon in any network queuing system, and is unavoidable if the queuing system is operated near capacity. In this paper we study how to set the rules of a queuing system so that all the users have a self-interest in controlling congestion when it happens.Routers in the internet respond to local congestion by dropping packets. But if packets are dropped indiscriminately, the effect can be to encourage senders to actually increase their transmission rates, worsening the congestion and destabilizing the system. Alternatively, and only slightly more preferably, the effect can be to arbitrarily let a few insistent senders take over most of the router capacity.We approach this problem from first principles: a router packet-dropping protocol is a mechanism that sets up a game between the senders, who are in turn competing for link capacity. Our task is to design this mechanism so that the game equilibrium is desirable: high total rate is achieved and is shared widely among all senders. In addition, equilibrium should be reestablished quickly in response to changes in transmission rates. Our solution is based upon auction theory: in principle, although not always in practice, we drop packets of the highest-rate sender, in case of congestion. We will prove the game-theoretic merits of our method. We'll also describe a variant of the method with some further advantages that will be supported by network simulations."
SODA	Polynomial interpolation from multiples.	Joachim von zur Gathen,Igor Shparlinski	2004	We are given an unknown polynomial f &isin; ℤ[x] by a black box which on input a &isin; ℤ returns a value rq &middot; f(a) for some unknown nonzero rational numbers ra. If we have appropriate upper bounds on the numerator and denominator of ra and the degree of f, then the coefficients of f can be computed in probabilistic polynomial time.
SODA	Succinct ordinal trees with level-ancestor queries.	Richard F. Geary,Rajeev Raman,Venkatesh Raman	2004	We consider suc cinct or space-efficient representations of trees that efficiently support a variety of navigation operations. We focus on static ordinal trees, i.e., arbitrary static rooted trees where the children of each node are ordered. The set of operations is essentially the union of the sets of operations supported by previous succinct representations (Jacobson, Proc. 30th FOCS, 549--554, 1989; Munro and Raman, SIAM J. Comput. 31 (2001), 762--776; and Benoit et. al Proc. 6th WADS, LNCS 1663, 169--180, 1999), to which we add the level-ancestor operation.Our representation takes 2n + o(n) bits to represent an n-node tree, which is within o(n) bits of the information-theoretic minimum, and supports all operations in O(1) time on the RAM model. These operations also provide a mapping from the n nodes of the tree onto the integers {1,...,n}. In addition to the existing motivations for studying such data structures, we are motivated by the problem of representing XML documents compactly so that XPath queries can be supported efficiently.
SODA	Finding dominators revisited: extended abstract.	Loukas Georgiadis,Robert Endre Tarjan	2004	"The problem of finding dominators in a flowgraph arises in many kinds of global code optimization and other settings. In 1979 Lengauer and Tarjan gave an almost-linear-time algorithm to find dominators. In 1985 Harel claimed a linear-time algorithm, but this algorithm was incomplete; Alstrup et al. [1999] gave a complete and ""simpler"" linear-time algorithm on a random-access machine. In 1998, Buchsbaum et al. claimed a ""new, simpler"" linear-time algorithm with implementations both on a random access machine and on a pointer machine. In this paper, we begin by noting that the key lemma of Buchsbaum et al. does not in fact apply to their algorithm, and their algorithm does not run in linear time. Then we provide a complete, correct, simpler linear-time dominators algorithm. One key result is a linear-time reduction of the dominators problem to a nearest common ancestors problem, implementable on either a random-access machine or a pointer machine."
SODA	Covering minimum spanning trees of random subgraphs.	Michel X. Goemans,Jan Vondrák	2004	We consider the problem of covering the minimum spanning tree (MST) of a random subgraph of G by a sparse set of edges, with high probability. The two random models that we consider are subgraphs induced by a random subset of vertices, each vertex included independently with probability p, and subgraphs generated as a random subset of edges, each edge with probability p.Let n be the number of vertices in G. We show that in both cases, there is a covering set Q of cardinality O(n logb n) where b = 1/(1 -- p) (and p is possibly a function of n) and this is asymptotically optimal. More generally, we show a similar bound on the covering set in a matroid, which contains the minimum-weight basis of a random subset with high probability. Also, we give a randomized algorithm which calls an MST subroutine only a polylogarithmic number of times, and finds the covering set with high probability.
SODA	Algorithms for infinite huffman-codes.	Mordecai J. Golin,Kin Keung Ma	2004	"Optimal (minimum cost) binary prefix-free codes for infinite sources with geometrically distributed frequencies, e.g., P = {pi(1 - p)}&infin;i=0 0 < p < 1, were first (implicitly) suggested by Golomb over thirty years ago in the context of run-length encodings. Ten years later Gallager and Van Voorhis exhibited such optimal codes for all values of p: Just recently Merhav, Seroussi and Weinberger extended this further to find optimal binary prefix-free codes for two-sided geometric distributions.These codes were derived by cleverly ""guessing"" optimal codes for finite sources, validating these guesses by using the sibling property of Huffman encoding, and then showing that the finite codes converge in a very specific sense to an optimal infinite one.In this paper we describe the first algorithmic approach to constructing optimal prefix-free infinite codes. Our approach is to define an infinite weighted graph with the property that the least cost infinite path in the graph corresponds to the optimal code. We then show that even though the graph is infinite, the leastcost infinite path has a repetitive structure and that it is therefore possible to not only find this path but to find it relatively efficiently.This approach will work for even more complicated generalizations of geometric sources where solutions can't be guessed as well as in extensions of Huffman-coding for which the Huffman algorithm no longer works, e.g., non-uniform cost encoding alphabet characters and/or other restrictions on the codewords. We illustrate our approach by deriving an algorithm for constructing optimal prefix free codes with a geometric source for the telegraph channel. We also implement our algorithm and show what the constructed codes look like in this case."
SODA	When indexing equals compression: experiments with compressing suffix arrays and applications.	Roberto Grossi,Ankur Gupta,Jeffrey Scott Vitter	2004	We report on a new and improved version of high-order entropy-compressed suffix arrays, which has theoretical performance guarantees similar to those in our earlier work [16], yet represents an improvement in practice. Our experiments indicate that the resulting text index offers state-of-the-art compression. In particular, we require roughly 20% of the original text size---without requiring a separate instance of the text---and support fast and powerful searches. To our knowledge, this is the best known method in terms of space for fast searching.
SODA	Efficiently decodable codes meeting Gilbert-Varshamov bound for low rates.	Venkatesan Guruswami,Piotr Indyk	2004	We demonstrate a probabilistic construction of binary linear codes meeting the GV bound (with overwhelming probability) for rates up to about 10-4 together with polynomial time algorithms to perform encoding and decoding up to half the distance. The only previous result of this type (for rates up to about 0.02) suffered from sub-exponential time decoding [3].
SODA	Variable length path coupling.	Thomas P. Hayes,Eric Vigoda	2004	We present a new technique for constructing and analyzing couplings to bound the convergence rate of finite Markov chains. Our main theorem is a generalization of the path coupling theorem of Bubley and Dyer, allowing the defining partial couplings to have length determined by a random stopping time. Unlike the original path coupling theorem, our version can produce multi-step (non-Markovian) couplings. Using our variable length path coupling theorem, we improve the upper bound on the mixing time of the Glauber dynamics for randomly sampling colorings.
SODA	A note on the nearest neighbor in growth-restricted metrics.	Kirsten Hildrum,John Kubiatowicz,Sean Ma,Satish Rao	2004	In this paper, we give results relevant to sequential and distributed dynamic data structures for finding nearest neighbors in growth-restricted metrics. Our sequential data structure uses linear space, and requires O(log n) queries in expecation and O(log n) queries for lookups with high probability. This improves the results of Karger and Ruhl [4], whose data structure uses O(n log n) space with comparable expected time bounds. This also improves on the time bound of a load-balanced version of algorithm (for dynamic networks) presented in [3].Our algorithm was inspired by the object location data structure developed by Plaxton, Rajaraman and Richa [6], and is similar in structure to the algorithm of Krauthgamer and Lee [5]. It is significantly different that of Karger and Ruhl [4].A distributed version of the algorithm presented here is in use as a part of Tapestry [3, 8], a peer-to-peer object location system based on [6].
SODA	On the costs and benefits of procrastination: approximation algorithms for stochastic combinatorial optimization problems.	Nicole Immorlica,David R. Karger,Maria Minkoff,Vahab S. Mirrokni	2004	"Combinatorial optimization is often used to ""plan ahead,"" purchasing and allocating resources for demands that are not precisely known at the time of solution. This advance planning may be done because resources become very expensive to purchase or difficult to allocate at the last minute when the demands are known. In this work we study the tradeoffs involved in making some purchase/allocation decisions early to reduce cost while deferring others at greater expense to take advantage of additional, late-arriving information. We consider a number of combinatorial optimization problems in which the problem instance is uncertain---modeled by a probability distribution---and in which solution elements can be purchased cheaply now or at greater expense after the distribution is sampled. We show how to approximately optimize the choice of what to purchase in advance and what to defer."
SODA	Approximate Nearest Neighbor under edit distance via product metrics.	Piotr Indyk	2004	We present a data structure for the approximate nearest neighbor problem under edit metric (which is defined as the minimum number of insertions, deletions and character substitutions needed to transform one string into another). For any l &ge; 1 and a set of n strings of length d, the data structure reports a 3l-approximate Nearest Neighbor for any given query string q in O(d) time. The space requirement of this data structure is roughly O(nd1/(l+1)), i.e., strongly subexponential. To our knowledge, this is the first data structure for this problem with both o(n) query time and storage subexponential in d.
SODA	Rank-maximal matchings.	Robert W. Irving,Telikepalli Kavitha,Kurt Mehlhorn,Dimitrios Michail,Katarzyna E. Paluch	2004	Suppose that each member of a set A of applicants ranks a subset of a set P of posts in an order of preference, possibly involving ties. A matching is a set of (applicant, post) pairs such that each applicant and each post appears in at most one pair. A greedy matching is one in which the maximum possible number of applicants are matched to their first choice post, and subject to that condition, the maximum possible number are matched to their second choice post, and so on. This is a relevant concept in any practical matching situation and it was first studied by Irving [8].We define the bipartite graph G = (A U P,ε), where ε consists of all pairs (a, p) such that post p appears in the preference list of applicant a. Each edge (a, p) has a rank i, which means that post p is an ith choice for applicant a. The traditional solution of computing a greedy matching in G would be to use the Hungarian algorithm to compute a maximum weight matching by assigning a suitably steeply decreasing sequence of weights to the edges. This would result in an algorithm with worst case running time rn(m + n log n) and the space requirement &Theta;(rm), where n is the number of vertices, m is the number of edges and r is the largest rank of an edge.Here, we describe two algorithms to compute a greedy matching that improve upon this algorithm. We give a combinatorial algorithm with running time O(min(n + C,C&radic;n)m), where C &le; r is the maximal rank of an edge used in a greedy matching. This algorithm works in phases and uses the maximum cardinality matching algorithm. We also give an O(Cnm) algorithm that tackles the problem of large edge weights introduced by the Hungarian algorithm. This algorithm uses scaling and works in phases. The space requirement of both these algorithms is O(m).
SODA	Randomized pursuit-evasion with limited visibility.	Volkan Isler,Sampath Kannan,Sanjeev Khanna	2004	We study the following pursuit-evasion game: One or more hunters are seeking to capture an evading rabbit on a graph. At each round, the rabbit tries to gather information about the l ocation of the hunters but it can see them only if they are located on adjacent nodes. We show that two hunters suffice for catching rabbits with limited visibility with high probability. We distinguish between reactive rabbits who who move only when the hunter is visible and general rabbits can employ more sophisticated strategies. We present polynomial time algorithms that decide whether a graph G is hunter-win, that is, if a single hunter can capture a rabbit of either kind on G.
SODA	Improved upper bounds for 3-SAT.	Kazuo Iwama,Suguru Tamaki	2004	Improved upper bounds for 3-SAT.
SODA	On rectangle packing: maximizing benefits.	Klaus Jansen,Guochuan Zhang	2004	We consider the following rectangle packing problem: Given a set of rectangles, each of which is associated with a profit, we are requested to pack a subset of the rectangles into a bigger rectangle to maximize the total profit of rectangles packed. The rectangles may not overlap and may or may not be rotated. This problem is strongly NP-hard even for packing squares with identical profits. A simple (3 + ε)-approximation algorithm is presented. We further improve the algorithm by showing a worst-case ratio of at most 5/2 + ε. Finally we devise a (2 + ε)-approximation algorithm. A number of restricted cases are also considered.
SODA	On the convergence time of a path-vector protocol.	Howard J. Karloff	2004	"We study the running time of a particular path-vector protocol for distributively and asynchronously computing shortest paths in a network to a given target node t. We study two cases. In both, the protocol starts with each node possibly knowing some path to t, subject to conditions discussed in the paper. In the first case, the ""withdrawal case,"" all edges incident to the target are cut. We prove that in this case, the protocol always terminates but may need exponential time to do so, if the nodes ""fire"" (i.e., execute) in an adversarially chosen order, even if the initial paths are shortest. If the graph is a clique, the protocol terminates in polynomial time. If, on the other hand, the nodes fire in random order, and the graph is arbitrary, then the algorithm terminates in polynomial expected time. In the second case, the ""announcement case,"" in which new edges incident to t appear, we prove that the protocol terminates in polynomial time, regardless of the firing order.This protocol is interesting since it models the shortest-path protocol used by BGP, the interdomain routing protocol of the Internet, in the absence of policy."
SODA	On broadcasting in heterogenous networks.	Samir Khuller,Yoo Ah Kim	2004	In this paper we study a well known broadcasting heuristic for heterogenous networks of workstations, called fastest node first. We show that this heuristic produces an optimal solution for minimizing the sum of all completion times, and in addition produces a 1.5 approximation for the problem of minimizing the maximum completion time. We extend these results to show that the same bounds can be obtained for the multicast operation on such heterogenous networks. In addition we show that the problem of minimizing the maximum completion time is N P-hard, which settles the complexity of this open problem.
SODA	Minimizing migrations in fair multiprocessor scheduling of persistent tasks.	Tracy Kimbrel,Baruch Schieber,Maxim Sviridenko	2004	Suppose that we are given n persistent tasks (jobs) that need to be executed in an equitable way on m processors (machines). Each machine is capable of performing one unit of work in each integral time unit and each job may be executed on at most one machine at a time. The schedule needs to specify which job is to be executed on each machine in each time window. The goal is to find a schedule that minimizes job migrations between machines while guaranteeing a fair schedule. We measure the fairness by the drift d defined as the maximum difference between the execution times accumulated by any two jobs. Since jobs are persistent we measure the quality of the schedule by the ratio of the number of migrations to time windows. We show a tradeoff between the drift and the number of migrations. Let n = qm + r with 0 < r < m (the problem is trivial for n &le; m and for r = 0). For any d &ge; 1, we show a schedule that achieves a migration ratio of r(m - r)/(n(q(d 1) + 1)) + o(1); namely, it asymptotically requires r(m - r) job migrations every n(q(d 1) + 1) time windows. We show how to implement the schedule efficiently. We prove that our algorithm is almost optimal by proving a lower bound of r(m r)/(nqd) on the migration ratio. We also give a more complicated schedule that matches the lower bound for an infinite number of instances. Our algorithms can be extended to the dynamic case in which jobs enter and leave the system over time.
SODA	On distributions computable by random walks on graphs.	Guy Kindler,Dan Romik	2004	We answer a question raised by Donald E. Knuth and Andrew C. Yao, concerning the class of polynomials on [0, 1] that can be realized as the distribution function of a random variable, whose binary expansion is the output of a finite state automaton driven by unbiased coin tosses. The polynomial distribution functions which can be obtained in this way are precisely those with rational coefficients, whose derivative has no irrational roots on [0, 1].We also show, strengthening a result of Knuth and Yao, that all smooth distribution functions which can be obtained by such automata are polynomials.
SODA	End-to-end packet-scheduling in wireless ad-hoc networks.	V. S. Anil Kumar,Madhav V. Marathe,Srinivasan Parthasarathy,Aravind Srinivasan	2004	"Packet-scheduling is a particular challenge in wireless networks due to interference from nearby transmissions. A distance-2 interference model serves as a useful abstraction here, and we study packet routing and scheduling under this model. The main focus of our work is the development of fully-distributed (decentralized) protocols. We present polylogarithmic/constant factor approximation algorithms for various families of disk graphs (which capture the geometric nature of wireless-signal propagation), as well as near-optimal approximation algorithms for general graphs. The packet-scheduling work by L eighton, Maggs and Rao (Combinatorica, 1994) and a basic distributed coloring procedure, originally due to Luby (J. Computer and System Sciences, 1993), underlie many of our algorithms. Experimental work of Finocchi, Panconesi, and Silvestri (SODA 2002) showed that a natural modification of Luby's algorithm leads to improved performance, and a rigorous explanation of this was left as an open question; we prove that the modified algorithm is provably better in the worst-case. Finally, using simulations, we study the impact of the routing strategy and the choice of parameters on the performance of our distributed algorithm for unit disk graphs."
SODA	Network failure detection and graph connectivity.	Jon M. Kleinberg,Mark Sandler,Aleksandrs Slivkins	2004	"We consider a model for monitoring the connectivity of a network subject to node or edge failures. In particular, we are concerned with detecting (ε, k)-failures: events in which an adversary deletes up to network elements (nodes or edges), after which there are two sets of nodes A and B, each at least an ε fraction of the network, that are disconnected from one another. We say that a set D of nodes is an (ε k)-detection set if, for any (ε k)-failure of the network, some two nodes in D are no longer able to communicate; in this way, D ""witnesses"" any such failure. Recent results show that for any graph G, there is an is (ε k)-detection set of size bounded by a polynomial in k and ε, independent of the size of G.In this paper, we expose some relationships between bounds on detection sets and the edge-connectivity &lambda; and node-connectivity &kappa; of the underlying graph. Specifically, we show that detection set bounds can be made considerably stronger when parameterized by these connectivity values. We show that for an adversary that can delete &kappa;&lambda; edges, there is always a detection set of size O((&kappa;/ε) log (1/ε)) which can be found by random sampling. Moreover, an (ε, &lambda)-detection set of minimum size (which is at most 1/ε) can be computed in polynomial time. A crucial point is that these bounds are independent not just of the size of G but also of the value of &lambda;.Extending these bounds to node failures is much more challenging. The most technically difficult result of this paper is that a random sample of O((&kappa;/ε) log (1/ε)) nodes is a detection set for adversaries that can delete a number of nodes up to &kappa;, the node-connectivity.For the case of edge-failures we use VC-dimension techniques and the cactus representation of all minimum edge-cuts of a graph; for node failures, we develop a novel approach for working with the much more complex set of all minimum node-cuts of a graph."
SODA	Quantum computing.	Raymond Laflamme	2004	Quantum computing.
SODA	Navigating nets: simple algorithms for proximity search.	Robert Krauthgamer,James R. Lee	2004	"We present a simple deterministic data structure for maintaining a set S of points in a general metric space, while supporting proximity search (nearest neighbor and range queries) and updates to S (insertions and deletions). Our data structure consists of a sequence of progressively finer ε-nets of S, with pointers that allow us to navigate easily from one scale to the next.We analyze the worst-case complexity of this data structure in terms of the ""abstract dimensionality"" of the metric S. Our data structure is extremely efficient for metrics of bounded dimension and is essentially optimal in a certain model of distance computation. Finally, as a special case, our approach improves over one recently devised by Karger and Ruhl [KR02]."
SODA	Complexity classification of network information flow problems.	April Rasala Lehman,Eric Lehman	2004	We address the network information flow problem, in which messages available to a set of sources must be passed through a network to a set of sinks with specified demands. This differs from traditional multicommodity flow, because information can be duplicated and encoded. Previous work has focused on the special case of multicasting using linear coding. In this paper, we explore the applicability of network coding to a breadth of problems and consider the greater potential of nonlinear coding techniques. Our main contribution is a taxonomy of network information flow problems. We establish a three-way partition consisting of problems solvable without resorting to network coding, problems requiring network coding that are polynomial-time solvable, and problems for which obtaining a linear network coding solution is NP-hard. We also demonstrate limitations of linear coding: for multicasting, nonlinear codes may employ a smaller alphabet than any linear code and, more generally, there exist solvable information flow problems that do not admit a linear solution.
SODA	Locally satisfiable formulas.	Daniel Král	2004	A CNF formula &psi; is k-satisfiable if each k clauses of &psi; can be satisfied simultaneously. Let &pi;k be the largest real number such that for each k-satisfiable formula with variables xi, there are probabilities pi with the following property: If each variable xi is chosen randomly and independently to be true with the probability pi, then each clause of is satisfied with the probability at least &pi;k.We determine the numbers &pi;k and design a linear-time algorithm which given a formula either outputs that &psi; is not k-satisfiable or finds probabilities pi such that each clause &psi; of is satisfied with the probability at least &pi;k. Our approach yields a robust linear-time deterministic algorithm which finds for a k-satisfiable formula a truth assignment satisfying at least the fraction of &pi;k of the clauses.A related parameter is rk which is the largest ratio such that for each k-satisfiable CNF formula with m clauses, there is a truth assignment which satisfies at least rkm clauses. It was known that &pi;k = rk for k = 1, 2, 3. We compute the ratio r4 and show &pi;4 6 = r4. We also design a linear-time algorithm which finds a truth assignment satisfying at least the fraction r4 of the clauses for 4-satisfiable formulas.
SODA	A time efficient Delaunay refinement algorithm.	Gary L. Miller	2004	In this paper we present a Delaunay refinement algorithm for generating good aspect ratio and optimal size triangulations. This is the first algorithm known to have sub-quadratic running time. The algorithm is based on the extremely popular Delaunay refinement algorithm of Ruppert. We know of no prior refinement algorithm with an analyzed subquadratic time bound. For many natural classes of meshing problems, our time bounds are comparable to know bounds for quadtree methods.
SODA	"A stronger bound on Braess's Paradox."	Henry C. Lin,Tim Roughgarden,Éva Tardos	2004	"A stronger bound on Braess's Paradox."
SODA	The pure literal rule threshold and cores in random hypergraphs.	Michael Molloy	2004	We describe a technique for determining the thresholds for the appearance of cores in random structures. We use it to determine (i) the threshold for the pure literal rule to find a satisfying assignment for a random instance of r-SAT, r &ge; 3, and (ii) the threshold for the appearance of a k-core in a random r-uniform hypergraph for all r, k &ge; 2, r + k > 4.
SODA	Generic quantum Fourier transforms.	Cristopher Moore,Daniel N. Rockmore,Alexander Russell	2004	"The quantum Fourier transform (QFT) is the principal ingredient of most efficient quantum algorithms. We present a generic framework for the construction of efficient quantum circuits for the QFT by ""quantizing"" the highly successful separation of variables technique for the construction of efficient classical Fourier transforms. Specifically, we use Bratteli diagrams, Gel'fand-Tsetlin bases, and strong generating sets of small adapted diameter to provide efficient quantum circuits for the QFT over a wide variety of finite Abelian and non-Abelian groups, including all group families for which efficient QFTs are currently known and many new group families. Moreover, our method provides the first subexponential-size quantum circuits for the QFT over the linear groups GLk(q), SLk(q), and the finite groups of Lie type, for any fixed prime power q."
SODA	The power of basis selection in fourier sampling: hidden subgroup problems in affine groups.	Cristopher Moore,Daniel N. Rockmore,Alexander Russell,Leonard J. Schulman	2004	"Many quantum algorithms, including Shor's celebrated factoring and discrete log algorithms, proceed by reduction to a hidden subgroup problem, in which a unknown subgroup H of a group G must be determined from a quantum state &psi; over G that is uniformly supported on a left coset of H. These hidden subgroup problems are typically solved by Fourier sampling: the quantum Fourier transform of &psi; is computed and measured. When the underlying group is nonabelian, two important variants of the Fourier sampling paradigm have been identified: the weak standard method, where only representation names are measured, and the strong standard method, where full measurement (i.e., the row and column of the representation as well as its name) occurs. It has remained open whether the strong method is indeed stronger, that is, whether there are hidden subgroups that can be reconstructed via the strong method but not by the weak, or any other known, method.In this article, we settle this question in the affirmative. We show that hidden subgroups of semidirect products of the form ℤq &times; ℤp, where q | (p - 1) and q = p/polylog(p), can be efficiently determined by the strong standard method. Furthermore, the weak standard method and the ""forgetful"" abelian method are insufficient for these groups so that, in fact, it appears that use of the corresponding nonabelian representation theory is crucial. We extend this to an informationtheoretic solution for the hidden subgroup problem over the groups ℤq &times; ℤp where q | (p - 1) and, in particular, the affine groups Ap. Finally, we prove a simple closure property for the class of groups over which the hidden subgroup problem can be solved efficiently."
SODA	Trade-offs on the location of the core node in a network.	Jean-François Macq,Michel X. Goemans	2004	The selection of a core node in a network is a crucial step in the set-up of several multimedia applications such as videoconferences or multi-player games. For a given group of application users, a poorly chosen location can lead to a waste of bandwidth or to long communication delays. Since this kind of application usually involves unicast and multicast communications at the same time, we are naturally interested in a core location such that both the sum of the unicast path lengths to the users and the cost of the multicast tree spanning the users and the core are simultaneously small. While optimizing the first criterion is equivalent to finding a 1-median of the users, the second criterion corresponds to the minimum cost Steiner tree problem.The goal of this paper is to show that there always exists a core location for which both criteria are close to their optimum. More precisely, we give a continuum of results which proves in particular that both criteria can simultaneously be within 1.37 times their optimum. Finally we apply our results to the problem of minimizing a weighted sum of the criteria and we give an easy and fast heuristic with a small approximation ratio.
SODA	Caching queues in memory buffers.	Rajeev Motwani,Dilys Thomas	2004	Motivated by the need for maintaining multiple, large queues of data in modern high-performance systems, we study the problem of caching queues in memory under the following simple, but widely applicable, model. At each clock-tick, any number of data items may enter the various queues, while data-items are consumed from the heads of the queues. Since the number of unconsumed items may exceed memory buffer size, some items in the queues need to be spilled to secondary storage and later moved back into memory for consumption. We provide online queue-caching algorithms under a number of interesting cost models.
SODA	Fast mixing for independent sets, colorings and other models on trees.	Fabio Martinelli,Alistair Sinclair,Dror Weitz	2004	We study the mixing time of the Glauber dynamics for general spin systems on bounded-degree trees, including the Ising model, the hard-core model (independent sets) and the antiferromagnetic Potts model at zero temperature (colorings). We generalize a framework, developed in our recent paper [18] in the context of the Ising model, for establishing mixing time O(n log n), which ties this property closely to phase transitions in the underlying model. We use this framework to obtain rapid mixing results for several models over a significantly wider range of parameter values than previously known, including situations in which the mixing time is strongly dependent on the boundary condition.
SODA	Adaptive sampling for quickselect.	Conrado Martinez,Daniel Panario,Alfredo Viola	2004	"Quickselect with median-of-3 is largely used in practice and its behavior is fairly well understood. However, the following natural adaptive variant, which we call proportion-from-3, had not been previously analyzed: choose as pivot the smallest of the sample if the rank of the sought element is small, the largest if the rank is large, and the median if the rank is medium"". We first analyze proportion-from-2 and then proportion-from3. We also analyze &nu;-find, a generalization of proportion-from-3 with interval breakpoints at &nu; and 1 -- &nu;. We show that there exists an optimal value of &nu; and we also provide the range of values of &nu; where &nu;-find outperforms median-of-3. Our results atrongly suggest that a suitable implementation of this variant could be the method of choice in a practical setting. Finally, we also show that proportion-from-s and similar strategies are optimal when s &rarr; &infin;"
SODA	The directed circular arrangement problem.	Joseph Naor,Roy Schwartz	2004	"We consider the problem of embedding a directed graph onto evenly-spaced points on a circle while minimizing the total weighted edge length. We present the first poly-logarithmic approximation factor algorithm for this problem which yields an approximation factor of O(log n log log n), thus improving the previous &Otilde;(&radic;n) approximation factor. In order to achieve this, we introduce a new problem which we call the directed penalized linear arrangement. This problem generalizes both the directed feedback edge set problem and the directed linear arrangement problem. We present an O(log n log log n) approximation factor algorithm for this newly defined problem. Our solution uses two distinct directed metrics (""right"" and ""left"") which together yield a lower bound on the value of an optimal solution. In addition, we define a sequence of new directed spreading metrics that are used for applying the algorithm recursively on smaller subgraphs. The new spreading metrics allow us to define an asymmetric region growing procedure that accounts simultaneously for both incoming and outgoing edges. To the best of our knowledge, this is the first time that a region growing procedure is defined in directed graphs that allows for such an accounting."
SODA	A certifying algorithm for the consecutive-ones property.	Ross M. McConnell	2004	We give a forbidden substructure characterization of set families that have the consecutive-ones property, and a linear time algorithm to find the forbidden substructure if a set family does not have the property. The forbidden substructure has size O(n), where n is the size of the domain. The PQ tree is a well-known data structure for representing all consecutive-ones orderings. We show that it is given by a substitution decomposition of arbitrary set families that has not been described previously. This observation gives a generalization of the PQ tree to arbitrary set families, and we give a linear-time algorithm to compute it.
SODA	SRPT optimally utilizes faster machines to minimize flow time.	Jason McCullough,Eric Torng	2004	"We analyze the shortest remaining processing time (SRPT) algorithm with respect to the problem of scheduling n jobs with release times on m identical machines to minimize total flow time. It is known that SRPT is optimal if m = 1 but that SRPT has a worstcase approximation ratio of &Theta;(min(log n/m, log &Delta;)) for this problem, where &Delta; is the ratio of the length of the longest job divided by the length of the shortest job. It has previously been shown that SRPT is able to use faster machines to produce a schedule as good as an optimal algorithm using slower machines. We now show that SRPT optimally uses these faster machines with respect to the worst-case approximation ratio. That is, if SRPT is given machines that are s &ge; 2 - 1/m times as fast as those used by an optimal algorithm, SRPT's flow time is at least s times smaller than the flow time incurred by the optimal algorithm. Clearly no algorithm can offer a better worst-case guarantee, and we show that existing algorithms with similar performance guarantees to SRPT without resource augmentation do not optimally use extra resources."
SODA	Hole and antihole detection in graphs.	Stavros D. Nikolopoulos,Leonidas Palios	2004	In this paper, we study the problems of detecting holes and antiholes in general undirected graphs and present algorithms for them, which, for a graph on n vertices and m edges, run in O(n + m2) time and require O(nm) space; we thus provide a solution to the open problem posed by Hayward, Spinrad, and Sritharan in [12] asking for an O(n4)-time algorithm for finding holes in arbitrary graphs. The key element of the algorithms is a special type of depth-first search traversal which proceeds along P4s (i.e., chordless paths on four vertices) of the input graph. We also describe a different approach which allows us to detect antiholes in graphs that do not contain chordless cycles on 5 vertices in O(n + m2) time requiring O(n + m) space. Our algorithms are simple and can be easily used in practice. Additionally, we show how our detection algorithms can be augmented so that they return a hole or an antihole whenever such a structure is detected in the input graph; the augmentation takes O(n + m) time and space.
SODA	Approximate local search in combinatorial optimization.	James B. Orlin,Abraham P. Punnen,Andreas S. Schulz	2004	Local search algorithms for combinatorial optimization problems are in general of pseudopolynomial running time and polynomial-time algorithms are often not known for finding locally optimal solutions for NP-hard optimization problems. We introduce the concept of ε-local optimality and show that an ε-local optimum can be identified in time polynomial in the problem size and 1=ε whenever the corresponding neighborhood can be searched in polynomial time, for ε > 0. If the neighborhood can be searched in polynomial time for a &delta;-local optimum, a variation of our main algorithm produces a (&delta; + ε)-local optimum in time polynomial in the problem size and 1/ε. As a consequence, a combinatorial optimization problem has a fully polynomial-time approximation scheme if and only if the problem of determining a better solution---the so-called augmentation problem---has a fully polynomial-time approximation scheme.
SODA	Tight bounds for the partial-sums problem.	Mihai Patrascu,Erik D. Demaine	2004	We close the gaps between known lower and upper bounds for the online partial-sums problem in the RAM and group models of computation. If elements are chosen from an abstract group, we prove an &Omega;(lg n) lower bound on the number of algebraic operations that must be performed, matching a well-known upper bound. In the RAM model with b-bit memory registers, we consider the well-studied case when the elements of the array can be changed additively by &delta;-bit integers. We give a RAM algorithm that achieves a running time of &Theta;(1 + lg n / lg(b / &delta;)) and prove a matching lower bound in the cell-probe model. Our lower bound is for the amortized complexity, and makes minimal assumptions about the relations between n, b, and &delta;. The best previous lower bound was &Omega;(lg n = (lg lg n+lg b)), and the best previous upper bound matched only in the special case b = &Theta;(lg n) and &delta; = O(lg lg n).
SODA	Meldable RAM priority queues and minimum directed spanning trees.	Ran Mendelson,Mikkel Thorup,Uri Zwick	2004	"We consider the implementation of meldable priority queues with integer keys in the RAM model. We present two new general techniques for transforming non-meldable priority queues into meldable ones. These transformations can be described symbolically as:non-meldable priority queue +union-find &larr; meldable priority queuenon-meldable priority queue +slow meldable priority queue &larr;faster meldable priority queueUsing the first transformation to combine a recent non-meldable RAM priority queue of Thorup with the classical union-find data structure we obtain a meldable RAM priority queue with an amortized cost of O(log log n&middot;&alpha;(n)) per operation, where &alpha;(n) = &alpha;(n, n) is the inverse Ackermann function. Using instead a randomized priority queue of Han and Thorup we obtain an expected amortized cost of O(&radic;(log log n) &middot; &alpha;(n)) per operation. The second transformation yields slower meldable priority queues, but the obtained queues can support the insert, find-min and decrease-key operations in constant time. In particular, by combining a randomized ""atomic-heap"" of Thorup with, e.g., the classical Fibonacci heaps of Fredman and Tarjan, we obtain, for every fixed ε > 0, a meldable priority queue with an expected amortized cost of O(1) for each insert, find-min and decrease-key operation, and an expected amortized cost of O((log n)1/2+ε) for each delete or meld operation.Using the meldable priority queues of the first type, we obtain improved algorithms for finding minimum directed spanning trees in graphs with integer edge weights: a deterministic O(m &middot; log log n &middot; &alpha;(n)) time algorithm and a randomized O(m &middot; &radic;(log log n) &middot; &alpha;(n)) expected time algorithm. These bounds improve, for very sparse graphs, on the O(m + n log n) running time of an algorithm by Gabow, Galil, Spencer and Tarjan that works for arbitrary edge weights."
SODA	The maximum latency of selfish routing.	Tim Roughgarden	2004	The maximum latency of selfish routing.
SODA	Buffer minimization using max-coloring.	Sriram V. Pemmaraju,Rajiv Raman,Kasturi R. Varadarajan	2004	Given a graph G = (V,E) and positive integral vertex weights w : V &rarr; N, the max-coloring problem seeks to find a proper vertex coloring of G whose color classes C1, C2,...,Ck, minimize &Sigma;ki = 1 max&nu;&isin;Ciw(&nu;). This problem, restricted to interval graphs, arises whenever there is a need to design dedicated memory managers that provide better performance than the general purpose memory management of the operating system. Specifically, companies have tried to solve this problem in the design of memory managers for wireless protocol stacks such as GPRS or 3G.Though this problem seems similar to the wellknown dynamic storage allocation problem, we point out fundamental differences. We make a connection between max-coloring and on-line graph coloring and use this to devise a simple 2-approximation algorithm for max-coloring on interval graphs. We also show that a simple first-fit strategy, that is a natural choice for this problem, yields a 10-approximation algorithm. We show this result by proving that the first-fit algorithm for on-line coloring an interval graph G uses no more than 10.x(G) colors, significantly improving the bound of 26.x(G) by Kierstead and Qin (Discrete Math., 144, 1995). We also show that the max-coloring problem is NP-hard.
SODA	Minimum moment Steiner trees.	Wangqi Qiu,Weiping Shi	2004	For a rectilinear Steiner tree T with a root, define its k-th momentMk(T)= &int;T(dT(u))kduwhere the integration is over all edges of T, dT (u) is the length of the unique path in T from the root to u, and du is the incremental edge length. Given a set of points P in the plane, a k-th moment Steiner Minimum Tree (k-SMT) is a rectilinear Steiner tree that has the minimum k-th moment among all rectilinear Steiner trees for P, with the origin as the root. The definition is a natural extension of the traditional Steiner minimum tree, and motivated by application in VLSI routing. In this paper properties of the k-SMT are studied and approximation algorithms are presented.
SODA	Facility location with Service Installation Costs.	David B. Shmoys,Chaitanya Swamy,Retsef Levi	2004	"We consider a generalization of the uncapacitated facility location problem which we call Facility Location with Service Installation Costs. We are given a set of facilities, F,a set of demands or clients D, and a set of services S. Each facility i has a facility opening cost fi, and we have a service installation cost of fli for every facility-service pair (i, l). Each client j in D requests a specific service g(j) &isin; S and the cost of assigning a client j to facility i is given by cij. We want to open a set of facilities, install services at the open facilities, and assign each client j to an open facility at which service g(j) is installed, so as to minimize the sum of the facility opening costs, the service installation costs and the client assignment costs.Our main result is a primal-dual 6-approximation algorithm under the assumption that there is an ordering on the facilities such that if i comes before i' in this ordering then for every service type l, fli &le; fl i. This includes (as special cases) the settings where the service installation cost fli depends only on the service type l, or depends only on the location i. With arbitrary service installation costs, the problem becomes as hard as the set-cover problem. Our algorithm extends the algorithm of Jain & Vazirani [9] in a novel way. If the service installation cost depends only on the service type and not on the location, we give an LP rounding algorithm that attains an improved approximation ratio of 2.391. The algorithm combines both clustered randomized rounding [6] and the filtering based technique of [10, 14]. We also consider the k-median version of the problem where there is an additional requirement that at most k facilities may be opened. We use our primal-dual algorithm to give a constant-factor approximation for this problem when the service installation cost depends only on the service type."
SODA	Multicommodity facility location.	R. Ravi,Amitabh Sinha	2004	Multicommodity facility location refers to the extension of facility location to allow for different clients having demand for different goods, from among a finite set of goods. This leads to several optimization problems, depending on the costs of opening facilities (now a function of the commodities it serves). In this paper, we introduce and study some variants of multicommodity facility location, and provide approximation algorithms and hardness results for them.
SODA	Correlation Clustering: maximizing agreements via semidefinite programming.	Chaitanya Swamy	2004	"We consider the Correlation Clustering problem introduced in [2]. Given a graph G = (V,E) where each edge is labeled either ""+"" (similar) or ""-"" (different), we want to cluster the nodes so that the + edges lie within the clusters and the -- edges lie between clusters. Specifically, we want to maximize agreements --- the number of + edges within clusters and -- edges between clusters. This problem is NP-Hard [2]. We give a 0.7666-approximation algorithm for maximizing agreements on any graph even when the edges have non-negative weights (along with labels) and we want to maximize the weight of agreements. These were posed as open problems in [2]. Previously the only results known were a trivial 0.5-approximation for arbitrary edge weighted graphs, and a PTAS with unit edge weights when |E| = &Omega;(|V|2). Somewhat surprisingly, our algorithm always produces a clustering with at most 6 clusters. As a corollary we get a 0.7666-approximation algorithm for the k-clustering variant of the problem where we may create at most k clusters. A major component of this algorithm is a simple, easy-to-analyze algorithm that by itself achieves an approximation ratio of 0.75, opening at most 4 clusters."
SODA	Tabulation based 4-universal hashing with applications to second moment estimation.	Mikkel Thorup,Yin Zhang	2004	We show that 4-universal hashing can be implemented efficiently using tabulated 4-universal hashing for characters, gaining a factor of 5 in speed over the fastest existing methods. We also consider generalization to k-universal hashing, and as a prime application, we consider the approximation of the second moment of a data stream.
SODA	Graph decomposition and a greedy algorithm for edge-disjoint paths.	Kasturi R. Varadarajan,Ganesh Venkataraman	2004	Graph decomposition and a greedy algorithm for edge-disjoint paths.
SODA	Approximation schemes for Metric Bisection and partitioning.	Wenceslas Fernandez de la Vega,Marek Karpinski,Claire Kenyon	2004	We design polynomial time approximation schemes (PTASs) for Metric BISECTION, i.e. dividing a given finite metric space into two halves so as to minimize or maximize the sum of distances across the cut. The method extends to partitioning problems with arbitrary size constraints. Our approximation schemes depend on a hybrid placement method and on a new application of linearized quadratic programs.
SODA	How random is the human genome?	Peter Winkler	2004	"Now that the human genome is (mostly) sequenced, what do we really know about the statistical properties of that random-looking string of 3 billion A's, C's, G's and T's? The speaker and a group of scientists at Rockefeller University (Andy DeWan, Chad Hayes, Josephine Hoh, Jurg Ott, Tony Parrado, and Richard Sackler) have used a little algorithmic theory and some programming to try to get answers."
SODA	Optimal space lower bounds for all frequency moments.	David P. Woodruff	2004	We prove that any one-pass streaming algorithm which (ε, &delta;)-approximates the kth frequency moment Fk, for any real k &ne; 1 and any ε = &Omega;(1/&radic;m), must use &Omega;(1/ε&sup2;) bits of space, where m is the size of the universe. This is optimal in terms of ε, resolves the open questions of Bar-Yossef et al in [3, 4], and extends the &Omega;(1/ε&sup2;) lower bound for F0 in [11] to much smaller ε by applying novel techniques. Along the way we lower bound the one-way communication complexity of approximating the Hamming distance and the number of bipartite graphs with minimum/maximum degree constraints.
SODA	Detecting short directed cycles using rectangular matrix multiplication and dynamic programming.	Raphael Yuster,Uri Zwick	2004	"We present several new algorithms for detecting short fixed length cycles in digraphs. The new algorithms utilize fast rectangular matrix multiplication algorithms together with a dynamic programming approach similar to the one used in the solution of the classical chain matrix product problem. The new algorithms are instantiations of a generic algorithm that we present for finding a directed Ck, i.e., a directed cycle of length k, in a digraph, for any fixed k &ge; 3. This algorithm partitions the prospective Ck's in the input digraph G = (V,E) into O(logk V) classes, according to the degrees of their vertices. For each cycle class we determine, in O(Eck log V) time, whether G contains a Ck from that class, where ck = ck(&omega;) is a constant that depends only on !, the exponent of square matrix multiplication. The search for cycles from a given class is guided by the solution of a small dynamic programming problem. The total running time of the obtained deterministic algorithm is therefore O(Eck logk+1 V).For C3, we get c3 = 2&omega;/(&omega; + 1) < 1.41 where &omega; < 2.376 is the exponent of square matrix multiplication. This coincides with an existing algorithm of [AYZ97].For C4 we get c4 = (4&omega; - 1)/(2&omega; + 1) < 1.48. We can dispense, in this case, of the polylogarithmic factor and get an O(E(4&omega;-1)/(2&omega;+1)) = o(E1.48) time algorithm. This improves upon an O(E3/2) time algorithm of [AYZ97].For C5 we get c5 = 3&omega;/(&omega; + 2) < 1.63. The obtained running time of O(E3&omega;/(&omega;+2) log6 V) = o(E1.63) improves upon an O(E5/3) time algorithm of [AYZ97].Determining ck for k &ge; 6 is a difficult task. We conjecture that ck = (k + 1)&omega;/(2&omega; + k - 1), for every odd k. The values of ck for even k &ge; 6 seem to exhibit a much more complicated dependence on &omega;."
SODA	Family trees: an ordered dictionary with optimal congestion, locality, degree, and search time.	Kevin C. Zatloukal,Nicholas J. A. Harvey	2004	We consider the problem of storing an ordered dictionary data structure over a distributed set of nodes. In contrast to traditional sequential data structures, distributed data structures should ideally have low congestion. We present a novel randomized data structure, called a family tree, to solve this problem. A family tree has optimal expected congestion, uses only a constant amount of state per node, and supports searches and node insertion/deletion in expected O(log n) time on a system with n nodes. Furthermore, a family tree supports keys from any ordered domain. Because the keys are not hashed, searches have good locality in the sense that intermediate nodes on the search path have keys that are not far outside of the range between the source and destination.
SODA	Approximating the two-level facility location problem via a quasi-greedy approach.	Jiawei Zhang	2004	We propose a quasi-greedy algorithm for approximating the classical uncapacitated 2-level facility location problem (2-LFLP). Our algorithm, unlike the standard greedy algorithm, selects a sub-optimal candidate at each step. It also relates the minimization 2-LFLP problem, in an interesting way, to the maximization version of the single level facility location problem. Another feature of our algorithm is that it combines the technique of randomized rounding with that of dual fitting.This new approach enables us to approximate the metric 2-LFLP in polynomial time with a ratio of 1:77, a significant improvement on the previously known approximation ratios. Moreover, our approach results in a local improvement procedure for the 2-LFLP, which is useful in improving the approximation guarantees for several other multi-level facility location problems.
SODA	Proceedings of the Fifteenth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2004, New Orleans, Louisiana, USA, January 11-14, 2004	J. Ian Munro	2004	Proceedings of the Fifteenth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2004, New Orleans, Louisiana, USA, January 11-14, 2004
STOC	Multilinear formulas and skepticism of quantum computing.	Scott Aaronson	2004	"Several researchers, including Leonid Levin, Gerard 't Hooft, and Stephen Wolfram, have argued that quantum mechanics will break down before the factoring of large numbers becomes possible. If this is true, then there should be a natural set of quantum states that can account for all quantum computing experiments performed to date, but not for Shor's factoring algorithm. We investigate as a candidate the set of states expressible by a polynomial number of additions and tensor products. Using a recent lower bound on multilinear formula size due to Raz, we then show that states arising in quantum error-correction require nΩ(log n) additions and tensor products even to approximate, which incidentally yields the first superpolynomial gap between general and multilinear formula size of functions. More broadly, we introduce a complexity classification of pure quantum states, and prove many basic facts about this classification. Our goal is to refine vague ideas about a breakdown of quantum mechanics into specific hypotheses that might be experimentally testable in the near future."
STOC	Lower bounds for local search by quantum arguments.	Scott Aaronson	2004	"The problem of finding a local minimum of a black-box function is central for understanding local search as well as quantum adiabatic algorithms. For functions on the Boolean hypercube $\left\{0,1\right\}^n$, we show a lower bound of $\Omega\left(2^{n/4}/n\right)$ on the number of queries needed by a quantum computer to solve this problem. More surprisingly, our approach, based on Ambainis's quantum adversary method, also yields a lower bound of $\Omega\left(2^{n/2}/n^2\right)$ on the problem's classical randomized query complexity. This improves and simplifies a 1983 result of Aldous. Finally, in both the randomized and quantum cases, we give the first nontrivial lower bounds for finding local minima on grids of constant dimension $d\geq3$."
STOC	A conjecture about polynomial time computable lattice-lattice functions.	Miklós Ajtai	2004	We formulate a conjecture which describes all of the polynomial time computable (p. t. c. ) functions f with domain(f)=lattice n, range(f) ⊆ lattice m, m ≤ nc, where latticen is the set of lattices in Rn with determinant 1. A former conjecture, the 0-1-conjecture, of the author states that all 0,1-valued functions defined on latticen are constant almost everywhere. Since the n-dimensional lattices as Abelian groups are pairwise isomorphic we can say that, according to this conjecture, the value of a p. t. c. 0,1-function may depend only on the algebraic structure of the lattice and not on the metric defined on it. The new conjecture generalizes this statement for functions where the value is also a lattice. As a typical example we can think of the function f(L)=L′, where L′ is the dual of L. When both the domain and the range of the functions are n-dimensional lattices with determinants 1 then, according to the conjecture, every p. c. t. functions are either constant or identical almost everywhere to f(L)=AL, or f(L)=AL′, where A is a suitably chosen linear transformation with determinant one.There is a striking analogy between the new conjecture and theorems describing the uniquely definable functions which assign for each n-dimensional vectorspace an m-dimensional vectorspace. These theorems are closely related to questions about the Axiom of Choice. In this analogy polynomial time computation corresponds to definability (in set theory) and lattices to finite dimensional vectorspaces.
STOC	The two possible values of the chromatic number of a random graph.	Dimitris Achlioptas,Assaf Naor	2004	For every d > 0, let kd be the smallest integer k such that d < 2k log k. We prove that the chromatic number of a random graph G(n,d/n) is either kd or kd+1 almost surely. If d ∈ (2k log k - log k, 2k log k) we further prove that the chromatic number almost surely equals k+1.
STOC	On the performance of greedy algorithms in packet buffering.	Susanne Albers,Markus Schmidt	2004	We study a basic buffer management problem that arises in network switches. Consider $m$ input ports, each of which is equipped with a buffer (queue) of limited capacity. Data packets arrive online and can be stored in the buffers if space permits; otherwise packet loss occurs. In each time step the switch can transmit one packet from one of the buffers to the output port. The goal is to maximize the number of transmitted packets. Simple arguments show that any work-conserving algorithm, which serves any nonempty buffer, is 2-competitive. Azar and Richter recently presented a randomized online algorithm and gave lower bounds for deterministic and randomized strategies. In practice, greedy algorithms are very important because they are fast, use little extra memory, and reduce packet loss by always serving a longest queue. In this paper we first settle the competitive performance of the entire family of greedy strategies. We prove that greedy algorithms are not better than 2-competitive no matter how ties are broken. Our lower bound proof uses a new recursive construction for building adversarial buffer configurations that may be of independent interest. We also give improved lower bounds for deterministic and randomized online algorithms.In this paper we present the first deterministic online algorithm that is better than 2-competitive. We develop a modified greedy algorithm, called semigreedy, and prove that it achieves a competitive ratio of $17/9 \approx 1.89$. The new algorithm is simple, fast, and uses little extra memory. Only when the risk of packet loss is low does it not serve the longest queue. Additionally we study scenarios when an online algorithm is granted additional resources. We consider resource augmentation with respect to memory and speed; i.e., an online algorithm may be given larger buffers or higher transmission rates. We analyze greedy and other online strategies.
STOC	"Approximating the cut-norm via Grothendieck's inequality."	Noga Alon,Assaf Naor	2004	"The cut-norm $||A||_C$ of a real matrix $A=(a_{ij})_{i\in R,j\in S}$ is the maximum, over all $I \subset R$, $J \subset S$, of the quantity $|\sum_{i \in I, j\in J} a_{ij}|$. This concept plays a major role in the design of efficient approximation algorithms for dense graph and matrix problems. Here we show that the problem of approximating the cut-norm of a given real matrix is MAX SNP hard, and we provide an efficient approximation algorithm. This algorithm finds, for a given matrix $A=(a_{ij})_{i\in R,j\in S}$, two subsets $I \subset R$ and $J \subset S$, such that $|\sum_{i \in I, j\in J} a_{ij}| \geq \rho ||A||_C$, where $\rho>0$ is an absolute constant satisfying $\rho >0.56$. The algorithm combines semidefinite programming with a rounding technique based on Grothendieck's inequality. We present three known proofs of Grothendieck's inequality, with the necessary modifications which emphasize their algorithmic aspects. These proofs contain rounding techniques which go beyond the random hyperplane rounding of Goemans and Williamson [J. ACM, 42 (1995), pp. 1115-1145], allowing us to transfer various algorithms for dense graph and matrix problems to the sparse case."
STOC	Visibly pushdown languages.	Rajeev Alur,P. Madhusudan	2004	We propose the class of visibly pushdown languages as embeddings of context-free languages that is rich enough to model program analysis questions and yet is tractable and robust like the class of regular languages. In our definition, the input symbol determines when the pushdown automaton can push or pop, and thus the stack depth at every position. We show that the resulting class Vpl of languages is closed under union, intersection, complementation, renaming, concatenation, and Kleene-*, and problems such as inclusion that are undecidable for context-free languages are Exptime-complete for visibly pushdown automata. Our framework explains, unifies, and generalizes many of the decision procedures in the program analysis literature, and allows algorithmic verification of recursive programs with respect to many context-free properties including access control properties via stack inspection and correctness of procedures with respect to pre and post conditions. We demonstrate that the class Vpl is robust by giving two alternative characterizations: a logical characterization using the monadic second order (MSO) theory over words augmented with a binary matching predicate, and a correspondence to regular tree languages. We also consider visibly pushdown languages of infinite words and show that the closure properties, MSO-characterization and the characterization in terms of regular trees carry over. The main difference with respect to the case of finite words turns out to be determinizability: nondeterministic Büchi visibly pushdown automata are strictly more expressive than deterministic Muller visibly pushdown automata.
STOC	Quantum algorithms a decade after shor.	Andris Ambainis	2004	"In 1994, Peter Shor discovered a polynomial time quantum algorithm for factoring and discrete logarithm. Two years later, in 1996, Lov Grover discovered a search algorithm which is quadratically better than conventional search. By now, each of the two algorithms has developed into a line of research which goes well beyond the original algorithm. Shor's algorithm has inspired the study of quantum Fourier sampling which has resulted in more quantum algorithms for number-theoretic and group-theoretic problems. Grover's algorithm has developed into the area of quantum query algorithms.I will survey the developments in quantum query algorithms. The topics will include: applications of Grover's algorithm to element distinctness and other problems, lower bounds on quantum algorithms and the use of quantum random walks to design better search algorithm. I will also describe how some of techniques in this area can be used as ""quantum black boxes"" in an otherwise classical algorithm."
STOC	Lower bounds for linear degeneracy testing.	Nir Ailon,Bernard Chazelle	2004	"In the late nineties, Erickson proved a remarkable lower bound on the decision tree complexity of one of the central problems of computational geometry: given n numbers, do any r of them add up to 0? His lower bound of &Omega;(n&lceil;r/2&rceil;), for any fixed r, is optimal if the polynomials at the nodes are linear and at most r-variate. We generalize his bound to s-variate polynomials for s > r. Erickson's bound decays quickly as r grows and never reaches above pseudo-polynomial: we provide an exponential improvement. Our arguments are based on three ideas: (i) a geometrization of Erickson's proof technique; (ii) the use of error-correcting codes; and (iii) a tensor product construction for permutation matrices."
STOC	Expander flows, geometric embeddings and graph partitioning.	Sanjeev Arora,Satish Rao,Umesh V. Vazirani	2004	"We give a O(&sqrt;log n)-approximation algorithm for the sparsest cut, edge expansion, balanced separator, and graph conductance problems. This improves the O(log n)-approximation of Leighton and Rao (1988). We use a well-known semidefinite relaxation with triangle inequality constraints. Central to our analysis is a geometric theorem about projections of point sets in Rd, whose proof makes essential use of a phenomenon called measure concentration. We also describe an interesting and natural &ldquo;approximate certificate&rdquo; for a graph's expansion, which involves embedding an n-node expander in it with appropriate dilation and congestion. We call this an expander flow."
STOC	Adaptive routing with end-to-end feedback: distributed learning and geometric approaches.	Baruch Awerbuch,Robert D. Kleinberg	2004	Minimal delay routing is a fundamental task in networks. Since delays depend on the (potentially unpredictable) traffic distribution, online delay optimization can be quite challenging. While uncertainty about the current network delays may make the current routing choices sub-optimal, the algorithm can nevertheless try to learn the traffic patterns and keep adapting its choice of routing paths so as to perform nearly as well as the best static path. This online shortest path problem is a special case of online linear optimization, a problem in which an online algorithm must choose, in each round, a strategy from some compact set S ⊆ Rd so as to try to minimize a linear cost function which is only revealed at the end of the round. Kalai and Vempala[4] gave an algorithm for such problems in the transparent feedback model, where the entire cost function is revealed at the end of the round. Here we present an algorithm for online linear optimization in the more challenging opaque feedback model, in which only the cost of the chosen strategy is revealed at the end of the round. In the special case of shortest paths, opaque feedback corresponds to the notion that in each round the algorithm learns only the end-to-end cost of the chosen path, not the cost of every edge in the network.We also present a second algorithm for online shortest paths, which solves the shortest-path problem using a chain of online decision oracles, one at each node of the graph. This has several advantages over the online linear optimization approach. First, it is effective against an adaptive adversary, whereas our linear optimization algorithm assumes an oblivious adversary. Second, even in the case of an oblivious adversary, the second algorithm performs better than the first, as measured by their additive regret.
STOC	The zero-one principle for switching networks.	Yossi Azar,Yossi Richter	2004	"Recently, approximation analysis has been extensively used to study algorithms for routing weighted packets in various network settings. Although different techniques were applied in the analysis of diverse models, one common property was evident: the analysis of input sequences composed solely of two different values is always substantially easier, and many results are known only for restricted value sequences. Motivated by this, we introduce our zero-one principle for switching networks which characterizes a wide range of algorithms for which achieving c-approximation (as well as c-competitiveness) with respect to sequences composed of 0's and 1's implies achieving c-approximation. The zero-one principle proves to be very efficient in the design of switching algorithms, and substantially facilitates their analysis. We present three applications. First, we consider the Multi-Queue QoS Switching model and design a 3-competitive algorithm, improving the result from [6]. Second, we study the Weighted Dynamic Routing problem on a line topology of length k and present a (k+1)-competitive algorithm, which improves and generalizes the results from [1,12]. As a third application, we consider the work of [11], that compares the performance of local algorithms to the global optimum in various network topologies, and generalize their results from 2-value sequences to arbitrary value sequences."
STOC	Approximation algorithms for deadline-TSP and vehicle routing with time-windows.	Nikhil Bansal,Avrim Blum,Shuchi Chawla,Adam Meyerson	2004	"Given a metric space G on n nodes, with a start node r and deadlines D(v) for each vertex v, we consider the Deadline-TSP problem of finding a path starting at r that visits as many nodes as possible by their deadlines. We also consider the more general Vehicle Routing with Time-Windows problem, in which each node v also has a release-time R(v) and the goal is to visit as many nodes as possible within their ""time-windows"" [R(v),D(v)]. No good approximations were known previously for these problems on general metric spaces. We give an O(logn) approximation algorithm for Deadline-TSP, and extend this algorithm to an O(log2n) approximation for the Time-Window problem. We also give a bicriteria approximation algorithm for both problems: Given an ε>0, our algorithm produces a (1/ε) approximation, while exceeding the deadlines by a factor of 1+ε. We use as a subroutine for these results a constant-factor approximation that we develop for a generalization of the orienteering problem in which both the start and the end nodes of the path are fixed. In the process, we give a 3-approximation to the orienteering problem, improving on the previously best known 4-approximation of [6]."
STOC	Exponential separation of quantum and classical one-way communication complexity.	Ziv Bar-Yossef,T. S. Jayram,Iordanis Kerenidis	2004	"We give the first exponential separation between quantum and bounded-error randomized one-way communication complexity. Specifically, we define the Hidden Matching Problem HMn: Alice gets as input a string x ∈ (0, 1)n and Bob gets a perfect matching M on the n coordinates. Bob's goal is to output a tuple [i,j,b] such that the edge (i,j) belongs to the matching M and b = xi ⊕ xj. We prove that the quantum one-way communication complexity of HMn is O(log n), yet any randomized one-way protocol with bounded error must use Ω(√n) bits of communication. No asymptotic gap for one-way communication was previously known. Our bounds also hold in the model of Simultaneous Messages (SM) and hence we provide the first exponential separation between quantum SM and randomized SM with public coins.For a Boolean decision version of HMn, we show that the quantum one-way communication complexity remains O(log n) and that the 0-error randomized one-way communication complexity is Ω(n). We prove that any randomized linear one-way protocol with bounded error for this problem requires Ω(√[3] n log n) bits of communication."
STOC	Sublinear algorithms for testing monotone and unimodal distributions.	Tugkan Batu,Ravi Kumar,Ronitt Rubinfeld	2004	The complexity of testing properties of monotone and unimodal distributions, when given access only to samples of the distribution, is investigated. Two kinds of sublinear-time algorithms---those for testing monotonicity and those that take advantage of monotonicity---are provided. The first algorithm tests if a given distribution on [n] is monotone or far away from any monotone distribution in L1-norm; this algorithm uses O(√n) samples and is shown to be nearly optimal. The next algorithm, given a joint distribution on [n] x [n], tests if it is monotone or is far away from any monotone distribution in L1-norm; this algorithm uses O(n3/2) samples. The problems of testing if two monotone distributions are close in L1-norm and if two random variables with a monotone joint distribution are close to being independent in L1-norm are also considered. Algorithms for these problems that use only poly(log n) samples are presented. The closeness and independence testing algorithms for monotone distributions are significantly more efficient than the corresponding algorithms as well as the lower bounds for arbitrary distributions. Some of the above results are also extended to unimodal distributions.
STOC	Typical properties of winners and losers in discrete optimization.	René Beier,Berthold Vöcking	2004	We present a probabilistic analysis for a large class of combinatorial optimization problems containing, e. g., all binary optimization problems defined by linear constraints and a linear objective function over (0,1)n. By parameterizing which constraints are of stochastic and which are of adversarial nature, we obtain a semi-random input model that enables us to do a general average-case analysis for a large class of optimization problems while at the same time taking care for the combinatorial structure of individual problems. Our analysis covers various probability distributions for the choice of the stochastic numbers and includes smoothed analysis with Gaussian and other kinds of perturbation models as a special case. In fact, we can exactly characterize the smoothed complexity of optimization problems in terms of their random worst-case complexity.A binary optimization problem has a polynomial smoothed complexity if and only if it has a pseudopolynomial complexity. Our analysis is centered around structural properties of binary optimization problems, called winner, loser, and feasibility gaps. We show, when the coefficients of the objective function and/or some of the constraints are stochastic, then there usually exist a polynomial n-Ω(1) gap between the best and the second best solution as well as a polynomial slack to the boundary of the constraints. Similar to the condition number for linear programming, these gaps describe the sensitivity of the optimal solution to slight perturbations of the input and can be used to bound the necessary accuracy as well as the complexity for solving an instance. We exploit the gaps in form of an adaptive rounding scheme increasing the accuracy of calculation until the optimal solution is found. The strength of our techniques is illustrated by applications to various NP-hard optimization problems from mathematical programming, network design, and scheduling for which we obtain the the first algorithms with polynomial average-case/smoothed complexity.
STOC	Robust pcps of proximity, shorter pcps and applications to coding.	Eli Ben-Sasson,Oded Goldreich,Prahladh Harsha,Madhu Sudan,Salil P. Vadhan	2004	We continue the study of the trade-off between the length of probabilistically checkable proofs (PCPs) and their query complexity, establishing the following main results (which refer to proofs of satisfiability of circuits of size $n$): 1. We present PCPs of length $\exp(o(\log\log n)^2)\cdot n$ that can be verified by making $o(\log\log n)$ Boolean queries. 2. For every \epsilon>0, we present PCPs of length $\exp(\log^\epsilon n)\cdot n$ that can be verified by making a constant number of Boolean queries. In both cases, false assertions are rejected with constant probability (which may be set to be arbitrarily close to 1). The multiplicative overhead on the length of the proof, introduced by transforming a proof into a probabilistically checkable one, is just quasi polylogarithmic in the first case (of query complexity $o(\log\log n)$), and is $2^{(\log n)^\epsilon}$, for any $\epsilon > 0$, in the second case (of constant query complexity). Our techniques include the introduction of a new variant of PCPs that we call &ldquo;robust PCPs of proximity.&rdquo; These new PCPs facilitate proof composition, which is a central ingredient in the construction of PCP systems. (A related notion and its composition properties were discovered independently by Dinur and Reingold.) Our main technical contribution is a construction of a &ldquo;length-efficient&rdquo; robust PCP of proximity. While the new construction uses many of the standard techniques used in PCP constructions, it does differ from previous constructions in fundamental ways, and in particular does not use the &ldquo;parallelization&rdquo; step of Arora et al. [J. ACM, 45 (1998), pp. 501-555]. The alternative approach may be of independent interest. We also obtain analogous quantitative results for locally testable codes. In addition, we introduce a relaxed notion of locally decodable codes and present such codes mapping $k$ information bits to codewords of length $k^{1+\epsilon}$ for any $\epsilon>0$.
STOC	Isotopic implicit surface meshing.	Jean-Daniel Boissonnat,David Cohen-Steiner,Gert Vegter	2004	This paper addresses the problem of piecewise linear approximation of implicit surfaces. We first give a criterion ensuring that the zero-set of a smooth function and the one of a piecewise linear approximation of it are isotopic. Then, we deduce from this criterion an implicit surface meshing algorithm certifying that the output mesh is isotopic to the actual implicit surface. This is the first algorithm achieving this goal in a provably correct way.
STOC	Solving fractional packing problems in (1/?) iterations.	Daniel Bienstock,Garud Iyengar	2004	We adapt a method proposed by Nesterov [16] to design an algorithm that computes ε-optimal solutions to fractional packing problems by solving O*(ε-1 √Kn) separable convex quadratic programs, where K is the maximum number of non-zeros per row and n is the number of variables. We also show that the quadratic program can be approximated to any degree of accuracy by an appropriately defined piecewise-linear program. For the special case of the maximum concurrent flow problem on a graph G =(V,E) with rational capacities and demands we obtain an algorithm that computes an Ε-optimal flow by solving O*(ε-1 K3/2|E| √|V| (log 1/ε+ LU + LD)) shortest path problems, where K is the number of commodities, and LU, LD are, respectively, the number of bits needed to store the capacities and demands. We also show that the complexity of computing a maximum multicommodity flow is O*(1/εlog2(1/ε)). In contrast, previous algorithms required Ω(ε-2) iterations.
STOC	Counting complexity classes for numeric computations II: algebraic and semialgebraic sets.	Peter Bürgisser,Felipe Cucker	2004	"We define counting classes #PR and #PC in the Blum-Shub-Smale setting of computations over the real or complex numbers, respectively. The problems of counting the number of solutions of systems of polynomial inequalities over R, or of systems of polynomial equalities over C, respectively, turn out to be natural complete problems in these classes. We investigate to what extent the new counting classes capture the complexity of computing basic topological invariants of semialgebraic sets (over R) and algebraic sets (over C). We prove that the problem of computing the Euler-Yao characteristic of semialgebraic sets is FPR#PR-complete, and that the problem of computing the geometric degree of complex algebraic sets is FPC#PC-complete. We also define new counting complexity classes in the classical Turing model via taking Boolean parts of the classes above, and show that the problems to compute the Euler characteristic and the geometric degree of (semi)algebraic sets given by integer polynomials are complete in these classes. We complement the results in the Turing model by proving, for all k ∈ N, the FPSPACE-hardness of the problem of computing the kth Betti number of the set of real zeros of a given integer polynomial. This holds with respect to the singular homology as well as for the Borel-Moore homology."
STOC	Multi-processor scheduling to minimize flow time with epsilon resource augmentation.	Chandra Chekuri,Ashish Goel,Sanjeev Khanna,Amit Kumar	2004	Multi-processor scheduling to minimize flow time with epsilon resource augmentation.
STOC	The all-or-nothing multicommodity flow problem.	Chandra Chekuri,Sanjeev Khanna,F. Bruce Shepherd	2004	We consider the all-or-nothing multicommodity flow problem in general graphs. We are given a capacitated undirected graph G=(V,E,u) and set of k pairs s1 t1, s2t2, …, sktk. Each pair has a unit demand. The objective is to find a largest subset S of 1,2,…,k such that for every i in S we can send a flow of one unit between si and ti. Note that this differs from the edge-disjoint path problem (EDP) in that we do not insist on integral flows for the pairs. This problem is NP-hard, and APX-hard, even on trees. For trees, a 2--approximation is known for the cardinality case and a 4--approximation for the weighted case. In this paper we build on a recent result of Räcke on low congestion oblivious routing in undirected graphs to obtain a poly-logarithmic approximation for the all-or-nothing problem in general undirected graphs. The best previous known approximation for all-or-nothing flow problem was O(min(n<2/3, √m)), the same as that for EDP. Our algorithm extends to the case where each pair siti has a demand di associated with it and we need to completely route di to get credit for pair i. We also consider the online admission control version where pairs arrive online and the algorithm has to decide immediately on its arrival whether to accept it or not. We obtain a randomized algorithm with a competitive ratio that is similar to the approximation ratio for the offline algorithm.
STOC	Linear FPT reductions and computational lower bounds.	Jianer Chen,Xiuzhen Huang,Iyad A. Kanj,Ge Xia	2004	We develop new techniques for deriving very strong computational lower bounds for a class of well-known NP-hard problems, including weighted satisfiability, dominating set, hitting set, set cover, clique, and independent set. For example, although a trivial enumeration can easily test in time O(nk) if a given graph of n vertices has a clique of size k, we prove that unless an unlikely collapse occurs in parameterized complexity theory, the problem is not solvable in time f(k) no(k) for any function f, even if we restrict the parameter value k to be bounded by an arbitrarily small function of n. Under the same assumption, we prove that even if we restrict the parameter values k to be Θ(μ(n)) for any reasonable function μ, no algorithm of running time no(k) can test if a graph of n vertices has a clique of size k. Similar strong lower bounds are also derived for other problems in the above class. Our techniques can be extended to derive computational lower bounds on approximation algorithms for NP-hard optimization problems. For example, we prove that the NP-hard distinguishing substring selection problem, for which a polynomial time approximation scheme has been recently developed, has no polynomial time approximation schemes of running time f(1/ε)no(1/ε) for any function f unless an unlikely collapse occurs in parameterized complexity theory.
STOC	(Almost) tight bounds and existence theorems for confluent flows.	Jiangzhuo Chen,Robert D. Kleinberg,László Lovász,Rajmohan Rajaraman,Ravi Sundaram,Adrian Vetta	2004	A flow is said to be confluent if at any node all the flow leaves along a single edge. Given a directed graph G with k sinks and non-negative demands on all the nodes of G, we consider the problem of determining a confluent flow that routes every node demand to some sink such that the maximum congestion at a sink is minimized. Confluent flows arise in a variety of application areas, most notably in networking; in fact, most flows in the Internet are confluent since Internet routing is destination based.We present near-tight approximation algorithms, hardness results, and existence theorems for confluent flows. The main result of this paper is a polynomial-time algorithm for determining a confluent flow with congestion at most 1 + ln(k) in G, if G admits a splittable flow with congestion at most 1. We complement this result in two directions. First, we present a graph G that admits a splittable flow with congestion at most 1, yet no confluent flow with congestion smaller than Hk, thus establishing tight upper and lower bounds to within an additive constant less than 1. Second, we show that it is NP-hard to approximate the congestion of an optimal confluent flow to within a factor of (lg k)/2, thus resolving the polynomial-time approximability to within a multiplicative constant. We also consider a demand maximization version of the problem. We show that if G admits a splittable flow of congestion at most 1, then a variant of the congestion minimization algorithm yields a confluent flow in G with congestion at most 1 that satisfies 1/3 fraction of total demand.We show that the gap between confluent flows and splittable flows is much smaller, if the underlying graph were k connected. In particular, we prove that k-connected graphs with k sinks admit confluent flows of congestion less than C + dmax, where C is the congestion of the best splittable flow, and dmax is the maximum demand of any node in G. The proof of this existence theorem is non-constructive and relies on topological techniques introduced in [16].
STOC	Collective asynchronous reading with polylogarithmic worst-case overhead.	Bogdan S. Chlebus,Dariusz R. Kowalski,Alexander A. Shvartsman	2004	The Collect problem for an asynchronous shared-memory system has the objective for the processors to learn all values of a collection of shared registers, while minimizing the total number of read and write operations. First abstracted by Saks, Shavit, and Woll [37], Collect is among the standard problems in distributed computing, The model consists of $n$ asynchronous processes, each with a single-writer multi-reader register of a polynomial capacity. The best previously known deterministic solution performs O(n3/2log n) reads and writes, and it is due to Ajtai, Aspnes, Dwork, and Waarts [3]. This paper presents a new deterministic algorithm that performs O(n log7 n) read/write operations, thus substantially improving the best previous upper bound. Using an approach based on epidemic rumor-spreading, the novelty of the new algorithm is in using a family of expander graphs and ensuring that each of the successive groups of processes collect and propagate sufficiently many rumors to the next group. The algorithm is adapted to the Repeatable Collect problem, which is an on-line version. The competitive latency of the new algorithm is O(log7 n) vs. the much higher competitive latency O(√nlog n) given in [3]. A result of independent interest in this paper abstracts a gossiping game that is played on a graph and that gives its payoff in terms of expansion.
STOC	Asymmetric k-center is log -hard to approximate.	Julia Chuzhoy,Sudipto Guha,Eran Halperin,Sanjeev Khanna,Guy Kortsarz,Joseph Naor	2004	In the Asymmetric k-Center problem, the input is an integer k and a complete digraph over n points together with a distance function obeying the directed triangle inequality. The goal is to choose a set of k points to serve as centers and to assign all the points to the centers, so that the maximum distance of any point to its center is as small as possible. We show that the Asymmetric k-Center problem is hard to approximate up to a factor of log* n - Θ(1) unless NP ⊆ DTIME(nlog log n). Since an O(log* n)-approximation algorithm is known for this problem, this essentially resolves the approximability of this problem. This is the first natural problem whose approximability threshold does not polynomially relate to the known approximation classes. We also resolve the approximability threshold of the metric k-Center problem with costs.
STOC	New hardness results for congestion minimization and machine scheduling.	Julia Chuzhoy,Joseph Naor	2004	We study the approximability of two natural NP-hard problems. The first problem is congestion minimization in directed networks. We are given a directed capacitated graph and a set of source-sink pairs. The goal is to route all pairs with minimum congestion on the network edges. A special well-studied case of this problem is the edge-disjoint paths problem, where all edges have unit capacities. The second problem is discrete machine scheduling, where we are given a set of jobs, and for each job a list of intervals in which it can be scheduled. The goal is to find the smallest number of machines on which all jobs can be scheduled, such that no two jobs assigned to the same machine overlap. Both problems are known to be O(log n/log log n)-approximable via the randomized rounding technique of Raghavan and Thompson. However, until recently, only a Max SNP hardness was known for each problem. We make some progress in closing this gap by showing that both problem are Ω(log log n)-hard to approximate unless NP ⊆ DTIME(nO(log log log n)). Our hardness proof for congestion minimization holds even for the special case of the edge-disjoint paths problem.
STOC	"Dictionary matching and indexing with errors and don't cares."	Richard Cole,Lee-Ad Gottlieb,Moshe Lewenstein	2004	"This paper considers various flavors of the following online problem: preprocess a text or collection of strings, so that given a query string p, all matches of p with the text can be reported quickly. In this paper we consider matches in which a bounded number of mismatches are allowed, or in which a bounded number of ""don't care"" characters are allowed. The specific problems we look at are: indexing, in which there is a single text t, and we seek locations where p matches a substring of t; dictionary queries, in which a collection of strings is given upfront, and we seek those strings which match p in their entirety; and dictionary matching, in which a collection of strings is given upfront, and we seek those substrings of a (long) p which match an original string in its entirety. These are all instances of an all-to-all matching problem, for which we provide a single solution.The performance bounds all have a similar character. For example, for the indexing problem with n=|t| and m=|p|, the query time for k substitutions is O(m + (c1 log n)k⁄k! + # matches), with a data structure of size O(n (c2 log n)k⁄k!) and a preprocessing time of O(n (c2 log n)k⁄k!), where c1,c2 > 1 are constants. The deterministic preprocessing assumes a weakly nonuniform RAM model; this assumption is not needed if randomization is used in the preprocessing."
STOC	"An approximate König's theorem for edge-coloring weighted bipartite graphs."	José R. Correa,Michel X. Goemans	2004	"An approximate König's theorem for edge-coloring weighted bipartite graphs."
STOC	Estimating the weight of metric minimum spanning trees in sublinear-time.	Artur Czumaj,Christian Sohler	2004	In this paper we present a sublinear-time $(1+\varepsilon)$-approximation randomized algorithm to estimate the weight of the minimum spanning tree of an $n$-point metric space. The running time of the algorithm is $\widetilde{\mathcal{O}}(n/\varepsilon^{\mathcal{O}(1)})$. Since the full description of an $n$-point metric space is of size $\Theta(n^2)$, the complexity of our algorithm is sublinear with respect to the input size. Our algorithm is almost optimal as it is not possible to approximate in $o(n)$ time the weight of the minimum spanning tree to within any factor. We also show that no deterministic algorithm can achieve a $B$-approximation in $o(n^2/B^3)$ time. Furthermore, it has been previously shown that no $o(n^2)$ algorithm exists that returns a spanning tree whose weight is within a constant times the optimum.
STOC	The spending constraint model for market equilibrium: algorithmic, existence and uniqueness results.	Nikhil R. Devanur	2004	The traditional model of market equilibrium supports impressive existence results, including the celebrated Arrow-Debreu Theorem. However, in this model, polynomial time algorithms for computing (or approximating) equilibria are known only for linear utility functions. We present a new, and natural, model of market equilibrium that not only admits existence and uniqueness results paralleling those for the traditional model but is also amenable to efficient algorithms.
STOC	A simple polynomial-time rescaling algorithm for solving linear programs.	John Dunagan,Santosh Vempala	2004	The perceptron algorithm, developed mainly in the machine learning literature, is a simple greedy method for finding a feasible solution to a linear program (alternatively, for learning a threshold function). In spite of its exponential worst-case complexity, it is often quite useful, in part due to its noise-tolerance and also its overall simplicity. In this paper, we show that a randomized version of the perceptron algorithm along with periodic rescaling runs in polynomial-time. The resulting algorithm for linear programming has an elementary description and analysis.
STOC	Unconditional lower bounds on the time-approximation tradeoffs for the distributed minimum spanning tree problem.	Michael Elkin	2004	The design of distributed approximation protocols is a relatively new rapidly developing area of research. However, so far little progress was done in the study of the hardness of distributed approximation. In this paper we initiate the systematic study of this subject, and show strong unconditional lower bounds on the time-approximation tradeoff of the distributed minimum spanning tree problem, and some of its variants.
STOC	The complexity of pure Nash equilibria.	Alex Fabrikant,Christos H. Papadimitriou,Kunal Talwar	2004	We investigate from the computational viewpoint multi-player games that are guaranteed to have pure Nash equilibria. We focus on congestion games, and show that a pure Nash equilibrium can be computed in polynomial time in the symmetric network case, while the problem is PLS-complete in general. We discuss implications to non-atomic congestion games, and we explore the scope of the potential function method for proving existence of pure Nash equilibria.
STOC	On sums of independent random variables with unbounded variance, and estimating the average degree in a graph.	Uriel Feige	2004	We prove the following inequality: for every positive integer $n$ and every collection $X_1, \ldots, X_n$ of nonnegative independent random variables, each with expectation 1, the probability that their sum remains below $n+1$ is at least $\alpha > 0$. Our proof produces a value of $\alpha = 1/13 \simeq 0.077$, but we conjecture that the inequality also holds with $\alpha = 1/e \simeq 0.368$.As an example for the use of the new inequality, we consider the problem of estimating the average degree of a graph by querying the degrees of some of its vertices. We show the following threshold behavior: approximation factors above 2 require far fewer queries than approximation factors below 2. The new inequality is used in order to get tight (up to multiplicative constant factors) relations between the number of queries and the quality of the approximation. We show how the degree approximation algorithm can be used in order to quickly find those edges in a network that belong to many shortest paths.
STOC	Sorting and searching in the presence of memory faults (without redundancy).	Irene Finocchi,Giuseppe F. Italiano	2004	We investigate the design of algorithms resilient to memory faults, i. e., algorithms that, despite the corruption of some memory values during their execution, are able to produce a correct output on the set of uncorrupted values. In this framework, we consider two fundamental problems: sorting and searching. In particular, we prove that any O(nlog n) comparison-based sorting algorithm can tolerate at most O((nlog n)1/2) memory faults. Furthermore, we present one comparison-based sorting algorithm with optimal space and running time that is resilient to O((nlog n)1/3) faults. We also prove polylogarithmic lower and upper bounds on fault-tolerant searching.
STOC	The difficulty of testing for isomorphism against a graph that is given in advance.	Eldar Fischer	2004	"Motivated by a question from [E. Fischer, G. Kindler, D. Ron, S. Safra, and A. Samorodnitsky, J. Comput. System Sci., 68 (2004), pp. 753--787], we investigate the number of queries required for testing that an input graph G is isomorphic to a fixed graph H that is given in advance. We correlate this number with a measure of the ""complexity"" of H that we define here, by proving both an upper bound and a lower bound on the number of queries that depends on this new measure. As far as we know this is the first characterization of this type for graphs."
STOC	Finding paths and cycles of superpolylogarithmic length.	Harold N. Gabow	2004	Let $\ell$ be the number of edges in a longest cycle containing a given vertex $v$ in an undirected graph. We show how to find a cycle through $v$ of length $\exp(\Omega(\sqrt {\log \ell/\log\log \ell}))$ in polynomial time. This implies the same bound for the longest cycle, longest $vw$-path, and longest path. The previous best bound for longest path is length $\Omega( (\log \ell )^2/\, \log\log \ell)$ due to Bjo&uml;rklund and Husfeldt. Our approach, which builds on Bjo&uml;rklund and Husfeldt&rsquo;s, uses cycles to enlarge cycles. This self-reducibility allows the approximation method to be iterated.
STOC	Computing Nash equilibria for scheduling on restricted parallel links.	Martin Gairing,Thomas Lücking,Marios Mavronicolas,Burkhard Monien	2004	We consider the problem of routing n users on m parallel links, under the restriction that each user may only be routed on a link from a certain set of allowed links for the user. Thus, the problem is equivalent to the correspondingly restricted problem of assigning n jobs to m parallel machines. In a pure Nash equilibrium, no user may improve its own individual cost (delay) by unilaterally switching to another link from its set of allowed links. As our main result, we introduce a polynomial time algorithm to compute from any given assignment a pure Nash equilibrium with non-increased makespan. The algorithm gradually changes a given assignment by pushing unsplittable user traffics through a network that is defined by the users and the links. Here, we use ideas from blocking flows. Furthermore, we use similar techniques as in the generic Preflow-Push algorithm to approximate a schedule with minimum makespan, gaining an improved approximation factor of 2 - 1/w1 for identical links, where w1 is the largest user traffic. We extend this result to related links, gaining an approximation factor of 2. Our approximation algorithms run in polynomial time. We close with tight upper bounds on the coordination ratio for pure Nash equilibria.
STOC	Auction algorithms for market equilibrium.	Rahul Garg,Sanjiv Kapoor	2004	In this paper we study algorithms for computing market equilibrium in markets with linear utility functions. The buyers in the market have an initial endowment given by a portfolio of goods. The market equilibrium problem is to compute a price vector that ensures market clearing, i.e., the demand of a positively priced good equals its supply, and given the prices, each buyer maximizes its utility. The problem is of considerable interest in economics. This paper presents a formulation of the market equilibrium problem as a parameterized linear program. We construct a family of duals corrresponding to these parameterized linear programs and show that finding the market equilibrium is the same as finding a linear program from this family of linear programs. The market-clearing conditions arise naturally from complementary slackness conditions. We then define an auction mechanism that computes prices such that approximate market clearing is achieved. The algorithm we obtain outperforms previously known methods.
STOC	Sharp thresholds For monotone properties in random geometric graphs.	Ashish Goel,Sanatan Rai,Bhaskar Krishnamachari	2004	Random geometric graphs result from taking n uniformly distributed points in the unit cube, [0,1]d, and connecting two points if their Euclidean distance is at most r, for some prescribed r. We show that monotone properties for this class of graphs have sharp thresholds by reducing the problem to bounding the bottleneck matching on two sets of $n$ points distributed uniformly in [0,1]d. We present upper bounds on the threshold width, and show that our bound is sharp for d = 1 and at most a sublogarithmic factor away for d ≥ 2. Interestingly, the threshold width is much sharper for random geometric graphs than for Bernoulli random graphs. Further, a random geometric graph is shown to be a subgraph, with high probability, of another independently drawn random geometric graph with a slightly larger radius; this property is shown to have no analogue for Bernoulli random graphs.
STOC	Boosted sampling: approximation algorithms for stochastic optimization.	Anupam Gupta,Martin Pál,R. Ravi,Amitabh Sinha	2004	Several combinatorial optimization problems choose elements to minimize the total cost of constructing a feasible solution that satisfies requirements of clients. In the Steiner Tree problem, for example, edges must be chosen to connect terminals (clients); in Vertex Cover, vertices must be chosen to cover edges (clients); in Facility Location, facilities must be chosen and demand vertices (clients) connected to these chosen facilities. We consider a stochastic version of such a problem where the solution is constructed in two stages: Before the actual requirements materialize, we can choose elements in a first stage. The actual requirements are then revealed, drawn from a pre-specified probability distribution π thereupon, some more elements may be chosen to obtain a feasible solution for the actual requirements. However, in this second (recourse) stage, choosing an element is costlier by a factor of σ> 1. The goal is to minimize the first stage cost plus the expected second stage cost.We give a general yet simple technique to adapt approximation algorithms for several deterministic problems to their stochastic versions via the following method. First stage: Draw σ independent sets of clients from the distribution π and apply the approximation algorithm to construct a feasible solution for the union of these sets. Second stage: Since the actual requirements have now been revealed, augment the first-stage solution to be feasible for these requirements. We use this framework to derive constant factor approximations for stochastic versions of Vertex Cover, Steiner Tree and Uncapacitated Facility Location for arbitrary distributions π in one fell swoop. For special (product) distributions, we obtain additional and improved results. Our techniques adapt and use the notion of strict cost-shares introduced in [5].
STOC	Better extractors for better codes?	Venkatesan Guruswami	2004	"We present an explicit construction of codes that can be list decoded from a fraction (1-ε) of errors in sub-exponential time and which have rate ε/logO(1)(1/ε). This comes close to the optimal rate of Ω(ε), and is the first sub-exponential complexity construction to beat the rate of ε2 achieved by Reed-Solomon or algebraic-geometric codes. Our construction is based on recent extractor constructions with very good seed length [17]. While the ""standard"" way of viewing extractors as codes (as in [16]) cannot beat the O(ε2) rate barrier due to the 2 log (1/ε) lower bound on seed length for extractors, we use such extractor codes as a component in a well-known expander-based construction scheme to get our result. The O(ε2) rate barrier also arises if one argues about list decoding using the minimum distance (via the so-called Johnson bound) --- so this also gives the first explicit construction that ""beats the Johnson bound"" for list decoding from errors.The main message from our work is perhaps conceptual, namely that good strong extractors for low min-entropies will yield near-optimal list decodable codes. Given all the progress that has been made on extractors, we view this as an optimistic avenue to look for better list decodable codes, both by looking for better explicit extractor constructions, as well as by importing non-trivial techniques from the extractor world in reasoning about and constructing codes."
STOC	Rational secret sharing and multiparty computation: extended abstract.	Joseph Y. Halpern,Vanessa Teague	2004	We consider the problems of secret sharing and multiparty computation, assuming that agents prefer to get the secret (resp., function value) to not getting it, and secondarily, prefer that as few as possible of the other agents get it. We show that, under these assumptions, neither secret sharing nor multiparty function computation is possible using a mechanism that has a fixed running time. However, we show that both are possible using randomized mechanisms with constant expected running time.
STOC	On coresets for k-means and k-median clustering.	Sariel Har-Peled,Soham Mazumdar	2004	In this paper, we show the existence of small coresets for the problems of computing k-median and k-means clustering for points in low dimension. In other words, we show that given a point set P in Rd, one can compute a weighted set S ⊆ P, of size O(k ε-d log n), such that one can compute the k-median/means clustering on S instead of on P, and get an (1+ε)-approximation. As a result, we improve the fastest known algorithms for (1+ε)-approximate k-means and k-median. Our algorithms have linear running time for a fixed k and ε. In addition, we can maintain the (1+ε)-approximate k-median or k-means clustering of a stream when points are being only inserted, using polylogarithmic space and update time.
STOC	Completeness in two-party secure computation: a computational view.	Danny Harnik,Moni Naor,Omer Reingold,Alon Rosen	2004	"A Secure Function Evaluation (SFE) of a two-variable function f(·,·) is a protocol that allows two parties with inputs x and y to evaluate f(x,y) in a manner where neither party learns ""more than is necessary"". A rich body of work deals with the study of completeness for secure two-party computation. A function f is complete for SFE if a protocol for securely evaluating f allows the secure evaluation of all (efficiently computable) functions. The questions investigated are which functions are complete for SFE, which functions have SFE protocols unconditionally and whether there are functions that are neither complete nor have efficient SFE protocols.The previous study of these questions was mainly conducted from an Information Theoretic point of view and provided strong answers in the form of combinatorial properties. However, we show that there are major differences between the information theoretic and computational settings. In particular, we show functions that are considered as having SFE unconditionally by the combinatorial criteria but are actually complete in the computational setting. We initiate the fully computational study of these fundamental questions. Somewhat surprisingly, we manage to provide an almost full characterization of the complete functions in this model as well. More precisely, we present a computational criterion (called computational row non-transitivity) for a function f to be complete for the asymmetric case. Furthermore, we show a matching criterion called computational row transitivity for f to have a simple SFE (based on no additional assumptions). This criterion is close to the negation of the computational row non-transitivity and thus we essentially characterize all ""nice"" functions as either complete or having SFE unconditionally."
STOC	Using nondeterminism to amplify hardness.	Alexander Healy,Salil P. Vadhan,Emanuele Viola	2004	"We revisit the problem of hardness amplification in $\mathcal{NP}$, as recently studied by O'Donnell [J. Comput. System Sci., 69 (2004), pp. 68-94]. We prove that if $\mathcal{NP}$ has a balanced function $f$ such that any circuit of size $s(n)$ fails to compute $f$ on a $1/\poly(n)$ fraction of inputs, then $\mathcal{NP}$ has a function $f'$ such that any circuit of size $s'(n)=s(\sqrt{n})^{\Omega(1)}$ fails to compute $f'$ on a $1/2 - 1/s'(n)$ fraction of inputs. In particular, \begin{enumerate} \item if $s(n)=n^{\omega(1)}$, we amplify to hardness $1/2-1/n^{\omega(1)}$; \item if $s(n)=2^{n^{\Omega(1)}}$, we amplify to hardness $1/2-1/2^{n^{\Omega(1)}}$; \item if $s(n)=2^{\Omega(n)}$, we amplify to hardness $1/2-1/2^{\Omega(\sqrt{n})}$. \end{enumerate}Our results improve those of of O'Donnell, which amplify to $1/2-1/\sqrt{n}$. O'Donnell also proved that no construction of a certain general form could amplify beyond $1/2-1/n$. We bypass this barrier by using both derandomization and nondeterminism in the construction of $f'$.We also prove impossibility results demonstrating that both our use of nondeterminism and the hypothesis that $f$ is balanced are necessary for ""black-box"" hardness amplification procedures (such as ours)."
STOC	A new PCP outer verifier with applications to homogeneous linear equations and max-bisection.	Jonas Holmerin,Subhash Khot	2004	"We show an optimal hardness result for the following problem: Given a system of homogeneous linear equations over GF(2) with 3 variables per equation, find a balanced assignment that satisfies maximum number of equations. For arbitrarily small constant ζ > 0, we show that it is hard to determine (in polynomial time) whether such a system has a balanced assignment that satisfies 1-ζ fraction of equations or there is no balanced assignment that satisfies more than ½+ζ fraction of equations. As a corollary, we show that it is hard to approximate (in polynomial time) the Max-Bisection problem within factor 16⁄15-ζ. These hardness results hold under the assumption NP ⊈ ∩ε > 0 DTIME(2nε).Our results are obtained via a construction of a new PCP outer verifier that has a mixing property and a smoothness property. These properties are crucial in the analysis of the inner verifier. No previous outer verifier can achieve both these properties simultaneously. An outer verifier is essentially a 2-query PCP over a large alphabet. Loosely speaking, the mixing property says that the locations of the two queries read by the verifier are uncorrelated. The smoothness property says that the verifier's acceptance predicate is close to being a bijective predicate. Our construction relies on the algebraic techniques used to prove the PCP Theorem. This is in contrast with all earlier constructions that use the PCP Theorem as a black-box. The progress in inapproximability theory seems to require new ideas for building outer verifiers and our construction takes a first step in that direction."
STOC	Algorithms for dynamic geometric problems over data streams.	Piotr Indyk	2004	Algorithms for dynamic geometric problems over data streams.
STOC	Batch codes and their applications.	Yuval Ishai,Eyal Kushilevitz,Rafail Ostrovsky,Amit Sahai	2004	A batch code encodes a string x into an m-tuple of strings, called buckets, such that each batch of k bits from x can be decoded by reading at most one (more generally, t) bits from each bucket. Batch codes can be viewed as relaxing several combinatorial objects, including expanders and locally decodable codes. We initiate the study of these codes by presenting some constructions, connections with other problems, and lower bounds. We also demonstrate the usefulness of batch codes by presenting two types of applications: trading maximal load for storage in certain load-balancing scenarios, and amortizing the computational cost of private information retrieval (PIR) and related cryptographic protocols.
STOC	Spectral partitioning, eigenvalue bounds, and circle packings for graphs of bounded genus.	Jonathan A. Kelner	2004	In this paper, we address two long-standing questions about finding good separators in graphs of bounded genus and degree: 1. It is a classical result of Gilbert, Hutchinson, and Tarjan [J. Algorithms, 5 (1984), pp. 391-407] that one can find asymptotically optimal separators on these graphs if given both the graph and an embedding of it onto a low genus surface. Does there exist a simple, efficient algorithm to find these separators, given only the graph and not the embedding? 2. In practice, spectral partitioning heuristics work extremely well on these graphs. Is there a theoretical reason why this should be the case? We resolve these two questions by showing that a simple spectral algorithm finds separators of cut ratio $O(\sqrt{\smash[b]{g/n}})$ and vertex bisectors of size $O(\sqrt{gn})$ in these graphs, both of which are optimal. As our main technical lemma, we prove an $O(g/n)$ bound on the second smallest eigenvalue of the Laplacian of such graphs and show that this is tight, thereby resolving a conjecture of Spielman and Teng. While this lemma is essentially combinatorial in nature, its proof comes from continuous mathematics, drawing on the theory of circle packings and the geometry of compact Riemann surfaces.
STOC	A decentralized algorithm for spectral analysis.	David Kempe,Frank McSherry	2004	"In many large network settings, such as computer networks, social networks, or hyperlinked text documents, much information can be obtained from the network's spectral properties. However, traditional centralized approaches for computing eigenvectors struggle with at least two obstacles: the data may be difficult to obtain (both due to technical reasons and because of privacy concerns), and the sheer size of the networks makes the computation expensive. A decentralized, distributed algorithm addresses both of these obstacles: it utilizes the computational power of all nodes in the network and their ability to communicate, thus speeding up the computation with the network size. And as each node knows its incident edges, the data collection problem is avoided as well.Our main result is a simple decentralized algorithm for computing the top k eigenvectors of a symmetric weighted adjacency matrix, and a proof that it converges essentially in O(τMIXlog2 n) rounds of communication and computation, where τMIX is the mixing time of a random walk on the network. An additional contribution of our work is a decentralized way of actually detecting convergence, and diagnosing the current error. Our protocol scales well, in that the amount of computation performed at any node in any one round, and the sizes of messages sent, depend polynomially on k, but not on the (typically much larger) number n of nodes."
STOC	Low distortion maps between point sets.	Claire Kenyon,Yuval Rabani,Alistair Sinclair	2004	We initiate the study of the minimum distortion problem: given as input two n-point metric spaces, find a bijection between them with minimum distortion. This is an abstraction of certain geometric problems in shape and image matching, and is also a natural variation and extension of the fundamental problems of graph isomorphism and bandwidth. Our focus is on algorithms that find an optimal (or near-optimal) bijection when the distortion is fairly small. We present a polynomial time algorithm that finds an optimal bijection between two line metrics, provided the distortion is less than 3+2√2. We also give a parameterized polynomial time algorithm that finds an optimal bijection between an arbitrary unweighted graph metric and a bounded-degree tree metric.
STOC	Using mixture models for collaborative filtering.	Jon M. Kleinberg,Mark Sandler	2004	A collaborative filtering system at an e-commerce site or similar service uses data about aggregate user behavior to make recommendations tailored to specific user interests. We develop recommendation algorithms with provable performance guarantees in a probabilistic mixture model for collaborative filtering proposed by Hoffman and Puzicha. We identify certain novel parameters of mixture models that are closely connected with the best achievable performance of a recommendation algorithm; we show that for any system in which these parameters are bounded, it is possible to give recommendations whose quality converges to optimal as the amount of data grows.All our bounds depend on a new measure of independence that can be viewed as an L1-analogue of the smallest singular value of a matrix. Using this, we introduce a technique based on generalized pseudoinverse matrices and linear programming for handling sets of high-dimensional vectors. We also show that standard approaches based on L2-spectral methods are not strong enough to yield comparable results, thereby suggesting some inherent limitations of spectral analysis.
STOC	Approximation algorithm for k-node connected subgraphs via critical graphs.	Guy Kortsarz,Zeev Nutov	2004	We present two new approximation algorithms for the problem of finding a k-node connected spanning subgraph (directed or undirected) of minimum cost. The best known approximation guarantees for this problem were O(min (k,n/√n-k)) for both directed and undirected graphs, and O(ln k) for undirected graphs with n ≥ 6k2, where n is the number of nodes in the input graph. Our first algorithm has approximation ratio O(k/n-kln 2 k, which is O(ln2 k) except for very large values of k, namely, k=n-o(n). This algorithm is based on a new result on l-connected p-critical graphs, which is of independent interest in the context of graph theory. Our second algorithm uses the primal-dual method and has approximation ratio O(√n ln k) for all values of n,k. Combining these two gives an algorithm with approximation ratio O(ln k • min (√k, k/n-k ln k)), which asymptotically improves the best known approximation guarantee for directed graphs for all values of n,k, and for undirected graphs for k> √n⁄6. Moreover, this is the first algorithm that has an approximation guarantee better than Θ(k) for all values of n,k. Our approximation ratio also provides an upper bound on the integrality gap of the standard LP-relaxation to the problem.As a byproduct, we also get the following result which is of independent interest. To get a faster implementation of our algorithms, we consider the problem of adding a minimum-cost edge set to increase the outconnectivity of a directed graph by Δ a graph is said to be l-outconnected from its node r if it contains l internally disjoint paths from r to any other node. The best known time complexity for the later problem is O(m3). For the particular case of Δ=1, we give a primal-dual algorithm with running time O(m2).
STOC	Primal-dual algorithms for deterministic inventory problems.	Retsef Levi,Robin Roundy,David B. Shmoys	2004	We consider several classical models in deterministic inventory theory: the single-item lot-sizing problem, the joint replenishment problem, and the multistage assembly problem. These inventory models have been studied extensively, and play a fundamental role in broader planning issues, such as the management of supply chains. For each of these problems, we wish to balance the cost of maintaining surplus inventory for future demand against the cost of replenishing inventory more frequently. For example, in the joint replenishment problem, demand for several commodities is specified over a discrete finite planning horizon, the cost of maintaining inventory is linear in the number of units held, but the cost incurred for ordering a commodity is independent of the size of the order; furthermore, there is an additional fixed cost incurred each time a nonempty subset of commodities is ordered. The goal is to find a policy that satisfies all demands on time and minimizes the overall holding and ordering cost. We shall give a novel primal-dual framework for designing algorithms for these models that significantly improve known results in several ways: the performance guarantees for the quality of the solutions improve on or match previously known results; the performance guarantees hold under much more general assumptions about the structure of the costs, and the algorithms and their analysis are significantly simpler than previous known results. Finally, our primal-dual framework departs from the structure of previously studied primal-dual approximation algorithms in significant ways, and we believe that our approach may find applications in other settings. More specifically, we provide 2-approximation algorithms for the joint replenishment problem and for the assembly problem, and solve the single-item lot-sizing problem to optimality. The results for the joint replenishment and the lot-sizing problems also hold for their generalizations with back orders allowed. As a byproduct of our work, we prove known and new upper bounds on the integrality gap of some linear-programming (LP) relaxations of the abovementioned problems.
STOC	Hit-and-run from a corner.	László Lovász,Santosh Vempala	2004	We show that the hit-and-run random walk mixes rapidly starting from any interior point of a convex body. This is the first random walk known to have this property. In contrast, the ball walk can take exponentially many steps from some starting points. The proof extends to sampling an exponential density over a convex body.
STOC	"Know thy neighbor's neighbor: the power of lookahead in randomized P2P networks."	Gurmeet Singh Manku,Moni Naor,Udi Wieder	2004	"Several peer-to-peer networks are based upon randomized graph topologies that permit efficient greedy routing, e. g., randomized hypercubes, randomized Chord, skip-graphs and constructions based upon small-world percolation networks. In each of these networks, a node has out-degree Θ(log n), where n denotes the total number of nodes, and greedy routing is known to take O(log n) hops on average. We establish lower-bounds for greedy routing for these networks, and analyze Neighbor-of-Neighbor (NoN)-greedy routing. The idea behind NoN, as the name suggests, is to take a neighbor's neighbors into account for making better routing decisions.The following picture emerges: Deterministic routing networks like hypercubes and Chord have diameter Θ(log n) and greedy routing is optimal. Randomized routing networks like randomized hypercubes, randomized Chord, and constructions based on small-world percolation networks, have diameter Θ(log n / log log n) with high probability. The expected diameter of Skip graphs is also Θ(log n / log log n). In all of these networks, greedy routing fails to find short routes, requiring Ω(log n) hops with high probability. Surprisingly, the NoN-greedy routing algorithm is able to diminish route-lengths to Θ(log n / log log n) hops, which is asymptotically optimal."
STOC	Approximate max-integral-flow/min-multicut theorems.	Kenji Obata	2004	We establish several approximate max-integral-flow / min-multicut theorems. While in general this ratio can be very large, we prove strong approximation ratios in the case where the min-multicut is a constant fraction ε of the total capacity of the graph. This setting is motivated by several combinatorial and algorithmic applications. Prior to this work, a general max-integral-flow / min-multicut bound was known only for the special case where the graph is a tree. We prove that, for arbitrary graphs, the max-integral-flow / min-multicut ratio is O(ε-1 log k), where k is the number of commodites; for graphs excluding a fixed subgraph as a minor (for instance, planar graphs), O(1 / ε); and, for dense graphs, O(1√ε). Our proofs are constructive in the sense that we give efficient algorithms which compute either an integral flow achieving the claimed approximation ratios, or a witness that the precondition is violated.
STOC	Multi-linear formulas for permanent and determinant are of super-polynomial size.	Ran Raz	2004	An arithmetic formula is multilinear if the polynomial computed by each of its subformulas is multilinear. We prove that any multilinear arithmetic formula for the permanent or the determinant of an n &times; n matrix is of size super-polynomial in n. Previously, super-polynomial lower bounds were not known (for any explicit function) even for the special case of multilinear formulas of constant depth.
STOC	Bounded-concurrent secure multi-party computation with a dishonest majority.	Rafael Pass	2004	We show how to securely realize any multi-party functionality in a way that preserves security under an a-priori bounded number of concurrent executions, regardless of the number of corrupted parties. Previous protocols for the above task either rely on set-up assumptions such as a Common Reference String, or require an honest majority. Our constructions are in the plain model and rely on standard intractability assumptions (enhanced trapdoor permutations and collision resistant hash functions). Even though our main focus is on feasibility of concurrent multi-party computation we actually obtain a protocol using only a constant number of communication rounds. As a consequence our protocol yields the first construction of constant-round phstand-alone secure multi-party computation with a dishonest majority, proven secure under standard (polynomial-time) hardness assumptions; previous solutions to this task either require logarithmic round-complexity, or subexponential hardness assumptions. The core of our protocol is a novel construction of (concurrently) simulation-sound zero-knowledge protocols, which might be of independent interest. Finally, we extend the framework constructed to give a protocol for secure multi-party (and thus two-party) computation for any number of corrupted parties, which remains secure even when arbitrary subsets of parties concurrently execute the protocol, possibly with interchangeable roles. As far as we know, for the case of two-party or multi-party protocols with a dishonest majority, this is the first positive result for any non-trivial functionality which achieves this property in the plain model.
STOC	Lower bounds for dynamic connectivity.	Mihai Patrascu,Erik D. Demaine	2004	"We prove an Ω(lg Erik n) cell-probe lower bound on maintaining connectivity in dynamic graphs, as well as a more general trade-off between updates and queries. Our bound holds even if the graph is formed by disjoint paths, and thus also applies to trees and plane graphs. The bound is known to be tight for these restricted cases, proving optimality of these data structures (e. g., Sleator and Tarjan's dynamic trees). Our trade-off is known to be tight for trees, and the best two data structures for dynamic connectivity in general graphs are points on our trade-off curve. In this sense these two data structures are optimal, and this tightness serves as strong evidence that our lower bounds are the best possible. From a more theoretical perspective, our result is the first logarithmic cell-probe lower bound for any problem in the natural class of dynamic language membership problems, breaking the long standing record of Ω(lg n / lg lg n). In this sense, our result is the first data-structure lower bound that is ""truly"" logarithmic, i. e., logarithmic in the problem size counted in bits. Obtaining such a bound is listed as one of three major challenges for future research by Miltersen [13] (the other two challenges remain unsolved). Our techniques form a general framework for proving cell-probe lower bounds on dynamic data structures. We show how our framework also applies to the partial-sums problem to obtain a nearly complete understanding of the problem in cell-probe and algebraic models, solving several previously posed open problems."
STOC	New notions of security: achieving universal composability without trusted setup.	Manoj Prabhakaran,Amit Sahai	2004	We propose a modification to the framework of Universally Composable (UC) security [3]. Our new notion involves comparing the real protocol execution with an ideal execution involving ideal functionalities (just as in UC-security), but allowing the environment and adversary access to some super-polynomial computational power. We argue the meaningfulness of the new notion, which in particular subsumes many of the traditional notions of security. We generalize the Universal Composition theorem of [3] to the new setting. Then under new computational assumptions, we realize secure multi-party computation (for static adversaries) without a common reference string or any other set-up assumptions, in the new framework. This is known to be impossible under the UC framework.
STOC	A fully dynamic reachability algorithm for directed graphs with an almost linear update time.	Liam Roditty,Uri Zwick	2004	"We obtain a new fully dynamic algorithm for the reachability problem in directed graphs. Our algorithm has an amortized update time of O(m+n log n) and a worst-case query time of O(n), where m is the current number of edges in the graph, and n is the number of vertices in the graph. Each update operation either inserts a set of edges that touch the same vertex, or deletes an arbitrary set of edges. The algorithm is deterministic and uses fairly simple data structures. This is the first algorithm that breaks the O(n2) update barrier for all graphs with o(n2) edges.One of the ingredients used by this new algorithm may be interesting in its own right. It is a new dynamic algorithm for strong connectivity in directed graphs with an interesting persistency property. Each insert operation creates a new version of the graph. A delete operation deletes edges from emphall versions. Strong connectivity queries can be made on each version of the graph. The algorithm handles each update in O(mα(m,n)) amortized time, and each query in O(1) time, where α(m,n) is a functional inverse of Ackermann's function appearing in the analysis of the union-find data structure. Note that the update time of O(mα(m,n)), in case of a delete operation, is the time needed for updating all versions of the graph."
STOC	The quantum adiabatic optimization algorithm and local minima.	Ben Reichardt	2004	The quantum adiabatic optimization algorithm uses the adiabatic theorem from quantum physics to minimize a function by interpolation between two Hamiltonians. The quantum wave function can sometimes tunnel through significant obstacles. However it can also sometimes get stuck in local minima, even for fairly simple problems. An initial Hamiltonian which insufficiently mixes computational basis states is analogous to a poorly mixing Markov transition rule. We study a physical system -- the Ising quantum chain with alternating sector interaction defects, but constant transverse field -- which is equivalent to applying the quantum adiabatic algorithm to a particular SAT problem. We prove that for a constant range of values for the transverse field, the spectral gap is exponentially small in the sector length. Indeed, we prove that there are exponentially many eigenvalues all exponentially close to the ground state energy. Applying the adiabatic theorem therefore takes exponential time, even for this simple problem.
STOC	A new family of Cayley expanders (?).	Eyal Rozenman,Aner Shalev,Avi Wigderson	2004	We assume that for some fixed large enough integer d, the symmetric group Sd can be generated as an expander using d1/30 generators. Under this assumption, we explicitly construct an infinite family of groups Gn, and explicit sets of generators Yn ⊂ Gn, such that all generating sets have bounded size (at most d1/7), and the associated Cayley graphs are all expanders. The groups Gn above are very simple, and completely different from previous known examples of expanding groups. Indeed, Gn is (essentially) all symmetries of the d-regular tree of depth n. The proof is completely elementary, using only simple combinatorics and linear algebra. The recursive structure of the groups Gn (iterated wreath products of the alternating group Ad) allows for an inductive proof of expansion, using the group theoretic analogue [4] of the zig-zag graph product of [38]. The explicit construction of the generating sets Yn uses an efficient algorithm for solving certain equations over these groups, which relies on the work of [33] on the commutator width of perfect groups.We stress that our assumption above on weak expansion in the symmetric group is an open problem. We conjecture that it holds for all d. We discuss known results related to its likelihood in the paper.
STOC	Quantum and classical query complexities of local search are polynomially related.	Miklos Santha,Mario Szegedy	2004	"Let f be an integer valued function on a finite set V. We call an undirected graph G(V,E) a neighborhood structure for f. The problem of finding a local minimum for f can be phrased as: for a fixed neighborhood structure G(V,E) find a vertex x ∈ V such that f(x) is not bigger than any value that f takes on some neighbor of x. The complexity of the algorithm is measured by the number of questions of the form ""what is the value of f on x?"" We show that the deterministic, randomized and quantum query complexities of the problem are polynomially related. This generalizes earlier results of Aldous[4] Ald and Aaronson [1] Aar and solves the main open problem in Aar."
STOC	Nearly-linear time algorithms for graph partitioning, graph sparsification, and solving linear systems.	Daniel A. Spielman,Shang-Hua Teng	2004	We present algorithms for solving symmetric, diagonally-dominant linear systems to accuracy ε in time linear in their number of non-zeros and log (κf (A) ε), where κf (A) is the condition number of the matrix defining the linear system. Our algorithm applies the preconditioned Chebyshev iteration with preconditioners designed using nearly-linear time algorithms for graph sparsification and graph partitioning.
STOC	Bypassing the embedding: algorithms for low dimensional metrics.	Kunal Talwar	2004	The doubling dimension of a metric is the smallest k such that any ball of radius 2r can be covered using 2k balls of radius r. This concept for abstract metrics has been proposed as a natural analog to the dimension of a Euclidean space. If we could embed metrics with low doubling dimension into low dimensional Euclidean spaces, they would inherit several algorithmic and structural properties of the Euclidean spaces. Unfortunately however, such a restriction on dimension does not suffice to guarantee embeddibility in a normed space.In this paper we explore the option of bypassing the embedding. In particular we show the following for low dimensional metrics: Quasi-polynomial time (1+ε)-approximation algorithm for various optimization problems such as TSP, k-median and facility location. (1+ε)-approximate distance labeling scheme with optimal label length. (1+ε)-stretch polylogarithmic storage routing scheme.
STOC	Network games.	Éva Tardos	2004	Network games.
STOC	Derandomizing homomorphism testing in general groups.	Amir Shpilka,Avi Wigderson	2004	The main result of this paper is a near-optimal derandomization of the affine homomorphism test of Blum, Luby, and Rubinfeld [J. Comput. System Sci., 47 (1993), pp. 549-595]. We show that for any groups G and &Ggr;, and any expanding generating set S of G, the natural deramdomized version of the BLR test in which we pick an element x randomly from G and y randomly from S and test whether $f(x)\cdot f(y)=f(x\cdot y)$, performs nearly as well (depending of course on the expansion) as the original test. Moreover, we show that the underlying homomorphism can be found by the natural local &ldquo;belief propagation decoding.&rdquo; We note that the original BLR test uses $2\log_2 |G|$ random bits, whereas the derandomized test uses only $(1+o(1))\log_2 |G|$ random bits. This factor of 2 savings in the randomness complexity translates to a near quadratic savings in the length of the tables in the related locally testable codes (and possibly probabilistically checkable proofs which may use them). Our result is a significant generalization of recent results that either refer to the special case of the groups $G=Z_p^m$ and $&Ggr; =Z_p$ or are nonconstructive. We use simple combinatorial arguments and the transitivity of Cayley graphs (and this analysis gives optimal results up to constant factors). Previous techniques used the Fourier transform, a method which seems unextendable to general groups (and furthermore gives suboptimal bounds). Finally, we provide a polynomial time (in $|G|$) construction of a (somewhat) small ($|G|^{\epsilon}$) set of expanding generators for every group $G$, which yield efficient testers of randomness $(1+\epsilon) \log |G|$ for $G$. This result follows from a simple derandomization of a known probabilistic construction.
STOC	Depth through breadth, or why should we attend talks in other areas?	Avi Wigderson	2004	"Given that the two other invited lectures in this conference are on such remote areas as ""Quantum Computation"" and ""Algorithmic Game Theory,"" and given the diversity of other topics represented in the program, it makes sense to ask if the STOC/FOCS community is still one.Indeed, the program chair has asked me to respond to this question.In the talk I'll try to illustrate, with a few (of many) examples, how the presence of such diversity in our community and conferences was actually responsible for important progress in specific areas of research, why I find these a natural and expected phenomena, and why I expect this trend to continue."
STOC	Graph entropy and quantum sorting problems.	Andrew Chi-Chih Yao	2004	"Let P = (X, < P) be a partial order on a set of n elements X = x1, x2,..., xn. Define the quantum sorting problem QSORTP as: given n distinct numbers x1, x2,..., xn consistent with P, sort them by a quantum decision tree using comparisons of the form ""xi: xj"". Let Qε(P) be the minimum number of queries used by any quantum decision tree for solving QSORTP with error less than ε (where 0 < ε < 1/10 is fixed). It was proved by Hoyer, Neerbek and Shi (Algorithmica 34 (2002), 429--448) that, when P0 is the empty partial order, Qε(P0) ≥ Ω (n log n), i. e., the classical information lower bound holds for quantum decision trees when the input permutations are unrestricted.In this paper we show that the classical information lower bound holds, up to an additive linear term, for quantum decision trees for any partial order P. Precisely, we prove Qε(P) ≥ c log2 e(P)-c'n where c,c' > 0 are constants and e(P) is the number of linear orderings consistent with P. Our proof builds on an interesting connection between sorting and Korner's graph entropy that was first noted and developed by Kahn and Kim (JCSS 51(1995), 390--399)."
STOC	Proceedings of the 36th Annual ACM Symposium on Theory of Computing, Chicago, IL, USA, June 13-16, 2004	László Babai	2004	Proceedings of the 36th Annual ACM Symposium on Theory of Computing, Chicago, IL, USA, June 13-16, 2004
FOCS	A Characterization of the (natural) Graph Properties Testable with One-Sided Error.	Noga Alon,Asaf Shapira	2005	The problem of characterizing all the testable graph properties is considered by many to be the most important open problem in the area of property testing. Our main result in this paper is a solution of an important special case of this general problem: Call a property tester oblivious if its decisions are independent of the size of the input graph. We show that a graph property ${\cal P}$ has an oblivious one-sided error tester if and only if ${\cal P}$ is semihereditary. We stress that any &ldquo;natural&rdquo; property that can be tested (either with one-sided or with two-sided error) can be tested by an oblivious tester. In particular, all the testers studied thus far in the literature were oblivious. Our main result can thus be considered as a precise characterization of the natural graph properties, which are testable with one-sided error. One of the main technical contributions of this paper is in showing that any hereditary graph property can be tested with one-sided error. This general result contains as a special case all the previous results about testing graph properties with one-sided error. More importantly, as a special case of our main result, we infer that some of the most well-studied graph properties, both in graph theory and computer science, are testable with one-sided error. Some of these properties are the well-known graph properties of being perfect, chordal, interval, comparability, permutation, and more. None of these properties was previously known to be testable.
FOCS	Additive Approximation for Edge-Deletion Problems.	Noga Alon,Asaf Shapira,Benny Sudakov	2005	A graph property is monotone if it is closed under removal of vertices and edges. In this paper we consider the following edge-deletion problem; given a monotone property P and a graph G, compute the smallest number of edge deletions that are needed in order to turn G into a graph satisfying P. We denote this quantity by \rm E^1p (G). The first result of this paper states that the edge-deletion problem can be efficiently approximated for any monotone property.For any \in > 0 and any monotone property P, there is a deterministic algorithm, which given a graph G of size n, approximates {\rm E}^1 _p (G)\, in time O(n^2) to within an additive error of \in n^2 .Given the above, a natural question is for which monotone properties one can obtain better additive approximations of \rm E^1 _p. Our second main result essentially resolves this problem by giving a precise characterization of the monotone graph properties for which such approximations exist.1. If there is a bipartite graph that does not satisfy P, then there is a \delta > 0 for which it is possible to approximate \rm E^1p to within an additive error of n^2-\delta in polynomial time.2.On the other hand, if all bipartite graphs satisfy P, then for any \delta > 0 it is NP-hard to approximate \rm E^1 _p to within an additive error of n^2-\delta.While the proof of (1) is simple, the proof of (2) requires several new ideas and involves tools from Extremal Graph Theory together with spectral techniques. This approach may be useful for obtaining other hardness of approximation results. Interestingly, prior to this work it was not even
FOCS	On the Complexity of Two-PlayerWin-Lose Games.	Timothy G. Abbott,Daniel M. Kane,Paul Valiant	2005	The efficient computation of Nash equilibria is one of the most formidable challenges in computational complexity today. The problem remains open for two-player games. We show that the complexity of two-player Nash equilibria is unchanged when all outcomes are restricted to be 0 or 1. That is, win-or-lose games are as complex as the general case for two-player games.
FOCS	Metric Embeddings with Relaxed Guarantees.	Ittai Abraham,Yair Bartal,Hubert T.-H. Chan,Kedar Dhamdhere,Anupam Gupta,Jon M. Kleinberg,Ofer Neiman,Aleksandrs Slivkins	2005	We consider the problem of embedding finite metrics with slack: we seek to produce embeddings with small dimension and distortion while allowing a (small) constant fraction of all distances to be arbitrarily distorted. This definition is motivated by recent research in the networking community, which achieved striking empirical success at embedding Internet latencies with low distortion into low-dimensional Euclidean space, provided that some small slack is allowed. Answering an open question of Kleinberg, Slivkins, and Wexler [29], we show that provable guarantees of this type can in fact be achieved in general: any finite metric can be embedded, with constant slack and constant distortion, into constant-dimensional Euclidean space. We then show that there exist stronger embeddings into \ell 1 which exhibit gracefully degrading distortion: these is a single embedding into \ell 1 that achieves distortion at most O(\log \frac{1}{\varepsilon }) on allbut at most an \varepsilon fraction of distances, simultaneously for all \varepsilon > 0. We extend this with distortion O(\log \frac{1}{\varepsilon })to maps into general \ell p, p\ge 1 for several classes of metrics, including those with bounded doubling dimension and those arising from the shortest-path metric of a graph with an excluded minor. Finally, we show that many of our constructions are tight, and give a general technique to obtain lower bounds for \varepsilon-slack embeddings from lower bounds for low-distortion embeddings.
FOCS	Hardness of Approximating the Closest Vector Problem with Pre-Processing.	Mikhail Alekhnovich,Subhash Khot,Guy Kindler,Nisheeth K. Vishnoi	2005	We show that, unless NP\subseteqDTIME(2^{poly\log (n)}), the closest vector problem with pre-processing, for \ell \rho norm for any p \ge 1, is hard to approximate within a factor of (\log n)^{1/p - \ell } for any \varepsilon > 0. This improves the previous best factor of 3^{1/p} - \varepsilon due to Regev [19]. Our results also imply that under the same complexity assumption, the nearest codeword problem with pre-processing is hard to approximate within a factor of (\log n)^{1 - \varepsilon }for any \varepsilon > 0.
FOCS	Fitting tree metrics: Hierarchical clustering and Phylogeny.	Nir Ailon,Moses Charikar	2005	Given dissimilarity data on pairs of objects in a set, we study the problem of fitting a tree metric to this data so as to minimize additive error (i.e. some measure of the difference between the tree metric and the given data). This problem arises in constructing an M-level hierarchical clustering of objects (or an ultrametric on objects) so as to match the given dissimilarity data - a basic problem in statistics. Viewed in this way, the problem is a generalization of the correlation clustering problem (which corresponds to M = 1). We give a very simple randomized combinatorial algorithm for the Mlevel hierarchical clustering problem that achieves an approximation ratio of M+2. This is a generalization of a previous factor 3 algorithm for correlation clustering on complete graphs. The problem of fitting tree metrics also arises in phylogeny where the objective is to learn the evolution tree by fitting a tree to dissimilarity data on taxa. The quality of the fit is measured by taking the \ellp norm of the difference between the tree metric constructed and the given data. Previous results obtained a factor 3 approximation for finding the closest tree tree metric under the \ell\infty norm. No non-trivial approximation for general \ellp norms was known before. We present a novel LP formulation for this problem and obtain an O(({\rm{log n log log n}})^{1/p} ) approximation using this. En route, we obtain an O(({\rm{log n log log n}})^{1/p} ) approximation for the closest ultrametric under the \ellp norm. Our techniques are based on representing and viewing an ultrametric as a hierarchy of clusterings, and may be useful in other contexts.
FOCS	Hardness of the Undirected Edge-Disjoint Paths Problem with Congestion.	Matthew Andrews,Julia Chuzhoy,Sanjeev Khanna,Lisa Zhang	2005	Hardness of the Undirected Edge-Disjoint Paths Problem with Congestion.
FOCS	On Non-Approximability for Quadratic Programs.	Sanjeev Arora,Eli Berger,Elad Hazan,Guy Kindler,Muli Safra	2005	This paper studies the computational complexity of the following type of quadratic programs: given an arbitrary matrix whose diagonal elements are zero, find \chi \varepsilon {-1, 1}^n that maximizes \chi ^{\rm T} Mx this problem recently attracted attention due to its application in various clustering settings, as well as an intriguing connection to the famous Grothendieck inequality. It is approximable to within a factor of O(log n), and known to be NP-hard to approximate within any factor better than 13/110 - \varepsilon for all \varepsilon > O. We show showthat it is quasi-NP-hard to approximate to a factor better than O(Log^\gamman) for some \gamma > 0.The integrality gap of the natural semide?nite relaxation for this problem is known as the Grothendieck constant the complete graph, and known to be \theta (\log n). The proof this fact was nonconstructive, and did not yield an explicit problem instance where this integrality gap is achieved. Our techniques yield an explicit instance for which the integrality gap is \Omega (\frac{{\log n}}{{\log \log n}}), essentially answering one of the open problems of Alon et al. [AMMN].
FOCS	Fast Algorithms for Approximate Semide.nite Programming using the Multiplicative Weights Update Method.	Sanjeev Arora,Elad Hazan,Satyen Kale	2005	Semidefinite programming (SDP) relaxations appear in many recent approximation algorithms but the only general technique for solving such SDP relaxations is via interior point methods. We use a Lagrangian-relaxation based technique (modified from the papers of Plotkin, Shmoys, and Tardos (PST), and Klein and Lu) to derive faster algorithms for approximately solving several families of SDP relaxations. The algorithms are based upon some improvements to the PST ideas-which lead to new results even for their framework - as well as improvements in approximate eigenvalue computations by using random sampling.
FOCS	From optimal measurement to efficient quantum algorithms for the hidden subgroup problem over semidirect product groups.	Dave Bacon,Andrew M. Childs,Wim van Dam	2005	We approach the hidden subgroup problem by performing the so-called pretty good measurement on hidden subgroup states. For various groups that can be expressed as the semidirect product of an abelian group and a cyclic group, we show that the pretty good measurement is optimal and that its probability of success and unitary implementation are closely related to an average-case algebraic problem. By solving this problem, we find efficient quantum algorithms for a number of nonabelian hidden subgroup problems, including some for which no efficient algorithm was previously known: certain metacyclic groups as well as all groups of the form Z^r _p xZp for fixed r (including the Heisenberg group, r = 2). In particular, our results show that entangled measurements across multiple copies of hidden subgroup states can be useful for efficiently solving the nonabelian HSP.
FOCS	Mechanism Design via Machine Learning.	Maria-Florina Balcan,Avrim Blum,Jason D. Hartline,Yishay Mansour	2005	Mechanism Design via Machine Learning.
FOCS	A Tale of Two Dimensional Bin Packing.	Nikhil Bansal,Andrea Lodi,Maxim Sviridenko	2005	"The 2-dimensional Bin Packing problem (2BP) is a generalization of the classical Bin Packing problem and is defined as follows: Given a collection of rectangles specified by their width and height, oack: these into minimum number of squares bins of units size. We study the case of ""orthogonal packing without rotations"", where rectangles cannot be rotated and must be packed parallel to the edges of a bin.Often in practical cases of 2BP problems there are additional constraints on how complicated the packing patterns in a bin can be. A well-studied and frequently used constraint is that every rectangle in the packing must be obtainable by recursively applying a sequence of edge-to-edge cuts parallel to the edge of the bin. Such cuts are known as guillotine cuts. Our main results is that the guillotine 2BP problem admits an asymptotic polynomial time approximation scheme. This is sharp contrast with the fact that the general 2BP problem is APX-Hard. En route to our main result, we show a structural theorem about approximating general guilootine packings by simpler packings, which could be of independent interest."
FOCS	How To Play Almost Any Mental Game Over The Net - Concurrent Composition via Super-Polynomial Simulation.	Boaz Barak,Amit Sahai	2005	"We construct a secure protocol for any multi-party functionality that remains secure (under a relaxed definition of security introduced by Prabhakaran and Sahai (STOC ¿04)) when executed concurrently with multiple copies of itself and other protocols, without any assumptions on existence of trusted parties, common reference string, honest majority or synchronicity of the network. The relaxation of security is obtained by allowing the ideal-model simulator to run in quai-polynomial (as opposed to polynomial) time. Quasipolynomial simulation suffices to ensure security for most applications of multi-party computation. Furthermore, Lindell (FOCS ¿03, TCC¿ 04) recently showed that such a protocol is impossible to obtain under the more standard defi- nition of polynomial-time simulation by an ideal adversary. Our construction is the first such protocol under reasonably standard cryptographic assumptions (i.e., existence of a hash function collection that is collision resistent with respect to circuits of subexponential size, and existence of trapdoor permutations which are secure with respect to circuits of quasi-polynomial size). We introduce a new technique: ""protocol condensing"". That is, taking a protocol that has strong security properties but requires super-polynomial communication and computation, and then transforming it into a protocol with polynomial communication and computation, that still inherits the strong security properties of the original protocol. Our result is obtained by combining this technique with previous techniques of Canetti, Lindell, Ostrovsky, and Sahai (STOC ¿02) and Pass (STOC ¿04)."
FOCS	Nash Equilibria in Random Games.	Imre Bárány,Santosh Vempala,Adrian Vetta	2005	"We consider Nash equilibria in 2-player random games and analyze a simple Las Vegas algorithm for finding an equilibrium. The algorithm is combinatorial and always finds a Nash equilibrium; on m &times; n payoff matrices, it runs in time O(m2nloglog n + n2mloglog m) with high probability. Our result follows from showing that a 2-player random game has a Nash equilibrium with supports of size two with high probability, at least 1 - O(1&#x002F;log n). Our main tool is a polytope formulation of equilibria. &copy; 2007 Wiley Periodicals, Inc. Random Struct. Alg., 2007"
FOCS	On the Complexity of Real Functions.	Mark Braverman	2005	"We establish a new connection between the two most common traditions in the theory of real computation, the Blum-Shub-Smale model and the Computable Analysis approach. We then use the connection to develop a notion of computability and complexity of functions over the reals that can be viewed as an extension of both models. We argue that this notion is very natural when one tries to determine just how ""difficult"" a certain function is for a very rich class of functions."
FOCS	Analysis and Prediction of the Long-Run Behavior of Probabilistic Sequential Programs with Recursion (Extended Abstract).	Tomás Brázdil,Javier Esparza,Antonín Kucera	2005	We introduce a family of long-run average properties of Markov chains that are useful for purposes of performance and reliability analysis, and show that these properties can effectively be checked for a subclass of infinite-state Markov chains generated by probabilistic programs with recursive procedures. We also show how to predict these properties by analyzing finite prefixes of runs, and present an ef?cient prediction algorithm for the mentioned subclass of Markov chains.
FOCS	A Recursive Greedy Algorithm for Walks in Directed Graphs.	Chandra Chekuri,Martin Pál	2005	Given an arc-weighted directed graph G = (V, A, \ell) and a pair of nodes s, t, we seek to find an s-t walk of length at most B that maximizes some given function f of the set of nodes visited by the walk. The simplest case is when we seek to maximize the number of nodes visited: this is called the orienteering problem. Our main result is a quasipolynomial time algorithm that yields an O(log OPT) approximation for this problem when f is a given submodular set function. We then extend it to the case when a node v is counted as visited only if the walk reaches v in its time window [R(v),D(v)]. We apply the algorithm to obtain several new results. First, we obtain an O(log OPT) approximation for a generalization of the orienteering problem in which the profit for visiting each node may vary arbitrarily with time. This captures the time window problem considered earlier for which, even in undirected graphs, the best approximation ratio known [4] is O(\log^2 OPT). The second application is an O(\log^2 k) approximation for the k-TSP problem in directed graphs (satisfying asymmetric triangle inequality). This is the first non-trivial approximation algorithm for this problem. The third application is an O(\log^2 k) approximation (in quasi-poly time) for the group Steiner problem in undirected graphs where k is the number of groups. This improves earlier ratios [15, 19, 8]] by a logarithmic factor and almost matches the inapproximability threshold on trees [20]. This connection to group Steiner trees also enables us to prove that the problem we consider is hard to approximate to a ratio better than \Omega(\log^{1 - \varepsilon} OPT), even in undirected graphs.
FOCS	Error Correction via Linear Programming.	Emmanuel J. Candès,Mark Rudelson,Terence Tao,Roman Vershynin	2005	Error Correction via Linear Programming.
FOCS	Algorithmic Techniques and Tools from Computational Geometry.	Bernard Chazelle	2005	Algorithmic Techniques and Tools from Computational Geometry
FOCS	Group-theoretic Algorithms for Matrix Multiplication.	Henry Cohn,Robert D. Kleinberg,Balázs Szegedy,Christopher Umans	2005	We further develop the group-theoretic approach to fast matrix multiplication introduced by Cohn and Umans, and for the first time use it to derive algorithms asymptotically faster than the standard algorithm. We describe several families of wreath product groups that achieve matrix multiplication exponent less than 3, the asymptotically fastest of which achieves exponent 2.41. We present two conjectures regarding specific improvements, one combinatorial and the other algebraic. Either one would imply that the exponent of matrix multiplication is 2.
FOCS	Cryptography In the Bounded Quantum-Storage Model.	Ivan Damgård,Serge Fehr,Louis Salvail,Christian Schaffner	2005	"We initiate the study of two-party cryptographic primitives with unconditional security, assuming that the adversary's quantum memory is of bounded size. We show that oblivious transfer and bit commitment can be implemented in this model using protocols where honest parties need no quantum memory, whereas an adversarial player needs quantum memory of size at least $n/2$ in order to break the protocol, where $n$ is the number of qubits transmitted. This is in sharp contrast to the classical bounded-memory model, where we can only tolerate adversaries with memory of size quadratic in honest players' memory size. Our protocols are efficient and noninteractive and can be implemented using today's technology. On the technical side, a new entropic uncertainty relation involving min-entropy is established."
FOCS	On Learning Mixtures of Heavy-Tailed Distributions.	Anirban Dasgupta,John E. Hopcroft,Jon M. Kleinberg,Mark Sandler	2005	We consider the problem of learning mixtures of arbitrary symmetric distributions.We formulate sufficient separation conditions and present a learning algorithm with provable guarantees for mixtures of distributions that satisfy these separation conditions. Our bounds are independent of the variances of the distributions; to the best of our knowledge, there were no previous algorithms knownwith provable learning guarantees for distributions having infinite variance and/or expectation. For Gaussians and log-concave distributions, our results match the best known sufficient separation conditions [1, 15]. Our algorithm requires a sample of size o(dk), where d is the number of dimensions and k is the number of distributions in the mixture.Wealso show that for isotropic power-laws, exponential, and Gaussian distributions, our separation condition is optimal up to a constant factor.
FOCS	Algorithmic Graph Minor Theory: Decomposition, Approximation, and Coloring.	Erik D. Demaine,Mohammad Taghi Hajiaghayi,Ken-ichi Kawarabayashi	2005	At the core of the seminal Graph Minor Theory of Robertson and Seymour is a powerful structural theorem capturing the structure of graphs excluding a fixed minor. This result is used throughout graph theory and graph algorithms, but is existential. We develop a polynomialtime algorithm using topological graph theory to decompose a graph into the structure guaranteed by the theorem: a clique-sum of pieces almost-embeddable into boundedgenus surfaces. This result has many applications. In particular, we show applications to developing many approximation algorithms, including a 2-approximation to graph coloring, constant-factor approximations to treewidth and the largest grid minor, combinatorial polylogarithmicapproximation to half-integral multicommodity flow, subexponential fixed-parameter algorithms, and PTASs for many minimization and maximization problems, on graphs excluding a fixed minor.
FOCS	Improved Smoothed Analysis of the Shadow Vertex Simplex Method.	Amit Deshpande,Daniel A. Spielman	2005	Spielman and Teng (JACM ¿04), proved that the smoothed complexity of a two-phase shadow-vertex method for linear programming is polynomial in the number of constraints n, the number of variables d, and the parameter of perturbation 1/\sigma. The key geometric result in their proof was an upper bound of o(nd^3 /\min (\sigma ,(9d\ln n)^{ - 1/2} )^6 ) on the expected size of the shadow of the polytope de?ned by the perturbed linear program. In this paper, we give a much simpler proof of a better bound: o(n^3 d\ln n/\min (\sigma ,(4d\ln n)^{ - 1/2} )^2 )When evaluated at \sigma= (9d\ln n)^{ - 1/2}, this improves the size estimate from O(nd^6 \ln ^3 n) to o(n^2 d^2 \ln n). The improvement only becomes better as s decreases.
FOCS	How to Pay, Come What May: Approximation Algorithms for Demand-Robust Covering Problems.	Kedar Dhamdhere,Vineet Goyal,R. Ravi,Mohit Singh	2005	"Robust optimization has traditionally focused on uncertainty in data and costs in optimization problems to formulate models whose solutions will be optimal in the worstcase among the various uncertain scenarios in the model. While these approaches may be thought of defining data- or cost-robust problems, we formulate a new ""demand-robust"" model motivated by recent work on two-stage stochastic optimization problems. We propose this in the framework of general covering problems and prove a general structural lemma about special types of first-stage solutions for such problems: there exists a first-stage solution that is a minimal feasible solution for the union of the demands for some subset of the scenarios and its objective function value is no more than twice the optimal. We then provide approximation algorithms for a variety of standard discrete covering problems in this setting, including minimum cut, minimum multi-cut, shortest paths, Steiner trees, vertex cover and un-capacitated facility location. While many of our results draw from rounding approaches recently developed for stochastic programming problems, we also show new applications of old metric rounding techniques for cut problems in this demand-robust setting."
FOCS	Structuring labeled trees for optimal succinctness, and beyond.	Paolo Ferragina,Fabrizio Luccio,Giovanni Manzini,S. Muthukrishnan	2005	Consider an ordered, static tree \tau on t nodes where each node has a label from alphabet set \sum. Tree \tau may be of arbitrary degree and of arbitrary shape. Say, we wish to support basic navigational operations such as find the parent of node u, the ith child of u, and any child of u with label a.In a seminal work over fifteen years ago, Jacobson [15] observed that pointer-based tree representations are wasteful in space and introduced the notion of succinct data structures. He studied the special case of unlabeled trees and presented a succinct data structure of 2t+o(t) bits supporting navigational operations in O(1) time. The space used is asymptotically optimal with the information-theoretic lower bound averaged over all trees. This led to a slew of results on succinct data structures for arrays, trees, strings and multisets. Still, for the fundamental problem of structuring labeled trees succinctly, few results, if any, exist even though labeled trees arise frequently in practice, e.g. in the data as in markup text (XML) or in augmented data structures. We present a novel approach to the problem of succinct manipulation of labeled trees by designing what we call the xbw transform of the tree, in the spirit of the well-known Burrows-Wheeler transform for strings. xbw transform uses path-sorting and grouping to linearize the labeled tree T into two coordinated arrays, one capturing the structure and the other the labels. Using the properties of the xbw transform, we (i) derive the first-known (near-)optimal results for succinct representation of labeled trees with O(1) time for navigation operations, (ii) optimally support the powerful subpath search operation for the first time, and (iii) introduce a notion of tree entropy and present linear time algorithms for compressing a given labeled tree up to its entropy beyond the information-theoretic lower bound averaged over all tree inputs.Our xbw transform is simpleand likely to spur new resultsin the theory of treecompression and indexing, and
FOCS	Linear Lower Bounds on Real-World Implementations of Concurrent Objects.	Faith Ellen Fich,Danny Hendler,Nir Shavit	2005	This paper proves \Omega (\pi ) lower bounds on the time to perform a singleinstance of an operation in any implementation of a large class of data structures shared by (\pi ) processes. For standard data structures such as counters, stacks, and queues, the bound is tight. The implementations considered may apply any deterministic primitives to a base object. No bounds are assumed on either the number of base objects or their size. Time is measured as the number of steps a process performs on base objects and the number of stalls it incurs as a result of contention with other processes.
FOCS	Deterministic Extractors for Affine Sources over Large Fields.	Ariel Gabizon,Ran Raz	2005	An (n, k)-affine source over a finite field F is a random variable X = (X_1 ,...,X_n ) \in F^n, which is uniformly distributed over an (unknown) k-dimensional affine subspace of F^n. We show how to (deterministically) extract practically all the randomness from affine sources, for any field of size larger than nc (where c is a large enough constant). Our main results are as follows: 1.(For arbitrary k): For any n, k and any F of size larger than n^20, we give an explicit construction for a function D:F^n \to F^{k - 1} , such that for any (n,k)- affine source X over F, the distribution of D(X) is \in -close to uniform, where \in is polynomially small in |F|. 2. (For k = 1): For any n and any F of size larger than nc, we give an explicit construction for a function D : D:F^n\to \{ 0,1\} ^{(1 - 8)\log _2 |F|} |, such that for any (n, 1)- affine source X over F, the distribution of D(X) is \in -close to uniform, where\in is polynomially small in |F|. Here, \delta > 0 is an arbitrary small constant, and c is a constant depending on \delta.
FOCS	Sink Equilibria and Convergence.	Michel X. Goemans,Vahab S. Mirrokni,Adrian Vetta	2005	We introduce the concept of a sink equilibrium. A sink equilibrium is a strongly connected component with no outgoing arcs in the strategy profile graph associated with a game. The strategy profile graph has a vertex set induced by the set of pure strategy profiles; its arc set corresponds to transitions between strategy profiles that occur with nonzero probability. (Here our focus will just be on the special case in which the strategy profile graph is actually a best response graph; that is, its arc set corresponds exactly to best response moves that result from myopic or greedy behaviour.) We argue that there is a natural convergence process to sink equilibria in games where agents use pure strategies. This leads to an alternative measure of the social cost of a lack of coordination, the price of sinking, which measures the worst case ratio between the value of a sink equilibrium and the value of the socially optimal solution. We define the value of a sink equilibrium to be the expected social value of the steady state distribution induced by a random walk on that sink. We illustrate the value of this measure in three ways. Firstly, we show that it may more accurately reflects the inefficiency of uncoordinated solutions in competitive games when the use of pure strategies is the norm. In particular, we give an example (a valid-utility game) in which the game converges to solutions which are a factor
FOCS	On the Impossibility of Obfuscation with Auxiliary Input.	Shafi Goldwasser,Yael Tauman Kalai	2005	Barak et al. formalized the notion of obfuscation, and showed that there exist (contrived) classes of functions that cannot be obfuscated. In contrast, Canetti and Wee showed how to obfuscate point functions, under various complexity assumptions. Thus, it would seem possible that most programs of interest can be obfuscated even though in principle general purpose obfuscators do not exist. We show that this is unlikely to be the case. In particular, we consider the notion of obfuscation w.r.t. auxiliary input, which corresponds to the setting where the adversary, which is given the obfuscated circuit, may have some additional a priori information. This is essentially the case of interest in any usage of obfuscation we can imagine. We prove that there exist many natural classes of functions that cannot be obfuscated w.r.t. auxiliary input, both when the auxiliary input is dependent of the function being obfuscated and even when the auxiliary input is independent of the function being obfuscated. We also give a positive result. In particular, we show that any obfuscator for the class of point functions is also an obfuscator w.r.t. independent auxiliary input.
FOCS	Lower Bounds for the Noisy Broadcast Problem.	Navin Goyal,Guy Kindler,Michael E. Saks	2005	"We prove the first nontrivial (superlinear) lower bound in the noisy broadcast model, defined by El Gamal in [Open problems presented at the $1984$ workshop on Specific Problems in Communication and Computation sponsored by Bell Communication Research, in Open Problems in Communication and Computation, T. M. Cover and B. Gopinath, eds., Springer-Verlag, New York, 1987, pp. 60-62]. In this model there are $n+1$ processors $P_0,P_1,\ldots,P_n$, each of which is initially given a private input bit $x_i$. The goal is for $P_0$ to learn the value of $f(x_1,\ldots,x_n)$, for some specified function $f$, using a series of noisy broadcasts. At each step a designated processor broadcasts one bit to all of the other processors, and the bit received by each processor is flipped with fixed probability (independently for each recipient). In 1988, Gallager [IEEE Trans. Inform. Theory, 34 (1988), pp. 176-180] gave a noise-resistant protocol that allows $P_0$ to learn the entire input with constant probability in $O(n\log\log n)$ broadcasts. We prove that Gallager's protocol is optimal, up to a constant factor. Our lower bound follows by reduction from a lower bound for generalized noisy decision trees, a new model which may be of independent interest. For this new model we show a lower bound of $\Omega(n \log n)$ on the depth of a tree that learns the entire input. While the above lower bound is for an $n$-bit function, we also show an $\Omega(n\log\log n)$ lower bound for the number of broadcasts required to compute certain explicit boolean-valued functions, when the correct output must be attained with probability at least $1-n^{-\alpha}$ for a constant parameter $\alpha>0$ (this bound applies to all threshold functions as well as any other boolean-valued function with linear sensitivity). This bound also follows by reduction from a lower bound of $\Omega(n\log n)$ on the depth of generalized noisy decision trees that compute the same functions with the same error. We also show a (nontrivial) $\Omega(n)$ lower bound on the depth of generalized noisy decision trees that compute such functions with small constant error. Finally, we show the first protocol in the noisy broadcast model that computes the Hamming weight of the input using a linear number of broadcasts."
FOCS	An Algorithmic Version of the Hypergraph Regularity Method.	Penny E. Haxell,Brendan Nagle,Vojtech Rödl	2005	Extending the Szemer&eacute;di regularity lemma for graphs, P. Frankl and V. R&ouml;dl [Random Structures Algorithms, 20 (2002), pp. 131-164] established a 3-graph regularity lemma triple systems ${\cal G}_n$ admit bounded partitions of their edge sets, most classes of which consist of regularly distributed triples. Many applications of this lemma require a companion counting lemma [B. Nagle and V. R&ouml;dl, Random Structures Algorithms, 23 (2003), pp. 264-332] allowing one to find and enumerate subhypergraphs of a given isomorphism type in a &ldquo;dense and regular&rdquo; environment created by the 3-graph regularity lemma. Combined applications of these lemmas are known as the 3-graph regularity method. In this paper, we provide an algorithmic version of the 3-graph regularity lemma which, as we show, is compatible with a counting lemma. We also discuss some applications.
FOCS	A general lower bound for mixing of single-site dynamics on graphs.	Thomas P. Hayes,Alistair Sinclair	2005	"We prove that any Markov chain that performs local, reversible updates on randomly chosen vertices of a bounded-degree graph necessarily has mixing time at least \Omega (n\log n), where n is the number of vertices. Our bound applies to the so-called ""Glauber dynamics"" that has been used extensively in algorithms for the Ising model, independent sets, graph colorings and other structures in computer science and statistical physics, and demonstrates that many of these algorithms are optimal up to constant factors within their class. Previously no super-linear lower bound for this class of algorithms was known. Though widely conjectured, such a bound had been proved previously only in very restricted circumstances, such as for the empty graph and the path. We also show that the assumption of bounded degree is necessary by giving a family of dynamics on graphs of unbounded degree with mixing time O(n)."
FOCS	Rational Secure Computation and Ideal Mechanism Design.	Sergei Izmalkov,Silvio Micali,Matt Lepinski	2005	Secure Computation essentially guarantees that whatever computation n players can do with the help of a trusted party, they can also do by themselves. Fundamentally, however, this notion depends on the honesty of at least some players. We put forward and implement a stronger notion, Rational Secure Computation, that does not depend on player honesty, but solely on player rationality. The key to our implementation is showing that the ballotbox -the venerable device used throughout the world to tally secret votes securely can actually be used to securely compute any function. Our work bridges the fields of Game Theory and Cryptography, and has broad implications for Mechanism Design.
FOCS	Agnostically Learning Halfspaces.	Adam Tauman Kalai,Adam R. Klivans,Yishay Mansour,Rocco A. Servedio	2005	We give a computationally efficient algorithm that learns (under distributional assumptions) a halfspace in the difficult agnostic framework of Kearns, Schapire, and Sellie [Mach. Learn., 17 (1994), pp. 115-141], where a learner is given access to a distribution on labelled examples but where the labelling may be arbitrary (similar to malicious noise). It constructs a hypothesis whose error rate on future examples is within an additive $\epsilon$ of the optimal halfspace, in time poly$(n)$ for any constant $\epsilon>0$, for the uniform distribution over $\{-1,1\}^n$ or unit sphere in $\mathbb R^n,$ as well as any log-concave distribution in $\mathbb R^n$. It also agnostically learns Boolean disjunctions in time $2^{\tilde{O}(\sqrt{n})}$ with respect to any distribution. Our algorithm, which performs $L_1$ polynomial regression, is a natural noise-tolerant arbitrary-distribution generalization of the well-known &ldquo;low-degree&rdquo; Fourier algorithm of Linial, Mansour, and Nisan. We observe that significant improvements on the running time of our algorithm would yield the fastest known algorithm for learning parity with noise, a challenging open problem in computational learning theory.
FOCS	Beyond VCG: Frugality of Truthful Mechanisms.	Anna R. Karlin,David Kempe,Tami Tamir	2005	"We study truthful mechanisms for auctions in which the auctioneer is trying to hire a team of agents to perform a complex task, and paying them for their work. As common in the field of mechanism design, we assume that the agents are selfish and will act in such a way as to maximize their profit, which in particular may include misrepresenting their true incurred cost. Our first contribution is a new and natural definition of the frugality ratio of a mechanism, measuring the amount by which a mechanism ""overpays"", and extending previous definitions to all monopoly-free set systems. After reexamining several known results in light of this new definition, we proceed to study in detail shortest path auctions and ""r-out-of-k sets"" auctions. We show that when individual set systems (e.g., graphs) are considered instead of worst cases over all instances, these problems exhibit a rich structure, and the performance of mechanisms may be vastly different. In particular, we show that the wellknown VCG mechanism may be far from optimal in these settings, and we propose and analyze a mechanism that is always within a constant factor of optimal."
FOCS	Almost Orthogonal Linear Codes are Locally Testable.	Tali Kaufman,Simon Litsyn	2005	A code is said to be locally testable if an algorithm can distinguish between a codeword and a vector being essentially far from the code using a number of queries that is independent of the code¿s length. The question of characterizing codes that are locally testable is highly complex. In this work we provide a sufficient condition for linear codes to be locally testable. Our condition is based on the weight distribution (spectrum) of the code and of its dual.Codes of (large) length n and minimum distance \frac{n}{2} - \Theta (\sqrt n ) have size which is at most polynomial in n. We call such codes almost-orthogonal. We use our condition to show that almost-orthogonal codes are locally testable, and, moreover, their dual codes can be spanned by words of constant weights (weight of a codeword refers to the number of its non-zero coordinates).
FOCS	On the Unique Games Conjecture.	Subhash Khot	2005	The discovery of the PCP Theorem in 1992 led to an avalanche of hardness of approximation results, i.e. results showing that for certain NP-hard optimization problems, computing even approximate solutions is hard. However, for many fundamental problems, obtaining satisfactory hardness results seems out of reach of current techniques. The Unique Games Conjecture (UGC) was proposed in 2002 as an approach towards settling some of these open problems. A 2-Prover-1-Round game is called unique if for every answer of either prover, there is exactly one answer of the other prover if the verifier is to accept. The UGC states that for every constant \varepsilon > 0, it is NP-hard to distinguish whether the optimal strategy of provers in a unique 2P1R game has acceptance probability at least 1 - e or at most e. The answer size {\rm{k = k(}}\varepsilon {\rm{)}} could be an arbitrary function of \varepsilon.The UGC has been shown to imply optimal hardness results for Vertex Cover and MAX-CUT problems, and superconstant hardness results for Sparsest Cut and Min-2SAT-Deletion problems. A variation of the conjecture has been shown to imply hardness of coloring 3-colorable graphs with constantly many colors. Apart from these applications to hardness results, the UGC has led to important (unconditional) results in Fourier analysis, the theory of metric embeddings, and integrality gap results for semidefinite programming relaxations.The tutorial aims to give an overview of the UGC, its applications, and attempts to prove or disprove it. The powerpoint slides for the presentation are available at http://www.cc.gatech.edu/~khot.
FOCS	Nonembeddability theorems via Fourier analysis.	Subhash Khot,Assaf Naor	2005	Various new nonembeddability results (mainly into L1) are proved via Fourier analysis. In particular, it is shown that the Edit Distance on {0,1}^d has L1 distortion (\log d)^frac{1}{2}^{} - (1). We also give new lower bounds on the L1 distortion of quotients of the discrete hypercube under group actions, and the transportation cost (Earthmover) metric.
FOCS	The Unique Games Conjecture, Integrality Gap for Cut Problems and Embeddability of Negative Type Metrics into l.	Subhash Khot,Nisheeth K. Vishnoi	2005	The Unique Games Conjecture, Integrality Gap for Cut Problems and Embeddability of Negative Type Metrics into l.
FOCS	A linear-time approximation scheme for planar weighted TSP.	Philip N. Klein	2005	We give an algorithm requiring O(c^{1/ \in ^2 }) time to find an \in -optimal traveling salesman tour in the metric defined by a planar graph with nonnegative edge-lengths.
FOCS	An Approximation Algorithm for the Disjoint Paths Problem in Even-Degree Planar Graphs.	Jon M. Kleinberg	2005	In joint work with Eva Tardos in 1995, we asked whether it was possible to obtain a polynomial-time, polylogarithmic approximation algorithm for the disjoint paths problem in the class of all even-degree planar graphs [19]. This paper answers the question in the affirmative, by providing such an algorithm. The algorithm builds on recent work of Chekuri, Khanna, and Shepherd [7, 8], who considered routing problems in planar graphs where each edge can carry up to two paths.
FOCS	Query Incentive Networks.	Jon M. Kleinberg,Prabhakar Raghavan	2005	The concurrent growth of on-line communities exhibiting large-scale social structure, and of large decentralized peer-to-peer file-sharing systems, has stimulated new interest in understanding networks of interacting agents as economic systems. Here we formulate a model for query incentive networks, motivated by such systems: users seeking information or services can pose queries, together with incentives for answering them, that are propagated along paths in a network. This type of information-seeking process can be formulated as a game among the nodes in the network, and this game has a natural Nash equilibrium. In such systems, it is a fundamental question to understand how much incentive is needed in order for a node to achieve a reasonable probability of obtaining an answer to a query from the network. We study the size of query incentives as a function both of the rarity of the answer and the structure of the underlying network. This leads to natural questions related to strategic behavior in branching processes. Whereas the classically studied criticality of branching processes is centered around the region where the branching parameter is 1, we show in contrast that strategic interaction in incentive propagation exhibits critical behavior when the branching parameter is 2.
FOCS	Safraless Decision Procedures.	Orna Kupferman,Moshe Y. Vardi	2005	The automata-theoretic approach is one of the most fundamental approaches to developing decision procedures in mathematical logics. To decide whether a formula in a logic with the tree-model property is satisfiable, one constructs an automaton that accepts all (or enough) tree models of the formula and then checks that the language of this automaton is nonempty. The standard approach translates formulas into alternating parity tree automata, which are then translated, via Safra¿s determinization construction, into nondeterministic parity automata. This approach is not amenable to implementation because of the difficulty of implementing Safra¿s construction and the nonemptiness test for nondeterministic parity tree automata. In this paper we offer an alternative to the standard automata-theoretic approach. The crux of our approach is avoiding the use of Safra¿s construction and of nondeterministic parity tree automata. Our approach goes instead via universal co-Buchi tree automata and nondeterministic Büchi tree automata. Our translations are significantly simpler than the standard approach, less difficult to implement, and have practical advantages like being amenable to optimizations and a symbolic implementation. We also show that our approach yields better complexity bounds.
FOCS	Approximation Algorithms for Scheduling on Multiple Machines.	V. S. Anil Kumar,Madhav V. Marathe,Srinivasan Parthasarathy,Aravind Srinivasan	2005	We develop a single rounding algorithm for scheduling on unrelated parallel machines; this algorithm works well with the known linear programming-, quadratic programming-, and convex programming-relaxations for scheduling to minimize completion time, makespan, and other well-studied objective functions. We obtain the following applications for the general setting of unrelated parallel machines: (i) a bicriteria algorithm for a schedule whose weighted completion-time and makespan simultaneously exhibit the current-best individual approximations for these criteria (3/2 and 2, respectively); (ii) better-than two approximation guarantees for scheduling under the Lp norm for all 1
FOCS	Truthful and Near-Optimal Mechanism Design via Linear Programming.	Ron Lavi,Chaitanya Swamy	2005	We give a general technique to obtain approximation mechanisms that are truthful in expectation. We show that for packing domains, any \alpha-approximation algorithm that also bounds the integrality gap of the LP relaxation of the problem by \alpha can be used to construct an \alpha-approximation mechanism that is truthful in expectation. This immediately yields a variety of new and significantly improved results for various problem domains and furthermore, yields truthful (in expectation) mechanisms with guarantees that match the best known approximation guaranteeswhen truthfulness is not required. In particular, we obtain the first truthful mechanisms with approximation guarantees for a variety of multi-parameter domains. We obtain truthful (in expectation) mechanisms achieving approximation guarantees of O(\sqrt m ) for combinatorial auctions (CAs),(1+ \in) for multiunit CAs with B = \Omega (\log m) copies of each item, and 2 for multi-parameter knapsack problems (multi-unit auctions).Our construction is based on considering an LP relaxation of the problem and using the classic VCG [24, 9, 12] mechanism to obtain a truthful mechanism in this fractional domain. We argue that the (fractional) optimal solution scaled down by \alpha where \alpha is the integrality gap of the problem, can be represented as a convex combination of integer solutions, and by viewing this convex combination as specifying a probability distribution over integer solutions, we get a randomized, truthful in expectation mechanism. Our construction can be seen as a way of exploiting VCG in a computational tractable way even when the underlying social-welfare maximization problem is NP-hard.
FOCS	The Closest Substring problem with small distances.	Dániel Marx	2005	In the CLOSEST SUBSTRING problem k strings s1, . . . sk are given, and the task is to find a string s of length L such that each string si has a consecutive substring of length L whose distance is at most d from s. The problem is motivated by applications in computational biology. We present two algorithms that can be efficient for small fixed values of d and k: for some functions f and g, the algorithms have running time f(d)· n^o^{(\log d)}and g(d,k)·n^o ^{(\log log)},respectively. The second algorithm is based on connections with the extremal combinatorics of hypergraphs. The CLOSEST SUBSTRING problem is also investigated from the parameterized complexity point of view. Answering an open question from [6, 7, 11, 12], we show that the problem is W[1]- hard even if both d and k are parameters. It follows as a consequence of this hardness result that our algorithms are optimal in the sense that the exponent of n in the running time cannot be improved to o(logd) or to o(log log k) (modulo some complexity0-theoretic assumptions). Another consequence is that the running time n^o ^{(1/\varepsilon^4)}of the approximation scheme for CLOSEST SUBSTRING presented in [13] cannot be improved to f (\varepsilon) · {n^c}, i.e., the \varepsilon has to appear in the exponent of n.
FOCS	AdWords and Generalized On-line Matching.	Aranyak Mehta,Amin Saberi,Umesh V. Vazirani,Vijay V. Vazirani	2005	How does a search engine company decide what ads to display with each query so as to maximize its revenue? This turns out to be a generalization of the online bipartite matching problem. We introduce the notion of a tradeoff revealing LP and use it to derive two optimal algorithms achieving competitive ratios of 1 - 1/e for this problem.
FOCS	The Parking Permit Problem.	Adam Meyerson	2005	We consider online problems where purchases have time durations which expire regardless of whether the purchase is used or not. The Parking Permit Problem is the natural analog of the well-studied ski rental problem in this model, and we provide matching upper and lower bounds on the competitive ratio for this problem. By extending the techniques thus developed, we give an online-competitive algorithm for the problem of renting steiner forest edges with time durations.
FOCS	Every decision tree has an in.uential variable.	"Ryan O'Donnell,Michael E. Saks,Oded Schramm,Rocco A. Servedio"	2005	Every decision tree has an in.uential variable.
FOCS	The Symmetric Group Defies Strong Fourier Sampling.	Cristopher Moore,Alexander Russell,Leonard J. Schulman	2005	The dramatic exponential speedups of quantum algorithms over their best existing classical counterparts were ushered in by the technique of Fourier sampling, introduced by Bernstein and Vazirani and developed by Simon and Shor into an approach to the hidden subgroup problem. This approach has proved successful for abelian groups, leading to efficient algorithms for factoring, extracting discrete logarithms, and other number-theoretic problems. We show, however, that this method cannot resolve the hidden subgroup problem in the symmetric groups, even in the weakest, information-theoretic sense. In particular, we show that the Graph Isomorphism problem cannot be solved by this approach. Our work implies that any quantum approach based upon the measurement of coset states must depart from the original framework by using entangled measurements on multiple coset states.
FOCS	Noise stability of functions with low in.uences invariance and optimality.	"Elchanan Mossel,Ryan O'Donnell,Krzysztof Oleszkiewicz"	2005	"In this paper we study functions with low influences on product probability spaces. The analysis of boolean functions f : {-1,1}^n\to : {-1,1} with low influences has become a central problem in discrete Fourier analysis. It is motivated by fundamental questions arising from the construction of probabilistically checkable proofs in theoretical computer science and from problems in the theory of social choice in economics. We prove an invariance principle for multilinear polynomials with low influences and bounded degree; it shows that under mild conditions the distribution of such polynomials is essentially invariant for all product spaces. Ours is one of the very few known non-linear invariance principles. It has the advantage that its proof is simple and that the error bounds are explicit. We also show that the assumption of bounded degree can be eliminated if the polynomials are slightly ""smoothed""; this extension is essential for our applications to ""noise stability""-type problems. In particular, as applications of the invariance principle we prove two conjectures: the ""Majority Is Stablest"" conjecture [29] from theoretical computer science, which was the original motivation for this work, and the ""It Ain¿t Over Till It¿s Over"" conjecture [27] from social choice theory. The ""Majority Is Stablest"" conjecture and its generalizations proven here, in conjunction with the ""Unique Games Conjecture"" and its variants, imply a number of (optimal) inapproximability results for graph problems."
FOCS	Error-Correcting Codes for Automatic Control.	Rafail Ostrovsky,Yuval Rabani,Leonard J. Schulman	2005	Systems with automatic feedback control may consist of several remote devices, connected only by unreliable communication channels. It is necessary in these conditions to have a method for accurate, real-time state estimation in the presence of channel noise. This problem is addressed, for the case of polynomial-growth-rate state spaces, through a new type of error-correcting code that is online and computationally efficient. This solution establishes a constructive analog, for some applications in estimation and cuntrol, of the Shannon coding theorem.
FOCS	Quantum Information and the PCP Theorem.	Ran Raz	2005	Our main result is that the membership x \in SAT (for x of length n) can be proved by a logarithmic-size quantum state |\Psi \rangle , together with a polynomial-size classical proof consisting of blocks of length polylog(n) bits each, such that after measuring the state |\Psi \rangle the verifier only needs to read one block of the classical proof. This shows that if a short quantum witness is available then a (classical) PCP with only one query is possible. Our second result is that the class QIP/qpoly contains all languages. That is, for any language L (even nonrecursive), the membership x \in L (for x of length n) can be proved by a polynomial-size quantum interactive proof, where the verifier is a polynomial-size quantum circuit with working space initiated with some quantum state |\Psi _{L,n} \rangle(depending only on L and n). Moreover, the interactive proof that we give is of only one round, and the messages communicated are classical. The advice |\Psi _{L,n} \rangle given to the verifier can also be replaced by a classical probabilistic advice, as long as this advice is kept as a secret from the prover. Our result can hence be interpreted as: the class IP/rpoly contains all languages. For the proof of the second result, we introduce the quantum low-degree-extension of a string of bits. The main result requires an additional machinery of quantum lowdegree- test.
FOCS	The Complexity of Online Memory Checking.	Moni Naor,Guy N. Rothblum	2005	"We consider the problem of storing a large file on a remote and unreliable server. To verify that the file has not been corrupted, a user could store a small private (randomized) ""fingerprint"" on his own computer. This is the setting for the well-studied authentication problem in cryptography, and the required fingerprint size is well understood. We study the problem of sub-linear authentication: suppose the user would like to encode and store the file in a way that allows him to verify that it has not been corrupted, but without reading the entire file. If the user only wants to read t bits of the file, how large does the size s of the private fingerprint need to be?We define this problem formally, and show a tight lower bound on the relationship between s and t when the adversary is not computationally bounded, namely: s × t = \Omega(n), where n is the file size. This is an easier case of the online memory checking problem, introduced by Blum et al. in 1991, and hence the same (tight) lower bound applies also to that problem. It was previously shown that when the adversary is computationally bounded, under the assumption that one-way functions exist, it is possible to construct much better online memory checkers and sub-linear authentication schemes. We show that the existence of one-way functions is also a necessary condition: even slightly breaking the s × t = \Omega(n) lower bound in a computational setting implies the existence of one-way functions."
FOCS	Correcting Errors Beyond the Guruswami-Sudan Radius in Polynomial Time.	Farzad Parvaresh,Alexander Vardy	2005	We introduce a new family of error-correcting codes that have a polynomial-time encoder and a polynomial-time listdecoder, correcting a fraction of adversarial errors up to \tau {\rm M} = 1 - ^{{\rm M} + 1} \sqrt {{\rm M}^{\rm M} R^{\rm M} } where R is the rate of the code and {\rm M} \ge is an arbitrary integer parameter. This makes it possible to decode beyond the Guruswami-Sudan radius of 1 - \sqrt R for all rates less than 1/16. Stated another way, for any \varepsilon > 0, we can listdecode in polynomial time a fraction of errors up to 1 - \varepsilon with a code of length n and rate \Omega(\varepsilon/log(1/\varepsilon)), defined over an alphabet of size n^{\rm M}= n^{{\rm O}(\log (1/\varepsilon ))} . Notably, thiserror-correction is achieved in the worst-case against adversarial errors: a probabilistic model for the error distribution is neither needed nor assumed. The best results so far for polynomial-time list-decoding of adversarial errors required a rate of O(\varepsilon^2) to achieve the correction radius of 1-\varepsilon.Our codes and list-decoders are based on two key ideas. The first is the transition from bivariate polynomial interpolation, pioneered by Sudan and Guruswami-Sudan [12,22], to multivariate interpolation decoding. The second idea is to part ways with Reed-Solomon codes, for which numerous prior attempts [2, 3, 12, 18] at breaking the O(\varepsilon^2) rate barrier in the worst-case were unsuccessful. Rather than devising a better list-decoder for Reed-Solomon codes, we devise better codes. Standard Reed-Solomon encoders view a message as a polynomial f(X) over a field Fq, and produce the corresponding codeword by evaluating f(X) at n distinct elements of Fq. Herein, given f(X), we first compute one or more related polynomials g1(X), g2(X), . . . , gM-1(X) and produce the corresponding codeword by evaluating all these polynomials. Correlation between f (X) and gi(X), carefully designed into our encoder, then provides the additional information we need to recover the encoded message from the output of the multivariate interpolation process.
FOCS	Concurrent Non-Malleable Commitments.	Rafael Pass,Alon Rosen	2005	We present a non-malleable commitment scheme that retains its security properties even when concurrently executed a polynomial number of times. That is, a manin- the-middle adversary who is simultaneously participating in multiple concurrent commitment phases of our scheme, both as a sender and as a receiver, cannot make the values he commits to depend on the values he receives commitments to. Our result is achieved without assuming an a-priori bound on the number of executions and without relying on any set-up assumptions. Our construction relies on the existence of standard collision resistant hash functions and only requires a constant number of communication rounds.
FOCS	"On Delsarte's Linear Programming Bounds for Binary Codes."	Michael Navon,Alex Samorodnitsky	2005	We prove two results about the value of Delsarte¿s linear program for binary codes.Our main result is a new lower bound on the value of the program, which, in particular, is nearly tight for low rate codes. We also give an easy proof of a (known) upper bound, which coincides with the best known bound for a wide range of parameters.
FOCS	Towards a Final Analysis of Pairing Heaps.	Seth Pettie	2005	Fredman, Sedgewick, Sleator, and Tarjan proposed the pairing heap as a self-adjusting, streamlined version of the Fibonacci heap. It provably supports all priority queue operations in logarithmic time and is known to be extremely efficient in practice. However, despite its simplicity and empirical superiority, the pairing heap is one of the few popular data structures whose basic complexity remains open. In this paper we prove that pairing heaps support the deletemin operation in optimal logarithmic time and all other operations (insert, meld, and decreasekey) in time O(2^2 \sqrt {\log \log n} ) This result gives the first sub-logarithmic time bound for decreasekey and comes close to the lower bound of \Omega (\log \log n) established by Fredman.
FOCS	FOCS 2005 - Title Page.		2005	FOCS 2005 - Title Page.
FOCS	Foreword.		2005	Foreword.
FOCS	Committees.		2005	Committees.
FOCS	Best Paper Awards.		2005	Best Paper Awards.
FOCS	Machtey Award.		2005	Machtey Award.
FOCS	Knuth Prize.		2005	Knuth Prize.
FOCS	Reviewers.		2005	Reviewers.
FOCS	Corporate Sponsors.		2005	Corporate Sponsors.
FOCS	Learning mixtures of product distributions over discrete domains.	"Jon Feldman,Ryan O'Donnell,Rocco A. Servedio"	2005	We consider the problem of learning mixtures of product distributions over discrete domains in the distribution learning framework introduced by Kearns et al. [Proceedings of the $26$th Annual Symposium on Theory of Computing (STOC), Montr&eacute;al, QC, 1994, ACM, New York, pp. 273-282]. We give a $\operatorname{poly}(n/\epsilon)$-time algorithm for learning a mixture of $k$ arbitrary product distributions over the $n$-dimensional Boolean cube $\{0,1\}^n$ to accuracy $\epsilon$, for any constant $k$. Previous polynomial-time algorithms could achieve this only for $k = 2$ product distributions; our result answers an open question stated independently in [M. Cryan, Learning and Approximation Algorithms for Problems Motivated by Evolutionary Trees, Ph.D. thesis, University of Warwick, Warwick, UK, 1999] and [Y. Freund and Y. Mansour, Proceedings of the $12$th Annual Conference on Computational Learning Theory, 1999, pp. 183-192]. We further give evidence that no polynomial-time algorithm can succeed when $k$ is superconstant, by reduction from a difficult open problem in PAC (probably approximately correct) learning. Finally, we generalize our $\operatorname{poly}(n/\epsilon)$-time algorithm to learn any mixture of $k = O(1)$ product distributions over $\{0,1, \dots, b-1\}^n$, for any $b = O(1)$.
FOCS	FOCS 2005 - Copyright.		2005	FOCS 2005 - Copyright.
FOCS	Sampling-based Approximation Algorithms for Multi-stage Stochastic.	Chaitanya Swamy,David B. Shmoys	2005	"Stochastic optimization problems provide a means to model uncertainty in the input data where the uncertainty is modeled by a probability distribution over the possible realizations of the actual data. We consider a broad class of these problems in which the realized input is revealed through a series of stages, and hence are called multi-stage stochastic programming problems. Our main result is to give the first fully polynomial approximation scheme for a broad class of multi-stage stochastic linear programming problems with any constant number of stages. The algorithm analyzed, known as the sample average approximation (SAA) method, is quite simple, and is the one most commonly used in practice. The algorithm accesses the input by means of a ""black box"" that can generate, given a series of outcomes for the initial stages, a sample of the input according to the conditional probability distribution (given those outcomes). We use this to obtain the first polynomial-time approximation algorithms for a variety of k-stage generalizations of basic combinatorial optimization problems."
FOCS	Approximation Algorithms for Unique Games.	Luca Trevisan	2005	We present a polynomial time algorithm based on semidefinite programming that, given a unique game of value 1 - O(1/ log n), satisfies a constant fraction of constraints, where n is the number of variables. For suficiently large alphabets, it improves an algorithm of Khot (STOC¿02) that satisfies a constant fraction of constraints in unique games of value 1 - O(1/(k^{10} (\log k)^5 )), where k is the size of the alphabet. We also present a simpler algorithm for the special case of unique games with linear constraints.Finally, we present a simple approximation algorithm for 2-to-1 games.
FOCS	A Randomness-Efficient Sampler for Matrix-valued Functions and Applications.	Avi Wigderson,David Xiao	2005	In this paper we give a randomness-efficient sampler for matrix-valued functions. Specifically, we show that a random walk on an expander approximates the recent Chernoff-like bound for matrix-valued functions of Ahlswede and Winter [1], in a manner which depends optimally on the spectral gap. The proof uses perturbation theory, and is a generalization of Gillman¿s and Lezaud¿s analyses of the Ajtai-Komlos-Szemeredi sampler for realvalued functions [11, 21, 2]. Derandomizing our sampler gives a few applications, yielding deterministic polynomial time algorithms for problems in which derandomizing independent sampling gives only quasi-polynomial time deterministic algorithms. The first (which was our original motivation) is to a polynomialtime derandomization of the Alon-Roichmantheorem [4, 20, 22]: given a group of size n, find O(log n) elements which generate it as an expander. This implies a second application efficiently constructing a randomness-optimal homomorphism tester, significantly improving the previous result of Shpilka and Wigderson [29]. A third application, which derandomizes a generalization of the set cover problem, is deferred to the full version of this paper.
FOCS	Answering distance queries in directed graphs using fast matrix multiplication.	Raphael Yuster,Uri Zwick	2005	Let G = (V, E,w) be a weighted directed graph, where w : \rm E \to{-M, . . . , 0, . . . , M}.We show that G can be preprocessed in O(m^\omega) time,where \omega n^{\omega - 1/2} \simeq n^{1.876}.
FOCS	46th Annual IEEE Symposium on Foundations of Computer Science (FOCS 2005), 23-25 October 2005, Pittsburgh, PA, USA, Proceedings		2005	46th Annual IEEE Symposium on Foundations of Computer Science (FOCS 2005), 23-25 October 2005, Pittsburgh, PA, USA, Proceedings
SODA	Popular matchings.	David J. Abraham,Robert W. Irving,Telikepalli Kavitha,Kurt Mehlhorn	2005	"We consider the problem of matching a set of applicants to a set of posts, where each applicant has a preference list, ranking a nonempty subset of posts in order of preference, possibly involving ties. We say that a matching $M$ is popular if there is no matching $M'$ such that the number of applicants preferring $M'$ to $M$ exceeds the number of applicants preferring $M$ to $M'$. In this paper, we give the first polynomial-time algorithms to determine if an instance admits a popular matching and to find a largest such matching, if one exists. For the special case in which every preference list is strictly ordered (i.e., contains no ties), we give an $O(n + m)$ time algorithm, where $n$ is the total number of applicants and posts and $m$ is the total length of all of the preference lists. For the general case in which preference lists may contain ties, we give an $O(\sqrt{n}m)$ time algorithm."
SODA	Ordinal embeddings of minimum relaxation: general properties, trees, and ultrametrics.	Noga Alon,Mihai Badoiu,Erik D. Demaine,Martin Farach-Colton,Mohammad Taghi Hajiaghayi,Anastasios Sidiropoulos	2005	We introduce a new notion of embedding, called minimum-relaxation ordinal embedding, parallel to the standard notion of minimum-distortion (metric) embedding. In an ordinal embedding, it is the relative order between pairs of distances, and not the distances themselves, that must be preserved as much as possible. The (multiplicative) relaxation of an ordinal embedding is the maximum ratio between two distances whose relative order is inverted by the embedding. We develop several worst-case bounds and approximation algorithms on ordinal embedding. In particular, we establish that ordinal embedding has many qualitative differences from metric embedding, and we capture the ordinal behavior of ultrametrics and shortest-path metrics of unweighted trees.
SODA	Collecting correlated information from a sensor network.	Micah Adler	2005	A fundamental problem in the study of sensor networks is collecting data to a central server from a set of k distributed sensor nodes. A considerable amount of recent research in this area attempts to reduce the number of bits sent by the nodes by taking advantage of correlations between the data items collected from different nodes. In this paper, we study this problem in the following model: let D be a probability distribution over k binary strings of length n. A sample &Xmacr; is drawn from D and the k strings of &Xmacr; are revealed to the nodes, one string per node. The goal is to inform the server of all k strings of &Xmacr;. Our primary objective is to minimize the total number of bits sent by the nodes, but we also seek to minimize both the bits sent by the server and the number of rounds required. This problem is a natural parallelization of the model introduced in [2], and is also well motivated by recent work on distributed source coding for sensor networks. Our main result is a protocol that allows the server to correctly determine &Xmacr;. In this protocol, the nodes send O(H(D) + k) bits in expectation, where H(D) is the binary entropy of D; this is asymptotically optimal. The server sends O(kn + H(D) log n) bits in expectation, and the number of rounds is O(1 + log[H(D)]) in expectation. We also demonstrate that if the server is allowed to produce an incorrect result with probability up to &Delta;, then the expected number of bits sent by the server can be reduced to O(k log(nk/&Delta;) + H(D) log n), without increasing the other measures of performance.
SODA	Linear equations, arithmetic progressions and hypergraph property testing.	Noga Alon,Asaf Shapira	2005	For a fixed k-uniform hypergraph D (k-graph for short, k &ge; 3), we say that a k-graph H satisfies property PD (resp. P*D) if it contains no copy (resp. induced copy) of D. Our goal in this paper is to classify the k-graphs D for which there are property-testers for testing PD and P*D whose query complexity is polynomial in 1/&epsilon;. For such k-graphs, we say that PD (or P*D) is easily testable.For P*D, we prove that aside from a single 3-graph, P*D is easily testable if and only if D is a single k-edge. For large k, we obtain stronger lower bounds than those obtained for the general case on the query complexity of testing P*D for any D other than the single k-edge. These bounds are proved by applying a more sophisticated technique than the basic one that works for all k. These results extend and improve previous results about graphs [5] and k-graphs [18].For PD, we show that for any k-partite k-graph D, PD, is easily testable, by giving an efficient one-sided error-property tester, which improves the one obtained by [18]. We further prove a nearly matching lower bound on the query complexity of such a property-tester. Finally, we give a sufficient condition for inferring that PD is not easily testable. Though our results do not supply a complete characterization of the k-graphs for which PD is easily testable, they are a natural extension of the previous results about graphs [1].Our proofs combine results and arguments from additive number theory, linear algebra and extremal hypergraph theory. We also develop new techniques, which are of independent interest. The first is a construction of a dense set of integers, which does not contain a subset that satisfies a certain set of linear equations. The second is an algebraic construction of certain extremal hypergraphs. We demonstrate the applicability of this last construction by resolving several cases of an open problem raised by Brown, Erd&ouml;s and S&oacute;s in 1973. These two techniques have already been applied in two recent subsequent papers [6], [27].
SODA	An optimal dynamic interval stabbing-max data structure?	Pankaj K. Agarwal,Lars Arge,Ke Yi	2005	In this paper we consider the dynamic stabbing-max problem, that is, the problem of dynamically maintaining a set S of n axis-parallel hyper-rectangles in Rd, where each rectangle s &isin; S has a weight w(s) &isin; R, so that the rectangle with the maximum weight containing a query point can be determined efficiently. We develop a linear-size structure for the one-dimensional version of the problem, the interval stabbing-max problem, that answers queries in worst-case O(log n) time and supports updates in amortized O(log n) time. Our structure works in the pointer-machine model of computation and utilizes many ingredients from recently developed external memory structures. Using standard techniques, our one-dimensional structure can be extended to higher dimensions, while paying a logarithmic factor in space, update time, and query time per dimension. Furthermore, our structure can easily be adapted to external memory, where we obtain a linear-size structure that answers queries and supports updates in O(logB n) I/Os, where B is the disk block size.
SODA	Coins make quantum walks faster.	Andris Ambainis,Julia Kempe,Alexander Rivosh	2005	"We show how to search N items arranged on a &radic;N &times; &radic;N grid in time O(&radic;N log N), using a discrete time quantum walk. This result for the first time exhibits a significant difference between discrete time and continuous time walks without coin degrees of freedom. since it has been shown recently that such a continuous time walk needs time &Omega;(N) to perform the same task. Our result improves on a previous bound for quantum local search by Aaronson and Ambainis. We generalize our result to 3 and more dimensions where the walk yields the optimal performance of O(&radic;N) and give several extensions of quantum walk search algorithms and generic expressions for its performance for general graphs. The coin-flip operation needs to be chosen judiciously: we show that another ""natural"" choice of coin gives a walk that takes &Omega;(N) steps. We also show that in 2 dimensions it is sufficient to have a two-dimensional coin-space to achieve the time O(&radic;N log N)."
SODA	Lower bound for sparse Euclidean spanners.	Pankaj K. Agarwal,Yusu Wang,Peng Yin	2005	Given a one-dimensional graph G such that any two consecutive nodes are unit distance away, and such that the minimum number of links between any two nodes (the diameter of G) is O(log n), we prove an &Omega;(n log n/log log n) lower bound on the sum of lengths of all the edges (i.e., the weight of G). The problem is a variant of the widely studied partial sum problem. This in turn provides a lower bound on Euclidean spanner graphs with small diameter and low weight, showing that the upper bound from [1] is almost tight.
SODA	On distance scales, embeddings, and efficient relaxations of the cut cone.	James R. Lee	2005	"A central open problem in the field of finite metric spaces is to find an efficient relaxation of the cut cone---the collection of positive linear combinations of cut pseudo-metrics on a finite set. In particular, it has been asked how well squared-Euclidean metrics (the so-called metrics of ""negative type"") embed into L1, and it is known that the answer to this question coincides with the integrality gap of a folklore semi-definite relaxation for computing the Sparsest Cut of a graph.Bourgain's classical embedding theorem implies that any n-point metric space embeds into L2 with O(log n) distortion. We give the first embeddings for metrics of negative type which beat Bourgain's bound. Specifically, we show that for every &isin; > 0, there exists a &delta; > 0 such that every n-point metric of negative type embeds into L2+&isin;, with distortion O(log n)1-&delta;. We also exhibit the first o(log n) bounds on the Euclidean distortion of finite subsets of Lp, for 1 < p < 2. These spaces naturally interpolate between L1 and L2, and thus provide a necessary first step in resolving the long-standing open question on the Euclidean distortion of finite subsets of L1.In proving these results, we introduce a number of new techniques for the construction of low-distortion embeddings. These include a generic Gluing Lemma which avoids the overhead that typically arises from the na&iuml;ve concatenation of different scales, and which provides new insights into the cut structure of finite graphs. We also exhibit the utility of Lipschitz extension theorems from Functional Analysis to the embedding of finite metric spaces. Finally, we prove the ""Big Core"" Theorem---a significantly improved and quantitatively optimal version of the main structural theorem in [ARV04] about random projections. The latter result offers a simplified hyperplane rounding algorithm for the computation of an O(&radic;logn)-approximation to the Sparsest Cut problem with uniform demands."
SODA	On approximating the depth and related problems.	Boris Aronov,Sariel Har-Peled	2005	In this paper, we study the problem of finding a disk covering the largest number of red points, while avoiding all the blue points. We reduce it to the question of finding a deepest point in an arrangement of pseudodisks and provide a near-linear expected-time randomized approximation algorithm for this problem. As an application of our techniques, we show how to solve linear programming with violations approximately. We also prove that approximate range counting has roughly the same time and space complexity as answering emptiness range queries.
SODA	On geometric permutations induced by lines transversal through a fixed point.	Boris Aronov,Shakhar Smorodinsky	2005	A line transversal of a family S of n pairwise disjoint convex objects is a straight line meeting all members of S. A geometric permutation of S is the pair of orders in which members of S are met by a line transversal, one order being the reverse of the other.In this note we consider a long-standing open problem in transversal theory, namely that of determining the largest number of geometric permutations that a family of n pairwise disjoint convex objects in Rd can admit. We settle a restricted variant of this problem. Specifically, we show that the maximum number of those geometric permutations to a family of n > 2 pairwise disjoint convex objects that are induced by lines passing through any fixed point is between K(n - 1, d - 1) and K(n,d - 1), where K(n,d) = &Sigma;di=0 (n-1/i) = &Theta;(nd) is the number of pairs of antipodal cells in a simple arrangement of n great (d - 1)-spheres in a d-sphere. By a similar argument, we show that the maximum number of connected components of the space of all lines transversal through a fixed point to a family of n > 2 possibly intersecting convex objects is K(n, d - 1). Finally, we refute a conjecture of Sharir and Smorodinsky on the number of neighbor pairs in geometric permutations and offer an alternative conjecture which may be a first step towards solving the aforementioned general problem of bounding the number of geometric permutations.
SODA	Space-time tradeoffs for approximate spherical range counting.	Sunil Arya,Theocharis Malamatos,David M. Mount	2005	We present space-time tradeoffs for approximate spherical range counting queries. Given a set S of n data points in Rd along with a positive approximation factor &epsilon;, the goal is to preprocess the points so that, given any Euclidean ball B, we can return the number of points of any subset of S that contains all the points within a (1 - &epsilon;)-factor contraction of B, but contains no points that lie outside a (1 + &epsilon;)-factor expansion of B.In many applications of range searching it is desirable to offer a tradeoff between space and query time. We present here the first such tradeoffs for approximate range counting queries. Given 0 < &epsilon; &le; 1/2 and a parameter &gamma;, where 2 &le; &gamma; &le; 1/&epsilon;, we show how to construct a data structure of space O(n&gamma;d log (1/&epsilon;)) that allows us to answer &epsilon;-approximate spherical range counting queries in time O(log(n&gamma;) + 1/(&epsilon;&gamma;d-1). The data structure can be built in time O(n&gamma;d log (n/&epsilon;)) log (1/&epsilon;)). Here n, &epsilon;, and &gamma; are asymptotic quantities, and the dimension d is assumed to be a fixed constant.At one extreme (low space), this yields a data structure of space O(n log (1/e)) that can answer approximate range queries in time O(logn + 1/(ed-1) which, up to a factor of O(n log (1/e) in space, matches the best known result for approximate spherical range counting queries. At the other extreme (high space), it yields a data structure of space O((n/ed) log(1/&epsilon;)) that can answer queries in time O(logn + 1/&epsilon;). This is the fastest known query time for this problem.We also show how to adapt these data structures to the problem of computing an &epsilon;-approximation to the kth nearest neighbor, where k is any integer from 1 to n given at query time. The space bounds are identical to the range searching results, and the query time is larger only by a factor of O(1/(&epsilon;&gamma;)).Our approach is broadly based on methods developed for approximate Voronoi diagrams (AVDs), but it involves a number of significant extensions from the context of nearest neighbor searching to range searching. These include generalizing AVD node-separation properties from leaves to internal nodes of the tree and constructing efficient generator sets through a radial decomposition of space. We have also developed new arguments to analyze the time and space requirements in this more general setting.
SODA	Inoculation strategies for victims of viruses and the sum-of-squares partition problem.	James Aspnes,Kevin L. Chang,Aleksandr Yampolskiy	2005	We propose a simple game for modeling containment of the spread of viruses in a graph of n nodes. Each node must choose to either install anti-virus software at some known cost C, or risk infection and a loss L if a virus that starts at a random initial point in the graph can reach it without being stopped by some intermediate node. The goal of individual nodes is to minimize their individual expected cost. We prove many game theoretic properties of the model, including an easily applied characterization of Nash equilibria, culminating in our showing that allowing selfish users to choose Nash equilibrium strategies is highly undesirable, because the price of anarchy is an unacceptable &Theta;(n) in the worst case. This shows in particular that a centralized solution can give a much better total cost than an equilibrium solution. Though it is NP-hard to compute such a social optimum, we show that the problem can be reduced to a previously unconsidered combinatorial problem that we call the sum-of-squares partition problem. Using a greedy algorithm based on sparse cuts, we show that this problem can be approximated to within a factor of O(log2 n), giving the same approximation ratio for the inoculation game.
SODA	Dotted interval graphs and high throughput genotyping.	Yonatan Aumann,Moshe Lewenstein,Oren Melamud,Ron Y. Pinter,Zohar Yakhini	2005	We introduce a generalization of interval graphs, which we call dotted interval graphs (DIG). A dotted interval graph is an intersection graph of arithmetic progressions (=dotted intervals). Coloring of dotted intervals graphs naturally arises in the context of high throughput genotyping. We study the properties of dotted interval graphs, with a focus on coloring. We show that any graph is a DIG but that DIGd graphs, i.e. DIGs in which the arithmetic progressions have a jump of at most d, form a strict hierarchy. We show that coloring DIGd, graphs is NP-complete even for d = 2. For any fixed d, we provide a 7/8d approximation for the coloring of DIGd graphs.
SODA	Online client-server load balancing without global information.	Baruch Awerbuch,Mohammad Taghi Hajiaghayi,Robert D. Kleinberg,Tom Leighton	2005	We consider distributed online algorithms for maximizing through-put in a network of clients and servers, modeled as a bipartite graph. Unlike most prior work on online load balancing, we do not assume centralized control and seek algorithms and lower bounds for decentralized algorithms in which each participant has only local knowledge about the state of itself and its neighbors. Our problem can be seen as analogous to the recent work on oblivious routing in [8, 14, 19], but with the objective of maximizing through-put rather than minimizing congestion. In contrast to that work, we prove a strong lower bound (polynomial in n, the size of the graph) on the competitive ratio of any oblivious algorithm. This is accompanied by simple algorithms achieving upper bounds which are tight in terms of k, the maximum throughput achievable by an omniscient algorithm. Finally, we examine a restricted model in which clients, upon becoming active, must remain so for at least log(n) time steps. In contrast to the primarily negative results in the oblivious case, here we present an algorithm which is constant-competitive. Our lower bounds justify the intuition, implicit in earlier work on the subject [2], that some such restriction (i.e. requiring some stability in the demand pattern over time) is necessary in order to achieve a constant --- or even polylogarithmic --- competitive ratio.
SODA	Improved recommendation systems.	Baruch Awerbuch,Boaz Patt-Shamir,David Peleg,Mark R. Tuttle	2005	"We consider a model of competitive recommendation systems proposed by Drineas et al. [4]. In recommendation systems (e.g., for books or movies), the system tracks which product each user chose in the past, and tries to deduce which other products an asking user is likely to be satisfied with. Obviously, recommendation systems can be effective only for users who share preferences with many other users. Such users are said to belong to a ""dominant type."" Current approaches to on-line recommendation systems involve using Singular Value Decomposition (SVD), which is computationally intensive and, more important, often applicable only under additional strong conditions. Specifically, correctness is guaranteed in [4] only if users of different dominant types essentially do not share a product they like (""type separability""), and only if the number of users in non-dominant types is significantly smaller than the number of users in dominant types (""gap assumption""). The complexity of that algorithm is O(mn), where m and n denote the number of users and products, respectively. In this paper, we show that in fact, very simple combinatorial algorithms can make good recommendations without using SVD. Our algorithms require neither the type separability nor the gap assumption, they are naturally amenable to distibuted computation, and their complexity is lower. In particular, the paper presents an O(m + n) time centralized algorithm and a distributed algorithm that can be implemented in a peer-to-peer model even in the presence of adaptively colluding malicious players, with only logarithmic over-head."
SODA	Near-independence of permutations and an almost sure polynomial bound on the diameter of the symmetric group.	László Babai,Thomas P. Hayes	2005	"We address the long-standing conjecture that all permutations have polynomially bounded word length in terms of any set of generators of the symmetric group Sn This is equivalent to polynomial-time (O(nc)) mixing of the (lazy) random walk on Sn where one step is multiplication by a generator or its inverse.We prove that the conjecture is true for almost all pairs of generators. Specifically, our bound is &Otilde;(n7). For almost all pairs of generators, words of this length representing any given permutation can be constructed in Las Vegas polynomial time. The best previous bound on the word length for a random pair of generators was nInn(1/2+o(1)) (Babai-Hetyei, 1992).We build on recent major progress by Babai-Beals-Seress (SODA, 2004), confirming the conjecture under the assumption that at least one of the generators has degree < 0.33n.The main technical contribution of the present paper is the following near-independence result for permutations. The first cycle of a permutation is the trajectory of the first element of the permutation domain. For a random permutation, the distribution of the length of the first cycle is uniform. We show that if &tau; &isin; Sn is a given permutation of degree &ge; n3/4 and &sigma; &isin; Sn is chosen at random, then the distributions of the length of the first cycle of &sigma; and the length of the first cycle in &sigma;&tau; are nearly independent. The ability of an essentially arbitrarily fixed permutation (&tau;) to ""scramble"" another permutation in this technical sense may be of independent interest and suggests new directions in the statistical theory of permutations pioneered by Goncharov and Erd&odblac;s-Tur&aacute;n."
SODA	Approximation algorithms for low-distortion embeddings into low-dimensional spaces.	Mihai Badoiu,Kedar Dhamdhere,Anupam Gupta,Yuri Rabinovich,Harald Räcke,R. Ravi,Anastasios Sidiropoulos	2005	We present several approximation algorithms for the problem of embedding metric spaces into a line, and into the two-dimensional plane. Among other results, we give an O(&radic;n)-approximation algorithm for the problem of finding a line embedding of a metric induced by a given unweighted graph, that minimizes the (standard) multiplicative distortion. We give an improved &Otilde;(n1/3) approximation for the case of metrics generated by unweighted trees. This is the first result of this type.
SODA	Loop quantum gravity.	John C. Baez	2005	"One of the great challenges facing physics today is to reconcile quantum theory and general relativity. Loop quantum gravity is an approach to this challenge that incorporates quantum theory into our description of spacetime from the very start. Quantum states of the geometry of space are described by ""spin networks"" - graphs with certain labellings of their edges and vertices. The theory predicts that geometrical quantities such as area and volume take on a discrete spectrum of possible values, and it explains the entropy of black holes by associating information to each point at which a spin network edge punctures the event horizon. I will give a nontechnical introduction to these ideas, focussing on some computational challenges that arise in studying this theory. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player"
SODA	Approximating the average response time in broadcast scheduling.	Nikhil Bansal,Moses Charikar,Sanjeev Khanna,Joseph Naor	2005	We consider the problem of approximating the minimum average response time in on-demand data broadcasting systems. The best approximation factors known for this problem involve resource augmentation. We provide the first non-trivial approximation factors in the absence of resource augmentation, achieving an additive O(&radic;n)-approximation, where n is the number of distinct pages. Our result can be extended, for any &epsilon; > 0, to a (1 + &epsilon;)-speed, additive O(1/&epsilon;)-approximation algorithm. Prior to our work, no non-trivial approximation factor was known for the case of &epsilon; < 1.
SODA	Job shop scheduling with unit processing times.	Nikhil Bansal,Tracy Kimbrel,Maxim Sviridenko	2005	We consider randomized algorithms for the preemptive job shop problem, or equivalently, the case in which all operations have unit length. We give an α-approximation for the case of two machines where α O(log m/log log m) for an arbitrary number m of machines, and the first (2 + ε)-approximation for a constant number of machines. The first result is via an approximation algorithm for a string matching problem that is of independent interest.
SODA	New constructions of (alpha, beta)-spanners and purely additive spanners.	Surender Baswana,Telikepalli Kavitha,Kurt Mehlhorn,Seth Pettie	2005	An (&alpha;, &beta;)-spanner of an unweighted graph G is a subgraph H that approximates distances in G in the following sense. For any two vertices u, v: &delta;H (u, v) &le; &alpha;&delta;G(u, v) + &beta;, where &delta;G is the distance w.r.t. G. It is well known that there exist (multiplicative) (2k - 1, 0)-spanners of size O(n1+1/k) and that there exist (purely additive) (1, 2)-spanners of size O(n3/2). However no other (1, O(1))-spanners are known to exist.In this paper we develop a couple new techniques for constructing (&alpha;, &beta;)-spanners. The first result is a purely additive (1, 6)-spanner of size O(n4/3). Our construction algorithm can be understood as an economical agent that assigns costs and values to paths in the graph, purchasing affordable paths and ignoring expensive ones, which are intuitively well-approximated by paths already purchased. This general approach should lead to new spanner constructions.The second result is a truly simple linear time construction of (k, k - 1)-spanners with size O(n1+1/k). In a distributed network the algorithm terminates in a constant number of rounds and has expected size O(n1+1/k). The new idea here is primarily in the analysis of the construction. We show that a few simple and local rules for picking spanner edges induce seemingly coordinated global behavior.
SODA	Sharing the cost more efficiently: improved approximation for multicommodity rent-or-buy.	Luca Becchetti,Jochen Könemann,Stefano Leonardi,Martin Pál	2005	In the multicommodity rent-or-buy (MROB) network design problems, we are given a network together with a set of k terminal pairs (s1, t1), &hellip;, (sk, tk. The goal is to provision the network so that a given amount of flow can be shipped between si and ti for all 1 &le; i &le; k simultaneously. In order to provision the network, one can either rent capacity on edges at some cost per unit of flow, or buy them at some larger fixed cost. Bought edges have no incremental, flow-dependent cost. The overall objective is to minimize the total provisioning cost. Recently, Gupta et al. [2003a] presented a 12-approximation for the MROB problem. Their algroithm chooses a subset of the terminal pairs in the graph at random and then buys the edges of an approximate Steiner forest for these pairs. This technique had previously been introduced [Gupta et al. 2003b] for the single-sink rent-or-buy network design problem. In this article we give a 6.828-approximation for the MROB problem by refining the algorithm of Gupta et al. and simplifying their analysis. The improvement in our article is based on a more careful adaptation and simplified analysis of the primal-dual algorithm for the Steiner forest problem due to Agrawal et al. [1995]. Our result significantly reduces the gap between the single-sink and multisink case.
SODA	A constant-factor approximation algorithm for optimal terrain guarding.	Boaz Ben-Moshe,Matthew J. Katz,Joseph S. B. Mitchell	2005	We present the first constant-factor approximation algorithm for a non-trivial instance of the optimal guarding (coverage) problem in polygons. In particular, we give an O(1)-approximation algorithm for placing the fewest point guards on a 1.5D terrain, so that every point of the terrain is seen by at least one guard. While polylogarithmic-factor approximations follow from set cover results, our new results exploit geometric structure of terrains to obtain a substantially improved approximation algorithm.
SODA	On the spread of viruses on the internet.	Noam Berger,Christian Borgs,Jennifer T. Chayes,Amin Saberi	2005	We analyze the contact process on random graphs generated according to the preferential attachment scheme as a model for the spread of viruses in the Internet. We show that any virus with a positive rate of spread from a node to its neighbors has a non-vanishing chance of becoming epidemic. Quantitatively, we discover an interesting dichotomy: for a virus with effective spread rate &lambda;, if the infection starts at a typical vertex, then it develops into an epidemic with probability &lambda;&Theta;(log(1/&lambda;)/log log(1/&lambda;), but on average the epidemic probability is &lambda;&Theta;(1).
SODA	Dictionaries using variable-length keys and data, with applications.	Daniel K. Blandford,Guy E. Blelloch	2005	We consider the problem of maintaining a dynamic dictionary in which both the keys and the associated data are variable-length bit-strings. We present a dictionary structure based on hashing that supports constant time lookup and expected amortized constant time insertion and deletion. To store the key-data pairs (s1, t1) ... (sn, tn), our dictionary structure uses O(m) bits where m = &Sigma;(max(|si| -- log n, 1) + |ti| and |si| is the length of bit string si. We assume a word length w > log m.We present several applications, including representations for semi-dynamic graphs, ordered sets for integers in a bounded range, cardinal trees with varying cardinality, and simplicial meshes of k dimensions. These results either generalize or simplify previous results.
SODA	Near-optimal online auctions.	Avrim Blum,Jason D. Hartline	2005	"We consider the online auction problem proposed by Bar-Yossef, Hildrum, and Wu [4] in which an auctioneer is selling identical items to bidders arriving one at a time. We give an auction that achieves a constant factor of the optimal profit less an O(h) additive loss term, where h is the value of the highest bid. Furthermore, this auction does not require foreknowledge of the range of bidders' valuations. On both counts, this answers open questions from [4, 5]. We further improve on the results from [5] for the online posted-price problem by reducing their additive loss term from O(h log h log log h) to O(h log log h). Finally, we define the notion of an (offline) attribute auction for modeling the problem of auctioning items to consumers who are not a-priori indistinguishable. We apply our online auction solution to achieve good bounds for the attribute auction problem with 1-dimensional attributes."
SODA	The relative worst order ratio applied to paging.	Joan Boyar,Lene M. Favrholdt,Kim S. Larsen	2005	The relative worst-order ratio, a relatively new measure for the quality of on-line algorithms, is extended and applied to the paging problem. We obtain results significantly different from those obtained with the competitive ratio. First, we devise a new deterministic paging algorithm, Retrospective-LRU, and show that, according to the relative worst-order ratio and in contrast with the competitive ratio, it performs better than LRU. Our experimental results, though not conclusive, are slightly positive and leave it possible that Retrospective-LRU or similar algorithms may be worth considering in practice. Furthermore, the relative worst-order ratio (and practice) indicates that LRU is better than the marking algorithm FWF, though all deterministic marking algorithms have the same competitive ratio. Look-ahead is also shown to be a significant advantage with this new measure, whereas the competitive ratio does not reflect that look-ahead can be helpful. Finally, with the relative worst-order ratio, as with the competitive ratio, no deterministic marking algorithm can be significantly better than LRU, but the randomized algorithm MARK is better than LRU.
SODA	Multidimensional balanced allocations.	Andrei Z. Broder,Michael Mitzenmacher	2005	We consider a multidimensional variant of the balls-and-bins problem, where balls correspond to random D-dimensional 0-1 vectors. This variant is motivated by a problem in load balancing documents for distributed search engines. We demonstrate the utility of the power of two choices in this domain.
SODA	Improved range-summable random variable construction algorithms.	A. Robert Calderbank,Anna C. Gilbert,Kirill Levchenko,S. Muthukrishnan,Martin Strauss	2005	Range-summable universal hash functions, also known as range-summable random variables, are binary-valued hash functions which can efficiently hash single values as well as ranges of values from the domain. They have found several applications in the area of data stream processing where they are used to construct sketches---small-space summaries of the input sequence.We present two new constructions of range-summable universal hash functions on n-bit strings, one based on Reed-Muller codes which gives k-universal hashing using O(nlog k) space and time for point operations and O(n2 log k) for range operations, and another based on a new subcode of the second-order Reed-Muller code, which gives 5-universal hashing using O(n) space, O(n log3 n) time for point operations, and O(n3) time for range operations.We also present a new sketch data structure using the new hash functions which improves several previous results.
SODA	An O(VE) algorithm for ear decompositions of matching-covered graphs.	Marcelo H. de Carvalho,Joseph Cheriyan	2005	"Our main result is an O(nm)-time (deterministic) algorithm for constructing an ear decomposition of a matching-covered graph, improving on the previous best running time of O(nm2). where n and m denote the number of nodes and edges. The improvement in the running time comes from new structural results that give a sharpened version of Lov&aacute;sz and Plummer's Two-ear Theorem. Our algorithm is based on O(nm)-time algorithms for two other fundamental problems in matching theory, namely, finding all the allowed edges of a graph, and finding the canonical partition of an elementary graph. (To the best of our knowledge, no faster deterministic algorithms are known for these two fundamental problems.)"
SODA	The influence of search engines on preferential attachment.	Soumen Chakrabarti,Alan M. Frieze,Juan Vera	2005	"There is much current interest in the evolution of social networks, especially, the Web graph, through time. ""Preferential attachment"" and the ""copying model"" are well-known models which explain the observed degree distribution of the Web graph reasonably closely. We claim that the presence of highly popular search engines like Google substantially mediate the act of hyperlink creation by limiting the author's attention to a small set of ""celebrity"" URLs. Page authors (who are also Web surfers) frequently (with probability p) locate pages using a search engine. Then they link to popular pages among those they visit. We initiate an analysis of this more realistic process, and show that the celebrity nodes eventually accumulate a constant fraction of all links created whp, and that the degrees of the other nodes still follow a power-law distribution, but with a steeper power: Pr(degree = k) &alpha; k-(1+2/(1-p)) Whp. Our analysis adds evidence to the recent concern that search engines offer new Web pages a steep, self-sustaining barrier to entry to well-connected, entrenched Web communities."
SODA	On levels in arrangements of surfaces in three dimensions.	Timothy M. Chan	2005	"A favorite open problem in combinatorial geometry is to determine the worst-case complexity of a level in an arrangement. Up to now, nontrivial upper bounds in three dimensions are known only for the linear cases of planes and triangles. We propose the first technique that can deal with more general surfaces in three dimensions. For example, in an arrangement of n ""pseudo-planes"" or ""pseudo-spheres"" (where each triple of surfaces has at most two common intersections), we prove that there are at most O(n2.9986) vertices of any given level."
SODA	Finding the shortest bottleneck edge in a parametric minimum spanning tree.	Timothy M. Chan	2005	"The result. Parametric optimization problems that concern graphs with continuously changing edge weights have been explored by numerous researchers, with motivation ranging from sensitivity analysis to mobile-data applications. For instance, Dey [5] has shown that for an undirected graph with n vertices and m edges where the edge weights are linear functions in one parameter (""time""), the minimum spanning tree (MST) can undergo at most O(mn1/3) changes (edge swaps). Agarwal et al. [1] have given data structures to maintain the MST over time, with a cost of O(n2/3 polylog n) per change. Fernandez-Baca et al. [7] have given an algorithm to compute all changes to the MST in O(mn log n) total time."
SODA	On hierarchical routing in doubling metrics.	Hubert T.-H. Chan,Anupam Gupta,Bruce M. Maggs,Shuheng Zhou	2005	We study the problem of routing in doubling metrics, and show how to perform hierarchical routing in such metrics with small stretch and compact routing tables (i.e., with small amount of routing information stored at each vertex). We say that a metric (X, d) has doubling dimension dim(X) at most &alpha; if every set of diameter D can be covered by 2&alpha; sets of diameter D/2. (A doubling metric is one whose doubling dimension dim(X) is a constant.) We show how to perform (1 + &tau;)-stretch routing on metrics for any 0 < T &le; 1 with routing tables of size at most (&alpha;/&tau;)O(&alpha;) log2 &Delta; bits with only (&alpha;/&tau;)O(&alpha;) log &Delta; entries, where &Delta; is the diameter of the graph; hence the number of routing table entries is just &tau;-O(1) log &Delta; for doubling metrics. These results extend and improve on those of Talwar (2004).We also give better constructions of sparse spanners for doubling metrics than those obtained from the routing tables above; for &tau; > 0, we give algorithms to construct (1 + &tau;)-stretch spanners for a metric (X, d) with maximum degree at most (2 + 1/&tau;)O(dim(X)), matching the results of Das et al. for Euclidean metrics.
SODA	Dynamic dictionary matching and compressed suffix trees.	Ho-Leung Chan,Wing-Kai Hon,Tak Wah Lam,Kunihiko Sadakane	2005	Recent breakthrough in compressed indexing data structures has reduced the space for indexing a text (or a collection of texts) of length n from O(n log n) bits to O(n) bits, while allowing very efficient pattern matching [10, 13]. Yet the compressed nature of such indices also makes them difficult to update dynamically. This paper presents the first O(n)-bit representation of a suffix tree for a dynamic collection of texts whose total length is n, which supports insertion and deletion of a text T in O(|T | log2 n) time, as well as all suffix tree traversal operations, including forward and backward suffix links. This work can be regarded as a generalization of the compressed representation of static texts. Our new suffix tree representation serves as a core part in a compact solution for the dynamic dictionary matching problem, i.e., providing an O(d)-bit data structure for a dynamic collection of patterns of total length d that can support the dictionary matching query efficiently. When compared with the O(d log d)-bit suffix tree based solution of Amir et al., the compact solution increases the query time by roughly a factor of log d only. In the study of the above results, we also derive the first O(n)-bit representation for maintaining n pairs of balanced parentheses in O(log n/log log n) time per operation, matching the time complexity of the previous O(n log n)-bit solution.
SODA	A tight threshold for metric Ramsey phenomena.	Moses Charikar,Adriana Karagiozova	2005	In this paper, we examine the metric Ramsey problem for the normed spaces lp: given some 1 &le; p &le; &infin;, &alpha; &ge; 1 and an integer n, we ask for the largest m such that every n-point metric space contains an m-point subspace which embeds into lp with distortion at most &alpha;. Bartal, Linial, Mendel and Naor show in [3] that in the case of 1 &le; p &le; 2, the dependence of m on &alpha; undergoes a phase transition at &alpha; = 2. The case of p > 2 was left as an open problem. We show that the phase transition occurs around &alpha; = 2 for all p &ge; 1. The basis of our result is a proof that there exist {1, 2} metrics which require distortion arbitrarily close to 2 for embedding into lp. In order to show this, we develop new tools for analyzing embeddings of random metrics into lp.
SODA	Embeddings of negative-type metrics and an improved approximation to generalized sparsest cut.	Shuchi Chawla,Anupam Gupta,Harald Räcke	2005	In this article, we study metrics of negative type, which are metrics (V, d) such that &sqrt;d is an Euclidean metric; these metrics are thus also known as &ell;2-squared metrics. We show how to embed n-point negative-type metrics into Euclidean space &ell;2 with distortion D &equals; O(log3/4n). This embedding result, in turn, implies an O(log3/4k)-approximation algorithm for the Sparsest Cut problem with nonuniform demands. Another corollary we obtain is that n-point subsets of &ell;1 embed into &ell;2 with distortion O(log3/4 n).
SODA	Manifold reconstruction from point samples.	Siu-Wing Cheng,Tamal K. Dey,Edgar A. Ramos	2005	"We present an algorithm to ""reconstruct"" a smooth k-dimensional manifold M embedded in an Euclidean space Rd from a ""sufficiently dense"" point sample from the manifold. The algorithm outputs a simplicial manifold that is homeomorphic and geometrically close to M. The running time is O(n log n) where n is the number of points in the sample (the multiplicative constant depends exponentially on the dimension though)."
SODA	Approximation hardness of optimization problems in intersection graphs of -dimensional boxes.	Miroslav Chlebík,Janka Chlebíková	2005	The MAXIMUM INDEPENDENT SET problem in d-box graphs, i.e., in the intersection graphs of axis-parallel rectangles in Rd, is a challenge open problem. For any fixed d &ge; 2 the problem is NP-hard and no approximation algorithm with ratio o(logd-1 n) is known. In some restricted cases, e.g., for d-boxes with bounded aspect ratio, a PTAS exists [17]. In this paper we prove APX-hardness (and hence non-existence of a PTAS, unless P = NP), of the MAXIMUM INDEPENDENT SET problem in d-box graphs for any fixed d &ge; 3. We state also first explicit lower bound 443/442 on efficient approximability in such case. Additionally, we provide a generic method how to prove APX-hardness for many NP-hard graph optimization problems in d-box graphs for any fixed d &ge; 3. In 2-dimensional case we give a generic approach to NP-hardness results for these problems in highly restricted intersection graphs of axis-parallel unit squares (alternatively, in unit disk graphs).
SODA	External-memory exact and approximate all-pairs shortest-paths in undirected graphs.	Rezaul Alam Chowdhury,Vijaya Ramachandran	2005	We present several new external-memory algorithms for finding all-pairs shortest paths in a V-node. E-edge undirected graph. For all-pairs shortest paths and diameter in unweighted undirected graphs we present cache-oblivious algorithms with O(V&middot;E/B log M/B E/B) I/Os, where B is the block-size and M is the size of internal memory. For weighted undirected graphs we present a cache-aware APSP algorithm that performs O(V&middot;(&radic;VE/B+E/B log E/B)) I/Os. We also present efficient cache-aware algorithms that find paths between all pairs of vertices in an unweighted graph with lengths within a small additive constant of the shortest path length.All of our results improve earlier results known for these problems. For approximate APSP we provide the first nontrivial results. Our diameter result uses O(V + E) extra space, and all of our other algorithms use O(V2) space.
SODA	On the approximability of some network design problems.	Julia Chuzhoy,Anupam Gupta,Joseph Naor,Amitabh Sinha	2005	Consider the following classical network design problem: a set of terminals T &equals; &lcub;ti&rcub; wishes to send traffic to a root r in an n-node graph G &equals; (V, E). Each terminal ti sends di units of traffic and enough bandwidth has to be allocated on the edges to permit this. However, bandwidth on an edge e can only be allocated in integral multiples of some base capacity ue and hence provisioning k &times; ue bandwidth on edge e incurs a cost of &lceil;k&rceil; times the cost of that edge. The objective is a minimum-cost feasible solution. This is one of many network design problems widely studied where the bandwidth allocation is governed by side constraints: edges can only allow a subset of cables to be purchased on them or certain quality-of-service requirements may have to be met. In this work, we show that this problem and, in fact, several basic problems in this general network design framework cannot be approximated better than &Omega;(log log n) unless NP &sube; DTIME (nO(log log log n)), where &verbar;V&verbar; &equals; n. In particular, we show that this inapproximability threshold holds for (i) the Priority-Steiner Tree problem, (ii) the (single-sink) Cost-Distance problem, and (iii) the single-sink version of an even more fundamental problem, Fixed Charge Network Flow. Our results provide a further breakthrough in the understanding of the level of complexity of network design problems. These are the first nonconstant hardness results known for all these problems.
SODA	Approximating k-median with non-uniform capacities.	Julia Chuzhoy,Yuval Rabani	2005	In this paper we give a constant factor approximation algorithm for the capacitated k-median problem. Our algorithm produces a solution where capacities are exceeded by at most a constant factor, while the number of open facilities is at most k. This problem resisted attempts to apply the plethora of methods designed for the uncapacitated case. Our algorithm is based on adding some new ingredients to the approach using the primal-dual schema and lagrangian relaxations.Previous results on the capacitated k-median problem gave approximations where the number of facilities is exceeded by some constant factor. Relaxing the constraint on the number of facilities seems to render k-median problems much simpler. In some applications it is important not to violate the constraint on the number of facilities, whereas relaxing the capacity constraints is a natural thing to do, as the capacities express rough estimates on cluster sizes.
SODA	On the polynomial time computation of equilibria for certain exchange economies.	Bruno Codenotti,Sriram V. Pemmaraju,Kasturi R. Varadarajan	2005	The problem of computing equilibria for exchange economies has recently started to receive a great deal of attention in the theoretical computer science community. It has been shown that equilibria can be computed in polynomial time in various special cases, the most important of which are when traders have linear, Cobb-Douglas, or a range of CES utility functions. These important special cases are instances when the market satisfies a property called weak gross substitutability. Classical results in economics, which theoretical computer scientists (including us) appear to have been hitherto unaware of, show that the equilibrium prices in such markets are characterized by an infinite number of linear inequalities and therefore form a convex set. In this paper, we show that under fairly general assumptions, there are polynomial-time algorithms to compute equilibria in such markets. To the best of our knowledge, these are the first polynomial-time algorithms for exchange markets under the general setting of weak gross substitutability. To show this result, we need to build on the proofs that characterize the equilibria as a convex set.As a consequence, we obtain alternative polynomial-time algorithms for computing equilibria with linear, Cobb-Douglas, a range of CES, as well as certain other non-homogeneous utility functions that satisfy weak gross substitutability. Unlike previous polynomial-time algorithms, our approach does not make use of the specific form of these utility functions and is in this sense more general. We expect our framework to work or be readily adaptable to handle other exchange markets, provided that the utility functions satisfy weak gross substitutability.
SODA	A spectral heuristic for bisecting random graphs.	Amin Coja-Oghlan	2005	"The minimum bisection problem is to partition the vertices of a graph into two classes of equal size so as to minimize the number of crossing edges. The problem is NP-hard in the worst case. In this paper we analyze a spectral heuristic for the minimum bisection problem on random graphs Gn(p,p'), which are made up as follows. Partition n vertices into two classes of equal size randomly, and then insert edges inside the two classes with probability p' and edges crossing the partition with probability p independently. If n(p'-p) &ge; c0&radic;np'In(np') for a certain constant c0 > 0, then with probability 1 - 0(1) as n &larr; &infin; the heuristic finds a minimum bisection of Gn(p,p') along with a certificate of optimality in polynomial time. Furthermore, we observe that the structure of the set of all minimum bisections of Gn(p,p') undergoes a phase transition as n(p' - p) = &Theta;(&radic;np' In n). The heuristic solves instances in the subcritical, the critical, and the supercritical phase of the phase transition optimally with probability 1-o(1). These results extend the work of Boppana [5]."
SODA	Sampling regular graphs and a peer-to-peer network.	Colin Cooper,Martin E. Dyer,Catherine S. Greenhill	2005	We consider a simple Markov chain for d-regular graphs on n vertices, and show that the mixing time of this Markov chain is bounded above by a polynomial in n and d. A related Markov chain for d-regular graphs on a varying number of vertices is introduced, for even degree d. We use this to model a certain peer-to-peer network structure. We prove that the related chain has mixing time which is bounded by a polynomial in N, the expected number of vertices, under reasonable assumptions about the arrival and departure process.
SODA	The cover time of two classes of random graphs.	Colin Cooper,Alan M. Frieze	2005	Let G = (V,E) be a connected graph, let |V| = n, and |E| = m. A random walk Wu, u &isin; V on the undirected graph G = (V, E) is a Markov chain X0 = u, X1,...Xt,... &isin; V associated to a particle that moves from vertex to vertex according to the following rule: the probability of a transition from vertex i, of degree di, to vertex j is 1/di if {i,j} &isin; E, and 0 otherwise. For u &isin; V let Cu be the expected time taken for Wu to visit every vertex of G. The cover time CG of G is defined as CG = maxu&isin;V Cu. The cover time of connected graphs has been extensively studied. It is a classic result of Aleliunas, Karp, Lipton, Lov&aacute;sz and Rackoff [2] that CG &le; 2m(n - 1). It was shown by Feige [11], [12], that for any connected graph G[EQUATION]The lower bound is achieved by (for example) the complete graph Kn, whose cover time is determined by the Coupon Collector problem.
SODA	Sparse source-wise and pair-wise distance preservers.	Don Coppersmith,Michael Elkin	2005	"We introduce and study the notions of pair-wise and source-wise preservers.Given an undirected N-vertex graph G = (V, E) and a subset P of pairs of vertices, let G' = (V, H), H &sube; E, be called a pair-wise preserver of G with respect to P if for every pair {u, w} &isin; P, distG' (u, w) = distG (u, w). For a set S &sube; V of sources, a pair-wise preserver of G with respect to the set of all pairs P = (S/2) of sources is called a source-wise preserver of G with respect to S.We prove that for every undirected possibly weighted N-vertex graph G and every subset P of P = O(N1/2) pairs of vertices of G, there exists a linear-size pair-wise preserver of G with respect to P. Consequently, for every subset S &sube; V of S = O(N1/4) sources, there exists a linear-size source-wise preserver of G with respect to S. On the negative side we show that neither of the two exponents (1/2 and 1/4) can be improved even when the attention is restricted to unweighted graphs.Our lower bounds involve constructions of dense convexly independent sets of vectors with small Euclidean norms. We believe that the link between the areas of Discrete Geometry and spanners that we establish is of independent interest, and might be useful in the study of other problems in the area of low-distortion embeddings."
SODA	Substring compression problems.	Graham Cormode,S. Muthukrishnan	2005	We initiate a new class of string matching problems called Substring Compression Problems. Given a string S that may be preprocessed, the problem is to quickly find the compressed representation or the compressed size of any query substring of S (Substring Compression Query or SCQ) or to find the length l substring of S whose compression is the least (Least Compressible Substring or LCS problem).Starting from the seminal paper of Lempel and Ziv over 25 years ago, many different methods have emerged for compressing entire strings. Determining substring compressibility is a natural variant that is combinatorially and algorithmically challenging, yet surprisingly has not been studied before. In addition, compressibility of strings is emerging as a tool to compare biological sequences and analyze their information content. However, typically, the compressibility of the entire sequence is not as informative as that of portions of the sequences. Thus substring compressibility may be a more suitable basis for sequence analysis.We present the first known, nearly optimal algorithms for substring compression problems---SCQ, LCS and their generalizations---that are exact or provably approximate. Our exact algorithms exploit the structure in strings via suffix trees and our approximate algorithms rely on new relationships we find between Lempel-Ziv compression and string parsings.
SODA	Adaptivity and approximation for stochastic packing problems.	Brian C. Dean,Michel X. Goemans,Jan Vondrák	2005	"We study stochastic variants of Packing Integer Programs (PIP) --- the problems of finding a maximum-value 0/1 vector x satisfying Ax &le; b, with A and b nonnegative. Many combinatorial problems belong to this broad class, including the knapsack problem, maximum clique, stable set, matching, hypergraph matching (a.k.a. set packing), b-matching, and others. PIP can also be seen as a ""multidimensional"" knapsack problem where we wish to pack a maximum-value collection of items with vector-valued sizes. In our stochastic setting, the vector-valued sizes of each item is known to us apriori only as a probability distribution, and the size of an item is instantiated once we commit to including the item in our solution.Following the framework of [3], we consider both adaptive and non-adaptive policies for solving such problems, adaptive policies having the flexibility of being able to make decisions based on the instantiated sizes of items already included in the solution. We investigate the adaptivity gap for these problems: the maximum ratio between the expected values achieved by optimal adaptive and non-adaptive policies. We show tight bounds on the adaptivity gap for set packing and b-matching, and we also show how to find efficiently non-adaptive policies approximating the adaptive optimum. For instance, we can approximate the adaptive optimum for stochastic set packing to within O(d1/2), which is not only optimal with respect to the adaptivity gap, but it is also the best known approximation factor in the deterministic case. It is known that there is no polynomial-time d1/2-&epsilon; approximation for set packing, unless NP = ZPP. Similarly, for b-matching, we obtain algorithmically a tight bound on the adaptivity gap of O(&lambda;) where &lambda; satisfies &Sigma; &lambda;bj+1 = 1.For general Stochastic Packing, we prove that a simple greedy algorithm provides an O(d)-approximation to the adaptive optimum. For A &isin; [0, 1]dxn, we provide an O(&lambda;) approximation where &Sigma; 1/&lambda;bj = 1. (For b = (B, B,..., B), we get &lambda; = d1/B.) We also improve the hardness results for deterministic PIP: in the general case, we prove that a polynomial-time d1-&epsilon;-approximation algorithm would imply NP = ZPP. In the special case when A &isin; [0,1]dxn and b = (B,B,...,B), we show that a d1/B-&isin;-approximation would imply NP = ZPP. Finally, we prove that it is PSPACE-hard to find the optimal adaptive policy for Stochastic Packing in any fixed dimension d &ge; 2."
SODA	Bidimensionality: new connections between FPT algorithms and PTASs.	Erik D. Demaine,Mohammad Taghi Hajiaghayi	2005	"We demonstrate a new connection between fixed-parameter tractability and approximation algorithms for combinatorial optimization problems on planar graphs and their generalizations. Specifically, we extend the theory of so-called ""bidimensional"" problems to show that essentially all such problems have both subexponential fixed-parameter algorithms and PTASs. Bidimensional problems include e.g. feedback vertex set, vertex cover, minimum maximal matching, face cover, a series of vertex-removal problems, dominating set, edge dominating set, r-dominating set, diameter, connected dominating set, connected edge dominating set, and connected r-dominating set. We obtain PTASs for all of these problems in planar graphs and certain generalizations; of particular interest are our results for the two well-known problems of connected dominating set and general feedback vertex set for planar graphs and their generalizations, for which PTASs were not known to exist. Our techniques generalize and in some sense unify the two main previous approaches for designing PTASs in planar graphs, namely, the Lipton-Tarjan separator approach [FOCS'77] and the Baker layerwise decomposition approach [FOCS'83]. In particular, we replace the notion of separators with a more powerful tool from the bidimensionality theory, enabling the first approach to apply to a much broader class of minimization problems than previously possible; and through the use of a structural backbone and thickening of layers we demonstrate how the second approach can be applied to problems with a ""nonlocal"" structure."
SODA	Graphs excluding a fixed minor have grids as large as treewidth, with combinatorial and algorithmic applications through bidimensionality.	Erik D. Demaine,Mohammad Taghi Hajiaghayi	2005	We prove that any H-minor-free graph, for a fixed graph H, of treewidth &omega; has an &Omega;(&omega;) &times; &Omega;(&omega;) grid graph as a minor. Thus grid minors suffice to certify that H-minor-free graphs have large treewidth, up to constant factors. This strong relationship was previously known for the special cases of planar graphs and bounded-genus graphs, and is known not to hold for general graphs. The approach of this paper can be viewed more generally as a framework for extending combinatorial results on planar graphs to hold on H-minor-free graphs for any fixed H. Our result has many combinatorial con-sequences on bidimensionality theory, parameter-treewidth bounds, separator theorems, and bounded local treewidth; each of these combinatorial results has several algorithmic consequences including subexponential fixed-parameter algorithms and approximation algorithms.
SODA	Delaunay triangulations approximate anchor hulls.	Tamal K. Dey,Joachim Giesen,Samrat Goswami	2005	Recent results establish that a subset of the Voronoi diagram of a point set that is sampled from the smooth boundary of a shape approximates the medial axis. The corresponding question for the dual Delaunay triangulation is not addressed in the literature. We show that, for two-dimensional shapes, the Delaunay triangulation approximates a specific structure which we call anchor hulls. As an application we demonstrate that our approximation result is useful for the problem of shape matching.
SODA	Matrix rounding with low error in small submatrices.	Benjamin Doerr	2005	We show that any real valued matrix A can be rounded to an integer one B such that the error in all 2 x 2 (geometric) submatrices is less than 1.5, that is, we have |aij - bij| < 1 and |&Sigma;i+1k=i &Sigma;j+1l=j(akl - bkl| < 1.5 for all i, j. More precisely, an error of less than 1.5 - 3-2mn + 3-d+1 can be achieved in time O(mnd).
SODA	An improved approximation algorithm for virtual private network design.	Friedrich Eisenbrand,Fabrizio Grandoni	2005	"Virtual private network design deals with the reservation of capacities in a network, such that the nodes can share communication. Each node in the network has associated upper bounds on the amount of flow that it can send to the network and receive from the network respectively. The problem then is to reserve capacities at minimum cost and to compute paths between every pair of nodes such that all valid traffic-matrices can be routed along the corresponding paths.In this paper we present a simple 4.74-approximation algorithm for virtual private network design. The previous best approximation algorithm for this problem achieves a ratio of 5.55 (Gupta, Kumar, and Roughgarden STOC'03)."
SODA	Improved schedule for radio broadcast.	Michael Elkin,Guy Kortsarz	2005	We show that for every radio network G = (V, E) and source s &epsilon; V, there exists a radio broadcast schedule for G of length Rad(G, s) + O(&radic; Rad(G, s). log2 n) = O(Rad(G, s) + log4 n), where Rad(G, s) is the radius of the radio network G with respect to the source s. This result improves the previously best-known upper bound of O(Rad(G, s)+log5 n) due to Gaber and Mansour [12].For graphs with small genus, particularly for planar graphs, we provide an even better upper bound of Rad(G, S) + O(&radic; Rad(G, s). log n + log3 n) = O(Rad(G, s) + log3 n).
SODA	All maximal independent sets and dynamic dominance for sparse graphs.	David Eppstein	2005	"We describe algorithms, based on Avis and Fukuda's reverse search paradigm, for listing all maximal independent sets in a sparse graph in polynomial time and delay per output. For bounded degree graphs, our algorithms take constant time per set generated; for minor-closed graph families, the time is O(n) per set, and for more general sparse graph families we achieve subquadratic time per set. We also describe new data structures for maintaining a dynamic vertex set S in a sparse or minor-closed graph family, and querying the number of vertices not dominated by S; for minor-closed graph families the time per update is constant, while it is sublinear for any sparse graph family. We can also maintain a dynamic vertex set in an arbitrary m-edge graph and test the independence of the maintained set in time O(&radic;m) per update. We use the domination data structures as part of our enumeration algorithms."
SODA	Lower bounds for external algebraic decision trees.	Jeff Erickson	2005	We propose a natural extension of algebraic decision trees to the external-memory setting, where the cost of disk operations overwhelms CPU time, and prove a tight lower bound of &Omega;(n logm n) on the complexity of both sorting and element uniqueness in this model of computation. We also prove a &Omega;(min{n logm n, N}) lower bound for both problems in a less restrictive model, which requires only that the worst-case internal-memory computation time is finite. Standard reductions immediately generalize these lower bounds to a large number of fundamental computational geometry problems.
SODA	Greedy optimal homotopy and homology generators.	Jeff Erickson,Kim Whittlesey	2005	"We describe simple greedy algorithms to construct the shortest set of loops that generates either the fundamental group (with a given basepoint) or the first homology group (over any fixed coefficient field) of any oriented 2-manifold. In particular, we show that the shortest set of loops that generate the fundamental group of any oriented combinatorial 2-manifold, with any given basepoint, can be constructed in O(n log n) time using a straightforward application of Dijkstra's shortest path algorithm. This solves an open problem of Colin de Verdi&egrave;re and Lazarus."
SODA	Fast convergence of selfish rerouting.	Eyal Even-Dar,Yishay Mansour	2005	We consider n anonymous selfish users that route their communication through m parallel links. The users are allowed to reroute, concurrently, from overloaded links to underloaded links. The different rerouting decisions are concurrent, randomized and independent. The rerouting process terminates when the system reaches a Nash equilibrium, in which no user can improve its state.We study the convergence rate of several migration policies. The first is a very natural policy, which balances the expected load on the links, for the case that all users are identical and apply it, we show that the rerouting terminates in expected O(log log n + log m) stages. Later, we consider the Nash rerouting policies class, in which every rerouting stage is a Nash equilibrium and the users are greedy with respect to the next load they observe. We show a similar termination bounds for this class. We study the structural properties of the Nash rerouting policies, and derive both existence result and an efficient algorithm for the case that the number of links is small. We also show that if the users have different weights then there exists a set of weights such that every Nash rerouting terminates in &Omega;(&radic;n) stages with high probability.
SODA	Two algorithms for general list matrix partitions.	Tomás Feder,Pavol Hell,Daniel Král,Jiri Sgall	2005	"List matrix partitions are restricted binary list constraint satisfaction problems which generalize list homomorphisms and many graph partition problems arising, e.g., in the study of perfect graphs. Most of the existing algorithms apply to concrete small matrices, i.e., to partitions into a small number of parts. We focus on two general classes of partition problems, provide algorithms for their solution, and discuss their implications.The first is an O(nr+2)-algorithm for the list M-partition problem where M is any r by r matrix over subsets of {0, 1}, which has the ""bisplit property"". This algorithm can be applied to recognize so-called k-bisplit graphs in polynomial time, yielding a solution of an open problem from [2].The second is an algorithm running in time (rn)O(log r log n/log log n)nO(log2r) for the list M-partition problem where M is any r &times; r matrix over subsets of {0,1,...,q- 1}, with the ""incomplete property"". This algorithm applies to all non-NP-complete list M-partition problems with r = 3, and it improves the running time of the quasi-polynomial algorithm for the ""stubborn problem"" from [5], and for the ""edge-free three-coloring problem"" from [12]."
SODA	Finding large cycles in Hamiltonian graphs.	Tomás Feder,Rajeev Motwani	2005	We show how to find in Hamiltonian graphs a cycle of length n^@W^(^1^/^l^o^g^l^o^g^n^)=exp(@W(logn/loglogn)). This is a consequence of a more general result in which we show that if G has a maximum degree d and has a cycle with k vertices (or a 3-cyclable minor H with k vertices), then we can find in O(n^3) time a cycle in G of length k^@W^(^1^/^l^o^g^d^). From this we infer that if G has a cycle of length k, then one can find in O(n^3) time a cycle of length k^@W^(^1^/^(^l^o^g^(^n^/^k^)^+^l^o^g^l^o^g^n^)^), which implies the result for Hamiltonian graphs. Our results improve, for some values of k and d, a recent result of Gabow (2004) [11] showing that if G has a cycle of length k, then one can find in polynomial time a cycle in G of length exp(@W(logk/loglogk)). We finally show that if G has fixed Euler genus g and has a cycle with k vertices (or a 3-cyclable minor H with k vertices), then we can find in polynomial time a cycle in G of length f(g)k^@W^(^1^), running in time O(n^2) for planar graphs.
SODA	Rigorous analysis of heuristics for NP-hard problems.	Uriel Feige	2005	Rigorous analysis of heuristics for NP-hard problems.
SODA	Graph distances in the streaming model: the value of space.	Joan Feigenbaum,Sampath Kannan,Andrew McGregor,Siddharth Suri,Jian Zhang	2005	We investigate the importance of space when solving problems based on graph distance in the streaming model. In this model, the input graph is presented as a stream of edges in an arbitrary order. The main computational restriction of the model is that we have limited space and therefore cannot store all the streamed data; we are forced to make space-efficient summaries of the data as we go along. For a graph of n vertices and m edges, we show that testing many graph properties, including connectivity (ergo any reasonable decision problem about distances) and bipartiteness, requires &Omega;(n) bits of space. Given this, we then investigate how the power of the model increases as we relax our space restriction. Our main result is an efficient randomized algorithm that constructs a (2t + 1)-spanner in one pass. With high probability, it uses O(t .n1+1/t log2n) bits of space and processes each edge in the stream in O(t2&middot;n1/t log n) time. We find approximations to diameter and girth via the constructed spanner. For t = &Omega;(log n/log log n), the space requirement of the algorithm is O(n .polylog n), and the per-edge processing time is O(polylog n). We also show a corresponding lower bound of t for the approximation ratio achievable when the space restriction is O(t.n1+1/t log2n).We then consider the scenario in which we are allowed multiple passes over the input stream. Here, we investigate whether allowing these extra passes will compensate for a given space restriction. We show that finding vertices at distance d from a particular vertex will always take d passes, for all d &isin; {1,...,t/2}, when the space restriction is o(n1+1/t). For girth, we show the existence of a direct trade-off between space and passes in the form of a lower bound on the product of the space requirement and number of passes. Finally, we conclude with two general techniques for speeding up the per-edge computation time of streaming algorithms while increasing the space by at most a log factor.
SODA	LP decoding achieves capacity.	Jon Feldman,Clifford Stein	2005	"We give a linear programming (LP) decoder that achieves the capacity (optimal rate) of a wide range of probabilistic binary communication channels. This is the first such result for LP decoding. More generally, as far as the authors are aware this is the first known polynomial-time capacity-achieving decoder with the maximum-likelihood (ML) certificate property---where output codewords come with a proof of optimality. Additionally, this result extends the capacity-achieving property of expander codes beyond the binary symmetric channel to a larger family of communication channels.Perhaps most importantly, since LP decoding performs well in practice on turbo codes and low-density parity-check (LDPC) codes (comparable to the popular ""belief propagation"" algorithm), this result exhibits the power of a new, widely applicable ""dual witness"" technique (Feldman, Malkin, Servedio, Stein and Wainwright, ISIT '04) for bounding decoder performance.For expander codes over an adversarial channel, we prove that LP decoding corrects a constant fraction of errors. To show this, we provide a new combinatorial characterization of error events that is of independent interest, and which we expect will lead to further improvements."
SODA	Online conflict-free coloring for intervals.	Amos Fiat,Meital Levy,Jirí Matousek,Elchanan Mossel,János Pach,Micha Sharir,Shakhar Smorodinsky,Uli Wagner,Emo Welzl	2005	We consider an online version of the conflict-free coloring of a set of points on the line, where each newly inserted point must be assigned a color upon insertion, and at all times the coloring has to be conflict-free, in the sense that in every interval I there is a color that appears exactly once in I. We present several deterministic and randomized algorithms for achieving this goal, and analyze their performance, that is, the maximum number of colors that they need to use, as a function of the number n of inserted points. We first show that a natural and simple (deterministic) approach may perform rather poorly, requiring &Omega;(&radic;n) colors in the worst case. We then modify this approach, to obtain an efficient deterministic algorithm that uses a maximum of &Theta;(log2 n) colors. Next, we present two randomized solutions. The first algorithm requires an expected number of at most O(log2 n) colors, and produces a coloring which is valid with high probability, and the second one, which is a variant of our efficient deterministic algorithm, requires an expected number of at most O(log n log log n) colors but always produces a valid coloring. We also analyze the performance of the simplest proposed algorithm when the points are inserted in a random order, and present an incomplete analysis that indicates that, with high probability, it uses only O(log n) colors. Finally, we show that in the extension of this problem to two dimensions, where the relevant ranges are disks, n colors may be required in the worst case. The average-case behavior for disks, and cases involving other planar ranges, are still open.
SODA	On the random 2-stage minimum spanning tree.	Abraham D. Flaxman,Alan M. Frieze,Michael Krivelevich	2005	"It is known [7] that if the edge costs of the complete graph Kn are independent random variables, uniformly distributed between 0 and 1, then the expected cost of the minimum spanning tree is asymptotically equal to &zeta;(3) = &Sigma; &infin;i=1 i-3. Here we consider the following stochastic two-stage version of this optimization problem. There are two sets of edge costs cM: E &larr; R and cT: E &larr; R, called Monday's prices and Tuesday's prices, respectively. For each edge e, both costs cM(e) and cT(e) are independent random variables, uniformly distributed in [0, 1]. The Monday costs are revealed first. The algorithm has to decide on Monday for each edge e whether to buy it at Monday's price cM(e), or to wait until its Tuesday price cT(e) appears. The set of edges XM bought on Monday is then completed by the set of edges XT bought on Tuesday to form a spanning tree. If both Monday's and Tuesday's prices were revealed simultaneously, then the optimal solution would have expected cost &zeta;(3)/2 + o(1). We show that in the case of two-stage optimization, the expected value of the optimal cost exceeds &zeta;(3)/2 by an absolute constant &isin; > 0. We also consider a threshold heuristic, where the algorithm buys on Monday only edges of cost less than &alpha; and completes them on Tuesday in an optimal way, and show that the optimal choice for &alpha; is &alpha; = 1/n with the expected cost &zeta;(3) - 1/2 + o(1). The threshold heuristic is shown to be sub-optimal. Finally we discuss the directed version of the problem, where the task is to construct a spanning out-arborescence rooted at a fixed vertex r, and show, somewhat surprisingly, that in this case a simple variant of the threshold heuristic gives the asymptotically optimal value 1 - 1/e + o(1)."
SODA	Adversarial deletion in a scale free random graph process.	Abraham Flaxman,Alan M. Frieze,Juan Vera	2005	We study a dynamically evolving random graph which adds vertices and edges using preferential attachment and is &lsquo;attacked by an adversary&rsquo;. At time $t$, we add a new vertex $x_t$ and $m$ random edges incident with $x_t$, where $m$ is constant. The neighbours of $x_t$ are chosen with probability proportional to degree. After adding the edges, the adversary is allowed to delete vertices. The only constraint on the adversarial deletions is that the total number of vertices deleted by time $n$ must be no larger than $\delta n$, where $\delta$ is a constant. We show that if $\delta$ is sufficiently small and $m$ is sufficiently large then with high probability at time $n$ the generated graph has a component of size at least $n/30$.
SODA	Online convex optimization in the bandit setting: gradient descent without a gradient.	Abraham Flaxman,Adam Tauman Kalai,H. Brendan McMahan	2005	"We study a general online convex optimization problem. We have a convex set S and an unknown sequence of cost functions c1, c2,..., and in each period, we choose a feasible point xt in S, and learn the cost ct(xt). If the function ct is also revealed after each period then, as Zinkevich shows in [25], gradient descent can be used on these functions to get regret bounds of O(&radic;n). That is, after n rounds, the total cost incurred will be O(&radic;n) more than the cost of the best single feasible decision chosen with the benefit of hindsight, minx &Sigma; ct(x).We extend this to the ""bandit"" setting, where, in each period, only the cost ct(xt) is revealed, and bound the expected regret as O(n3/4).Our approach uses a simple approximation of the gradient that is computed from evaluating ct at a single (random) point. We show that this biased estimate is sufficient to approximate gradient descent on the sequence of functions. In other words, it is possible to use gradient descent without seeing anything more than the value of the functions at a single point. The guarantees hold even in the most general case: online against an adaptive adversary.For the online linear optimization problem [15], algorithms with low regrets in the bandit setting have recently been given against oblivious [1] and adaptive adversaries [19]. In contrast to these algorithms, which distinguish between explicit explore and exploit periods, our algorithm can be interpreted as doing a small amount of exploration in each period."
SODA	Controlled perturbation for Delaunay triangulations.	Stefan Funke,Christian Klein,Kurt Mehlhorn,Susanne Schmitt	2005	Most geometric algorithms are idealistic in the sense that they are designed for the Real-RAM model of computation and for inputs in general position. Real inputs may be degenerate and floating point arithmetic is only an approximation of real arithmetic. Perturbation replaces an input by a nearby input which is (hopefully) in general position and on which the algorithm can be run with floating point arithmetic. Controlled perturbation as proposed by Halperin et al. calls for more: control over the amount of perturbation needed for a given precision of the floating point system. Or conversely, a control over the precision needed for a given amount of perturbation. Halperin et al. gave controlled perturbation schemes for arrangements of polyhedral surfaces, spheres, and circles.We extend their work and point out that controlled perturbation is a general scheme for converting idealistic algorithms into algorithms which can be executed with floating point arithmetic. We also show how to use controlled perturbation in the context of randomized geometric algorithms without deteriorating the running time. Finally, we give concrete schemes for planar Delaunay triangulations and convex hulls and Delaunay triangulations in arbitrary dimensions. We analyze the relation between the perturbation amount and the precision of the floating point system. We also report about experiments with a planar Delaunay diagram algorithm.
SODA	Dissections and trees, with applications to optimal mesh encoding and to random sampling.	Éric Fusy,Dominique Poulalhon,Gilles Schaeffer	2005	We present a bijection between some quadrangular dissections of an hexagon and unrooted binary trees. This correspondence has interesting consequences for enumeration, mesh compression and random graph sampling.It yields a succinct representation for the set P(n) of n-edge 3-connected planar graphs matching the entropy bound 1/n log |P(n)| = 2+o(1) bits per edge. This solves a theoretical problem in mesh compression, as these graphs abstract the combinatorial part of meshes with spherical topology.Once the entropy bound is matched, the guaranteed compression rate can only be improved on subclasses: we achieve the optimal parametric rate 1/n log |P(n, i, j)| bits per edge for graphs of P(n) with i vertices and j faces. This effectively reduces the entropy as soon as |i -j| &Gt; n1/2, and achieves the optimal rate for triangulations.It also yields an efficient uniform random sampler for labeled 3-connected planar graphs. Using it, the amortized complexity of sampling labeled planar graphs is reduced from the best previously known O(n6.5) to O(n3).
SODA	Approximating the smallest -edge connected spanning subgraph by LP-rounding.	Harold N. Gabow,Michel X. Goemans,Éva Tardos,David P. Williamson	2005	The smallest k-ECSS problem is, given a graph along with an integer k, find a spanning subgraph that is k-edge connected and contains the fewest possible number of edges. We examine a natural approximation algorithm based on rounding an LP solution. A tight bound on the approximation ratio is 1 + 3-k for undirected graphs with k > 1 odd, 1 + 2-k for undirected graphs with k even, and 1 + 2-k for directed graphs with k arbitrary. Using iterated rounding improves the first upper bound to 1 + 2-k. On the hardness side we show that for some absolute constant c > 0, for any integer k &ge; 2 (k &ge; 1), a polynomial-time algorithm approximating the smallest k-ECSS on undirected (directed) multigraphs to within ratio 1 + c-k would imply P = NP. &copy; 2008 Wiley Periodicals, Inc. NETWORKS, 2009
SODA	The expected value of random minimal length spanning tree of a complete graph.	David Gamarnik	2005	We consider the number c(n, m) of connected labeled graphs on n nodes and m edges and the intimately related object, the expected length of the minimal spanning tree of a complete graphs with random edge lengths. We use a very simple recursive procedure for computing the values of c(n, m) for computing the expected length of the minimal spanning tree exactly, under the uniform and the exponential distributions. Our computations are recursive, scale very well with the size of the problem, and we provide the values of the expected minimal length spanning trees for complete graphs Kn with sizes n &le; 45, extending recent results of Steele [Ste02], and Fill and Steele [FS04]. The main proof technique is based on introducing an artificial root to a graph and subsequently using a very simple inductive argument.
SODA	Improved approximation for universal facility location.	Naveen Garg,Rohit Khandekar,Vinayaka Pandit	2005	The Universal Facility Location problem (UniFL) is a generalized formulation which contains several variants of facility location including capacitated facility location (1-CFL) as its special cases. We present a 6 + &epsilon; approximation for the UniFL problem, thus improving the 8 + &isin; approximation given by Mahdian and Pal. Our result bridges the existing gap between the UniFL problem and the 1-CFL problem.
SODA	Dominator tree verification and vertex-disjoint paths.	Loukas Georgiadis,Robert Endre Tarjan	2005	We present a linear-time algorithm that given a flowgraph G = (V,A,r) and a tree T, checks whether T is the dominator tree of G. Also we prove that there exist two spanning trees of G, T1 and T2, such that for any vertex <u>v</u> the paths from r to <u>v</u> in T1 and T2 intersect only at the vertices that dominate <u>v</u>. The proof is constructive and our algorithm can build the two spanning trees in linear time. Simpler versions of our two algorithms run in O(m&alpha;(m, n))-time, where n is the number of vertices and m is the number of arcs in G. The existence of such two spanning trees implies that we can order the calculations of the iterative algorithm for finding dominators, proposed by Allen and Cocke [2], so that it builds the dominator tree in a single iteration.
SODA	Random planar graphs with nodes and a fixed number of edges.	Stefanie Gerke,Colin McDiarmid,Angelika Steger,Andreas Weißl	2005	Let P(n, m) be the class of simple labelled planar graphs with n nodes and m edges, and let Rn,q be a graph drawn uniformly at random from P(n, [qn]). We show properties that hold with high probability (w.h.p.) for Rn,q when 1 < q < 3. For example, we show that Rn,q contains w.h.p. linearly many nodes of each given degree and linearly many node disjoint copies of each given fixed connected planar graph. Additionally, we show that the probability that Rn,q is connected is bounded away from one by a non-zero constant. As a tool we show that (|P(n, [qn])|/n!)1/n tends to a limit as n tends to infinity.
SODA	Computing the shortest path: search meets graph theory.	Andrew V. Goldberg,Chris Harrelson	2005	We propose shortest path algorithms that use A* search in combination with a new graph-theoretic lower-bounding technique based on landmarks and the triangle inequality. Our algorithms compute optimal shortest paths and work on any directed graph. We give experimental results showing that the most efficient of our new algorithms outperforms previous algorithms, in particular A* search with Euclidean bounds, by a wide margin on road networks and on some synthetic problem families.
SODA	Collusion-resistant mechanisms for single-parameter agents.	Andrew V. Goldberg,Jason D. Hartline	2005	"We consider the problem of designing mechanisms with the incentive property that no coalition of agents can engage in a collusive strategy that results in an increase in the combined utility of the coalition. For single parameter agents, we give a characterization that essentially restricts such mechanisms to those that post a ""take it or leave it"" price to for each agent in advance. We then consider relaxing the incentive property to only hold with high probability. In this relaxed model, we are able to design approximate profit maximizing auctions and approximately efficient auctions. We generalized these results to give a methodology for designing collusion resistant mechanisms for single parameter agents. In addition, we give several results for a weaker incentive property from the literature known as group strategyproofness."
SODA	Rounds vs queries trade-off in noisy computation.	Navin Goyal,Michael E. Saks	2005	We show that a noisy parallel decision tree making O(n) queries needs &Omega;(log* n) rounds to compute OR of n bits. This answers a question of Newman [21]. We prove more general trade-offs between the number of queries and rounds. We also completely settle a similar question for computing MAX in the noisy comparison tree model; these results bring out interesting differences among the noise models.
SODA	Optimizing markov models with applications to triangular connectivity coding.	Stefan Gumhold	2005	In this work Markov Models are constructed to describe the asymptotic stochastical behavior of regular languages, what allows for optimal arithmetic coding of words from the language. A new method is presented for the optimization of Markov Models such that also constraints are captured that cannot be described within a regular language. The new technique is applied to the encoding of the connectivity graph of triangle meshes of low genus and boundary fraction. The resulting compression rates are up to one percent optimal and the best known upper bound for this class of models.
SODA	On profit-maximizing envy-free pricing.	Venkatesan Guruswami,Jason D. Hartline,Anna R. Karlin,David Kempe,Claire Kenyon,Frank McSherry	2005	"We study the problem of pricing items for sale to consumers so as to maximize the seller's revenue. We assume that for each consumer, we know the maximum amount he would be willing to pay for each bundle of items, and want to find pricings of the items with corresponding allocations that maximize seller profit and at the same time are envy-free, which is a natural fairness criterion requiring that consumers are maximally happy with the outcome they receive given the pricing. We study this problem for two important classes of inputs: unit demand consumers, who want to buy at most one item from among a selection they are interested in, and single-minded consumers, who want to buy one particular subset, but only if they can afford it.We show that computing envy-free prices to maximize the seller's revenue is APX-hard in both of these cases, and give a logarithmic approximation algorithm for them. For several interesting special cases, we derive polynomial-time algorithms. Furthermore, we investigate some connections with the corresponding mechanism design problem, in which the consumer's preferences are private values: for this case, we give a log-competitive truthful mechanism."
SODA	Maximum-likelihood decoding of Reed-Solomon codes is NP-hard.	Venkatesan Guruswami,Alexander Vardy	2005	Maximum-likelihood decoding is one of the central problems in coding theory. It has been known for over 25 years that maximum-likelihood decoding of general linear codes is NP-hard. Nevertheless, it was so far unknown whether maximum-likelihood decoding remains hard for any specific family of codes with nontrivial algebraic structure. In this paper, we prove that maximum-likelihood decoding is NP-hard for the family of Reed-Solomon codes. We moreover show that maximum-likelihood decoding of Reed-Solomon codes remains hard even with unlimited preprocessing, thereby strengthening a result of Bruck and Naor.
SODA	Oblivious routing on node-capacitated and directed graphs.	Mohammad Taghi Hajiaghayi,Robert D. Kleinberg,Tom Leighton,Harald Räcke	2005	Oblivious routing algorithms for general undirected networks were introduced by R&auml;cke [17], and this work has led to many subsequent improvements and applications. Comparatively little is known about oblivious routing in general directed networks, or even in undirected networks with node capacities.We present the first non-trivial upper bounds for both these cases, providing algorithms for k-commodity oblivious routing problems with competitive ratio O(&radic;klog(n)) for undirected node-capacitated graphs and O(&radic;kn1/4log(n)) for directed graphs. In the special case that all commodities have a common source or sink, our upper bound becomes O(&radic;nlog(n)) in both cases, matching the lower bound up to a factor of log(n). The lower bound (which first appeared in [6]) is obtained on a graph with very high degree. We show that in fact the degree of a graph is a crucial parameter for node-capacitated oblivious routing in undirected graphs, by providing an O( polylog(n))competitive oblivious routing scheme for graphs of degree. For the directed case, however, we show that the lower bound of &Omega;(&radic;n) still holds in low-degree graphs.Finally, we settle an open question about routing problems in which all commodities share a common source or sink. We show that even in this simplified scenario there are networks in which no oblivious routing algorithm can achieve a competitive ratio better than &Omega;(log n).
SODA	How fast is the k-means method?	Sariel Har-Peled,Bardia Sadri	2005	"We present polynomial upper and lower bounds on the number of iterations performed by the k-means method (a.k.a. Lloyd's method) for k-means clustering. Our upper bounds are polynomial in the number of points, number of clusters, and the spread of the point set. We also present a lower bound, showing that in the worst case the k-means heuristic needs to perform &Omega;(n) iterations, for n points on the real line and two centers. Surprisingly, the spread of the point set in this construction is polynomial. This is the first construction showing that the k-means heuristic requires more than a polylogarithmic number of iterations. Furthermore, we present two alternative algorithms, with guaranteed performance, which are simple variants of the k-means method."
SODA	Unknotting is in AM cup co-AM.	Masao Hara,Seiichi Tani,Makoto Yamamoto	2005	Hass, Lagarias, and Pippenger analyzed the computational complexity of various decision problems in knot theory. They proved that the problem whether a given knot is unknotting is in NP, and conjectured that the problem is contained in NP&cap;co-NP. Agol, Hass, and Thurston proved that the problem called ManifoldGenus, which is a general problem of Unknotting, is NP-complete. We construct an interactive proof system for Knotting, and prove that the problem is contained in IP(2). Consequently, Unknotting is contained in AM &cap; co-AM. If Unknotting is NP-complete, then &Sigma;2p = &Pi;2p.
SODA	Deterministic network coding by matrix completion.	Nicholas J. A. Harvey,David R. Karger,Kazuo Murota	2005	We present a new deterministic algorithm to construct network codes for multicast problems, a particular class of network information ow problems. Our algorithm easily generalizes to several variants of multicast problems. Our approach is based on a new algorithm for maximum-rank completion of mixed matrices---taking a matrix whose entries are a mixture of numeric values and symbolic variables, and assigning values to the variables so as to maximize the resulting matrix rank. Our algorithm is faster than existing deterministic algorithms and can operate over a smaller field.
SODA	Coupling with the stationary distribution and improved sampling for colorings and independent sets.	Thomas P. Hayes,Eric Vigoda	2005	We present an improved coupling technique for analyzing the mixing time of Markov chains. Using our technique, we simplify and extend previous results for sampling colorings and independent sets. Our approach uses properties of the stationary distribution to avoid worst-case configurations which arise in the traditional approach.As an application, we show that for k/&Delta; > 1.764, the Glauber dynamics on k-colorings of a graph on n vertices with maximum degree &Delta; converges in O(n log n) steps, assuming &Delta; = &Omega;(log n) and that the graph is triangle-free. Previously, girth &ge; 5 was needed.As a second application, we give a polynomial-time algorithm for sampling weighted independent sets from the Gibbs distribution of the hard-core lattice gas model at fugacity &lambda; < (1 - &epsilon;)e/&Delta;, on a regular graph G on n vertices of degree &Delta; = &Omega;(log n) and girth &ge; 6. The best known algorithm for general graphs currently assumes &lambda; < 2/(&Delta; - 2).
SODA	Network design for information networks.	Ara Hayrapetyan,Chaitanya Swamy,Éva Tardos	2005	We define a new class of network design problems motivated by designing information networks. In our model, the cost of transporting flow for a set of users (or servicing them by a facility) depends on the amount of information requested by the set of users. We assume that the aggregation cost follows economies of scale, that is, the incremental cost of a new user is less if the set of users already served is larger. Naturally, information requested by some sets of users might aggregate better than that of others, so our cost is now a function of the actual set of users. not just their total demand.We provide constant-factor approximation algorithms to two important problems in this general model. In the Group Facility Location problem, each user needs information about a resource. and the cost is a linear function of the number of resources involved (instead of the number of clients served). The Dependent Maybecast Problem extends the Karger-Minkoff maybecast model to probabilities with limited correlation and also contains the 2-stage stochastic optimization problem as a special case. We also give an O(ln n)-approximation algorithm for the Single Sink Information Network Design problem.We show that the Stochastic Steiner Tree problem can be approximated by dependent maybecast, and using this we obtain an O(1)-approximation algorithm for the k-stage stochastic Steiner tree problem for any fixed k. This is the first approximation algorithm for multi-stage stochastic optimization. Our algorithm allows scenarios to have different inflation factors, and works for any distribution provided that we can sample the distribution.
SODA	A categorization theorem on suffix arrays with applications to space efficient text indexes.	Meng He,J. Ian Munro,S. Srinivasa Rao	2005	In this paper, we design succinct index structures for a text string T of n binary symbols to support efficient searching of a pattern P of length m. Motivated by the fact that the standard representation of suffix arrays uses n lg n bits which is more than the theoretical minimum, we present a theorem that characterizes a permutation as the suffix array of a binary string. Based on the theorem, we design a succinct representation of suffix arrays of binary strings that uses n + o(n) bits, which is the theoretical minimum plus a lower order term, and answers existential and cardinality queries in O(m) time without storing the raw text. With 2n+o(n) bits, we can list pattern occurrences in O(m + occ lg n) time in the general case, and for long patterns, when m = &Omega;(lg1+&isin; n), we answer such listing queries in O(m + occ) time. We also present another implementation that uses O(n) bits and supports pattern searching in O(m + occ lg&lambda; n) time for any fixed &lambda; such that 0 < &lambda; < 1. More results and trade-offs are reported in the paper.
SODA	Computing minimal triangulations in time O(n log n) = o(n).	Pinar Heggernes,Jan Arne Telle,Yngve Villanger	2005	Computing minimal triangulations in time O(n log n) = o(n).
SODA	Approximating vertex cover on dense graphs.	Tomokazu Imamura,Kazuo Iwama	2005	Although many problems in MAX-SNP admit a PTAS for dense graphs, that is not the case for Vertex Cover, which is MAX-SNP hard even for dense graphs. This paper presents a randomized approximation algorithm for Vertex Cover on dense graphs, i.e., graphs whose average degree d is &Omega;(n). (i) Our algorithm improves the best-known bound for the approximation factor by Karpinski and Zelikovsky. For example, our bound is 2/1 + d/2&Delta; for dense graphs such that |E| &le; &Delta;(n - &Delta;) where &Delta; is the maximum degree. The improvement is especially large when d &ap; &Delta;; if d &ge; 2/3&Delta; for instance, our bound is at most 1.5 while the previous bound approaches to 2.0 as n/&Delta; increases. (ii) It achieves the same factor for a wider range of graphs, i.e., for the graphs whose &Delta; is &Omega;(n log log n/log n). (iii) It is probably optimal in the sense that if we can achieve a better approximation factor by &delta; > 0 for the above range of graphs, then we can achieve a factor of 2 - &delta; for general graphs.
SODA	Marriage, honesty, and stability.	Nicole Immorlica,Mohammad Mahdian	2005	Many centralized two-sided markets form a matching between participants by running a stable marriage algorithm. It is a well-known fact that no matching mechanism based on a stable marriage algorithm can guarantee truthfulness as a dominant strategy for participants. However, as we will show in this paper, in a probabilistic setting where the preference lists of one side of the market are composed of only a constant (independent of the the size of the market) number of entries, each drawn from an arbitrary distribution, the number of participants that have more than one stable partner is vanishingly small. This proves (and generalizes) a conjecture of Roth and Peranson [23]. As a corollary of this result, we show that, with high probability, the truthful strategy is the best response for a given player when the other players are truthful. We also analyze equilibria of the deferred acceptance stable marriage game. We show that the game with complete information has an equilibrium in which a (1 - o(1)) fraction of the strategies are truthful in expectation. In the more realistic setting of a game of incomplete information, we will show that the set of truthful strategies form a (1 + o(1))-approximate Bayesian-Nash equilibrium. Our results have implications in many practical settings and were inspired by the work of Roth and Peranson [23] on the National Residency Matching Program.
SODA	Limitations of cross-monotonic cost sharing schemes.	Nicole Immorlica,Mohammad Mahdian,Vahab S. Mirrokni	2005	A cost-sharing scheme is a set of rules defining how to share the cost of a service (often computed by solving a combinatorial optimization problem) amongs serviced customers. A cost-sharing scheme is cross-monotonic if it satisfies the property that everyone is better off when the set of people who receive the service expands. In this article, we develop a novel technique for proving upper bounds on the budget-balance factor of cross-monotonic cost-sharing schemes or the worst-case ratio of recovered cost to total cost. We apply this technique to games defined, based on several combinatorial optimization problems, including the problems of edge cover, vertex cover, set cover, and metric facility location and, in each case, derive tight or nearly-tight bounds. In particular, we show that for the facility location game, there is no cross-monotonic cost-sharing scheme that recovers more than a third of the total cost. This result, together with a recent 1/3-budget-balanced cross-monotonic cost-sharing scheme of P&aacute;l and Tardos &lsqb;2003&rsqb; closes the gap for the facility location game. For the vertex cover and set cover games, we show that no cross-monotonic cost-sharing scheme can recover more than a O(n&minus;1/3) and O(1/n) fraction of the total cost, respectively. Finally, we study the implications of our results on the existence of group-strategyproof mechanisms. We show that every group-strategyproof mechanism corresponds to a cost-sharing scheme that satisfies a condition weaker than cross-monotonicity. Using this, we prove that group-strategyproof mechanisms satisfying additional properties give rise to cross-monotonic cost-sharing schemes and therefore our upper bounds hold.
SODA	Market equilibria for homothetic, quasi-concave utilities and economies of scale in production.	Kamal Jain,Vijay V. Vazirani,Yinyu Ye	2005	"Eisenberg and Gale (1959) gave a convex program for computing market equilibrium for Fisher's model for linear utility functions, and Eisenberg (1961) generalized this to concave homogeneous functions of degree one. We further generalize to:1. Homothetic, quasi-concave utilities. This also helps extend Eisenberg's result to concave homogeneous functions of arbitrary degree.2. We introduce the notion of a trading cone which enables us to compute market equilibrium in the presence of economies of scale in production provided differential pricing is allowed. Applications to network pricing are provided."
SODA	Algorithms for combining rooted triplets into a galled phylogenetic network.	Jesper Jansson,Nguyen Bao Nguyen,Wing-Kin Sung	2005	This paper considers the problem of determining whether a given set T of rooted triplets can be merged without conflicts into a galled phylogenetic network, and if so, constructing such a network. When the input T is dense, we solve the problem in O(|T|) time, which is optimal since the size of the input is &Theta;(|T|). In comparison, the previously fastest algorithm for this problem runs in O(|T|2) time. Next, we prove that the problem becomes NP-hard if extended to non-dense inputs, even for the special case of simple phylogenetic networks. We also show that for every positive integer n, there exists some set T of rooted triplets on n leaves such that any galled network can be consistent with at most 0.4883&middot;|T| of the rooted triplets in T. On the other hand, we provide a polynomial-time approximation algorithm that always outputs a galled network consistent with at least a factor of 5/12 (>0.4166) of the rooted triplets in T.
SODA	Online topological ordering.	Irit Katriel,Hans L. Bodlaender	2005	It is shown that the problem of maintaining the topological order of the nodes of a directed acyclic graph while inserting m edges can be solved in O(min{m3/2 log n m3/3 + n2 log n}) time, an improvement over the best known result of O(mn). In addition, we analyze the complexity of the same algorithm with respect to the treewidth k of the underlying undirected graph. We show that the algorithm runs in time O(mk log2 n) for general k and that it can be implemented to run in O(n log n) time on trees, which is optimal. If the input contains cycles, the algorithm detects this.
SODA	The hidden subgroup problem and permutation group theory.	Julia Kempe,Aner Shalev	2005	We employ concepts and tools from the theory of finite permutation groups in order to analyse the Hidden Subgroup Problem via Quantum Fourier Sampling (QFS) for the symmetric group. We show that under very general conditions both the weak and the random-strong form (strong form with random choices of basis) of QFS fail to provide any advantage over classical exhaustive search. In particular we give a complete characterisation of polynomial size subgroups, and of primitive subgroups, that can be distinguished from the identity subgroup with the above methods. Furthermore, assuming a plausible group theoretic conjecture for which we give supporting evidence, we show that weak and random-strong QFS for the symmetric group have no advantage whatsoever over classical search.
SODA	Approximation algorithms for cycle packing problems.	Michael Krivelevich,Zeev Nutov,Raphael Yuster	2005	The cycle packing number vc(G) of a graph G is the maximum number of pairwise edge-disjoint cycles in G. Computing vc(G) is an NP-hard problem. We present approximation algorithms for computing vc(G) in both the undirected and directed cases. In the undirected case we analyze the modified greedy algorithm suggested in [4] and show that it has approximation ratio O(&radic;log n) where n = |V(G)|, and this is tight. This improves upon the previous O(log n) upper bound for the approximation ratio of this algorithm. In the directed case we present a &radic;n-approximation algorithm. Finally, we give an O(n2/3)-approximation algorithm for the problem of finding a maximum number of edge-disjoint cycles that intersect a specified subset S of vertices. Our approximation ratios are the currently best known ones and, in addition, provide bounds on the integrality gap of standard LP-relaxations to these problems.
SODA	Multiple-source shortest paths in planar graphs.	Philip N. Klein	2005	Given an n-node planar graph with nonnegative edge-lengths, our algorithm takes O(n log n) time to construct a data structure that supports queries of the following form in O(log n) time: given a destination node t on the boundary of the infinite face, and given a start node s anywhere, find the s-to-t distance.
SODA	A multiple-choice secretary algorithm with applications to online auctions.	Robert D. Kleinberg	2005	In the classical secretary problem, a set S of numbers is presented to an online algorithm in random order. At any time the algorithm may stop and choose the current element, and the goal is to maximize the probability of choosing the largest element in the set. We study a variation in which the algorithm is allowed to choose k elements, and the goal is to maximize their sum. We present an algorithm whose competitive ratio is 1-O(&radic;1/k). To our knowledge, this is the first algorithm whose competitive ratio approaches 1 as k &larr; &infin;. As an application we solve an open problem in the theory of online auction mechanisms.
SODA	Conformance testing in the presence of multiple faults.	Viraj Kumar,Mahesh Viswanathan	2005	Conformance testing is the problem of determining if a black-box implementation I is equivalent to a specification S, where both are modeled as finite state Mealy machines. The problem involves constructing a checking sequence based on the specification, which is a sequence of inputs that detects all faulty machines. Traditionally conformance testing algorithms have assumed that the number of states in the implementation does not exceed that in the specification. This is because it is known that, in the absence of this assumption, the length of the checking sequence needs to be at least exponential in the number of extra states in the implementation [41]. However, this has limited the applicability of these techniques in practice where the implementation typically has many more states than the specification.In this paper we relax the constraints on the size of the implementation and investigate the existence of polynomial length checking sequences for implementations with extra states, under the promise that they either have multiple faults or no faults at all. We present randomized algorithms to construct checking sequences that catch faulty implementations with at most &Delta; extra states, having at least r faults (where &Delta; and r are parameters to the algorithm), and pass all correct implementations. We demonstrate the near optimality of our algorithms by presenting lower bounds for this problem. One of the main technical lemmas used in our proof is an estimate of the probability that a random walk on directed graphs will reach a large target set. We believe that this lemma will be of independent interest in the context of verifying safety properties.
SODA	Isomorphism and embedding problems for infinite limits of scale-free graphs.	Robert D. Kleinberg,Jon M. Kleinberg	2005	"The study of random graphs has traditionally been dominated by the closely-related models G(n, m), in which a graph is sampled from the uniform distribution on graphs with n vertices and m edges, and G(n, p), in which each of the (n/2) edges is sampled independently with probability p. Recently, however, there has been considerable interest in alternate random graph models designed to more closely approximate the properties of complex real-world networks such as the Web graph, the Internet, and large social networks. Two of the most well-studied of these are the closely related ""preferential attachment"" and ""copying"" models, in which vertices arrive one-by-one in sequence and attach at random in ""rich-get-richer"" fashion to d earlier vertices.Here we study the infinite limits of the preferential attachment process --- namely, the asymptotic behavior of finite graphs produced by preferential attachment (brie y, PA graphs), as well as the infinite graphs obtained by continuing the process indefinitely. We are guided in part by a striking result of Erd&ouml;;s and R&eacute;nyi on countable graphs produced by the infinite analogue of the G(n, p) model, showing that any two graphs produced by this model are isomorphic with probability 1; it is natural to ask whether a comparable result holds for the preferential attachment process.We find, somewhat surprisingly, that the answer depends critically on the out-degree d of the model. For d = 1 and d = 2, there exist infinite graphs R&infin;d such that a random graph generated according to the infinite preferential attachment process is isomorphic to R&infin;d with probability 1. For d &ge; 3, on the other hand, two different samples generated from the infinite preferential attachment process are non-isomorphic with positive probability. The main technical ingredients underlying this result have fundamental implications for the structure of finite PA graphs; in particular, we give a characterization of the graphs H for which the expected number of subgraph embeddings of H in an n-node PA graph remains bounded as n goes to infinity."
SODA	Girth restrictions for the 5-flow conjecture.	Martin Kochol	2005	"Using counting arguments, we show that every smallest counterexample to Tutte's 5-flow Conjecture (that every bridgeless graph has a nowhere-zero 5-flow) has girth at least nine."
SODA	Provably good moving least squares.	Ravi Krishna Kolluri	2005	We analyze a moving least squares (MLS) interpolation scheme for reconstructing a surface from point cloud data. The input is a sufficiently dense set of sample points that lie near a closed surface F with approximate surface normals. The output is a reconstructed surface passing near the sample points. For each sample point s in the input, we define a linear point function that represents the local shape of the surface near s. These point functions are combined by a weighted average, yielding a three-dimensional function I. The reconstructed surface is implicitly defined as the zero set of I. We prove that the function I is a good approximation to the signed distance function of the sampled surface F and that the reconstructed surface is geometrically close to and isotopic to F. Our sampling requirements are derived from the local feature size function used in Delaunay-based surface reconstruction algorithms. Our analysis can handle noisy data provided the amount of noise in the input dataset is small compared to the feature size of F.
SODA	Pianos are not flat: rigid motion planning in three dimensions.	Vladlen Koltun	2005	"Consider a robot R that is either a line segment or the Minkowski sum of a line segment and a 3-ball, and a set S of polyhedral obstacles with a total of n vertices in R3. We design near-optimal exact algorithms for planning the motion of R among S when R is allowed to translate and rotate. Specifically, we can preprocess S in time O(n 4+&epsilon;) for any &epsilon; > 0 into a data structure that given two placements &alpha; and &beta; of R, can decide in time O(log n) whether a collision-free rigid motion of R between &alpha; and &beta; exists and if so, output such a motion in time asymptotically proportional to its complexity. Furthermore, we can find in time O(n4+&epsilon;) for any &epsilon; > 0 the largest placement of a similar (translated, rotated and scaled) copy of R that does not intersect S. A number of additional stronger results are provided. Our line segment motion planning algorithm improves the result of Ke and O'Rourke by two orders of magnitude and almost matches their lower bound, thus settling a classical motion planning problem first considered by Schwartz and Sharir in 1984. This implies a number of natural directions for future work concerning rigid motion planning in three dimensions."
SODA	Online ascending auctions for gradually expiring items.	Ron Lavi,Noam Nisan	2005	"In this paper we consider online auction mechanisms for the allocation of M items that are identical to each other except for the fact that they have different expiration times, and each item must be allocated before it expires. Players arrive at different times, and wish to buy one item before their deadline. The main difficulty is that players act ""selfishly"" and may mis-report their values, deadlines, or arrival times. We begin by showing that the usual notion of truthfulness (where players follow a single dominant strategy) cannot be used in this case, since any (deterministic) truthful auction cannot obtain better than an M-approximation of the social welfare. Therefore, instead of designing auctions in which players should follow a single strategy, we design two auctions that perform well under a wide class of selfish, ""semi-myopic"", strategies. For every combination of such strategies, the auction is associated with a different algorithm, and so we have a family of ""semi-myopic"" algorithms. We show that any algorithm in this family obtains a 3-approximation, and by this conclude that our auctions will perform well under any choice of such semi-myopic behaviors. We next turn to provide a game-theoretic justification for acting in such a semi-myopic way. We suggest a new notion of ""Set-Nash"" equilibrium, where we cannot pin-point a single best-response strategy, but rather only a set of possible best-response strategies. We show that our auctions have a Set-Nash equilibrium which is all semi-myopic, hence guarantees a 3-approximation. We believe that this notion is of independent interest."
SODA	A group-strategyproof mechanism for Steiner forests.	Jochen Könemann,Stefano Leonardi,Guido Schäfer	2005	In this paper we design an approximately budget-balanced and group-strategyproof cost-sharing mechanism for the Steiner forest game. An instance of this game consists of an undirected graph G = (V, E), non-negative costs ce for all edges e &isin; E, and a set R &sube; V x V of k terminal pairs. Each terminal pair (s, t) &isin; R is associated with an agent that wishes to establish a connection between nodes s and t in the underlying network. A feasible solution is a forest F that contains an s, t-path for each connection request (s, t) &isin; R.Previously, Jain and Vazirani [4] gave a 2-approximate budget-balanced and group-strategyproof cost-sharing mechanism for the Steiner tree game --- a special case of the game considered here. Such a result for Steiner forest games has proved to be elusive so far, in stark contrast to the well known primal-dual (2 -- 1/k)-approximate algorithms [1, 2] for the problem.The cost-sharing method presented in this paper is 2-approximate budget-balanced and this is tight with respect to the budget-balance factor.Our algorithm is an original extension of known primal-dual methods for Steiner forests [1]. An interesting byproduct of the work in this paper is that our Steiner forest algorithm is (2 -- 1/k)-approximate despite the fact that the forest computed by our method is usually costlier than those computed by known primal-dual algorithms. In fact the dual solution computed by our algorithm is infeasible but we can still prove that its total value is at most the cost of a minimum-cost Steiner forest for the given instance.
SODA	Distributions of points in the unit-square and large -gons.	Hanno Lefmann	2005	"We consider a generalization of Heilbronn's triangle problem by asking, given any integers n>=k, for the supremum @D""k(n) of the minimum area determined by the convex hull of some k of n points in the unit square [0,1]^2, where the supremum is taken over all distributions of n points in [0,1]^2. Improving the lower bound @D""k(n)=@W(1/n^(^k^-^1^)^/^(^k^-^2^)) from [C. Bertram-Kretzberg, T. Hofmeister, H. Lefmann, An algorithm for Heilbronn's problem, SIAM Journal on Computing 30 (2000) 383-390] and from [W.M. Schmidt, On a problem of Heilbronn, Journal of the London Mathematical Society (2) 4 (1972) 545-550] for k=4, we show that @D""k(n)=@W((logn)^1^/^(^k^-^2^)/n^(^k^-^1^)^/^(^k^-^2^)) for fixed integers k>=3 as asked for in [C. Bertram-Kretzberg, T. Hofmeister, H. Lefmann, An algorithm for Heilbronn's problem, SIAM Journal on Computing 30 (2000) 383-390]. Moreover, we provide a deterministic polynomial time algorithm which finds n points in [0,1]^2, which achieve this lower bound on @D""k(n)."
SODA	Network coding: does the model need tuning?	April Rasala Lehman,Eric Lehman	2005	We consider the general network information flow problem, which was introduced by Ahlswede et. al[1]. We show a periodicity effect: for every integer m &ge; 2, there exists an instance of the network information ow problem that admits a solution if and only if the alphabet size is a perfect mth power. Building on this result, we construct an instance with O(m) messages and O(m) nodes that admits a solution if and only if the alphabet size is an enormous 2exp(&Omega;(m1/3)). In other words, if we regard each message as a length-k bit string, then k must be exponential in the size of the network. For this same instance, we show that if edge capacities are slightly increased, then there is a solution with a modest alphabet size of O(2m). In light of these results, we suggest that a more appropriate model would assume that the network operates at slightly under capacity.
SODA	Complete partitions of graphs.	Guy Kortsarz,Jaikumar Radhakrishnan,Sivaramakrishnan Sivasubramanian	2005	A complete partition of a graph G is a partition of V(G) such that any two classes are connected by an edge. Let cp(G) denote the maximum number of classes in a complete partition of G. This measure was defined in 1969 by Gupta [18], and is known to be NP-hard on several classes of graphs. We obtain the first, and essentially tight, lower and upper bounds on the approximability of this problem. We show that there is a randomized polynomial-time algorithm that given a graph G produces a complete partition of size &Omega;(cp(G)/&radic;lg|V(G)|). This algorithm can be derandomized.We show that the upper bound is essentially tight: there is a constant C > 1, such that if there is a randomized polynomial-time algorithm that for all large n, when given a graph G with n vertices produces a complete partition into at least C cp(G)/&radic;lg n classes, then NP &sube; RTime(no(lg lg n)). The problem of finding a complete partition of a graph is thus the first natural problem whose approximation threshold has been determined to be of the form &theta;((lg n)c) for some constant c strictly between 0 and 1.
SODA	A constant approximation algorithm for the one-warehouse multi-retailer problem.	Retsef Levi,Robin Roundy,David B. Shmoys	2005	Deterministic inventory theory provides streamlined optimization models that attempt to capture tradeoffs in managing the flow of goods through a supply chain. We will consider a well-studied inventory model, called the one-warehouse multi-retailer problem (OWMR). and give the first approximation algorithm with constant performance guarantee; more specifically, we give a 2.398-approximation algorithm. Our results are based on an LP-rounding approach, and hence not only provide good algorithmic results, but show strong integrality gaps for these linear programs. Furthermore, we extend this result to obtain a constant performance guarantee for a capacitated variant of this model.
SODA	An optimal online algorithm for packet scheduling with agreeable deadlines.	Fei Li,Jay Sethuraman,Clifford Stein	2005	An important issue in IP-based QoS networks is the effective management of packets at the router level. Specifically, if the arriving packets cannot all be stored in a buffer, or if the packets have deadlines by which they must be delivered, the router needs to identify the packets that should be dropped. In recent work, Kesselman et al. [6] propose a model, called buffer management with bounded delay, which can be thought of as an online scheduling problem on a single machine: packets arrive at a network switch and are stored in a buffer of size B. Each packet has a positive weight and a deadline, with the weight representing the value of transmitting the packet by its deadline. At each integer time step, exactly one packet can be transmitted, and the objective is to maximize the total weight of the transmitted packets. If B = &infin;, this is the online version of the scheduling problem 1| pj = 1, rj, dj |&Sigma; wj Uj. (We assume that rj and dj are integers.)
SODA	Lower bounds on the size of selection and rank indexes.	Peter Bro Miltersen	2005	"The rank index problem is the following: Preprocess and store a bit string x &isin; {0,1}n on a random access machine with word size w so that rank queries ""What is &Sigma;ji=1 xi?"" for arbitrary values of j can afterwards be easily answered. The selection index problem is the following: Preprocess and store a bit string x &isin; {0,1}n so that selection queries ""What is the index of the j'th 1-bit in x?"" for arbitrary values of j can afterwards be easily answered. The data structure representing x should be an index structure, i.e., the n-bit string x is kept verbatim in [n/w] words and the preprocessing phase adds an r-bit index &phi;(x) with additional information contained in [r/w] words. We are interested in tradeoffs between r, the size of the index measured in bits (the redundancy of the scheme), and t, the worst case time for answering a query."
SODA	An optimal Bloom filter replacement.	Anna Pagh,Rasmus Pagh,S. Srinivasa Rao	2005	"This paper considers space-efficient data structures for storing an approximation S' to a set S such that S &sube; S' and any element not in S belongs to S' with probability at most &isin;. The Bloom filter data structure, solving this problem, has found widespread use. Our main result is a new RAM data structure that improves Bloom filters in several ways:&bull; The time for looking up an element in S' is O(1), independent of &isin;.&bull; The space usage is within a lower order term of the lower bound.&bull; The data structure uses explicit hash function families.&bull; The data structure supports insertions and deletions on S in amortized expected constant time.The main technical ingredient is a succinct representation of dynamic multisets. We also consider three recent generalizations of Bloom filters."
SODA	Multicoloring unit disk graphs on triangular lattice points.	Yuichiro Miyamoto,Tomomi Matsui	2005	Given a pair of non-negative integers m and n, P(m, n) denotes a subset of 2-dimensional triangular lattice points defined by P(m, n) [EQUATION], {(xe1 +ye2 | x &isin; {0, 1,..., m -1}, y &isin; {0, 1,..., n -1}} where e1 [EQUATION] (1,0), e2 [EQUATION] (1/2, &radic;3/2). Let Tm,n(d) be an undirected graph defined on vertex set P(m, n) satisfying that two vertices are adjacent if and only if the Euclidean distance between the pair is less than or equal to d. This paper discusses a necessary and sufficient condition that Tm,n(d) is perfect; we show that [&forall;m &isin; Z+ Tm,n(d) is perfect ] if and only if d &ge; &radic;n2 -3n + 3.Given a non-negative vertex weight vector w &isin; Zp(m,n)+ a multicoloring of (Tm,n(d), &omega;) is an assignment of colors to P(m, n) such that each vertex v &isin; P(m, n) admits w(v) colors and every adjacent pair of two vertices does not share a common color. We also give an efficient algorithm for multicoloring (Tm, n (d), w) when P(m, n) is perfect.In general case, our results on the perfectness of P(m, n) implies a polynomial time approximation algorithm for multicoloring (Tm, n (d), w). Our algorithm finds a multicoloring which uses at most &alpha;(d&omega; + O(d3) colors, where &omega; denotes the weighted clique number. When d = 1, &radic;3, 2, &radic;7, 3, the approximation ratio &alpha;(d) = (4/3), (5/3), (7/4), (5/3), (7/4), respectively. When d > 1, we showed that &alpha;(d) &le; (1 + 2/&radic;3 +2&radic;3-3/d) < 1 + 2/&radic;3 < 2.155.
SODA	Testing hierarchical systems.	Damon Mosk-Aoyama,Mihalis Yannakakis	2005	We investigate the testing of hierarchical (modular) systems, in which individual modules are modeled by finite state machines. Given a hierarchical system, we are interested in finding a small set of tests that exercises all the transitions of the system. We present tight approximation algorithms and hardness results for the problem. Our techniques extend to other criteria and metrics.
SODA	Quantum algorithms for the triangle problem.	Frédéric Magniez,Miklos Santha,Mario Szegedy	2005	We present two new quantum algorithms that either find a triangle (a copy of $K_{3}$) in an undirected graph $G$ on $n$ nodes, or reject if $G$ is triangle free. The first algorithm uses combinatorial ideas with Grover Search and makes $\tilde{O}(n^{10/7})$ queries. The second algorithm uses $\tilde{O}(n^{13/10})$ queries and is based on a design concept of Ambainis [in Proceedings of the $45$th IEEE Symposium on Foundations of Computer Science, 2004, pp. 22-31] that incorporates the benefits of quantum walks into Grover Search [L. Grover, in Proceedings of the Twenty-Eighth ACM Symposium on Theory of Computing, 1996, pp. 212-219]. The first algorithm uses only $O(\log n)$ qubits in its quantum subroutines, whereas the second one uses $O(n)$ qubits. The Triangle Problem was first treated in [H. Buhrman et al., SIAM J. Comput., 34 (2005), pp. 1324-1330], where an algorithm with $O(n+\sqrt{nm})$ query complexity was presented, where $m$ is the number of edges of $G$.
SODA	A new look at survey propagation and its generalizations.	Elitza N. Maneva,Elchanan Mossel,Martin J. Wainwright	2005	"We study the survey propagation algorithm [19, 5, 4], which is an iterative technique that appears to be very effective in solving random k-SAT problems even with densities close to threshold. We first describe how any SAT formula can be associated with a novel family of Markov random fields (MRFs), parameterized by a real number &rho;. We then show that applying belief propagation---a well-known ""message-passing technique---to this family of MRFs recovers various algorithms, ranging from pure survey propagation at one extreme (&rho; = 1) to standard belief propagation on the uniform distribution over SAT assignments at the other extreme (&rho; = 0). Configurations in these MRFs have a natural interpretation as generalized satisfiability assignments, on which a partial order can be defined. We isolate cores as minimal elements in this partial ordering, and prove that any core is a fixed point of survey propagation. We investigate the associated lattice structure, and prove a weight-preserving identity that shows how any MRF with p > 0 can be viewed as a ""smoothed"" version of the naive factor graph representation of the k-SAT problem (p = 0). Our experimental results show that message-passing on our family of MRFs is most effective for values of &rho; &ne; 1 (i.e., distinct from survey propagation); moreover, they suggest that random formulas may not typically possess non-trivial cores. Finally, we isolate properties of Gibbs sampling and message-passing algorithms that are typical for an ensemble of k-SAT problems. We prove that the space of cores for random formulas is highly disconnected, and show that for values of p sufficiently close to one, either the associated MRF is highly concentrated around the all-star assignment, or it has exponentially small conductance. Similarly, we prove that for p sufficiently close to one, the all-star assignment is attractive for message-passing when analyzed in the density-evolution setting."
SODA	The bin-covering technique for thresholding random geometric graph properties.	S. Muthukrishnan,Gopal Pandurangan	2005	We study the emerging phenomenon of ad hoc, sensor-based communication networks. The communication is modeled by the geometric random graph model G(n, r, &ell;) where n points randomly placed within [0, &ell;]d form the nodes, and any two nodes that correspond to points at most distance r away from each other are connected. We study fundamental properties of G(n, r, &ell;) of interest: connectivity, coverage, and routing-stretch. Our main contribution is a simple analysis technique we call bin-covering that we apply uniformly to get first known, (asymptotically) tight thresholds for each of these properties. Typically, in the past, geometric random graph analyses involved sophisticated methods from continuum percolation theory; on contrast, our bin-covering approach is discrete and very simple, yet it gives us tight threshold bounds. The technique also yields algorithmic benefits as illustrated by a simple local routing algorithm for finding paths with low stretch. Our specific results should also prove interesting to the networking community that has seen a recent increase in the study of geometric random graphs motivated by engineering ad hoc networks.
SODA	Analyzing and characterizing small-world graphs.	Van Nguyen,Charles U. Martel	2005	"We study variants of Kleinberg's small-world model where we start with a k-dimensional grid and add a random directed edge from each node. The probability u's random edge is to v is proportional to d(u,v)-r where d(u,v) is the lattice distance and r is a parameter of the model.For a k-dimensional grid, we show that these graphs have poly-log expected diameter when k < r < 2k, but have polynomial expected diameter when r > 2k. This shows an interesting phase-transition between small-world and ""large-world"" graphs.We also present a general framework to construct classes of small-world graphs with &Theta;(log n) expected diameter, which includes several existing settings such as Kleinberg's grid-based and tree-based settings [15].We also generalize the idea of 'adding links with probability &alpha; the inverse distance' to design small-world graphs. We use semi-metric and metric functions to abstract distance to create a class of random graphs where almost all pairs of nodes are connected by a path of length O (log n), and using only local information we can find paths of poly-log length."
SODA	Approximating connectivity augmentation problems.	Zeev Nutov	2005	Let G &equals; (V,E) be an undirected graph and let S &sube; V. The S-connectivity &lambda;SG(u,v) of a node pair (u,v) in G is the maximum number of uv-paths that no two of them have an edge or a node in S &minus; {u,v} in common. The corresponding Connectivity Augmentation (CA) problem is: given a graph G &equals; (V,E), a node subset S &sube; V, and a nonnegative integer requirement function r(u,v) on V &times; V, add a minimum size set F of new edges to G so that &lambda;SG+F(u,v) &ge; r(u,v) for all (u,v) &isin; V &times; V. Three extensively studied particular cases are: the Edge-CA (S &equals; &empty;), the Node-CA (S &equals; V), and the Element-CA (r(u,v)&equals; 0 whenever u &isin; S or v &isin; S). A polynomial-time algorithm for Edge-CA was developed by Frank. In this article we consider the Element-CA and the Node-CA, that are NP-hard even for r(u,v) &isin; {0,2}. The best known ratios for these problems were: 2 for Element-CA and O(rmax &sdot; ln n) for Node-CA, where rmax &equals; maxu,v &isin; V r(u,v) and n &equals; &verbar;V&verbar;. Our main result is a 7/4-approximation algorithm for the Element-CA, improving the previously best known 2-approximation. For Element-CA with r(u,v) &isin; {0,1,2} we give a 3/2-approximation algorithm. These approximation ratios are based on a new splitting-off theorem, which implies an improved lower bound on the number of edges needed to cover a skew-supermodular set function. For Node-CA we establish the following approximation threshold: Node-CA with r(u,v) &isin; {0,k} cannot be approximated within O(2log1&minus;&epsis; n) for any fixed &epsis; > 0, unless NP &sube; DTIME(npolylog(n)).
SODA	Optimal random number generation from a biased coin.	Sung-il Pae,Michael C. Loui	2005	We study the optimal generation of random numbers using a biased coin in two cases: first, when the bias is unknown, and second, when the bias is known. In the first case, we characterize the functions that use a discrete random source of unknown distribution to simulate a target discrete random variable with a given rational distribution. We identify the functions that minimize the ratio of source inputs to target outputs. We show that these optimal functions are efficiently computable. In the second case, we prove that it is impossible to construct an optimal tree algorithm recursively, using a model based on the algebraic decision tree. Our model of computation is sufficiently general to encompass virtually all previously known algorithms for this problem.
SODA	Can the TPRI structure help us to solve the algebraic eigenproblem?	Victor Y. Pan	2005	We modify the customary approach to solving the algebraic eigenproblem. Instead of applying the QR algorithm to a Hessenberg matrix, we begin with the recent unitary similarity transform into a triangular plus rank-one matrix. Then we show nonunitary transforms of this matrix at a low arithmetic cost into similar arrow-head matrices. The resulting eigenproblem can be effectively solved by the known algorithms. Based on some properties of the TPRI matrices, we also show that the similarity transforms into both Hessenberg and TPRI forms tend to decrease the geometric multiplicities of the eigenvalues, and we discuss some relevant research topics.
SODA	Selfish routing with atomic players.	Tim Roughgarden	2005	"One of the most successful applications of the price of anarchy---the worst-case ratio between the objective function values of noncooperative equilibria and optima---is to ""selfish routing"", a classical model of how independent network users route traffic in a congested network. However, almost all existing work on this topic (e.g., [2, 5, 7]) assumes a large population of very small network users, so that the actions of a single individual have negligible impact on the cost incurred by others. This assumption---in game theory terminology, that the game is nonatomic---is obviously not justifiable in all applications."
SODA	Efficient hashing with lookups in two memory accesses.	Rina Panigrahy	2005	The study of hashing is closely related to the analysis of balls and bins. Azar et. al. [1] showed that instead of using a single hash function if we randomly hash a ball into two bins and place it in the smaller of the two, then this dramatically lowers the maximum load on bins. This leads to the concept of two-way hashing where the largest bucket contains O(log log n) balls with high probability. The hash look up will now search in both the buckets an item hashes to. Since an item may be placed in one of two buckets, we could potentially move an item after it has been initially placed to reduce maximum load. Using this fact, we present a simple, practical hashing scheme that maintains a maximum load of 2, with high probability, while achieving high memory utilization. In fact, with n buckets, even if the space for two items are pre-allocated per bucket, as may be desirable in hardware implementations, more than n items can be stored giving a high memory utilization. Assuming truly random hash functions, we prove the following properties for our hashing scheme.&bull; Each lookup takes two random memory accesses, and reads at most two items per access.&bull; Each insert takes O(log n) time and up to log log n+O(1) moves, with high probability, and constant time in expectation.&bull; Maintains 83.75% memory utilization, without requiring dynamic allocation during inserts.We also analyze the trade-off between the number of moves performed during inserts and the maximum load on a bucket. By performing at most h moves, we can maintain a maximum load of O(log log n/h log (log log n/h)). So, even by performing one move, we achieve a better bound than by performing no moves at all.
SODA	Computing equilibria in multi-player games.	Christos H. Papadimitriou,Tim Roughgarden	2005	We initiate the systematic study of algorithmic issues involved in finding equilibria (Nash and correlated) in games with a large number of players; such games, in order to be computationally meaningful, must be presented in some succinct, game-specific way. We develop a general framework for obtaining polynomial-time algorithms for optimizing over correlated equilibria in such settings, and show how it can be applied successfully to symmetric games (for which we actually find an exact polytopal characterization), graphical games, and congestion games, among others. We also present complexity results implying that such algorithms are not possible in certain other such games. Finally, we present a polynomial-time algorithm, based on quantifier elimination, for finding a Nash equilibrium in symmetric games when the number of strategies is relatively small.
SODA	The complexity of low-distortion embeddings between point sets.	Christos H. Papadimitriou,Shmuel Safra	2005	We prove that it is NP-hard to approximate by a ratio better than 3 the minimum distortion of a bijection between two given finite three-dimensional sets of points.
SODA	Towards a complete characterization of tries.	GaHyun Park,Wojciech Szpankowski	2005	Tries and suffix trees are the most popular data structures on words. Tries were introduced in 1960 by Fredkin as an efficient method for searching and sorting digital data. Since then myriad of novel trie applications were found such as dynamic hashing, conflict resolution algorithms, leader election algorithms, IP addresses lookup, coding, polynomial factorization, Lempel-Ziv compression schemes, and so on. Furthermore, various analyses of tries reveal new fundamental properties of strings appearing in those applications. Parameters of interest are the (partial) fillup level (the largest full level of the trie), shortest path, height (longest path), typical depth, and path length (sum of depths). All of these parameters are analyzed here in a unifying manner by studying the external and internal profiles. A profile of a tree at level k is the number of nodes (internal or external) at level k. We derive recurrences for both profiles and solve them asymptotically for various ranges of k when the strings stored in the trie are generated by a memoryless source (extension to a Markov source is possible). In particular, we present asymptotic results for the average profile, the variance and the limiting distribution. As consequences we find the height, shortest path, fillup level, and the depth. These results are derived here by methods of analytic algorithmics such as generating functions, Mellin transform, poissonization and depoissonization, and the saddle point method.
SODA	An asymptotic approximation scheme for multigraph edge coloring.	Peter Sanders,David Steurer	2005	The edge coloring problem considers the assignment of colors from a minimum number of colors to edges of a graph such that no two edges with the same color are incident to the same node. We give polynomial time algorithms for approximate edge coloring of multigraphs, that is, parallel edges are allowed. The best previous algorithms achieve a fixed constant approximation factor plus a small additive offset. One of our algorithms achieves solution quality opt &plus; &sqrt;9opt/2 and has execution time polynomial in the number of nodes and the logarithm of the maximum edge multiplicity.
SODA	Distributed online call control on general networks.	Harald Räcke,Adi Rosén	2005	"We study the problem of online call admission and routing (""call control"") on general networks. We give new algorithms that with high probability achieve a poly-logarithmic fraction (in the size of the network) of the optimal solution. The decisions of our algorithms do not depend on the current load of all network links, as in previous algorithms for general network topologies [AAP93]. Instead, their admission decisions depend only on link loads along a single path between the communicating parties, and they can thus be performed in a distributed hop-by-hop manner through the network. Furthemore, our algorithms can handle concurrent requests in the network."
SODA	The interface between computational and combinatorial geometry.	Micha Sharir	2005	We illustrate the rich interface between computational and combinatorial geometry by a series of examples, including k-sets, randomized incremental algorithms, random sampling and partitioning, and analysis of geometric arrangements.
SODA	Ray shooting amid balls, farthest point from a line, and range emptiness searching.	Micha Sharir,Hayim Shaul	2005	"In the range emptiness searching problem, we are given a set P of n points in Rd, and wish to preprocess them into a data structure that supports efficient range emptiness queries, in which we specify a range &sigma;, which is a semi-algebraic set in Rd of some fixed kind, and wish to determine whether P &cap; &sigma; = &theta;. Range emptiness searching arises in many applications, and has been treated by Matou&scaron;ek [15] in the special case where the ranges are halfspaces bounded by hyperplanes. In this paper we extend the analysis to the general semi-algebraic case, and show how to adapt Matou&scaron;ek's technique to this case, without the need to linearize the ranges into a higher-dimensional space. This yields more efficient solutions to several interesting problems, and we demonstrate the new technique in two applications:(i) An algorithm for ray shooting amid balls in R3, which uses O* (n) storage and preprocessing, and answers a query in O* (n2/3) time, improving the previous bound of O* (n3/47).(ii) An algorithm that preprocesses, in O*(n) time, a set P of n points in R3 into a data structure with O*(n) storage, so that, for any query line l or segment e, the point of P farthest from l or from e can be computed in O* (n1/2) time.Our technique is closely related to the notions of nearest- or farthest-neighbor generalized Voronoi diagrams, and of the union or intersection of geometric objects, where sharper bounds on the combinatorial complexity of these structures yield faster range emptiness searching algorithms. For example, in the case of ray shooting amid balls, the structure that arises in our algorithm is the Euclidean Voronoi diagram of lines in 3-space, and the performance of the algorithm depends on the complexity of such diagrams (for which tight bounds are still unknown)."
SODA	Strictly convex drawings of planar graphs.	Günter Rote	2005	Every three-connected planar graph with n vertices has a drawing on an O(n7/3) &times; O(n7/3) grid in which all faces are strictly convex polygons.
SODA	Distributed approaches to triangulation and embedding.	Aleksandrs Slivkins	2005	"A number of recent papers in the networking community study the distance matrix defined by the node-to-node latencies in the Internet and, in particular, provide a number of quite successful distributed approaches that embed this distance into a low-dimensional Euclidean space. In such algorithms it is feasible to measure distances among only a linear or near-linear number of node pairs; the rest of the distances are simply not available. Moreover, for applications it is desirable to spread the load evenly among the participating nodes. Indeed, several recent studies use this 'fully distributed' approach and achieve, empirically, a low distortion for all but a small fraction of node pairs.This is concurrent with the large body of theoretical work on metric embeddings, but there is a fundamental distinction: in the theoretical approaches to metric embeddings, full and centralized access to the distance matrix is assumed and heavily used. In this paper we present the first fully distributed embedding algorithm with provable distortion guarantees for doubling metrics (which have been proposed as a reasonable abstraction of Internet latencies), thus providing some insight into the empirical success of the recent Vivaldi algorithm [5]. The main ingredient of our embedding algorithm is an improved fully distributed algorithm for a more basic problem of triangulation, where the triangle inequality is used to infer the distances that have not been measured; this problem received a considerable attention in the networking community, and has also been studied theoretically in [19].We use our techniques to extend &isin;-relaxed embeddings and triangulations to infinite metrics and arbitrary measures, and to improve on the approximate distance labeling scheme of Talwar [33]."
SODA	Theory of semidefinite programming for sensor network localization.	Anthony Man-Cho So,Yinyu Ye	2005	We analyze the semidefinite programming (SDP) based model and method for the position estimation problem in sensor network localization and other Euclidean distance geometry applications. We use SDP duality and interior-point algorithm theories to prove that the SDP localizes any network or graph that has unique sensor positions to fit given distance measures. Therefore, we show, for the first time, that these networks can be localized in polynomial time. We also give a simple and efficient criterion for checking whether a given instance of the localization problem has a unique realization in $$\mathcal{R}^2$$ using graph rigidity theory. Finally, we introduce a notion called strong localizability and show that the SDP model will identify all strongly localizable sub-networks in the input network.
SODA	Partial covering of hypergraphs.	Özgür Sümer	2005	Partial covering of hypergraphs.
SODA	Self-adjusting top trees.	Robert Endre Tarjan,Renato Fonseca F. Werneck	2005	"The dynamic trees problem is that of maintaining a forest that changes over time through edge insertions and deletions. We can associate data with vertices or edges, and manipulate this data individually or in bulk, with operations that deal with whole paths or trees. Efficient solutions to this problem have numerous applications, particularly in algorithms for network flows and dynamic graphs in general. Several data structures capable of logarithmic-time dynamic tree operations have been proposed. The first was Sleator and Tarjan's ST-tree [16, 17], which represents a partition of the tree into paths. Although reasonably fast in practice, adapting ST-trees to different applications is nontrivial. Topology trees [9], top trees [3], and RC-trees [1] are based on tree contractions: they progressively combine vertices or edges to obtain a hierarchical representation of the tree. This approach is more flexible in theory, but all known implementations assume the trees have bounded degree; arbitrary trees are supported only after ternarization. We show how these two approaches can be combined (with very little overhead) to produce a data structure that is as generic as any other, very easy to adapt, and as practical as ST-trees."
SODA	Primal-dual approach for directed vertex connectivity augmentation and generalizations.	László A. Végh,András A. Benczúr	2005	"In their seminal paper, Frank and Jord&aacute;n &lsqb;1995&rsqb; show that a large class of optimization problems, including certain directed graph augmentation, fall into the class of covering supermodular functions over pairs of sets. They also give an algorithm for such problems, however, it relies on the ellipsoid method. Prior to our result, combinatorial algorithms existed only for the 0--1 valued problem. Our key result is a combinatorial algorithm for the general problem that includes directed vertex or S&minus;T connectivity augmentation. The algorithm is based on Bencz&uacute;r's previous algorithm for the 0--1 valued case &lsqb;Bencz&uacute;r 2003&rsqb;. Our algorithm uses a primal-dual scheme for finding covers of partially ordered sets that satisfy natural abstract properties as in Frank and Jord&aacute;n. For an initial (possibly greedy) cover, the algorithm searches for witnesses for the necessity of each element in the cover. If no two (weighted) witnesses have a common cover, the solution is optimal. As long as this is not the case, the witnesses are gradually exchanged for smaller ones. Each witness change defines an appropriate change in the solution; these changes are finally unwound in a shortest-path manner to obtain a solution of size one less."
SODA	Proceedings of the Sixteenth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2005, Vancouver, British Columbia, Canada, January 23-25, 2005		2005	Proceedings of the Sixteenth Annual ACM-SIAM Symposium on Discrete Algorithms, SODA 2005, Vancouver, British Columbia, Canada, January 23-25, 2005
STOC	Representing hard lattices with O(n log n) bits.	Miklós Ajtai	2005	We present a variant of the Ajtai-Dwork public-key cryptosystem where the size of the public-key is only O(nlog n) bits and the encrypted text/clear text ratio is also O(nlog n). This is true with the assumption that all of the participants in the cryptosystem share O(n2log n) random bits which has to be picked only once and the users of the cryptosystem get them e.g. together with the software implementing the protocol. The public key is a random lattice with an nc-unique nonzero shortest vector, where the constant c>1‾2 can be picked arbitrarily close to 1‾2, and we pick the lattice according to a distribution described in the paper. We do not prove a worst-case average-case equivalence but the security of the system follows from the hardness of a randomized diophantine approximation problem related to a well-known theorem of Dirichlet.
STOC	The complexity of agreement.	Scott Aaronson	2005	"A celebrated 1976 theorem of Aumann asserts that Bayesian agents with common priors can never ""agree to disagree"": if their opinions about any topic are common knowledge, then those opinions must be equal. But two key questions went unaddressed: first, can the agents reach agreement after a conversation of reasonable length? Second, can the computations needed for that conversation be performed efficiently? This paper answers both questions in the affirmative, thereby strengthening Aumann's original conclusion.We show that for two agents with a common prior to agree within ε about the expectation of a [0,1] variable with high probability over their prior, it suffices for them to exchange O(1/ε2) bits. This bound is completely independent of the number of bits n of relevant knowledge that the agents have. We also extend the bound to three or more agents; and we give an example where the ""standard protocol"" (which consists of repeatedly announcing one's current expectation) nearly saturates the bound, while a new ""attenuated protocol"" does better. Finally, we give a protocol that would cause two Bayesians to agree within ε after exchanging O(1/ε2) messages, and that can be simulated by agents with limited computational resources. By this we mean that, after examining the agents' knowledge and a transcript of their conversation, no one would be able to distinguish the agents from perfect Bayesians. The time used by the simulation procedure is exponential in 1/ε6 but not in n."
STOC	On the bias of traceroute sampling: or, power-law degree distributions in regular graphs.	Dimitris Achlioptas,Aaron Clauset,David Kempe,Cristopher Moore	2005	"Understanding the graph structure of the Internet is a crucial step for building accurate network models and designing efficient algorithms for Internet applications. Yet, obtaining this graph structure can be a surprisingly difficult task, as edges cannot be explicitly queried. For instance, empirical studies of the network of Internet Protocol (IP) addresses typically rely on indirect methods like traceroute to build what are approximately single-source, all-destinations, shortest-path trees. These trees only sample a fraction of the network's edges, and a paper by Lakhina et al. [2003] found empirically that the resulting sample is intrinsically biased. Further, in simulations, they observed that the degree distribution under traceroute sampling exhibits a power law even when the underlying degree distribution is Poisson. In this article, we study the bias of traceroute sampling mathematically and, for a very general class of underlying degree distributions, explicitly calculate the distribution that will be observed. As example applications of our machinery, we prove that traceroute sampling finds power-law degree distributions in both &delta;-regular and Poisson-distributed random graphs. Thus, our work puts the observations of Lakhina et al. on a rigorous footing, and extends them to nearly arbitrary degree distributions."
STOC	Lower bounds for k-DNF resolution on random 3-CNFs.	Michael Alekhnovich	2005	We prove exponential lower bounds for the refutation of a random 3-CNF with linear number of clauses by k-DNF Resolution for k ≤ √ log n ⁄ log log n. For this we design a specially tailored random restrictions that preserve the structure of the input random 3-CNF while mapping every k-DNF with large covering number to 1 with high probability. Next we make use of the switching lemma for small restrictions by Segerlind, Buss and Impagliazzo to prove the lower bound.This work improves the previously known lower bound for Res(2) system on random 3-CNFs by Atserias, Bonet and Esteban and the result of Segerlind, Buss, Impagliazzo stating that random O(k2)-CNF do not possess short Res(k) refutations.
STOC	Towards asymptotic optimality in probabilistic packet marking.	Micah Adler,Jeff Edmonds,Jirí Matousek	2005	There has been considerable recent interest in probabilistic packet marking schemes for sending information from nodes (routers) along one or more paths traveled by a stream of packets to the end-host receiving that stream. A central consideration for such schemes is the tradeoff between the number B of possible states of the marking bits in a packet, the number of bits n of information being sent by the nodes, and the expected number of packets T required to reconstruct this information. For the case where the packets all travel along the same path, we prove a lower bound of T ≥ Ω(B22n/(B-1)), roughly the square of an earlier lower bound of Adler.For an upper bound, we consider a model where each of m nodes along a single path must send one of s possible messages (thus n = m log2 s total bits are sent). We prove that T ≤ O(m • 22m(log2 s)/(B-1)) suffices (the implicit constant depends on B and s); this almost matches the lower bound, and is roughly the square root of an earlier upper bound of Adler. The new bound holds for all B and s in two slightly relaxed models, while under the strictest requirements we prove it only for some special values of B and s. This is related to a challenging geometric problem: the existence of an s-reptile (B-1)-dimensional simplex, i.e. a simplex S that can be tiled by s congruent simplices similar to S.We also consider the case where the packets travel along multiple paths to the same destination. In this case, we present a new protocol and analysis technique that together allow us to significantly generalize over previous work the scenarios where the protocol is effective.
STOC	Towards strong nonapproximability results in the Lovasz-Schrijver hierarchy.	Michael Alekhnovich,Sanjeev Arora,Iannis Tourlakis	2005	Lovász and Schrijver described a generic method of tightening the LP and SDP relaxation for any 0-1 optimization problem. These tightened relaxations were the basis of several celebrated approximation algorithms (such as for max-cu , max-3sat, and sparsest cut).We prove strong inapproximability results in this model for well-known problems such as max-3sat, hypergraph vertex cover and set cover. We show that the relaxations produced by as many as Ω(n) rounds of the LS+ procedure do not allow nontrivial approximation, thus ruling out the possibility that the LS+ approach gives even slightly subexponential approximation algorithms for these problems.We also point out why our results are somewhat incomparable to known inapproximability results proved using PCPs, and formalize several interesting open questions.
STOC	O(sqrt(log n)) approximation algorithms for min UnCut, min 2CNF deletion, and directed cut problems.	Amit Agarwal,Moses Charikar,Konstantin Makarychev,Yury Makarychev	2005	O(sqrt(log n)) approximation algorithms for min UnCut, min 2CNF deletion, and directed cut problems.
STOC	Quadratic forms on graphs.	Noga Alon,Konstantin Makarychev,Yury Makarychev,Assaf Naor	2005	We introduce a new graph parameter, called the Grothendieck constant of a graph G=(V,E), which is defined as the least constant K such that for every A:E→R,supf:V→S|V|-1 Σ(u,v) ∈ E A(u,v) · ‹f(u),f(v)› ≤ K supf:V→(-1,+1) Σ(u,v)∈ E A(u,v) · f(u)f(v).The classical Grothendieck inequality corresponds to the case of bipartite graphs, but the case of general graphs is shown to have various algorithmic applications. Indeed, our work is motivated by the algorithmic problem of maximizing the quadratic form ∑u,v∈EA(u,v)f(vover all f: V →-1,1, which arises in the study of correlation clustering and in the investigation of the spin glass model. We give upper and lower estimates for the integrality gap of this program. We show that the integrality gap is O(log θḠ)) where θ(Ḡ) is the Lovász Theta Function of the complement of G, which is always smaller than the chromatic number of G. This yields an efficient constant factor approximation algorithm for the above maximization problem for a wide range of graphs G. We also show that the maximum possible integrality gap is always at least Ω(log ω(G)), where Ω(G) is the clique number of G. In particular it follows that the maximum possible integrality gap for the complete graph on n Θ vertices with no loops is ⏷(log n ). More generally, the maximum possible integrality gap for any perfect graph with chromatic number n is ⏷(log n). The lower bound for the complete graph improves a result of Kashin and Szarek on Gram matrices of uniformly bounded functions, and settles a problem of Megretski and of Charikar and Wirth.
STOC	Derandomization of auctions.	Gagan Aggarwal,Amos Fiat,Andrew V. Goldberg,Jason D. Hartline,Nicole Immorlica,Madhu Sudan	2005	We study the problem of designing seller-optimal auctions, i.e. auctions where the objective is to maximize revenue. Prior to this work, the only auctions known to be approximately optimal in the worst case employed randomization. Our main result is the existence of deterministic auctions that approximately match the performance guarantees of these randomized auctions. We give a fairly general derandomization technique for turning any randomized mechanism into an asymmetric deterministic one with approximately the same revenue. In doing so, we bypass the impossibility result for symmetric deterministic auctions and show that asymmetry is nearly as powerful as randomization for solving optimal mechanism design problems. Our general construction involves solving an exponential-sized flow problem and thus is not polynomial-time computable. To complete the picture, we give an explicit polynomial-time construction for derandomizing a specific auction with good worst-case revenue. Our results are based on toy problems that have a flavor similar to the hat problem from [3].
STOC	Every monotone graph property is testable.	Noga Alon,Asaf Shapira	2005	"A graph property is called monotone if it is closed under taking (not necessarily induced) subgraphs (or, equivalently, if it is closed under removal of edges and vertices). Many monotone graph properties are some of the most well-studied properties in graph theory, and the abstract family of all monotone graph properties was also extensively studied. Our main result in this paper is that any monotone graph property can be tested with one-sided error, and with query complexity depending only on ε. This result unifies several previous results in the area of property testing, and also implies the testability of well-studied graph properties that were previously not known to be testable. At the heart of the proof is an application of a variant of Szemerédi's Regularity Lemma. The main ideas behind this application may be useful in characterizing all testable graph properties, and in generally studying graph property testing.As a byproduct of our techniques we also obtain additional results in graph theory and property testing, which are of independent interest. One of these results is that the query complexity of testing testable graph properties with one-sided error may be arbitrarily large. Another result, which significantly extends previous results in extremal graph-theory, is that for any monotone graph property P, any graph that is ε -far from satisfying P, contains a subgraph of size depending on ε only, which does not satisfy P. Finally, we prove the following compactness statement: If a graph G is ε-far from satisfying a (possibly infinite) set of graph properties P, then it is at least δ P ε-far from satisfying one of the properties."
STOC	Covert two-party computation.	Luis von Ahn,Nicholas J. Hopper,John Langford	2005	"We introduce covert two-party computation, a stronger notion of security than standard secure two-party computation. Like standard secure two-party computation, covert two-party computation allows Alice and Bob, with secret inputs xA and xB respectively, to compute a function f(xA,xB) without leaking any additional information about their inputs. In addition, covert two-party computation guarantees that even the existence of a computation is hidden from all protocol participants unless the value of the function mandates otherwise. This allows the construction of protocols that return f(xA,xB) only when it equals a certain value of interest (such as ""Yes, we are romantically interested in each other"") but for which neither party can determine whether the other even ran the protocol whenever f(xA,xB) is not a value of interest. Since existing techniques for secure function evaluation always reveal that both parties participate in the computation, covert computation requires the introduction of new techniques based on provably secure steganography. We introduce security definitions for covert two-party computation and show that this surprising notion can be achieved by a protocol given the Decisional Diffie-Hellman assumption in the ""honest but curious"" model. Using this protocol as a subroutine, we present another protocol which is fair and secure against malicious adversaries in the Random Oracle Model --- unlike most other protocols against malicious adversaries, this protocol does not rely on zero-knowledge proofs (or similar cut-and-choose techniques), because they inherently reveal that a computation took place. We remark that all our protocols are of comparable efficiency to protocols for standard secure two-party computation."
STOC	Aggregating inconsistent information: ranking and clustering.	Nir Ailon,Moses Charikar,Alantha Newman	2005	We address optimization problems in which we are given contradictory pieces of input information and the goal is to find a globally consistent solution that minimizes the number of disagreements with the respective inputs. Specifically, the problems we address are rank aggregation, the feedback arc set problem on tournaments, and correlation and consensus clustering. We show that for all these problems (and various weighted versions of them), we can obtain improved approximation factors using essentially the same remarkably simple algorithm. Additionally, we almost settle a long-standing conjecture of Bang-Jensen and Thomassen and show that unless NP⊆BPP, there is no polynomial time algorithm for the problem of minimum feedback arc set in tournaments.
STOC	Hardness of the undirected edge-disjoint paths problem.	Matthew Andrews,Lisa Zhang	2005	We show that there is no log 1 over 3-ε M approximation for the undirected Edge-Disjoint Paths problem unless NP ⊆ ZPTIME(npolylog(n), where M is the size of the graph and ε is any positive constant. This hardness result also applies to the undirected All-or-Nothing Multicommodity Flow problem and the undirected Node-Disjoint Paths problem.
STOC	Hardness of the undirected congestion minimization problem.	Matthew Andrews,Lisa Zhang	2005	We show that there is no $\gamma\log\log M/\log\log\log M$-approximation for the undirected congestion minimization problem unless $NP \subseteq ZPTIME(n^{{\rm polylog} n})$, where $M$ is the size of the graph and &ggr; is some positive constant.
STOC	Euclidean distortion and the sparsest cut.	Sanjeev Arora,James R. Lee,Assaf Naor	2005	We prove that every n-point metric space of negative type (in particular, every n-point subset of L1) embeds into a Euclidean space with distortion O(√log n log log n), a result which is tight up to the O(log log n) factor. As a consequence, we obtain the best known polynomial-time approximation algorithm for the Sparsest Cut problem with general demands. If the demand is supported on a subset of size k, we achieve an approximation ratio of O(√log k log log k).
STOC	Large the price of routing unsplittable flow.	Baruch Awerbuch,Yossi Azar,Amir Epstein	2005	"The essence of the routing problem in real networks is that the traffic demand from a source to destination must be satisfied by choosing a single path between source and destination. The splittable version of this problem is when demand can be satisfied by many paths, namely a flow from source to destination. The unsplittable, or discrete version of the problem is more realistic yet is more complex from the algorithmic point of view; in some settings optimizing such unsplittable traffic flow is computationally intractable.In this paper, we assume this more realistic unsplittable model, and investigate the ""price of anarchy"", or deterioration of network performance measured in total traffic latency under the selfish user behavior. We show that for linear edge latency functions the price of anarchy is exactly $2.618 for weighted demand and exactly $2.5 for unweighted demand. These results are easily extended to (weighted or unweighted) atomic ""congestion games"", where paths are replaced by general subsets. We also show that for polynomials of degree d edge latency functions the price of anarchy is dδ(d). Our results hold also for mixed strategies.Previous results of Roughgarden and Tardos showed that for linear edge latency functions the price of anarchy is exactly 4/3 under the assumption that each user controls only a negligible fraction of the overall traffic (this result also holds for the splittable case). Note that under the assumption of negligible traffic pure and mixed strategies are equivalent and also splittable and unsplittable models are equivalent."
STOC	Convex programming for scheduling unrelated parallel machines.	Yossi Azar,Amir Epstein	2005	We consider the classical problem of scheduling parallel unrelated machines. Each job is to be processed by exactly one machine. Processing job j on machine i requires time pij. The goal is to find a schedule that minimizes the lp norm. Previous work showed a 2-approximation algorithm for the problem with respect to the l∞ norm. For any fixed lp norm the previously known approximation algorithm has a performance of θ(p). We provide a 2-approximation algorithm for any fixed lp norm (p>1). This algorithm uses convex programming relaxation. We also give a √ 2-approximation algorithm for the l2 norm. This algorithm relies on convex quadratic programming relaxation. To the best of our knowledge, this is the first time that general convex programming techniques (apart from SDPs and CQPs) are used in the area of scheduling. We show for any given lp norm a PTAS for any fixed number of machines. We also consider the multidimensional generalization of the problem in which the jobs are d-dimensional. Here the goal is to minimize the lp norm of the generalized load vector, which is a matrix where the rows represent the machines and the columns represent the jobs dimension. For this problem we give a (d+1)-approximation algorithm for any fixed lp norm (p>1).
STOC	Low-distortion embeddings of general metrics into the line.	Mihai Badoiu,Julia Chuzhoy,Piotr Indyk,Anastasios Sidiropoulos	2005	"A low-distortion embedding between two metric spaces is a mapping which preserves the distances between each pair of points, up to a small factor called distortion. Low-distortion embeddings have recently found numerous applications in computer science.Most of the known embedding results are ""absolute"",that is, of the form: any metric Y from a given class of metrics C can be embedded into a metric X with low distortion c. This is beneficial if one can guarantee low distortion for all metrics Y in C. However, in any situations, the worst-case distortion is too large to be meaningful. For example, if X is a line metric, then even very simple metrics (an n - point star or an n -point cycle) are embeddable into X only with distortion linear in n. Nevertheless, embeddings into the line (or into low-dimensional spaces) are important for many applications.A solution to this issue is to consider ""relative"" (or ""approximation"") embedding problems, where the goal is to design an (a-approxiation) algorithm which, given any metric X from C as an input, finds an embedding of X into Y which has distortion a *cY (X), where cY (X)is the best possible distortion of an embedding of X into Y.In this paper we show algorithms and hardness results for relative embedding problems.In particular we give: •an algorith that, given a general metric M, finds an embedding with distortion O (Δ3⁄4 poly(c line (M))), where Δ is the spread of M•an algorithm that,given a weighted tree etric M, finds an embedding with distortion poly(c line (M)) •a hardness result, showing that computing minimum line distortion is hard to approximate up to a factor polynomial in n,even for weighted tree metrics with spread Δ=n O (1)."
STOC	Simulating independence: new constructions of condensers, ramsey graphs, dispersers, and extractors.	Boaz Barak,Guy Kindler,Ronen Shaltiel,Benny Sudakov,Avi Wigderson	2005	A distribution X over binary strings of length n has min-entropy k if every string has probability at most 2-k in X. We say that X is a δ-source if its rate k⁄n is at least δ.We give the following new explicit instructions (namely, poly(n)- time computable functions) of deterministicextractors, dispersers and related objects. All work for any fixed rate δ>0. No previous explicit construction was known for either of these, for any δ‹1⁄2. The first two constitute major progress to very long-standing open problems. Bipartite Ramsey f1: (0,1)n)2 →0,1, such that for any two independent δ-sources X1, X2 we have f1(X1,X2) = 0,1 This implies a new explicit construction of 2N-vertex bipartite graphs where no induced Nδ by Nδ subgraph is complete or empty. Multiple source extraction f2: (0,1n)3→0,1 such that for any three independent δ-sources X1,X2,X3 we have that f2(X1,X2,X3) is (o(1)-close to being) an unbiased random bit. Constant seed condenser2 f3: n →(0,1m)c, such that for any δ-source X, one of the c output distributions f3(X)i, is a 0.9-source over 0,1m. Here c is a constant depending only on δ.Subspace Ramsey f4: 0,1n→0,1 such that for any affine-δ-source3 X we have f4(X)= 0,1.The constructions are quite involved and use as building blocks other new and known gadgets. But we can point out two important themes which recur in these constructions. One is that gadgets which were designed to work with independent inputs, sometimes perform well enough with correlated, high entropy inputs. The second is using the input to (introspectively) find high entropy regions within itself.
STOC	Polynomial time algorithm for computing the top Betti numbers of semi-algebraic sets defined by quadratic inequalities.	Saugata Basu	2005	For any fixed l > 0, we present an algorithm which takes as input a semi-algebraic set, S, defined by P1 ≥ 0,...,Ps ≥ 0, where each Pi ∈ R[X1,...,Xk] has degree ≤ 2, and computes the top l Betti numbers of S, bk-1(S), ..., bk-l(S), in polynomial time. The complexity of the algorithm, stated more precisely, is Σi=0l+2 (si k2O((l,s)). For fixed l, the complexity of the algorithm can be expressed as sl+2 k2O(l), which is polynomial in the input parameters s and k. To our knowledge this is the first polynomial time algorithm for computing non-trivial topological invariants of semi-algebraic sets in Rk defined by polynomial inequalities, where the number of inequalities is not fixed and the polynomials are allowed to have degree greater than one. For fixed s, we obtain by letting l = k, an algorithm for computing all the Betti numbers of S whose complexity is k2O(s)
STOC	Computing the first Betti number and the connected components of semi-algebraic sets.	Saugata Basu,Richard Pollack,Marie-Françoise Roy	2005	In this paper we describe the first singly exponential algorithm for computing the first Betti number of a given semi-algebraic set. We also describe algorithms for obtaining semi-algebraic descriptions of the semi-algebraically connected components of any given real algebraic or semi-algebraic set. Singly exponential algorithms for computing the zero-th Betti number, and the Euler-Poincaré characteristic, were known before. No singly exponential algorithm was known for computing any of the individual Betti numbers other than the zero-th one.
STOC	Fast quantum byzantine agreement.	Michael Ben-Or,Avinatan Hassidim	2005	We present a fast quantum Byzantine Agreement protocol that can reach agreement in O(1) expected communication rounds against a strong full information, dynamic adversary, tolerating up to the optimal t‹n3 faulty players in the synchronous setting, and up to t‹n4 faulty players for asynchronous systems. This should be contrasted with the known classical synchronous lower bound of Ω(√ nlog n) [3] when t=(n).
STOC	Simple PCPs with poly-log rate and query complexity.	Eli Ben-Sasson,Madhu Sudan	2005	"We give constructions of probabilistically checkable proofs (PCPs) of length n . poly(log n) (to prove satisfiability of circuits of size n) that can verified by querying poly(log n) bits of the proof. We also give constructions of locally testable codes (LTCs) with similar parameters.Previous constructions of short PCPs (from [5]to [9]) relied extensively on properties of low degree multi-variate polynomials. In contrast, our constructions rely on new problems and techniques revolving around the properties of codes based on high degree polynomials in one variable (also known as Reed-Solomon codes). We show how to convert the problem of verifying the satisfaction of a circuit by a given assignment to the task of verifying that a given function is close to being a Reed-Solomon codeword, i.e., a univariate polynomial of specified degree. This reduction is simpler than the corresponding steps in previous reductions, and gives a new alternative to using the popular ""sum-check protocol"". We then give a new PCP for the special task of proving that a function is close to being a Reed-Solomon codeword. This step of the construction is by a self-contained recursion, and the only ingredient needed in the analysis is the bi-variate low-degree test of Polischuk and Spielman[27].Note that our constructions yield LTCs first, which are then converted to PCPs. In contrast, most recent constructions go in the opposite (and less natural) direction of getting LTCs from PCPs."
STOC	Balanced boolean functions that can be evaluated so that every input bit is unlikely to be read.	Itai Benjamini,Oded Schramm,David Bruce Wilson	2005	A Boolean function of n bits is balanced if it takes the value 1 with probability 1⁄2. We exhibit a balanced Boolean function with a randomized evaluation procedure (with probability 0 of making a mistake) so that on uniformly random inputs, no input bit is read with probability more than Θ(n-1/2√ log n). We construct a balanced monotone Boolean function and a randomized algorithm computing it for which each bit is read with probability Θ(n-1⁄3 log n). We then show that for any randomized algorithm for evaluating a balanced Boolean function, when the input bits are uniformly random, there is some input bit that is read with probability at least Θ(n-1䊪). For balanced monotone Boolean functions, there is some input bit that is read with probability at least Θ(n-1䊫).
STOC	Pseudorandom generators for low degree polynomials.	Andrej Bogdanov	2005	"We investigate constructions of pseudorandom generators that fool polynomial tests of degree d in m variables over finite fields F. Our main construction gives a generator with seed length O(d4 log m (1 + log(d ⁄ ε) ⁄ log log m) + log |F|) bits that achieves arbitrarily small bias ε and works whenever |F| is at least polynomial in d, log m, and 1⁄ε. We also present an alternate construction that uses a seed that can be described by O(c2d8m6⁄(c-2) log(d⁄ε) + log |F|) bits (more precisely, O(c2d8m6⁄(c-2)) field elements, each chosen from a set of size poly(cd⁄ε), plus two field elements ranging over all of F), works whenever |F| is at least polynomial in c, d, and 1⁄ε, and has the property that every element of the output is a function of at most c field elements in the input. Both generators are computable by small arithmetic circuits. The main tool used in the construction is a reduction that allows us to transform any ""dense"" hitting set generator for polynomials into a pseudorandom generator."
STOC	Tree-walking automata do not recognize all regular languages.	Mikolaj Bojanczyk,Thomas Colcombet	2005	Tree-walking automata are a natural sequential model for recognizing tree languages. Every tree language recognized by a tree-walking automaton is regular. In this paper, we present a tree language which is regular but not recognized by any (nondeterministic) tree-walking automaton. This settles a conjecture of Engelfriet, Hoogeboom and Van Best. Moreover, the separating tree language is definable already in first-order logic over a signature containing the left-son, right-son and ancestor relations.
STOC	Approximation techniques for utilitarian mechanism design.	Patrick Briest,Piotr Krysta,Berthold Vöcking	2005	This paper deals with the design of efficiently computable incentive compatible, or truthful, mechanisms for combinatorial optimization problems with multi-parameter agents. We focus on approximation algorithms for NP-hard mechanism design problems. These algorithms need to satisfy certain monotonicity properties to ensure truthfulness. Since most of the known approximation techniques do not fulfill these properties, we study alternative techniques.Our first contribution is a quite general method to transform a pseudopolynomial algorithm into a monotone FPTAS. This can be applied to various problems like, e.g., knapsack, constrained shortest path, or job scheduling with deadlines. For example, the monotone FPTAS for the knapsack problem gives a very efficient, truthful mechanism for single-minded multi-unit auctions. The best previous result for such auctions was a 2-approximation. In addition, we present a monotone PTAS for the generalized assignment problem with any bounded number of parameters per agent.The most efficient way to solve packing integer programs (PIPs) is LP-based randomized rounding, which also is in general not monotone. We show that primal-dual greedy algorithms achieve almost the same approximation ratios for PIPs as randomized rounding. The advantage is that these algorithms are inherently monotone. This way, we can significantly improve the approximation ratios of truthful mechanisms for various fundamental mechanism design problems like single-minded combinatorial auctions (CAs), unsplittable flow routing and multicast routing. Our approximation algorithms can also be used for the winner determination in CAs with general bidders specifying their bids through an oracle.
STOC	On non-uniform multicommodity buy-at-bulk network design.	Moses Charikar,Adriana Karagiozova	2005	We study the multicommodity buy-at-bulk network design problem in which we seek to design a network that satisfies the demands between terminals from a given set of source-sink pairs. The key characteristic of this problem is the fact that the cost functions associated with the edges of the graph are sub-additive monotone and hence experience economies of scale. In the non-uniform case, each edge has its own cost function -- possibly different from other edges. Special cases of this problem have been studied extensively: there are approximation algorithms when the edge cost functions are identical or when all source-sink pairs share the same source. We present the first non-trivial approximation algorithm for the general case. Our algorithm is an extremely simple randomized greedy algorithm and has an approximation guarantee of exp(O√ln n ln ln n)) when the instance has at most n source-sink pairs with unit demands. In the case of general demands, this yields an approximation factor of exp(O √ln N ln ln N)), where N is the sum of all demands.
STOC	Multicommodity flow, well-linked terminals, and routing problems.	Chandra Chekuri,Sanjeev Khanna,F. Bruce Shepherd	2005	"We study multicommodity routing problems in both edge and node capacitated undirected graphs. The input to each problem is a capacitated graph G=(V,E) and a set Τ of node pairs. In the simplest setting, the goal is to route a unit of flow for as many pairs as possible subject to the edge (node) capacity constraints. If the flow for a routed pair is required to be along a single path, it is the well-studied disjoint paths problem. If we allow fractional routings of the flow, it is known as the all-or-nothing flow problem. The nodes in Τ are referred to as terminals.In recent work [8,9], the authors obtained the first poly-logarithmic approximation algorithms for some edge routing problems. A key idea in these algorithms is to decompose an instance into a collection of instances in which the terminals are well-linked. Informally speaking, a set of nodes is well-linked in a graph if it does not have small separators. A decomposition into well-linked instances was previously achieved in [8] via räcke's hierarchical graph decomposition for oblivious routing [32]. In this paper, we design a simple new decomposition algorithm that is based on computing sparse cuts in a graph. Our new algorithm improves the earlier results for edge routing problems. Another important advantage of the algorithm is that it also applies to node-capacitated problems. We note that for oblivious routing with node capacities, an Ω√n) lower bound is known on the congestion [18], and hence the oblivious routing approach cannot yield poly-logarithmic bounds for well-linked decompositions. Using the new decomposition, we obtain a poly-logarithmic approximation for the node capacitated all-or-nothing flow problem in general graphs and node-disjoint path problem in planar graphs with O(1) congestion. We also show that the flow-cut gap for product multicommodity flows in node capacitated planar graphs is O(1), improving upon the O(log n) bound from [28]."
STOC	On algorithms for discrete and approximate brouwer fixed points.	Xi Chen,Xiaotie Deng	2005	We study the algorithmic complexity of the discrete fixed point problem and develop an asymptotic matching bound for a cube in any constantly bounded finite dimension. To obtain our upper bound, we derive a new fixed point theorem, based on a novel characterization of boundary conditions for the existence of fixed points.In addition, exploring a linkage with the approximation problem of the continuous fixed point problem, we obtain asymptotic matching bounds for complexity of the approximate Brouwer fixed point problem in the continuous case for Lipschitz functions that close a previous exponential gap. It settles a fifteen years old open problem of Hirsch, Papadimitriou and Vavasis by improving both the upper and lower bounds.Our new characterization for existence of a fixed point is also applicable to functions defined on non-convex domain and makes it a potentially useful tool for design and analysis of algorithms for fixed points in general domain.
STOC	Approximation algorithms for network design with metric costs.	Joseph Cheriyan,Adrian Vetta	2005	We study undirected networks with edge costs that satisfy the triangle inequality. Let $n$ denote the number of nodes. We present an $O(1)$-approximation algorithm for a generalization of the metric-cost subset $k$-node-connectivity problem. Our approximation guarantee is proved via lower bounds that apply to the simple edge-connectivity version of the problem, where the requirements are for edge-disjoint paths rather than for openly node-disjoint paths. A corollary is that, for metric costs and for each $k=1,2,\dots,n-1$, there exists a $k$-node connected graph whose cost is within a factor of ${ 22\/}$ of the cost of any simple $k$-edge connected graph. Based on our $O(1)$-approximation algorithm, we present an $O(\log r_{\max})$-approximation algorithm for the metric-cost node-connectivity survivable network design problem, where $r_{\max}$ denotes the maximum requirement over all pairs of nodes. Our results contrast with the case of edge costs of 0 or 1, where Kortsarz, Krauthgamer, and Lee. [SIAM J. Comput., 33 (2004), pp. 704-720] recently proved, assuming NP$\nsubseteq\;$DTIME($n^{polylog(n)}$), a hardness-of-approximation lower bound of $2^{\log^{1-\epsilon}n}$ for the subset $k$-node-connectivity problem, where $\epsilon$ denotes a small positive number.
STOC	Cooperative asynchronous update of shared memory.	Bogdan S. Chlebus,Dariusz R. Kowalski	2005	The Write-All problem for an asynchronous shared-memory system has the objective for the processes to update the contents of a set of shared registers, while minimizing the total number of read and write operations. First abstracted by Kanellakis and Shvartsman [12], Write-All is among the standard problems in distributed computing. The model consists of $n$ asynchronous processes and n registers, where every process can read and write to any register. Processes may fail by crashing. The most efficient previously known deterministic algorithm performs O(n1+ε) reads and writes, for an arbitrary fixed constant ε>0, and is due to Anderson and Woll [4]. This paper presents a new deterministic algorithm that performs O(n polylog n) read/write operations, thus improving the best previously known upper bound from polynomial to polylogarithmic in the average number of read/write operations per process. Using an approach to store and retrieve information about progress made in auxiliary registers, the novelty of the new algorithm is in using a family of multi-partite graphs with expansion properties to structure a set of registers as a graph and then have each asynchronous process explore a part of the graph according to its pattern of traversals. An explicit instantiation of our Write-All algorithm, based on best-known polynomial-time constructions of lossless expanders and a-expanding graphs, performs n • 2O(log3 log n) reads and writes. In this explicit solution to Write-All, the processes perform asymptotically less read/write operations than the most efficient non-explicit solution known before.
STOC	The price of anarchy of finite congestion games.	George Christodoulou,Elias Koutsoupias	2005	We consider the price of anarchy of pure Nash equilibria in congestion games with linear latency functions. For asymmetric games, the price of anarchy of maximum social cost is Θ(√N), where N is the number of players. For all other cases of symmetric or asymmetric games and for both maximum and average social cost, the price of anarchy is 5/2. We extend the results to latency functions that are polynomials of bounded degree. We also extend some of the results to mixed Nash equilibria.
STOC	A new strategy for querying priced information.	Ferdinando Cicalese,Eduardo Sany Laber	2005	This paper focuses on competitive function evaluation in the context of computing with priced information. A function f is given together with a cost cx for each variable x of f. The cost cx has to be paid to read the value of x. The problem is to design algorithms that query the values of the variables sequentially in order to compute the function while trying to minimize the total cost incurred. Competitive analysis is employed to evaluate the performance of the algorithms. We describe a novel approach for devising efficient algorithms in this setting. We apply our approach to several classes of functions which have been studied in the literature of computing with priced information. In all cases considered, our approach provides algorithms that achieve better bounds than the best known algorithm for the same class of functions.More precisely, for the class of monotone boolean functions, we give a polynomial time algorithm with extremal competitiveness (k+l - √ min(k,l)) where k (l) denotes the minimum number of variables that one must read, in the worst case, in order to prove that the function under consideration evaluates to 1 (0). This dramatically improves upon the best known result which is an exponential time 2 max(k, l)-competitive algorithm. For the subclass of monotone boolean functions known as Threshold Trees we further improve our bounds and give a polynomial time algorithm with extremal competitive ratio 1.618 max(k, l).We then apply our methodology to classes of non-boolean functions. We consider the case of the so called Game Trees. We improve upon previously published results for this class of functions providing a polynomial time algorithm with extremal competitive ratio 1.5 γ(f), where γ(f) is a lower bound on the extremal competitive ratio of any deterministic algorithm.Finally, we consider the case when f is the function min (minimum). In this case, we are able to determine the optimal competitiveness for the problem. In fact we provide an algorithm with an (n-2)-competitive ratio, which matches the known lower bound.
STOC	Market equilibrium via the excess demand function.	Bruno Codenotti,Benton McCune,Kasturi R. Varadarajan	2005	"We consider the problem of computing market equilibria and show three results. (i) For exchange economies satisfying weak gross substitutability we analyze a simple discrete version of tâtonnement, and prove that it converges to an approximate equilibrium in polynomial time. This is the first polynomial-time approximation scheme based on a simple atonnement process. It was only recently shown, using vastly more sophisticated techniques, that an approximate equilibrium for this class of economies is computable in polynomial time. (ii) For Fisher's model, we extend the frontier of tractability by developing a polynomial-time algorithm that applies well beyond the homothetic case and the gross substitutes case. (iii) For production economies, we obtain the first polynomial-time algorithms for computing an approximate equilibrium when the consumers' side of the economy satisfies weak gross substitutability and the producers' side is restricted to positive production."
STOC	Approximately counting integral flows and cell-bounded contingency tables.	Mary Cryan,Martin E. Dyer,Dana Randall	2005	We consider the problem of approximately counting integral flows in a network. We show that there is an fpras based on volume estimation if all capacities are sufficiently large, generalising a result of Dyer, Kannan and Mount (1997). We apply this to approximating the number of contingency tables with prescribed cell bounds when the number of rows is constant, but the row sums, column sums and cell bounds may be arbitrary. We provide an fpras for this problem via a combination of dynamic programming and volume estimation. This generalises an algorithm of Cryan and Dyer (2002) for standard contingency tables, but the analysis here is considerably more intricate.
STOC	Approximation algorithms for combinatorial auctions with complement-free bidders.	Shahar Dobzinski,Noam Nisan,Michael Schapira	2005	"We exhibit three approximation algorithms for the allocation problem in combinatorial auctions with complement free bidders. The running time of these algorithms is polynomial in the number of items $m$ and in the number of bidders n, even though the ""input size"" is exponential in m. The first algorithm provides an O(log m) approximation. The second algorithm provides an O(√ m) approximation in the weaker model of value oracles. This algorithm is also incentive compatible. The third algorithm provides an improved 2-approximation for the more restricted case of ""XOS bidders"", a class which strictly contains submodular bidders. We also prove lower bounds on the possible approximations achievable for these classes of bidders. These bounds are not tight and we leave the gaps as open problems."
STOC	Correcting errors without leaking partial information.	Yevgeniy Dodis,Adam Smith	2005	"This paper explores what kinds of information two parties must communicate in order to correct errors which occur in a shared secret string W. Any bits they communicate must leak a significant amount of information about W --- that is, from the adversary's point of view, the entropy of W will drop significantly. Nevertheless, we construct schemes with which Alice and Bob can prevent an adversary from learning any useful information about W. Specifically, if the entropy of W is sufficiently high, then there is no function f(W) which the adversary can learn from the error-correction information with significant probability.This leads to several new results: (a) the design of noise-tolerant ""perfectly one-way"" hash functions in the sense of Canetti et al. [7], which in turn leads to obfuscation of proximity queries for high entropy secrets W; (b) private fuzzy extractors [11], which allow one to extract uniformly random bits from noisy and nonuniform data W, while also insuring that no sensitive information about W is leaked; and (c) noise tolerance and stateless key re-use in the Bounded Storage Model, resolving the main open problem of Ding [10].The heart of our constructions is the design of strong randomness extractors with the property that the source W can be recovered from the extracted randomness and any string W' which is close to W."
STOC	Locally decodable codes with 2 queries and polynomial identity testing for depth 3 circuits.	Zeev Dvir,Amir Shpilka	2005	In this work we study two, seemingly unrelated, notions. Locally Decodable Codes (LDCs) are codes that allow the recovery of each message bit from a constant number of entries of the codeword. Polynomial Identity Testing (PIT) is one of the fundamental problems of algebraic complexity: we are given a circuit computing a multivariate polynomial and we have to determine whether the polynomial is identically zero. We improve known results on locally decodable codes and on polynomial identity testing and show a relation between the two notions. In particular we obtain the following results:We show that if E: Fn → Fm is a linear LDC with 2 queries then m = exp(Ω(n)). Previously this was only known for fields of size << 2n [18].We show that from every depth 3 arithmetic circuit (ΣΠΣ circuit), C, with a bounded (constant) top fan-in that computes the zero polynomial, one can construct a locally decodeable code. More formally: Assume that C is minimal (no subset of the multiplication gates sums to zero) and simple (no linear function appears in all the multiplication gates). Denote by d the degree of the polynomial computed by C and by r the rank of the linear functions appearing in C. Then we can construct a linear LDC with 2 queries, that encodes messages of length r/polylog(d) by codewords of length O(d).We prove a structural theorem for ΣΠΣ circuits, with a bounded top fan-in, that compute the zero polynomial. In particular we show that if such a circuit is simple and minimal and of polynomial size then its rank, r, is only polylogarithmic in the number of variables (a priory it could have been linear).We give new PIT algorithms for ΣΠΣ circuits with a bounded top fan-in:A deterministic algorithm that runs in quasi polynomial time.A randomized algorithm that runs in polynomial time and uses only polylogarithmic number of random bits..Moreover, when the circuit is multilinear our deterministic algorithm runs in polynomial time. Previously, deterministic subexponential time algorithms for PIT in bounded depth circuits were known only for depth 2 circuits (in the black box model)[22, 9, 28]. In particular, for the special case of depth 3 circuits with 3 multiplication gates our result resolves an open question asked by Klivans and Spielman [28].
STOC	Lower-stretch spanning trees.	Michael Elkin,Yuval Emek,Daniel A. Spielman,Shang-Hua Teng	2005	We show that every weighted connected graph G contains as a subgraph a spanning tree into which the edges of G can be embedded with average stretch O (log2 n log log n). Moreover, we show that this tree can be constructed in time O (m log2n) in general, and in time O (mlog n) if the input graph is unweighted. The main ingredient in our construction is a novel graph decomposition technique.Our new algorithm can be immediately used to improve the running time of the recent solver for symmetric diagonally dominant linear systems of Spielman and Teng from m2(O√lognlog log n) to m log O(1)n and to O (n log2n log log n) when the system is planar. Our result can also be used to improve several earlier approximation algorithms that use low-stretch spanning trees.
STOC	Improved approximation algorithms for minimum-weight vertex separators.	Uriel Feige,Mohammad Taghi Hajiaghayi,James R. Lee	2005	We develop the algorithmic theory of vertex separators, and its relation to the embeddings of certain metric spaces. Unlike in the edge case, we show that embeddings into L1 (and even Euclidean embeddings) are insufficient, but that the additional structure provided by many embedding theorems does suffice for our purposes.We obtain an O(√log n) approximation for min-ratio vertex cuts in general graphs, based on a new semidefinite relaxation of the problem, and a tight analysis of the integrality gap which is shown to be Θ(√log n). We also prove various approximate max-flow/min-vertex-cut theorems, which in particular give a constant-factor approximation for min-ratio vertex cuts in any excluded-minor family of graphs. Previously, this was known only for planar graphs, and for general excluded-minor families the best-known ratio was O(log n).These results have a number of applications. We exhibit an O(√log n) pseudo-approximation for finding balanced vertex separators in general graphs. In fact, we achieve an approximation ratio of O(√log opt) where opt is the size of an optimal separator, improving over the previous best bound of O(log opt). Likewise, we obtain improved approximation ratios for treewidth: In any graph of treewidth k, we show how to find a tree decomposition of width at most O(k √log k), whereas previous algorithms yielded O(k log k). For graphs excluding a fixed graph as a minor (which includes, e.g., bounded genus graphs), we give a constant-factor approximation for the treewidth; this can be used to obtain the first polynomial-time approximation schemes for problems like minimum feedback vertex set and minimum connected dominating set in such graphs.
STOC	Testing versus estimation of graph properties.	Eldar Fischer,Ilan Newman	2005	"Tolerant testing is an emerging topic in the field of property testing, which was defined in [M. Parnas, D. Ron, and R. Rubinfeld, J. Comput. System Sci., 72 (2006), pp. 1012-1042] and has recently become a very active topic of research. In the general setting, there exist properties that are testable but are not tolerantly testable [E. Fischer and L. Fortnow, Proceedings of the $20$th IEEE Conference on Computational Complexity, 2005, pp. 135-140]. On the other hand, we show here that in the setting of the dense graph model, all testable properties are not only tolerantly testable (which was already implicitly proved in [N. Alon, E. Fischer, M. Krivelevich, and M. Szegedy, Combinatorica, 20 (2000), pp. 451-476] and [O. Goldreich and L. Trevisan, Random Structures Algorithms, 23 (2003), pp. 23-57]), but also admit a constant query size algorithm that estimates the distance from the property up to any fixed additive constant. In the course of the proof we develop a framework for extending Szemer&eacute;di's regularity lemma, both as a prerequisite for formulating what kind of information about the input graph will provide us with the correct estimation, and as the means for efficiently gathering this information. In particular, we construct a probabilistic algorithm that finds the parameters of a regular partition of an input graph using a constant number of queries, and an algorithm to find a regular partition of a graph using a $\mathrm{TC}_0$ circuit. This, in some ways, strengthens the results of [N. Alon, R. A. Duke, H. Lefmann, V. R&ouml;dl, and R. Yuster, J. Algorithms, 16 (1994), pp. 80-109]."
STOC	On the average case performance of some greedy approximation algorithms for the uncapacitated facility location problem.	Abraham Flaxman,Alan M. Frieze,Juan Carlos Vera	2005	In combinatorial optimization, a popular approach toNP-hard problems is the design of approximation algorithms. These algorithms typically run in polynomial time and are guaranteed to produce a solution which is within a known multiplicative factor of optimal. Unfortunately, the known factor is often known to be large in pathological instances. Conventional wisdom holds that, in practice, approximation algorithms will produce solutions closer to optimal than their proven guarantees. In this paper, we use the rigorous-analysis-of-heuristics framework to investigate this conventional wisdom.We analyze the performance of 3 related approximation algorithms for the uncapacitated facility location problem (from [Jain, Mahdian, Markakis, Saberi, Vazirani, 2003] and [Mahdian, Ye, Zhang, 2002]) when each is applied to an instances created by placing n points uniformly at random in the unit square. We find that, with high probability, these 3 algorithms do not find asymptotically optimal solutions, and, also with high probability, a simple plane partitioning heuristic does find an asymptotically optimal solution.
STOC	Beyond NP: the work and legacy of Larry Stockmeyer.	Lance Fortnow	2005	Shortly after Steve Cook and Richard Karp showed the ex-istence of many natural NP-complete languages, researchers started to realize the great importance of the P versus NP problem and the difficulty of settling it. One graduate student at the Massachusetts Institute of Technology started to look beyond NP, asking what problems have a higher complexity and how do we classify them. Larry Stockmeyer discovered an amazing structure of complexity classes that continues to direct the research in complexity to this day. Stockmeyer passed away on July 31, 2004 at the age of 55 and in this paper we review some of his research and the legacy he has left on the community.
STOC	Hierarchies for semantic classes.	Lance Fortnow,Rahul Santhanam,Luca Trevisan	2005	"We show that for any constant a, ZPP/b(n) strictly contains ZPTIME(na)/b(n) for some b(n) = O(log n log log n). Our techniques are very general and give the same hierarchy for all common semantic time classes including RTIME, NTIME ∩ coNTIME, UTIME, MATIME, AMTIME and BQTIME.We show a stronger hierarchy for RTIME: For every constant c, RP/1 is not contained in RTIME(nc)/(log n)1/2c. To prove this result we first prove a similar statement for NP by building on Zák's proof of the nondeterministic time hierarchy."
STOC	Coresets in dynamic geometric data streams.	Gereon Frahling,Christian Sohler	2005	A dynamic geometric data stream consists of a sequence of m insert/delete operations of points from the discrete space 1,…,Δd [26]. We develop streaming (1 + ε)-approximation algorithms for k-median, k-means, MaxCut, maximum weighted matching (MaxWM), maximum travelling salesperson (MaxTSP), maximum spanning tree (MaxST), and average distance over dynamic geometric data streams. Our algorithms maintain a small weighted set of points(a coreset) that approximates with probability 2/3 the current point set with respect to the considered problem during the m insert/delete operations of the data stream. They use poly (ε-1, log m, log Δ) space and update time per insert/delete operation for constant k and dimension dHaving a coreset one only needs a fast approximation algorithm for the weighted problem to compute a solution quickly. In fact, even an exponential algorithm is sometimes feasible as its running time may still be polynomial in n. For example one can compute in poly(log n, exp(O((1+log (1⁄ε)⁄ε)d-1))) time a solution to k-median and k-means [21] where n is the size of the current point set and k and d are constants. Finding an implicit solution to MaxCut can be done in poly(log n, exp((1⁄ε)O(1))) time. For MaxST and average distance we require poly(log n, ε-1) time and for MaxWM we require O(n3) time to do this.
STOC	Efficient testing of groups.	Katalin Friedl,Gábor Ivanyos,Miklos Santha	2005	We construct an efficient probabilistic algorithm that, given a finite set with a binary operation, tests if it is an abelian group. The distance used is an analogue of the edit distance for strings. The query complexity of the tester is polylogarithmic in the size of the set. Previous testers used Hamming type distances and had superlinear query complexity. A building block for our construction is a constant query complexity homomorphism tester for functions mapping an given finite group into an arbitrary set equipped with a binary operation.
STOC	From a static impossibility to an adaptive lower bound: the complexity of early deciding set agreement.	Eli Gafni,Rachid Guerraoui,Bastian Pochon	2005	Set agreement, where processors decisions constitute a set of outputs, is notoriously harder to analyze than consensus where the decisions are restricted to a single output. This is because the topological questions that underly set agreement are not about simple connectivity as in consensus. Analyzing set agreement inspired the discovery of the relation between topology and distributed algorithms, and consequently the impossibility of asynchronous set agreement.Yet, the application of topological reasoning has been to the static case, that of asynchronous and synchronous tasks. It is not known yet for example, how to characterize starvation-free solvability of non-terminating tasks. Non-terminating tasks are dynamic entities with no defined end. In a similar vain, early deciding synchronous set agreement, in which the number of rounds it takes a processor to decide adapts to the actual number of failures, falls in this category of dynamic entities.This paper develops a simulation technique that brings to bear topological results to deal with the dynamic situation that arises with early decisions. The novelty of the new simulation is the ability of simulators to look back at the transcript of past rounds of the simulation to influence their current behavior.Using our new technique, we not only re-derive past results, but we propose and prove a lower bound to synchronous early stopping set agreement. We then provide an algorithm to match the lower bound. Our technique uses the BG simulation, in the most creative way it was used to-date, to obtain a rather simple reduction from a static asynchronous impossibility. This reduction is a simple alternative to yet unknown topological argument, and in fact may suggest the way of finding such an argument.
STOC	Saving an epsilon: a 2-approximation for the k-MST problem in graphs.	Naveen Garg	2005	We present a polynomial time 2-approximation algorithm for the problem of finding the minimum tree that spans at least k vertices. Our result also leads to a 2-approximation algorithm for finding the minimum tour that visits k vertices and to a 3-approximation algorithm for the problem of finding the maximum number of vertices that can be spanned by a tree of length at most a given bound.
STOC	Edge partition of planar sraphs into two outerplanar graphs.	Daniel Gonçalves	2005	An outerplanar graph is a planar graph that can be embedded in the plane without crossing edges, in such a way that all the vertices are on the outer boundary. In this paper, we prove a conjecture of Chartrand, Geller, and Hedetniemi that any planar graph G=(V,E) has a bipartition of its edge set E = A ∪ B such that the graphs induced by these subsets, G[A] and G[B], are outerplanar.
STOC	Limits to list decoding Reed-Solomon codes.	Venkatesan Guruswami,Atri Rudra	2005	"In this paper, we prove the following two results that expose some combinatorial limitations to list decoding Reed-Solomon codes.Given n distinct elements α1,...,αn from a field F, and n subsets S1,...,Sn of F each of size at most l, the list decoding algorithm of Guruswami and Sudan [7] can in polynomial time output all polynomials p of degree at most k which satisfy p(αi) ∈ Si for every i, as long as l < ⌈ n/k ⌉. We show that the performance of this algorithm is the best possible in a strong sense; specifically, we show that when l = ⌈ n/k ⌉, the list of output polynomials can be super-polynomially large in n. One way to interpret our result is the following. The algorithm in [7] can, when given as input $n'$ distinct pairs (βi,∈i) ∈ F2 (the βi's need not be distinct), find and output all degree k polynomials p such that p(βi) = γi for at least $t$ values of i, provided t > √k n'. By our result, an improvement to the Reed-Solomon list decoder of [7] that works with slightly smaller agreement, say t > √kn' - k/2, can only be obtained by exploiting some property of the βi's (for example, their (near) distinctness).For Reed-Solomon codes of block length $n$ and dimension k where k = nδ for small enough δ, we exhibit an explicit received word r with a super-polynomial number of Reed-Solomon codewords that agree with it on $(2 - ε) k locations, for any desired ε > 0 (we note agreement of k is trivial to achieve). Such a bound was known earlier only for a non-explicit center. We remark that finding explicit bad list decoding configurations is of significant interest --- for example the best known rate vs. distance trade-off is based on a bad list decoding configuration for algebraic-geometric codes [14] which is unfortunately not explicitly known."
STOC	Oblivious routing in directed graphs with random demands.	Mohammad Taghi Hajiaghayi,Jeong Han Kim,Tom Leighton,Harald Räcke	2005	Oblivious routing algorithms for general undirected networks were introduced by Räcke, and this work has led to many subsequent improvements and applications. More precisely, Räcke showed that there is an oblivious routing algorithm with polylogarithmic competitive ratio (w.r.t. edge congestion) for any undirected graph. Comparatively little positive results are known about oblivious routing in general directed networks. Using a novel approach, we present the first oblivious routing algorithm which is O(log2 n) competitive with high probability in directed graphs given that the demands are chosen randomly from a known demand-distribution. On the other hand, we show that no oblivious routing algorithm can be o(logn/log log n) competitive even with constant probability in general directed graphs.Our routing algorithms are not oblivious in the traditional definition, but we add the concept of demand-dependence, i.e., the path chosen for an s-t pair may depend on the demand between s and t. This concept that still preserves that routing decisions are only based on local information proves very powerful in our randomized demand model.Finally, we show that our approach for designing competitive oblivious routing algorithms is quite general and has applications in other contexts like stochastic scheduling.
STOC	Fast quantum algorithms for computing the unit group and class group of a number field.	Sean Hallgren	2005	"Computing the unit group and class group of a number field are two of the main tasks in computational algebraic number theory. Factoring integers reduces to solving Pell's equation, which is a special case of computing the unit group, but a reduction in the other direction is not known and appears more difficult. We give polynomial-time quantum algorithms for computing the unit group and class group when the number field has constant degree."
STOC	Every 2-CSP allows nontrivial approximation.	Johan Håstad	2005	We use semidefinite programming to prove that any constraint satisfaction problem in two variables over any domain allows an efficient approximation algorithm that does provably better than picking a random assignment. To be more precise assume that each variable can take values in [d] and that each constraint rejects t out of the d2 possible input pairs. Then, for some universal constant c, we can, in probabilistic polynomial time, find an assignment whose objective value is, on expectation, within a factor (1- t/d2(1- c/d2 log d)) of optimal.
STOC	Key agreement from weak bit agreement.	Thomas Holenstein	2005	"Assume that Alice and Bob, given an authentic channel, have a protocol where they end up with a bit SA and SB, respectively, such that with probability 1+ε/2 these bits are equal. Further assume that conditioned on the event SA =n SB no polynomial time bounded algorithm can predict the bit better than with probability 1-δ/2. Is it possible to obtain key agreement from such a primitive? We show that for constant δ and ε the answer is yes if and only if δ > 1-ε/1+ε, both for uniform and non-uniform adversaries.The main computational technique used in this paper is a strengthening of Impagliazzo's hard-core lemma to the uniform case and to a set size parameter which is tight (i.e., twice the original size). This may be of independent interest."
STOC	Optimal approximations of the frequency moments of data streams.	Piotr Indyk,David P. Woodruff	2005	We give a 1-pass Õ(m1-2⁄k)-space algorithm for computing the k-th frequency moment of a data stream for any real k > 2. Together with the lower bounds of [1, 2, 4], this resolves the main problem left open by Alon et al in 1996 [1]. Our algorithm also works for streams with deletions and thus gives an Õ(m 1-2⁄p) space algorithm for the Lp difference problem for any p > 2. This essentially matches the known Ω(m1-2⁄p-o(1)) lower bound of [12, 2]. Finally the update time of our algorithms is Õ(1).
STOC	On strip packing With rotations.	Klaus Jansen,Rob van Stee	2005	We present an asymptotic fully polynomial time approximation scheme for two-dimensional strip packing with rotations. In this problem, a set of rectangles need to be packed into a rectangle (strip) of fixed width and minimum height, and these rectangles can be rotated by 90°. Additionally, we present a simple asymptotic polynomial time approximation scheme, and give an improved algorithm for two-dimensional bin packing with rotations.
STOC	An optimal multi-writer snapshot algorithm.	Prasad Jayanti	2005	"An m-component, n-process snapshot object is an abstraction of shared memory that consists of m words and allows up to n processes to concurrently execute the following two types of operations: write(i,v), which writes v into the ith word, and scan(), which returns the current values of all m locations [1, 3]. The snapshot problem is to design algorithms for the write and scan operations that meet two challenging requirements: (1) operations appear to be atomic, and (2) operations are wait-freeFor any (m-component, n-process) snapshot algorithm, which runs on hardware that supports only word-sized objects, Ω(1) and Ω(m) are trivial lower bounds on the time complexity of write(i,v) and scan(), respectively. But, are these bounds tight?For a restricted version of the snapshot problem, known in the literature as the single-writer snapshot problem, Riany, Shavit and Touitou [18] showed that the answer is yes: they designed an algorithm with O(1) and O(m) running times for the write(i,v) and scan() operations, respectively. (The single-writer snapshot problem assumes that (i) the number m of words of the snapshot object is equal to the number n of processes, and (ii) only the ith process may write into the ith snapshot word.This paper shows that the same (optimal) running times of O(1) for write(i,v) and O(m) for scan() are achievable for the general problem, known in the literature as the multiwriter snapshot problem. Our algorithm requires hardware support for the CAS (compare&swap) operation (in comparison, Riany, Shavit and Touitou's algorithm requires hardware support for CAS, fetch&inc, and fetch&dec operations)."
STOC	Universal approximations for TSP, Steiner tree, and set cover.	Lujun Jia,Guolong Lin,Guevara Noubir,Rajmohan Rajaraman,Ravi Sundaram	2005	We introduce a notion of universality in the context of optimization problems with partial information. Universality is a framework for dealing with uncertainty by guaranteeing a certain quality of goodness for all possible completions of the partial information set. Universal variants of optimization problems can be defined that are both natural and well-motivated. We consider universal versions of three classical problems: TSP, Steiner Tree and Set Cover.We present a polynomial-time algorithm to find a universal tour on a given metric space over n vertices such that for any subset of the vertices, the sub-tour induced by the subset is within O(log4n/log log n) of an optimal tour for the subset. Similarly, we show that given a metric space over n vertices and a root vertex, we can find a universal spanning tree such that for any subset of vertices containing the root, the sub-tree induced by the subset is within O(log4n/log log n) of an optimal Steiner tree for the subset. Our algorithms rely on a new notion of sparse partitions, that may be of independent interest. For the special case of doubling metrics, which includes both constant-dimensional Euclidean and growth-restricted metrics, our algorithms achieve an O(log n) upper bound. We complement our results for the universal Steiner tree problem with a lower bound of Ω(log n/log log n) that holds even for n vertices on the plane. We also show that a slight generalization of the universal Steiner Tree problem is coNP-hard and present nearly tight upper and lower bounds for a universal version of Set Cover.
STOC	Concurrent general composition of secure protocols in the timing model.	Yael Tauman Kalai,Yehuda Lindell,Manoj Prabhakaran	2005	"In the setting of secure multiparty computation, a set of mutually distrustful parties wish to jointly compute some function of their input (i.e., they wish to securely carry out some distributed task). %The joint computation should be such that even In the stand-alone case, it has been shown that every efficient function can be securely computed. However, in the setting of concurrent composition, broad impossibility results have been proven for the case where there is no honest majority (or trusted setup).In this paper, we investigate the feasibility of obtaining secure multiparty protocols in a network where certain time bounds are assumed. Specifically, the security of our protocols rely on the very reasonable assumption that local clocks do not ""drift"" too much (i.e., it is assumed that they proceed at approximately the same rate). We show that under this mild timing assumption, it is possible to securely compute any functionality under concurrent general composition (as long as messages from the arbitrary other protocols are delayed for a specified amount of time)."
STOC	Learning with attribute costs.	Haim Kaplan,Eyal Kushilevitz,Yishay Mansour	2005	"We study an extension of the ""standard"" learning models to settings where observing the value of an attribute has an associated cost (which might be different for different attributes). Our model assumes that the correct classification is given by some target function f from a class of functions cal F; most of our results discuss the ability to learn a clause (an OR function of a subset of the variables) in various settings:Offline: We are given both the function f and the distribution D that is used to generate an input x. The goal is to design a strategy to decide what attribute of x to observe next so as to minimize the expected evaluation cost of f(x). (In this setting there is no ""learning"" to be done but only an optimization problem to be solved; this problem to be NP-hard and hence approximation algorithms are presented.)Distributional online: We study two types of ""learning"" problems; one where the target function f is known to the learner but the distribution D is unknown (and the goal is to minimize the expected cost including the cost that stems from ""learning"" D), and the other where f is unknown (except that f∈cal F) but D is known (and the goal is to minimize the expected cost while limiting the prediction error involved in ""learning"" f).Adversarial online: We are given f, however the inputs are selected adversarially. The goal is to compare the learner's cost to that of the best fixed evaluation order (i.e., we analyze the learner's performance by a competitive analysis)."
STOC	Bounded-depth circuits: separating wires from gates.	Michal Koucký,Pavel Pudlák,Denis Thérien	2005	We develop a new method to analyze the flow of communication in constant-depth circuits. This point of view allows usto prove new lower bounds on the number of wires required to recognize certain languages. We are able to provide explicit languages that can be recognized by AC0 circuits with O(n) gates but not with O(n) wires, and similarly for ACC0 circuits. We are also able to characterize exactly the regular languages that can be recognized with O(n) wires, both in AC0 and ACC0 framework.
STOC	Collusion-free protocols.	Matt Lepinski,Silvio Micali,Abhi Shelat	2005	Secure protocols attempt to minimize the injuries to privacy and correctness inflicted by malicious participants who collude during run-time. They do not, however, prevent malicious parties from colluding and coordinating their actions in the first place!Eliminating such collusion of malicious parties during the execution of a protocol is an important and exciting direction for research in Cryptography. We contribute the first general result in this direction: (1) We provide a rigorous definition of what a collusion-free protocol is; and (2) We prove that, under standard physical and computational assumptions ---i.e., plain envelopes and trapdoor permutations---collusion-free protocols exist for all finite protocol tasks with publicly observable actions. (Note that such tasks are allowed to have secret global state, and thus include Poker, Bridge, and other such games.Our solution is tight in the sense that, for a collusion-free protocol to exist, each of (a) the finiteness of the game of interest, (b) the public observability of its actions, and (c) the use of some type of physically private channel is provably essential.
STOC	The mixing time of the Thorp shuffle.	Ben Morris	2005	The Thorp shuffle is defined as follows. Cut the deck into two equal piles. Drop the first card from the left pile or the right pile according to the outcome of a fair coin flip; then drop from the other pile. Continue this way until both piles are empty. We show that the mixing time for the Thorp shuffle with 2d cards is polynomial in d.
STOC	On dynamic range reporting in one dimension.	Christian Worm Mortensen,Rasmus Pagh,Mihai Patrascu	2005	"We consider the problem of maintaining a dynamic set of integers and answering queries of the form: report a point (equivalently, all points) in a given interval. Range searching is a natural and fundamental variant of integer search, and can be solved using predecessor search. However, for a RAM with w-bit words, we show how to perform updates in O(lg w) time and answer queries in O(lg lg w) time. The update time is identical to the van Emde Boas structure, but the query time is exponentially faster. Existing lower bounds show that achieving our query time for predecessor search requires doubly-exponentially slower updates. We present some arguments supporting the conjecture that our solution is optimal.Our solution is based on a new and interesting recursion idea which is ""more extreme"" that the van Emde Boas recursion. Whereas van Emde Boas uses a simple recursion (repeated halving) on each path in a trie, we use a nontrivial, van Emde Boas-like recursion on every such path. Despite this, our algorithm is quite clean when seen from the right angle. To achieve linear space for our data structure, we solve a problem which is of independent interest. We develop the first scheme for dynamic perfect hashing requiring sublinear space. This gives a dynamic Bloomier filter (a storage scheme for sparse vectors) which uses low space. We strengthen previous lower bounds to show that these results are optimal."
STOC	Learning nonsingular phylogenies and hidden Markov models.	Elchanan Mossel,Sébastien Roch	2005	In this paper, we study the problem of learning phylogenies and hidden Markov models. We call a Markov model nonsingular if all transition matrices have determinants bounded away from 0 (and 1). We highlight the role of the nonsingularity condition for the learning problem. Learning hidden Markov models without the nonsingularity condition is at least as hard as learning parity with noise. On the other hand, we give a polynomial-time algorithm for learning nonsingular phylogenies and hidden Markov models.
STOC	Balanced metric labeling.	Joseph Naor,Roy Schwartz	2005	We define the balanced metric labeling problem, a generalization of the metric labeling problem, in which each label has a capacity, i.e., at most l vertices can be assigned to it. The balanced metric labeling problem is a generalization of fundamental problems in the area of approximation algorithms, e.g., arrangements and balanced partitions of graphs. It is also motivated by resource limitations in certain practical scenarios. We focus on the case where the given metric is uniform and note that this case alone encompasses various well-known graph partitioning problems. We present the first (pseudo) approximation algorithm for this problem, achieving for any ε, 0 < ε < 1, an approximation factor of O((ln n)/ε), while assigning at most min {O(ln k)/1 - ε, l + 1| ( 1 + ε) l vertices to each label (k is the number of labels). Our approximation algorithm is based on a novel randomized rounding of a linear programming formulation that combines an embedding of the graph in a simplex together with spreading metrics and additional constraints that strengthen the formulation. Our randomized rounding technique uses both a randomized metric decomposition technique and a randomized label assignment technique. At the heart of our approach is the fact that only limited dependency is created between the labels assigned to different vertices, allowing us to bound the expected cost of the solution and the number of vertices assigned to each label, simultaneously. We note that the number of vertices assigned to each label is bounded via a new inequality of Janson[15] for tail bounds of (partly) dependent random variables.
STOC	Low distortion embeddings for edit distance.	Rafail Ostrovsky,Yuval Rabani	2005	We show that 0,1d endowed with edit distance embeds into l1 with distortion 2O(√log dlog log d). We further show efficient implementations of the embedding that yield solutions to various computational problems involving edit distance. These include sketching, communication complexity, nearest neighbor search. For all these problems, we improve upon previous bounds.
STOC	New and improved constructions of non-malleable cryptographic protocols.	Rafael Pass,Alon Rosen	2005	We present a new constant round protocol for non-malleable zero-knowledge. Using this protocol as a subroutine, we obtain a new constant-round protocol for non-malleable commitments. Our constructions rely on the existence of (standard) collision resistant hash functions. Previous constructions either relied on the existence of trapdoor permutations and hash functions that are collision resistant against sub-exponential sized circuits, or required a super-constant number of rounds.Additional results are the first construction of a non-malleable commitment scheme that is statistically hiding (with respect to opening), and the first non-malleable protocols that satisfy a strict polynomial-time simulation requirement. The latter are constructed by additionally assuming the existence of trapdoor permutations.Our approach differs from the approaches taken in previous works in that we view non-malleable zero-knowledge as a building-block rather than an end goal. This gives rise to a modular construction of non-malleable commitments and results in a somewhat simpler analysis.The techniques that we use to construct our zero-knowl-edge protocol are non black-box, but are different than the non black-box techniques previously used in the context of non-malleable coin-tossing.
STOC	Computing correlated equilibria in multi-player games.	Christos H. Papadimitriou	2005	We develop a polynomial-time algorithm for finding correlated equilibria (a well-studied notion of rationality due to Aumann that generalizes the Nash equilibrium) in a broad class of succinctly representable multiplayer games, encompassing essentially all known kinds, including all graphical games, polymatrix games, congestion games, scheduling games, local effect games, as well as several generalizations. Our algorithm is based on a variant of the existence proof due to Hart and Schmeidler [11], and employs linear programming duality, the ellipsoid algorithm, Markov chain steady state computations, as well as application-specific methods for computing multivariate expectations.
STOC	Extractors with weak random seeds.	Ran Raz	2005	We show how to extract random bits from two or more independent weak random sources in cases where only one source is of linear min-entropy and all other sources are of logarithmic min-entropy. Our main results are as follows: A long line of research, starting by Nisan and Zuckerman[14], gives explicit constructions of seeded-extractors, that is, extractors that use a short seed of truly random bits to extract randomness from a weak random source. For every such extractor E, with seed of length d, we construct an extractor E′, with seed of length d′=O(d), that achieves the same parameters as E but only requires the seed to be of min-entropy larger than (1⁄2+δ) •d′ (rather than fully random), where δ is an arbitrary small constant. Fundamental results of Chor and Goldreich and Vazirani [6,21] show how to extract Ω(n) random bits from two (independent) sources of length n and min-entropy larger than (1⁄2δ) • n, where δ is an arbitrary small constant. We show how to extract Ω(n) random bits (with optimal probability of error) when only one source is of min-entropy (1⁄2+δ) •n and the other source is of logarithmic min entropy.3 A recent breakthrough of Barak, Impagliazzo and Wigderson[4] shows how to extract Ω(n) random bits from a constant number of (independent) sources of length n and min-entropy larger than δ n, where δ is an arbitrary small constant. We show how to extract Ω (n) random bits (with optimal probability of error) when only one source is of min-entropy δ n and all other (constant number of) sources are of logarithmic min-entropy.A very recent result of Barak, Kindler, Shaltiel, Sudakov and Wigderson[5] shows how to extract a constant number of random bits from three (independent) sources of length n and min-entropy larger than δn, where δ is an arbitrary small constant. We show how to extract Ω(n)/ random bits, with sub-constant probability of error, from one source of min-entropy δ n and two sources of logarithmic min-entropy.In the same paper, Barak, Kindler, Shaltiel, Sudakov and Wigderson[5] give an explicit coloring of the complete bipartite graph of size 2n x 2n with two colors, such that there is no monochromatic subgraph of size larger than 2δn x 2 2δn, where δ is an arbitrary small constant. We give an explicit coloring of the complete bipartite graph of size 2n x 2n with a constant number of colors, such that there is no monochromatic subgraph of size larger than 2δn x n5.We also give improved constructions of mergers and condensers. In particular, We show that using a constant number of truly random bits, one can condense a source of length n and min-entropy rate δ into a source of length Ω (n) and min-entropy rate 1-δ, where δ is an arbitrary small constant.We show that using a constant number of truly random bits, one can merge a constant number of sources of length n, such that at least one of them is of min-entropy rate 1-δ, into one source of length Ω(n) and min-entropy rate slightly less than 1-δ, where δ is any small constant.
STOC	On lattices, learning with errors, random linear codes, and cryptography.	Oded Regev	2005	"Our main result is a reduction from worst-case lattice problems such as SVP and SIVP to a certain learning problem. This learning problem is a natural extension of the 'learning from parity with error' problem to higher moduli. It can also be viewed as the problem of decoding from a random linear code. This, we believe, gives a strong indication that these problems are hard. Our reduction, however, is quantum. Hence, an efficient solution to the learning problem implies a quantum algorithm for SVP and SIVP. A main open question is whether this reduction can be made classical.Using the main result, we obtain a public-key cryptosystem whose hardness is based on the worst-case quantum hardness of SVP and SIVP. Previous lattice-based public-key cryptosystems such as the one by Ajtai and Dwork were only based on unique-SVP, a special case of SVP. The new cryptosystem is much more efficient than previous cryptosystems: the public key is of size Õ(n2) and encrypting a message increases its size by Õ(n)(in previous cryptosystems these values are Õ(n4) and Õ(n2), respectively). In fact, under the assumption that all parties share a random bit string of length Õ(n2), the size of the public key can be reduced to Õ(n)."
STOC	Testing monotone high-dimensional distributions.	Ronitt Rubinfeld,Rocco A. Servedio	2005	A monotone distribution P over a (partially) ordered domain has P(y) ≥ P(x) if y ≥ x in the order. We study several natural problems of testing properties of monotone distributions over the n-dimensional Boolean cube, given access to random draws from the distribution being tested. We give a poly(n)-time algorithm for testing whether a monotone distribution is equivalent to or ε-far (in the L1 norm) from the uniform distribution. A key ingredient of the algorithm is a generalization of a known isoperimetric inequality for the Boolean cube. We also introduce a method for proving lower bounds on testing monotone distributions over the n-dimensional Boolean cube, based on a new decomposition technique for monotone distributions. We use this method to show that our uniformity testing algorithm is optimal up to polylog(n) factors, and also to give exponential lower bounds on the complexity of several other problems (testing whether a monotone distribution is identical to or ε-far from a fixed known monotone product distribution and approximating the entropy of an unknown monotone distribution).
STOC	Undirected ST-connectivity in log-space.	Omer Reingold	2005	We present a deterministic, log-space algorithm that solves st-connectivity in undirected graphs. The previous bound on the space complexity of undirected st-connectivity was log4/3 obtained by Armoni, Ta-Shma, Wigderson and Zhou [9]. As undirected st-connectivity is complete for the class of problems solvable by symmetric, non-deterministic, log-space computations (the class SL), this algorithm implies that SL = L (where L is the class of problems solvable by deterministic log-space computations). Independent of our work (and using different techniques), Trifonov [45] has presented an O(log n log log n)-space, deterministic algorithm for undirected st-connectivity.Our algorithm also implies a way to construct in log-space a fixed sequence of directions that guides a deterministic walk through all of the vertices of any connected graph. Specifically, we give log-space constructible universal-traversal sequences for graphs with restricted labelling and log-space constructible universal-exploration sequences for general graphs.
STOC	Spectral norm of random matrices.	Van H. Vu	2005	"In this paper, we present a new upper bound for the spectral norm of symmetric random matrices with independent (but not necessarily identical) entries. Our results improve an earlier result of F&#x00fc;redi and Koml&#x00f3;s."
STOC	On obfuscating point functions.	Hoeteck Wee	2005	"We investigate the possibility of obfuscating point functions in the framework of Barak et al. from Crypto '01. A point function is a Boolean function that assumes the value 1 at exactly one point. Our main results are as follows:We provide a simple construction of efficient obfuscators for point functions for a slightly relaxed notion of obfuscation, for which obfuscating general circuits is nonetheless impossible. Our construction relies on the existence of a very strong one-way permutation, and yields the first non-trivial obfuscator under general assumptions in the standard model. We also obtain obfuscators for point functions with multi-bit output and for prefix matching.Our assumption is that there is a one-way permutation wherein any polynomial-sized circuit inverts the permutation on at most a polynomial number of inputs. We show that a similar assumption is in fact necessary, and that our assumption holds relative to a random permutation oracle.Finally, we establish two impossibility results which indicate that the limitations on our construction, namely simulating only adversaries with single-bit output and using nonuniform advice in our simulator, are in some sense inherent.Previous work gave negative results for the general class of circuits (Barak et al., Crypto '01) and positive results in the random oracle model (Lynn et al., Eurocrypt '04) or under non-standard number-theoretic assumptions (Canetti, Crypto '97). This work represents the first effort to bridge the gap between the two for a natural class of functionalities."
STOC	The round complexity of two-party random selection.	Saurabh Sanghvi,Salil P. Vadhan	2005	"We study the round complexity of two-party protocols for generating a random n-bit string such that the output is guaranteed to have bounded bias (according to some measure) even if one of the two parties deviates from the protocol (even using unlimited computational resources). Specifically, we require that the output's statistical difference from the uniform distribution on zon is bounded by a constant less than 1.We present a protocol for the above problem that has 2 log*n+O(1) rounds, improving a 2n-round protocol that follows from the work of Goldreich, Goldwasser, and Linial (FOCS'91). Like the GGL protocol, our protocol actually provides a stronger guarantee, ensuring that the output lands in any set T⊆zon of density μ with probability at most O(√μ+δ), where δ is an arbitarily small constant.We then prove a matching lower bound, showing that any protocol guaranteeing bounded statistical difference requires at least log*n - log* log*n-O(1) rounds. As far as we know, this is the first nontrivial lower bound on the round complexity of random selection protocols (of any type) that does not impose additional constraints (e.g. on communication or ""simulatability"").We also state several results for the case when the output's bias is measured by the maximum multiplicative factor by which a party can increase the probability of a set T ⊆ zon."
STOC	How to spread adversarial nodes?: rotate!	Christian Scheideler	2005	In this paper we study the problem of how to keep a dynamic system of nodes well-mixed even under adversarial behavior. This problem is very important in the context of distributed systems.More specifically, we consider the following game: There are n white pebbles and ε n black pebbles for some fixed constant ε < 1. Initially, all of the white pebbles are laid down in a ring, and the adversary has all of the black pebbles in its bag. In each round, the adversary can look at the entire ring and can select to add a black pebble to the ring (if its bag is not empty) or to take any black pebble from the ring and put it back into its bag (i.e. we consider adaptive adversaries). However, the adversary cannot place a black pebble into any position it likes. This is handled by a join strategy to be specified by the system. The goal is to find an oblivious join strategy, i.e. a strategy that cannot distinguish between the white and black pebbles in the ring, that integrates the black pebbles into this ring and may do some further rearrangements so that for a polynomial number of rounds the adversary will not manage to include its black pebbles into the ring so that there is a sequence of s=Θ(log n) consecutive pebbles in which at least half of the pebbles are black. If this is achieved by the join strategy, it wins. Otherwise, the adversary wins.Of course, the brute-force strategy of rearranging all of the pebbles in the ring at random after each insertion of a black pebble will achieve the stated goal, with high probability, but this would be a very expensive strategy. The challenge is to find a join strategy that needs as little randomness and as few rearrangements as possible in order to win with high probability. In this paper, we present and analyze a very simple strategy called k-rotation that chooses k-1 existing positions uniformly at random in the ring, creates a new position uniformly at random in the ring, and then rotates the new pebble and the k-1 old pebbles along these positions. Interestingly, even if the adversary has just $s$ pebbles, it can still win for k=2. But the k-rotation rule wins with high probability for k=3 as long as ε<2/3, demonstrating that there is a sharp threshold for keeping pebbles in a sufficiently perturbed state.
STOC	Polynomial time quantum algorithm for the computation of the unit group of a number field.	Arthur Schmidt,Ulrich Vollmer	2005	"We present a quantum algorithm for the computation of the irrational period lattice of a function on Zn which is periodic in a relaxed sense. This algorithm is applied to compute the unit group of finite extensions of Q. Execution time for fixed field degree over Q is polynomial in the discriminant of the field. Our algorithms generalize and improve upon Hallgren's work [9] for the one-dimensional case corresponding to real-quadratic fields."
STOC	On random pm 1 matrices: singularity and determinant.	Terence Tao,Van H. Vu	2005	We proved several results concerning the determinant of a random pm 1 matrix. In particular, we show that with high probability, the determinant has absolute value very close to √n!.
STOC	Tensor norms and the classical communication complexity of nonlocal quantum measurement.	Yaoyun Shi	2005	Nonlocality is at the heart of quantum information processing. In this paper we investigate the minimum amount of classical communication required to simulate a nonlocal quantum measurement. We derive general upper bounds, which in turn translate to systematic classical simulations of quantum communication protocols.As a concrete application, we prove that any quantum communication protocol with shared entanglement for computing a Boolean function can be simulated by a classical protocol whose cost does not depend on the amount of the shared entanglement. This implies that if the cost of communication is a constant, quantum and classical protocols, with shared entanglement and shared coins, respectively, compute the same class of functions.Furthermore, we describe a new class of efficient quantum communication protocols based on fast quantum algorithms. While some of them have efficient classical simulations by our method, others appear to be good candidates for separating quantum v.s. classical protocols, and quantum protocols with v.s. without shared entanglement.Yet another application is in the context of simulating quantum correlations using local hidden variable models augmented with classical communications. We give a constant cost, approximate simulation of quantum correlations when the number of correlated variables is a constant, while the dimension of the entanglement and the number of possible measurements can be arbitrary.Our upper bounds are expressed in terms of some tensor norms on the measurement operator. Those norms capture the nonlocality of bipartite operators in their own way and may be of independent interest and further applications.
STOC	Worst-case update times for fully-dynamic all-pairs shortest paths.	Mikkel Thorup	2005	We present here the first solution to the fully-dynamic all pairs shortest path problem where every update is faster than a recomputation from scratch in Ω(n3log ⁄n) time. This is for a directed graph with arbitrary non-negative edge weights. An update inserts or deletes a vertex with all incident edges. After each such vertex update, we update a complete distance matrix in Õ(n2.75) time.
STOC	On uniform amplification of hardness in NP.	Luca Trevisan	2005	"We continue the study of amplification of average-case complexity within NP, and we focus on the uniform case.We prove that if every problem in NP admits an efficient uniform algorithm that (averaged over random inputs and over the internal coin tosses of the algorithm) succeeds with probability at least 1 ⁄ 2 +1 (log n )α, then for every problem in NP there is an efficient uniform algorithm that succeeds with probability at least 1 - 1 poly(n). Above, α > 0 is an absolute constant.Previously, Trevisan (FOCS'03) presented a similar redution between success 3⁄4 + 1 (log n) and 1 - 1 (log n)α Stronger reductions, due to O'Donnell (STOC'02) and Healy, Vadhan and Viola (FOCS'04) are known in the non-uniform case."
STOC	An O(log n log log n) space algorithm for undirected st-connectivity.	Vladimir Trifonov	2005	We present a deterministic O(log n log log n) space algorithm for undirected st-connectivity. It is based on the deterministic EREW algorithm of Chong and Lam [6] and uses the universal exploration sequences for trees constructed by Koucký [13]. Our result improves the O(log4/3 n) bound of Armoni et al.\ [2] and is a big step towards the optimal O(log n). Independently of our result and using a different set of techniques, the optimal bound was achieved by Reingold [18].
STOC	Tensor decomposition and approximation schemes for constraint satisfaction problems.	Wenceslas Fernandez de la Vega,Marek Karpinski,Ravi Kannan,Santosh Vempala	2005	"The only general class of MAX-rCSP problems for which Polynomial Time Approximation Schemes (PTAS) are known are the dense problems. In this paper, we give PTAS's for a much larger class of weighted MAX-rCSP problems which includes as special cases the dense problems and, for r = 2, all metric instances (where the weights satisfy the triangle inequality) and quasimetric instances; for r > 2, our class includes a generalization of metrics. Our algorithms are based on low-rank approximations with two novel features: (1) a method of approximating a tensor by the sum of a small number of ""rank-1"" tensors, akin to the traditional Singular Value Decomposition (this might be of independent interest) and (2) a simple way of scaling the weights. Besides MAX-rCSP problems, we also give PTAS's for problems with a constant number of global constraints such as maximum weighted graph bisection and some generalizations."
STOC	Proceedings of the 37th Annual ACM Symposium on Theory of Computing, Baltimore, MD, USA, May 22-24, 2005	Harold N. Gabow,Ronald Fagin	2005	Proceedings of the 37th Annual ACM Symposium on Theory of Computing, Baltimore, MD, USA, May 22-24, 2005
